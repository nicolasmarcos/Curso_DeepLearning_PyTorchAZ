{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MEU Projeto #1 Classificação binária breast cancer.ipynb","provenance":[{"file_id":"1mo51K2KJRBOvyK_HE2xWzjelfxbv1vy6","timestamp":1634586062379}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"rD_RSER5Lkb5"},"source":["# Projeto 1: Classificação binária brest cancer"]},{"cell_type":"markdown","metadata":{"id":"5tP2BcEILoLB"},"source":["## Etapa 1: Importação das bibliotecas"]},{"cell_type":"code","metadata":{"id":"B1WlABbCcw2B","executionInfo":{"status":"ok","timestamp":1634668463735,"user_tz":180,"elapsed":1794,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}}},"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, accuracy_score"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"b85d_o8BdFub","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1634668489561,"user_tz":180,"elapsed":25828,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"36a1cf99-3a74-4965-b4b6-c58c5fec59c7"},"source":["import torch\n","torch.__version__\n","#!pip install torch==1.4.0"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.9.0+cu111'"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"UVO3Mj3qdjru","executionInfo":{"status":"ok","timestamp":1634668489562,"user_tz":180,"elapsed":19,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}}},"source":["import torch.nn as nn"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C0SD4dJ4MDMN"},"source":["## Etapa 2: Base de dados"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EEuG9mmY7TpD","executionInfo":{"status":"ok","timestamp":1634668489562,"user_tz":180,"elapsed":18,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"665ec7f2-c1ff-4c3d-b272-920055ffbca5"},"source":["np.random.seed(123)\n","torch.manual_seed(123)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f26a7004310>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"VthvALiq7aby","executionInfo":{"status":"ok","timestamp":1634668489563,"user_tz":180,"elapsed":16,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}}},"source":["previsores = pd.read_csv(\"/content/entradas_breast.csv\")\n","classe = pd.read_csv(\"/content/saidas_breast.csv\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p0uwzW8f78Ss","executionInfo":{"status":"ok","timestamp":1634668489563,"user_tz":180,"elapsed":15,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"e34e7559-0908-45f1-c772-b168cec3e9e8"},"source":["previsores.shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(569, 30)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MoDCdOyx798f","executionInfo":{"status":"ok","timestamp":1634668489564,"user_tz":180,"elapsed":14,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"2d4377dc-52c9-45be-9a39-bbebd7eb3cfc"},"source":["classe.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(569, 1)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"yFDDZfZTfOq5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634668489564,"user_tz":180,"elapsed":10,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"3fad85ca-bcde-4ae5-ad42-b79b47351430"},"source":["np.unique(classe)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"rqiQvr3HfUc4","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1634668490272,"user_tz":180,"elapsed":716,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"957896fa-fa4d-4e76-a956-6ee05729f641"},"source":["previsores.head()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>radius_mean</th>\n","      <th>texture_mean</th>\n","      <th>perimeter_mean</th>\n","      <th>area_mean</th>\n","      <th>smoothness_mean</th>\n","      <th>compactness_mean</th>\n","      <th>concavity_mean</th>\n","      <th>concave_points_mean</th>\n","      <th>symmetry_mean</th>\n","      <th>fractal_dimension_mean</th>\n","      <th>radius_se</th>\n","      <th>texture_se</th>\n","      <th>perimeter_se</th>\n","      <th>area_se</th>\n","      <th>smoothness_se</th>\n","      <th>compactness_se</th>\n","      <th>concavity_se</th>\n","      <th>concave_points_se</th>\n","      <th>symmetry_se</th>\n","      <th>fractal_dimension_se</th>\n","      <th>radius_worst</th>\n","      <th>texture_worst</th>\n","      <th>perimeter_worst</th>\n","      <th>area_worst</th>\n","      <th>smoothness_worst</th>\n","      <th>compactness_worst</th>\n","      <th>concavity_worst</th>\n","      <th>concave_points_worst</th>\n","      <th>symmetry_worst</th>\n","      <th>fractal_dimension_worst</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.3001</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>0.07871</td>\n","      <td>1095.0000</td>\n","      <td>0.9053</td>\n","      <td>8589.0</td>\n","      <td>153.40</td>\n","      <td>0.006399</td>\n","      <td>0.04904</td>\n","      <td>0.05373</td>\n","      <td>0.01587</td>\n","      <td>0.03003</td>\n","      <td>0.006193</td>\n","      <td>25.38</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.1622</td>\n","      <td>0.6656</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.0869</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>0.05667</td>\n","      <td>0.5435</td>\n","      <td>0.7339</td>\n","      <td>3398.0</td>\n","      <td>74.08</td>\n","      <td>0.005225</td>\n","      <td>0.01308</td>\n","      <td>0.01860</td>\n","      <td>0.01340</td>\n","      <td>0.01389</td>\n","      <td>0.003532</td>\n","      <td>24.99</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.1238</td>\n","      <td>0.1866</td>\n","      <td>0.2416</td>\n","      <td>186.0000</td>\n","      <td>275.0000</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.1974</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>0.05999</td>\n","      <td>0.7456</td>\n","      <td>0.7869</td>\n","      <td>4585.0</td>\n","      <td>94.03</td>\n","      <td>0.006150</td>\n","      <td>0.04006</td>\n","      <td>0.03832</td>\n","      <td>0.02058</td>\n","      <td>0.02250</td>\n","      <td>0.004571</td>\n","      <td>23.57</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.1444</td>\n","      <td>0.4245</td>\n","      <td>0.4504</td>\n","      <td>243.0000</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.2414</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>0.09744</td>\n","      <td>0.4956</td>\n","      <td>1156.0000</td>\n","      <td>3445.0</td>\n","      <td>27.23</td>\n","      <td>0.009110</td>\n","      <td>0.07458</td>\n","      <td>0.05661</td>\n","      <td>0.01867</td>\n","      <td>0.05963</td>\n","      <td>0.009208</td>\n","      <td>14.91</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.2098</td>\n","      <td>0.8663</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>173.00000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>198.0000</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>0.05883</td>\n","      <td>0.7572</td>\n","      <td>0.7813</td>\n","      <td>5438.0</td>\n","      <td>94.44</td>\n","      <td>0.011490</td>\n","      <td>0.02461</td>\n","      <td>0.05688</td>\n","      <td>0.01885</td>\n","      <td>0.01756</td>\n","      <td>0.005115</td>\n","      <td>22.54</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.1374</td>\n","      <td>205.0000</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    radius_mean   texture_mean  ...   symmetry_worst   fractal_dimension_worst\n","0         17.99          10.38  ...           0.4601                   0.11890\n","1         20.57          17.77  ...         275.0000                   0.08902\n","2         19.69          21.25  ...           0.3613                   0.08758\n","3         11.42          20.38  ...           0.6638                 173.00000\n","4         20.29          14.34  ...           0.2364                   0.07678\n","\n","[5 rows x 30 columns]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"kKqSDj3bfdQB","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1634668490275,"user_tz":180,"elapsed":59,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"00c4dcc4-ca9a-43f1-b4b1-710d41d41647"},"source":["classe.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0\n","0  0\n","1  0\n","2  0\n","3  0\n","4  0"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"-jSqJh18fhL1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634668490276,"user_tz":180,"elapsed":56,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"84c8ace9-0526-46d0-830d-b7449913d654"},"source":["np.unique(classe)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"aKLO9jX0fs-3","colab":{"base_uri":"https://localhost:8080/","height":333},"executionInfo":{"status":"ok","timestamp":1634668490278,"user_tz":180,"elapsed":47,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"86247cd0-a4ad-48cf-ab63-4942555242da"},"source":["sns.countplot(classe['0']);"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPqElEQVR4nO3df6xfdX3H8efLFtFMN+h619W2rMR1M7jN4u4qm/uDQZxAshWNEkiUzpHUJbhoYozoH/NHRuIylajbSLqAFOPEzh+jM+wHq2zGRMFbV5GCzDuF0abQKyDCjCyt7/1xz/3wtb1tv8We7/e29/lITr7nvM/nnPu+SdNXzo/v56aqkCQJ4DnjbkCStHAYCpKkxlCQJDWGgiSpMRQkSc3ScTfw01i+fHmtXbt23G1I0kll586d36uqifn2ndShsHbtWqampsbdhiSdVJI8eKR93j6SJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNSf1N5qlU9n/vP/Xx92CFqCz/uybvZ6/tyuFJM9LcleSbyTZneR9Xf2mJN9Nsqtb1nf1JPlokukkdyd5eV+9SZLm1+eVwtPABVX1VJLTgC8n+adu3zuq6jOHjL8YWNctrwCu7z4lSSPS25VCzXqq2zytW472B6E3Ajd3x30VOCPJyr76kyQdrtcHzUmWJNkF7Adur6o7u13XdreIrktyeldbBTw0cPiernboOTcnmUoyNTMz02f7krTo9BoKVXWwqtYDq4ENSX4NeBfwEuC3gGXAO4/znFuqarKqJicm5p0OXJL0LI3kldSq+j5wB3BRVe3rbhE9DXwc2NAN2wusGThsdVeTJI1In28fTSQ5o1t/PvAq4FtzzwmSBLgUuKc7ZDtwZfcW0nnAE1W1r6/+JEmH6/Pto5XA1iRLmA2fbVX1hSRfTDIBBNgF/Ek3/jbgEmAa+CHwph57kyTNo7dQqKq7gXPnqV9whPEFXN1XP5KkY3OaC0lSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqSmt1BI8rwkdyX5RpLdSd7X1c9OcmeS6SSfTvLcrn56tz3d7V/bV2+SpPn1eaXwNHBBVb0MWA9clOQ84C+A66rql4HHgau68VcBj3f167pxkqQR6i0UatZT3eZp3VLABcBnuvpW4NJufWO3Tbf/wiTpqz9J0uF6faaQZEmSXcB+4Hbgv4HvV9WBbsgeYFW3vgp4CKDb/wTw8/Occ3OSqSRTMzMzfbYvSYtOr6FQVQeraj2wGtgAvOQEnHNLVU1W1eTExMRP3aMk6Rkjefuoqr4P3AH8NnBGkqXdrtXA3m59L7AGoNv/c8Cjo+hPkjSrz7ePJpKc0a0/H3gVcB+z4fC6btgm4NZufXu3Tbf/i1VVffUnSTrc0mMPedZWAluTLGE2fLZV1ReS3AvckuTPgf8EbujG3wB8Isk08BhweY+9SZLm0VsoVNXdwLnz1L/D7POFQ+s/Al7fVz+SpGPzG82SpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJTW+hkGRNkjuS3Jtkd5K3dvX3JtmbZFe3XDJwzLuSTCe5P8mr++pNkjS/pT2e+wDw9qr6epIXAjuT3N7tu66qPjg4OMk5wOXAS4EXAf+W5Feq6mCPPUqSBvR2pVBV+6rq6936k8B9wKqjHLIRuKWqnq6q7wLTwIa++pMkHW4kzxSSrAXOBe7sSm9JcneSG5Oc2dVWAQ8NHLaHeUIkyeYkU0mmZmZmeuxakhaf3kMhyQuAzwJvq6ofANcDLwbWA/uADx3P+apqS1VNVtXkxMTECe9XkhazXkMhyWnMBsInq+pzAFX1SFUdrKofA3/LM7eI9gJrBg5f3dUkSSPS59tHAW4A7quqDw/UVw4Mew1wT7e+Hbg8yelJzgbWAXf11Z8k6XB9vn30SuCNwDeT7Opq7wauSLIeKOAB4M0AVbU7yTbgXmbfXLraN48kabR6C4Wq+jKQeXbddpRjrgWu7asnSdLR+Y1mSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWr6/MtrJ4XffMfN425BC9DOv7xy3C1IY+GVgiSpMRQkSc1QoZBkxzA1SdLJ7aihkOR5SZYBy5OcmWRZt6wFVh3j2DVJ7khyb5LdSd7a1ZcluT3Jt7vPM7t6knw0yXSSu5O8/MT8ipKkYR3rSuHNwE7gJd3n3HIr8FfHOPYA8PaqOgc4D7g6yTnANcCOqloH7Oi2AS4G1nXLZuD64/5tJEk/laO+fVRVHwE+kuRPq+pjx3PiqtoH7OvWn0xyH7NXFxuB87thW4F/B97Z1W+uqgK+muSMJCu780iSRmCoV1Kr6mNJfgdYO3hMVQ31Pmd3u+lc4E5gxcB/9A8DK7r1VcBDA4ft6Wo/EQpJNjN7JcFZZ501zI+XJA1pqFBI8gngxcAu4GBXLuCYoZDkBcBngbdV1Q+StH1VVUnqeBquqi3AFoDJycnjOlaSdHTDfnltEjinu7UztCSnMRsIn6yqz3XlR+ZuCyVZCezv6nuBNQOHr+5qkqQRGfZ7CvcAv3g8J87sJcENwH1V9eGBXduBTd36JmYfWs/Vr+zeQjoPeMLnCZI0WsNeKSwH7k1yF/D0XLGq/vAox7wSeCPwzSS7utq7gQ8A25JcBTwIXNbtuw24BJgGfgi8adhfQpJ0YgwbCu893hNX1ZeBHGH3hfOML+Dq4/05kqQTZ9i3j/6j70YkSeM37NtHTzL7thHAc4HTgP+tqp/tqzFJ0ugNe6Xwwrn17gHyRma/pSxJOoUc9yypNesfgFf30I8kaYyGvX302oHN5zD7vYUf9dKRJGlshn376A8G1g8ADzB7C0mSdAoZ9pmC3xmQpEVg2D+yszrJ55Ps75bPJlndd3OSpNEa9kHzx5mdhuJF3fKPXU2SdAoZNhQmqurjVXWgW24CJnrsS5I0BsOGwqNJ3pBkSbe8AXi0z8YkSaM3bCj8MbMT1z3M7B+9eR3wRz31JEkak2FfSX0/sKmqHgdIsgz4ILNhIUk6RQx7pfAbc4EAUFWPMfvnNSVJp5BhQ+E5Sc6c2+iuFIa9ypAknSSG/Y/9Q8BXkvx9t/164Np+WpIkjcuw32i+OckUcEFXem1V3dtfW5KkcRj6FlAXAgaBJJ3CjnvqbEnSqctQkCQ1vYVCkhu7yfPuGai9N8neJLu65ZKBfe9KMp3k/iT+AR9JGoM+rxRuAi6ap35dVa3vltsAkpwDXA68tDvmb5Is6bE3SdI8eguFqvoS8NiQwzcCt1TV01X1XWAa2NBXb5Kk+Y3jmcJbktzd3V6a+0LcKuChgTF7utphkmxOMpVkamZmpu9eJWlRGXUoXA+8GFjP7MR6HzreE1TVlqqarKrJiQln75akE2mkoVBVj1TVwar6MfC3PHOLaC+wZmDo6q4mSRqhkYZCkpUDm68B5t5M2g5cnuT0JGcD64C7RtmbJKnHSe2SfAo4H1ieZA/wHuD8JOuBAh4A3gxQVbuTbGP2G9MHgKur6mBfvUmS5tdbKFTVFfOUbzjK+Gtxkj1JGiu/0SxJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLU9BYKSW5Msj/JPQO1ZUluT/Lt7vPMrp4kH00yneTuJC/vqy9J0pH1eaVwE3DRIbVrgB1VtQ7Y0W0DXAys65bNwPU99iVJOoLeQqGqvgQ8dkh5I7C1W98KXDpQv7lmfRU4I8nKvnqTJM1v1M8UVlTVvm79YWBFt74KeGhg3J6udpgkm5NMJZmamZnpr1NJWoTG9qC5qgqoZ3HclqqarKrJiYmJHjqTpMVr1KHwyNxtoe5zf1ffC6wZGLe6q0mSRmjUobAd2NStbwJuHahf2b2FdB7wxMBtJknSiCzt68RJPgWcDyxPsgd4D/ABYFuSq4AHgcu64bcBlwDTwA+BN/XVlyTpyHoLhaq64gi7LpxnbAFX99WLJGk4fqNZktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqVk6jh+a5AHgSeAgcKCqJpMsAz4NrAUeAC6rqsfH0Z8kLVbjvFL4vapaX1WT3fY1wI6qWgfs6LYlSSO0kG4fbQS2dutbgUvH2IskLUrjCoUC/jXJziSbu9qKqtrXrT8MrJjvwCSbk0wlmZqZmRlFr5K0aIzlmQLwu1W1N8kvALcn+dbgzqqqJDXfgVW1BdgCMDk5Oe8YSdKzM5Yrhara233uBz4PbAAeSbISoPvcP47eJGkxG3koJPmZJC+cWwd+H7gH2A5s6oZtAm4ddW+StNiN4/bRCuDzSeZ+/t9V1T8n+RqwLclVwIPAZWPoTZIWtZGHQlV9B3jZPPVHgQtH3Y8k6RkL6ZVUSdKYGQqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKlZcKGQ5KIk9yeZTnLNuPuRpMVkQYVCkiXAXwMXA+cAVyQ5Z7xdSdLisaBCAdgATFfVd6rq/4BbgI1j7kmSFo2l427gEKuAhwa29wCvGByQZDOwudt8Ksn9I+ptMVgOfG/cTSwE+eCmcbegn+S/zTnvyYk4yy8dacdCC4VjqqotwJZx93EqSjJVVZPj7kM6lP82R2eh3T7aC6wZ2F7d1SRJI7DQQuFrwLokZyd5LnA5sH3MPUnSorGgbh9V1YEkbwH+BVgC3FhVu8fc1mLibTktVP7bHJFU1bh7kCQtEAvt9pEkaYwMBUlSYyjIqUW0YCW5Mcn+JPeMu5fFwlBY5JxaRAvcTcBF425iMTEU5NQiWrCq6kvAY+PuYzExFDTf1CKrxtSLpDEzFCRJjaEgpxaR1BgKcmoRSY2hsMhV1QFgbmqR+4BtTi2ihSLJp4CvAL+aZE+Sq8bd06nOaS4kSY1XCpKkxlCQJDWGgiSpMRQkSY2hIElqDAXpBHPWWZ3MfCVVOoG6WWf/C3gVs/NIfQ24oqruHWtj0pC8UpBOLGed1UnNUJBOLGed1UnNUJAkNYaCdGI566xOaoaCdGI566xOakvH3YB0KqmqA0nmZp1dAtzorLM6mfhKqiSp8faRJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpOb/AcefD8mpVpUkAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"hQFTUNrb9KlT","executionInfo":{"status":"ok","timestamp":1634668490278,"user_tz":180,"elapsed":42,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}}},"source":["previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size = 0.25)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"7SEVQyX9gR4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634668490279,"user_tz":180,"elapsed":40,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"d55ade53-2006-4bd6-ae82-5f30ac033b94"},"source":["previsores_treinamento.shape"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(426, 30)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"ZA6wrOMygUmg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634668490279,"user_tz":180,"elapsed":38,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"16bfd962-b723-49c7-c8a1-6c07b4d739bf"},"source":["classe_treinamento.shape"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(426, 1)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"SKyN_plmgZzH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634668490280,"user_tz":180,"elapsed":37,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"91a6a1e5-e5e7-4c57-b0c0-bdf6e65d5cf4"},"source":["previsores_teste.shape"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(143, 30)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"wN_AXcfggdWC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634668490280,"user_tz":180,"elapsed":33,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"f6510a55-9c05-4837-99f7-feb6f2ab9b3b"},"source":["classe_teste.shape"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(143, 1)"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"72uvlxJrOuWd"},"source":["## Etapa 3: Transformação dos dados para tensores\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ngu_vX0_9rsJ","executionInfo":{"status":"ok","timestamp":1634668490280,"user_tz":180,"elapsed":29,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"2d1a666d-544c-4fdc-a43b-527fce0f30d7"},"source":["type(previsores_treinamento)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pandas.core.frame.DataFrame"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pD461pd39wJx","executionInfo":{"status":"ok","timestamp":1634668490281,"user_tz":180,"elapsed":26,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"bfd42c4e-8c4b-48ba-a455-5b8db43c03b1"},"source":["# Para poder trabalhar em pytorch, precisamos converter em tensores\n","# Para poder converter em tensores, precisamos que seja antes um numpy array\n","type(np.array(previsores_treinamento))"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"bEouZljw-wZM","executionInfo":{"status":"ok","timestamp":1634668490281,"user_tz":180,"elapsed":24,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}}},"source":["# Aqui faremos a conversão para tensores\n","previsores_treinamento = torch.tensor(np.array(previsores_treinamento))\n","classe_treinamento = torch.tensor(np.array(classe_treinamento))"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N2o9EPqQ_Jeh","executionInfo":{"status":"ok","timestamp":1634668490281,"user_tz":180,"elapsed":24,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"87e5611f-0a42-4742-b3c5-d6fd654f4466"},"source":["previsores_treinamento"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.1540e+01, 1.4440e+01, 7.4650e+01,  ..., 6.9180e-02, 2.3290e-01,\n","         8.1340e-02],\n","        [2.0310e+01, 2.7060e+01, 1.3290e+02,  ..., 1.6970e-01, 3.1510e-01,\n","         7.9990e-02],\n","        [1.1360e+01, 1.7570e+01, 7.2490e+01,  ..., 8.6980e-02, 2.9730e-01,\n","         7.7450e-02],\n","        ...,\n","        [1.2050e+01, 2.2720e+01, 7.8750e+01,  ..., 1.0920e-01, 2.1910e-01,\n","         9.3490e-02],\n","        [2.0440e+01, 2.1780e+01, 1.3380e+02,  ..., 1.7650e-01, 2.6090e-01,\n","         6.7350e-02],\n","        [1.1740e+01, 1.4690e+01, 7.6310e+01,  ..., 1.0560e-01, 2.6040e-01,\n","         9.8790e-02]], dtype=torch.float64)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3_r-Dog_K0U","executionInfo":{"status":"ok","timestamp":1634668490281,"user_tz":180,"elapsed":23,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"04de8d1a-f1b7-45a7-d214-bcfda806f06c"},"source":["classe_treinamento"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1],\n","        [0],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [0],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [0],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [1]])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-axiY2Ir_Phk","executionInfo":{"status":"ok","timestamp":1634668490284,"user_tz":180,"elapsed":24,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"4c022582-262c-4e06-a21e-5b6b4205109b"},"source":["type(previsores_treinamento)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Tensor"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YnP8gHqtAjOk","executionInfo":{"status":"ok","timestamp":1634668490284,"user_tz":180,"elapsed":19,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"b0811d3e-012c-43ac-b153-82bd16deab69"},"source":["type(classe_treinamento)"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Tensor"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"hHXnQFAMAlpq","executionInfo":{"status":"ok","timestamp":1634668491258,"user_tz":180,"elapsed":992,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}}},"source":["# Para o PyTorch é necessário que em um único objeto haja previsores e classe. Para isso, você usa o \n","# torch.utils.data.TensorDataset(previsores_treinamento, classe_treinamento)\n","# Ao fazer isso, você já gera um tensor no formato esperado\n","\n","df = torch.utils.data.TensorDataset(previsores_treinamento, classe_treinamento)\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3KQZFFBPBAyr","executionInfo":{"status":"ok","timestamp":1634668491259,"user_tz":180,"elapsed":21,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"29f52bcb-a395-493d-a6ae-d0c4ec3e26a6"},"source":["type(df)"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.utils.data.dataset.TensorDataset"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"3YQzGYP2BC4l","executionInfo":{"status":"ok","timestamp":1634668491259,"user_tz":180,"elapsed":19,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}}},"source":["# Px passo é gerar o train loader que fará o treinamento da rede\n","# Para isso, precisamos informar a qtd de batchs que serão usados por época de treinamento e o shuffle se vamos alternar\n","train_loader = torch.utils.data.DataLoader(df, batch_size=10, shuffle=True)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QGDLesyDQpIb"},"source":["## Etapa 4: Construção do modelo"]},{"cell_type":"code","metadata":{"id":"cedTUJaoDdRp","executionInfo":{"status":"ok","timestamp":1634668491259,"user_tz":180,"elapsed":19,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}}},"source":["# Aqui construíremos a RN\n","\n","# Temos 30 atributos\n","# 1 Saída\n","# Qtd de neurônios na camada oculta será: (entrada + saída) / 2 \n","# 31 / 2 =~ 16 neurônios\n","# Utilizaremos 2 camadas ocultas inicialmente, logo, arquitetura da rede será:\n","# 30 -> 16 -> 16 ->1\n","\n","# Sequential é a instanciação da rede toda, mostrando que os passos seguintes serão sequenciais \n","# Seria como o density do TensorFlow ou Keras\n","rede_neural = nn.Sequential(   \n","    # Ao instanciarmos uma camada Linear, indicamos que todos os neurônios desta camada se comunicam com todos da px camada\n","    # Como temos 30 atributos, a primeira camada será 30 -> 16\n","    nn.Linear(in_features=30,out_features=16),\n","    # Agora precisamos definir a função de ativação para a saída dos 16\n","    nn.ReLU(),\n","    \n","    # Agora faremos 16 -> 16\n","    nn.Linear(in_features=16,out_features=16),\n","    # Outra vez a função de ativação para o que passará para os últimos 16\n","    nn.ReLU(),\n","\n","    # Agora faremos 16 -> 1\n","    nn.Linear(in_features=16,out_features=1),\n","    # Utilizaremos sigmoid para uma probabilidade de chegar no último neurônio da rede\n","    nn.Sigmoid()\n",")"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93__XUstFV6b","executionInfo":{"status":"ok","timestamp":1634668491260,"user_tz":180,"elapsed":19,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"28a05ae1-3df7-40be-edeb-bb44343a03e4"},"source":["# A rede.parameters apresenta os parâmetros da rede\n","\n","rede_neural.parameters"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Module.parameters of Sequential(\n","  (0): Linear(in_features=30, out_features=16, bias=True)\n","  (1): ReLU()\n","  (2): Linear(in_features=16, out_features=16, bias=True)\n","  (3): ReLU()\n","  (4): Linear(in_features=16, out_features=1, bias=True)\n","  (5): Sigmoid()\n",")>"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"LPzXRVInFSUU","executionInfo":{"status":"ok","timestamp":1634668491260,"user_tz":180,"elapsed":18,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}}},"source":["# Precisamos agora instanciar o critério de perda\n","# BCE é Binary Cross Entropy\n","\n","criterion = nn.BCELoss()"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"DtH1gYrfFnX9","executionInfo":{"status":"ok","timestamp":1634668491260,"user_tz":180,"elapsed":17,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}}},"source":["# Precisamos definir o optimizador que buscará a melhor descida do gradiente\n","# Há diversos optimizadores no PyTorch, utilizaremos o Adam()\n","# Precisamos passar: \n","# Os parâmetros da rede;\n","# A learning rate do gradiente para o quanto ele descerá em cada época (padrão 0.001)\n","# A taxa de decaimento (padrão 0.0001) também para a descida mais íngreme do gradiente\n","\n","optimizer = torch.optim.Adam(rede_neural.parameters(), lr = 0.001, weight_decay=0.0001)"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"appMwDHtRTN5"},"source":["## Etapa 5: Treinamento do modelo"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DxuJMK4DO0Tr","executionInfo":{"status":"ok","timestamp":1634668503756,"user_tz":180,"elapsed":12513,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"808a4cde-b624-4003-8974-a0dd04fb711d"},"source":["# Precisaremos gerar um loop para a quantidade de épocas que ele pretende percorrer\n","for epoch in range(300):\n","  # Precisamos instanciar a primeira running_loss\n","  running_loss = 0.\n","\n","  # Para cada batch do train_loader faremos a execução da rede\n","  for data in train_loader:\n","    inputs, labels = data\n","    #print(inputs) # Podemos ver que estamos percorrendo cada um dos 10 batchs de atributos previsores\n","    #print(\"-------\")\n","    #print(labels) # E suas respectivas classes\n","    \n","    # Para cada ajuste de pesos precisamos calcular um gradiente separado. Então, precisamos zerar o gradiente\n","    optimizer.zero_grad()\n","\n","    # Aqui passaremos a diante na rede as saídas outputs, 2 formas de fazer:\n","    # 1)\n","    # outputs = rede_neural(inputs)\n","    # 2) Neste caso tb foi necessário converter o tipo de dados\n","    outputs = rede_neural.forward(inputs.float())\n","    #print(outputs)\n","\n","    # Aplicamos também a função de perda. Precisamos comparar as saídas com os dados reais.\n","    # Neste caso, foi necessário converter os dados\n","    # A cada batch teremos o erro\n","    loss = criterion(outputs.float(), labels.float())\n","    #print(loss)\n","\n","    # Aplicamos a função de perda na backpropagation para melhorar o acerto\n","    loss.backward()\n","\n","    # Aqui utilizaremos nosso otimizador Adan para fazer o ajuste dos pesos\n","    optimizer.step()\n","\n","    # Pegamos o erro corrente\n","    running_loss += loss.item()\n","\n","  print('Época %3d: perda %.5f' % (epoch+1, running_loss/len(train_loader)))\n","\n","\n"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Época   1: perda 10.78336\n","Época   2: perda 2.84863\n","Época   3: perda 1.67480\n","Época   4: perda 1.11414\n","Época   5: perda 0.63996\n","Época   6: perda 0.63753\n","Época   7: perda 0.58066\n","Época   8: perda 0.55460\n","Época   9: perda 0.55617\n","Época  10: perda 0.53322\n","Época  11: perda 0.55797\n","Época  12: perda 0.53816\n","Época  13: perda 0.52938\n","Época  14: perda 0.33227\n","Época  15: perda 0.51360\n","Época  16: perda 0.35532\n","Época  17: perda 0.49602\n","Época  18: perda 0.33208\n","Época  19: perda 0.29349\n","Época  20: perda 0.25046\n","Época  21: perda 0.29527\n","Época  22: perda 0.49888\n","Época  23: perda 0.47241\n","Época  24: perda 0.45883\n","Época  25: perda 0.27544\n","Época  26: perda 0.23399\n","Época  27: perda 0.26373\n","Época  28: perda 0.24136\n","Época  29: perda 0.28275\n","Época  30: perda 0.22633\n","Época  31: perda 0.19294\n","Época  32: perda 0.22258\n","Época  33: perda 0.20290\n","Época  34: perda 0.20888\n","Época  35: perda 0.20335\n","Época  36: perda 0.20316\n","Época  37: perda 0.18855\n","Época  38: perda 0.22316\n","Época  39: perda 0.23315\n","Época  40: perda 0.19261\n","Época  41: perda 0.17163\n","Época  42: perda 0.18287\n","Época  43: perda 0.17056\n","Época  44: perda 0.16674\n","Época  45: perda 0.18515\n","Época  46: perda 0.22250\n","Época  47: perda 0.17558\n","Época  48: perda 0.22754\n","Época  49: perda 0.19833\n","Época  50: perda 0.16371\n","Época  51: perda 0.16855\n","Época  52: perda 0.18337\n","Época  53: perda 0.17593\n","Época  54: perda 0.17882\n","Época  55: perda 0.18470\n","Época  56: perda 0.17073\n","Época  57: perda 0.15674\n","Época  58: perda 0.18435\n","Época  59: perda 0.14023\n","Época  60: perda 0.15765\n","Época  61: perda 0.16521\n","Época  62: perda 0.15513\n","Época  63: perda 0.13765\n","Época  64: perda 0.14962\n","Época  65: perda 0.15919\n","Época  66: perda 0.23974\n","Época  67: perda 0.16218\n","Época  68: perda 0.15015\n","Época  69: perda 0.15990\n","Época  70: perda 0.18359\n","Época  71: perda 0.14650\n","Época  72: perda 0.16269\n","Época  73: perda 0.12191\n","Época  74: perda 0.13901\n","Época  75: perda 0.13926\n","Época  76: perda 0.13105\n","Época  77: perda 0.12779\n","Época  78: perda 0.14741\n","Época  79: perda 0.20884\n","Época  80: perda 0.20729\n","Época  81: perda 0.22643\n","Época  82: perda 0.16890\n","Época  83: perda 0.11829\n","Época  84: perda 0.12809\n","Época  85: perda 0.12544\n","Época  86: perda 0.12474\n","Época  87: perda 0.15365\n","Época  88: perda 0.11945\n","Época  89: perda 0.15052\n","Época  90: perda 0.12977\n","Época  91: perda 0.16607\n","Época  92: perda 0.14753\n","Época  93: perda 0.09912\n","Época  94: perda 0.13184\n","Época  95: perda 0.10702\n","Época  96: perda 0.12766\n","Época  97: perda 0.12817\n","Época  98: perda 0.12291\n","Época  99: perda 0.13988\n","Época 100: perda 0.13753\n","Época 101: perda 0.11618\n","Época 102: perda 0.12441\n","Época 103: perda 0.15940\n","Época 104: perda 0.11434\n","Época 105: perda 0.10708\n","Época 106: perda 0.12147\n","Época 107: perda 0.15126\n","Época 108: perda 0.14897\n","Época 109: perda 0.11308\n","Época 110: perda 0.14515\n","Época 111: perda 0.11224\n","Época 112: perda 0.12243\n","Época 113: perda 0.12769\n","Época 114: perda 0.10704\n","Época 115: perda 0.12199\n","Época 116: perda 0.12206\n","Época 117: perda 0.14932\n","Época 118: perda 0.15264\n","Época 119: perda 0.10410\n","Época 120: perda 0.11391\n","Época 121: perda 0.09641\n","Época 122: perda 0.10930\n","Época 123: perda 0.16920\n","Época 124: perda 0.17965\n","Época 125: perda 0.14501\n","Época 126: perda 0.13296\n","Época 127: perda 0.14183\n","Época 128: perda 0.12327\n","Época 129: perda 0.10596\n","Época 130: perda 0.09524\n","Época 131: perda 0.09903\n","Época 132: perda 0.11645\n","Época 133: perda 0.11556\n","Época 134: perda 0.09646\n","Época 135: perda 0.11537\n","Época 136: perda 0.11098\n","Época 137: perda 0.09390\n","Época 138: perda 0.08960\n","Época 139: perda 0.12997\n","Época 140: perda 0.13778\n","Época 141: perda 0.10531\n","Época 142: perda 0.08753\n","Época 143: perda 0.09650\n","Época 144: perda 0.10198\n","Época 145: perda 0.10660\n","Época 146: perda 0.10859\n","Época 147: perda 0.10262\n","Época 148: perda 0.13961\n","Época 149: perda 0.12760\n","Época 150: perda 0.11410\n","Época 151: perda 0.13066\n","Época 152: perda 0.10944\n","Época 153: perda 0.11815\n","Época 154: perda 0.12828\n","Época 155: perda 0.17800\n","Época 156: perda 0.13193\n","Época 157: perda 0.09501\n","Época 158: perda 0.10221\n","Época 159: perda 0.10422\n","Época 160: perda 0.13867\n","Época 161: perda 0.11912\n","Época 162: perda 0.12288\n","Época 163: perda 0.10878\n","Época 164: perda 0.10347\n","Época 165: perda 0.08901\n","Época 166: perda 0.10394\n","Época 167: perda 0.09164\n","Época 168: perda 0.08536\n","Época 169: perda 0.11973\n","Época 170: perda 0.10165\n","Época 171: perda 0.08563\n","Época 172: perda 0.09116\n","Época 173: perda 0.09227\n","Época 174: perda 0.09951\n","Época 175: perda 0.10710\n","Época 176: perda 0.12458\n","Época 177: perda 0.09169\n","Época 178: perda 0.07768\n","Época 179: perda 0.09649\n","Época 180: perda 0.11542\n","Época 181: perda 0.13066\n","Época 182: perda 0.09416\n","Época 183: perda 0.12955\n","Época 184: perda 0.07945\n","Época 185: perda 0.06611\n","Época 186: perda 0.06444\n","Época 187: perda 0.08241\n","Época 188: perda 0.06735\n","Época 189: perda 0.08257\n","Época 190: perda 0.10594\n","Época 191: perda 0.06997\n","Época 192: perda 0.08125\n","Época 193: perda 0.07366\n","Época 194: perda 0.07801\n","Época 195: perda 0.10132\n","Época 196: perda 0.09008\n","Época 197: perda 0.09414\n","Época 198: perda 0.07439\n","Época 199: perda 0.10515\n","Época 200: perda 0.07463\n","Época 201: perda 0.10043\n","Época 202: perda 0.10857\n","Época 203: perda 0.10762\n","Época 204: perda 0.18867\n","Época 205: perda 0.12594\n","Época 206: perda 0.11125\n","Época 207: perda 0.10612\n","Época 208: perda 0.07230\n","Época 209: perda 0.06270\n","Época 210: perda 0.07189\n","Época 211: perda 0.06011\n","Época 212: perda 0.09195\n","Época 213: perda 0.08524\n","Época 214: perda 0.07186\n","Época 215: perda 0.05987\n","Época 216: perda 0.07424\n","Época 217: perda 0.12513\n","Época 218: perda 0.08698\n","Época 219: perda 0.08824\n","Época 220: perda 0.06452\n","Época 221: perda 0.06487\n","Época 222: perda 0.07085\n","Época 223: perda 0.06756\n","Época 224: perda 0.07207\n","Época 225: perda 0.06781\n","Época 226: perda 0.07493\n","Época 227: perda 0.06702\n","Época 228: perda 0.07925\n","Época 229: perda 0.07601\n","Época 230: perda 0.06271\n","Época 231: perda 0.07021\n","Época 232: perda 0.07765\n","Época 233: perda 0.08161\n","Época 234: perda 0.10717\n","Época 235: perda 0.06597\n","Época 236: perda 0.05742\n","Época 237: perda 0.07948\n","Época 238: perda 0.08428\n","Época 239: perda 0.06197\n","Época 240: perda 0.06566\n","Época 241: perda 0.06643\n","Época 242: perda 0.10941\n","Época 243: perda 0.06247\n","Época 244: perda 0.15372\n","Época 245: perda 0.10475\n","Época 246: perda 0.09291\n","Época 247: perda 0.06903\n","Época 248: perda 0.05153\n","Época 249: perda 0.08052\n","Época 250: perda 0.12238\n","Época 251: perda 0.07382\n","Época 252: perda 0.06930\n","Época 253: perda 0.06317\n","Época 254: perda 0.07214\n","Época 255: perda 0.05382\n","Época 256: perda 0.08285\n","Época 257: perda 0.09142\n","Época 258: perda 0.05753\n","Época 259: perda 0.06867\n","Época 260: perda 0.06736\n","Época 261: perda 0.07249\n","Época 262: perda 0.05492\n","Época 263: perda 0.05455\n","Época 264: perda 0.05553\n","Época 265: perda 0.07437\n","Época 266: perda 0.12452\n","Época 267: perda 0.16085\n","Época 268: perda 0.17084\n","Época 269: perda 0.09427\n","Época 270: perda 0.06616\n","Época 271: perda 0.09760\n","Época 272: perda 0.08158\n","Época 273: perda 0.07399\n","Época 274: perda 0.05925\n","Época 275: perda 0.06609\n","Época 276: perda 0.05235\n","Época 277: perda 0.05201\n","Época 278: perda 0.06020\n","Época 279: perda 0.05391\n","Época 280: perda 0.06083\n","Época 281: perda 0.04841\n","Época 282: perda 0.06957\n","Época 283: perda 0.07006\n","Época 284: perda 0.11257\n","Época 285: perda 0.06397\n","Época 286: perda 0.07122\n","Época 287: perda 0.07513\n","Época 288: perda 0.05900\n","Época 289: perda 0.08977\n","Época 290: perda 0.06100\n","Época 291: perda 0.08026\n","Época 292: perda 0.08260\n","Época 293: perda 0.07410\n","Época 294: perda 0.04887\n","Época 295: perda 0.05248\n","Época 296: perda 0.06015\n","Época 297: perda 0.06113\n","Época 298: perda 0.06778\n","Época 299: perda 0.05778\n","Época 300: perda 0.05311\n"]}]},{"cell_type":"markdown","metadata":{"id":"ITUtUdQNSJcs"},"source":["## Etapa 6: Visualização dos pesos"]},{"cell_type":"code","metadata":{"id":"jmhueozDjlpo","executionInfo":{"status":"ok","timestamp":1634668503757,"user_tz":180,"elapsed":37,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}}},"source":["# A estrutura da rede é:\n","# 30 -> 16 -> 16 -> 1\n","# Com o parameters, podemos visualizar todos os parâmetros da rede\n","params = list(rede_neural.parameters())"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"8dQps3kqk2pY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634668503757,"user_tz":180,"elapsed":36,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"81d5bfb3-0f00-4577-b4a5-a51d6c62dd6f"},"source":["#Parâmetros da rede\n","params"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Parameter containing:\n"," tensor([[-1.5219e-01, -2.8663e-01, -2.7835e-01,  9.7514e-02, -2.5460e-02,\n","           1.3026e-01,  5.4066e-02,  4.5641e-02, -1.3902e-01,  2.2695e-01,\n","           3.7599e-02,  5.3864e-02, -1.2807e-01, -4.9886e-02,  5.1757e-04,\n","          -2.5215e-01, -5.4503e-01, -2.3041e-02,  3.3099e-01,  2.1247e-03,\n","           3.5348e-02, -2.7691e-01, -1.4833e-01,  1.3639e-01,  7.6148e-01,\n","           1.0100e-01, -4.5419e-01,  8.2761e-02,  2.9650e-01,  1.6057e-01],\n","         [ 3.0091e-01,  1.5744e-01,  4.4858e-01,  9.5206e-02, -6.7210e-01,\n","          -9.2926e-02, -6.0004e-02, -2.7866e-01, -6.3077e-02,  2.3376e-01,\n","          -2.2981e-02, -5.2111e-02, -2.9425e-02,  1.7792e-01, -1.4984e-02,\n","           2.5385e-02,  1.0317e-01,  3.5367e-02, -2.4259e-01, -2.0004e-02,\n","           2.2576e-01, -9.8207e-02,  3.1511e-01, -1.8928e-03, -1.2241e-01,\n","          -2.6312e-01, -2.7559e-01, -4.0362e-02, -1.0538e-01, -1.8205e-01],\n","         [-3.8333e-02, -1.3197e-01, -3.0389e-01, -1.1665e-01, -3.2271e-04,\n","           1.7129e-02,  4.1207e-04, -1.8165e-06, -3.7978e-02,  4.3800e-01,\n","           2.7020e-01,  9.0042e-02, -1.6705e-01,  4.9125e-02, -4.5594e-06,\n","          -3.2012e-01,  1.5129e-04, -9.6748e-06,  4.7978e-01, -1.1008e-06,\n","           9.6249e-03, -2.7563e-01, -1.2891e-01, -1.1772e-03, -3.5994e-01,\n","          -1.4027e-01, -3.9661e-02,  1.3735e-01, -3.7336e-02, -8.8231e-04],\n","         [-5.0298e-01,  1.6417e-01, -2.5407e-01,  1.1442e-01,  1.4973e-02,\n","          -1.0147e-01,  1.7842e-02,  6.4655e-02,  5.3317e-02, -2.6022e-01,\n","           2.4025e-01, -1.4729e-01,  3.1651e-02,  1.0017e-02,  2.4064e-03,\n","           3.7913e-02,  5.2601e-02, -4.6696e-02,  2.4741e-04,  3.9556e-03,\n","          -6.7142e-02,  3.1955e-02, -1.7413e-01,  3.1532e-02,  2.5992e-01,\n","           6.6922e-02,  4.2831e-02,  4.5729e-01,  1.7880e-01,  4.0295e-01],\n","         [-6.5223e-01,  7.8615e-02, -2.9221e-01, -1.6812e-01,  5.1924e-01,\n","           1.9634e-01,  2.5524e-01, -3.3773e-01, -3.6250e-01,  3.5765e-01,\n","          -2.0992e-01,  1.6928e-02, -1.5454e-02,  5.7535e-02,  3.6397e-02,\n","          -3.8280e-01, -7.5282e-01,  1.5196e-03,  6.4620e-01,  2.2266e-01,\n","          -4.5388e-01,  3.3893e-01, -2.3644e-01,  2.8639e-01,  3.5337e-02,\n","          -1.3401e-01, -5.2628e-01, -2.1448e-01,  7.0732e-02,  7.0328e-01],\n","         [ 9.5341e-02, -1.7877e-01,  1.1296e-01,  1.2520e-01,  1.3019e-01,\n","           6.2422e-01,  3.8577e-01,  4.0012e-01,  6.0232e-01, -2.3571e-01,\n","           2.5678e-01,  1.9470e-01, -1.2193e-01,  2.9211e-01, -3.9464e-04,\n","           1.6804e-01,  4.9213e-01, -1.4884e-02, -3.9771e-01, -1.1770e-01,\n","           6.1630e-02, -4.8565e-01, -4.3758e-02, -5.5648e-02, -1.5309e-01,\n","          -1.5647e-02, -2.1978e-01,  3.9491e-01,  9.5198e-02, -3.4350e-01],\n","         [ 9.1775e-02, -6.5537e-02,  4.2392e-01, -1.5725e-01, -7.7070e-02,\n","          -5.4610e-01, -1.2411e-01, -1.3080e-01,  2.9534e-01,  4.1558e-02,\n","          -1.0211e-01, -5.0872e-01,  6.7746e-02,  4.4086e-02, -2.9322e-04,\n","          -4.3042e-02,  1.3691e-03, -6.0374e-03,  3.4052e-01, -7.6622e-03,\n","           1.7668e-01, -2.6639e-01,  3.2566e-01, -1.2630e-01, -5.7096e-01,\n","           1.8170e-01,  2.8195e-01, -2.5778e-01, -3.0362e-01, -9.3164e-02],\n","         [-4.3656e-01,  3.2681e-01, -2.5440e-01, -1.8811e-01,  3.8971e-01,\n","           1.4980e-01, -1.2276e-01,  2.2233e-01,  2.7457e-01,  1.3311e-02,\n","          -7.3168e-02, -1.3055e-01,  6.9752e-02,  2.0289e-01,  4.8390e-03,\n","           4.2540e-02,  1.4611e-02,  1.0241e-02, -2.0573e-01,  9.0421e-03,\n","          -3.2267e-01,  5.6052e-01, -3.7252e-01,  1.2438e-01,  5.5468e-02,\n","          -4.5992e-01,  8.2997e-03,  3.2850e-01, -8.9922e-02,  2.3193e-01],\n","         [-1.3925e-01, -2.4844e-01, -6.0752e-01, -4.7778e-02,  1.2915e-01,\n","           2.1318e-01, -5.2104e-01,  1.1379e-01,  1.3596e-01,  3.5684e-01,\n","           1.8792e-01, -7.0373e-03,  5.9099e-02,  1.5135e-01,  1.1820e-02,\n","          -3.3743e-02,  2.1822e-02, -9.7780e-02,  6.3134e-01,  5.8588e-02,\n","          -5.1335e-01, -4.1686e-03, -4.8141e-01,  2.1346e-01,  1.5952e-01,\n","           1.5827e-01, -1.1645e-01,  2.4201e-01, -1.1156e-02,  3.0939e-01],\n","         [ 8.8502e-02, -1.1163e-01,  4.2568e-01,  2.6709e-02, -3.2864e-01,\n","           8.1217e-02, -1.1011e-01,  1.7948e-01,  9.9221e-02,  3.5070e-01,\n","           9.7116e-02, -1.4705e-01,  1.2016e-01, -2.1537e-01, -1.4490e-02,\n","          -8.9496e-02,  7.0144e-01,  8.0938e-02,  2.4143e-01, -1.6034e-01,\n","           2.7490e-01, -5.7408e-01,  3.9104e-01, -1.1225e-01,  4.7199e-01,\n","          -1.3729e-02,  2.1907e-02, -8.9975e-02,  1.2451e-01, -3.9331e-01],\n","         [-2.3351e-01, -2.5963e-02, -5.7990e-02,  1.3569e-02, -9.6894e-03,\n","          -1.6127e-01, -3.4257e-01,  3.2755e-03,  4.7772e-01, -6.3169e-02,\n","          -1.5603e-01,  6.1569e-02, -1.1362e-01,  7.7997e-02,  2.3070e-04,\n","          -1.0751e-01, -3.3241e-02, -2.3461e-02, -3.0227e-01,  1.8765e-06,\n","          -2.7574e-01,  4.6144e-02, -1.4112e-02,  1.5517e-01,  2.8199e-01,\n","          -1.7713e-01,  4.0584e-01,  9.0912e-02, -1.5209e-01,  9.6924e-05],\n","         [ 1.7665e-01,  1.4831e-01,  2.8369e-01,  1.2757e-01,  2.4037e-01,\n","           2.8481e-01, -2.2547e-01,  2.7457e-01,  3.3006e-01, -2.4481e-01,\n","           2.2336e-02,  8.4590e-02, -2.4660e-02, -4.3737e-01, -2.0586e-03,\n","           3.9953e-01,  2.1350e-01,  4.9722e-02, -4.9407e-01, -1.4854e-01,\n","           3.5213e-01, -5.5583e-03,  3.9870e-01, -1.8134e-01, -2.9974e-01,\n","           1.5989e-01,  1.8004e-01,  5.7986e-02,  2.6818e-01, -1.5903e-01],\n","         [ 9.2654e-02,  3.3353e-01, -3.3818e-01, -1.6140e-01,  8.1584e-02,\n","           1.5840e-01,  5.2894e-01, -3.2218e-02, -2.0304e-01,  2.0654e-02,\n","           2.7720e-02, -4.4582e-02,  8.2496e-02, -5.4012e-02, -3.0758e-03,\n","           2.5535e-02, -1.9191e-01,  2.8451e-02, -1.8522e-01,  1.5308e-01,\n","           3.8315e-02,  5.6305e-01, -5.1872e-02,  1.2856e-02, -1.9122e-01,\n","           3.9338e-01,  2.3204e-01, -2.4992e-01,  1.5480e-01,  2.2738e-01],\n","         [ 4.1685e-02, -3.5299e-01, -1.9509e-01,  3.0834e-02, -1.0760e-02,\n","           5.5105e-02,  4.4350e-02,  1.8554e-02,  2.6848e-03, -1.5190e-01,\n","           2.0446e-01, -9.7698e-02, -1.8749e-01,  1.5218e-01,  6.4165e-04,\n","           9.8993e-03,  2.0292e-02, -9.2119e-03,  5.0615e-01,  1.8782e-03,\n","           5.6182e-02, -3.1338e-01, -1.8965e-01,  1.3333e-01, -1.8143e-02,\n","          -3.4034e-01, -1.1177e-02,  1.4116e-01,  1.0018e-01, -7.8555e-03],\n","         [ 5.6000e-02, -2.1272e-10,  3.9767e-04, -4.4700e-02,  1.8816e-39,\n","           4.0853e-39, -2.3082e-40, -9.7318e-40, -8.4461e-04, -1.0360e-39,\n","          -1.4410e-39, -1.7284e-02, -2.3408e-02, -2.1227e-02,  2.0858e-39,\n","           1.5876e-39, -2.2136e-03, -1.0430e-39,  2.1490e-39, -1.3229e-40,\n","           6.7788e-02,  5.1916e-08, -1.5505e-03, -7.1841e-02,  1.2716e-39,\n","          -1.7530e-39,  2.8057e-39,  7.5476e-40, -4.1344e-40,  5.8864e-39],\n","         [ 8.1623e-40, -1.9525e-39,  1.6446e-39, -3.0187e-09,  3.2149e-39,\n","           5.9565e-39,  3.6897e-40, -3.5876e-38,  2.7101e-39, -6.1409e-39,\n","          -3.7483e-39, -2.1865e-04, -6.9873e-04,  4.0764e-39, -1.7756e-41,\n","          -1.6650e-39,  5.4067e-40, -9.8553e-40,  6.3672e-39, -7.3117e-38,\n","          -4.7829e-39, -1.2328e-39,  8.4285e-41, -4.0982e-08,  1.6493e-39,\n","           1.9038e-39,  2.8472e-39, -4.0593e-40, -5.3171e-40,  2.3630e-38]],\n","        requires_grad=True), Parameter containing:\n"," tensor([-2.8432e-01,  5.9234e-01, -9.0008e-02, -3.5412e-01, -9.9234e-01,\n","          2.1540e-01,  3.8939e-01, -4.1536e-01, -7.2422e-01,  6.1096e-01,\n","         -2.0880e-01,  5.5659e-01, -2.1991e-01, -1.3701e-01, -3.1705e-39,\n","         -2.4359e-39], requires_grad=True), Parameter containing:\n"," tensor([[-6.3681e-02, -4.8449e-02, -6.3586e-03,  2.5297e-02,  9.4734e-02,\n","          -6.9399e-03,  7.8855e-02, -4.8707e-03, -1.6284e-01, -1.7232e-01,\n","          -1.8392e-01,  8.2747e-02,  2.3962e-01,  1.7831e-01,  3.0197e-02,\n","          -2.1995e-39],\n","         [ 9.4150e-02, -1.8014e-01,  5.8955e-02,  5.8698e-02,  1.2071e-02,\n","           1.3112e-01, -5.7402e-02, -7.6053e-02,  7.7211e-02, -6.5195e-01,\n","          -3.5181e-02, -2.2403e-02, -2.1229e-01,  2.3939e-01,  2.2949e-39,\n","          -2.6386e-38],\n","         [ 2.9954e-01, -9.2536e-02,  1.5944e-01,  1.3779e-01,  3.7058e-01,\n","          -1.5070e-01, -1.6270e-01, -7.8700e-02,  2.2496e-01,  3.0755e-03,\n","           5.5925e-02, -3.3806e-02,  2.2197e-01,  7.3978e-02,  5.5628e-02,\n","           8.7401e-03],\n","         [-2.2965e-01,  9.7447e-02,  1.3305e-01, -2.0226e-01, -8.1174e-02,\n","           1.7744e-01,  1.3421e-01, -8.6750e-02,  1.7639e-01,  9.7940e-02,\n","          -3.5949e-01,  2.9451e-01,  1.3046e-01,  1.4173e-01,  8.8684e-02,\n","          -1.1966e-02],\n","         [ 4.0625e-01, -2.1518e-01, -1.4657e-39, -2.4775e-01,  1.0892e-02,\n","          -9.3838e-01,  1.7595e-01,  4.3564e-01,  7.4495e-02, -4.7411e-02,\n","          -2.3258e-01,  2.2633e-01, -5.8265e-02, -5.0619e-18, -9.7328e-21,\n","           2.7365e-03],\n","         [ 5.0820e-02, -2.7745e-02, -5.5128e-02, -1.9810e-13, -8.5867e-02,\n","          -3.2323e-03, -1.0533e-39,  1.0492e-39, -1.3312e-01, -7.0476e-27,\n","          -1.3018e-01,  6.4464e-02, -1.9173e-03,  4.4490e-02,  2.7347e-39,\n","           1.2500e-39],\n","         [-8.7086e-02, -5.2787e-02,  4.9350e-02,  2.2539e-02,  2.4789e-01,\n","           1.8019e-01, -7.6949e-03, -1.8313e-01, -9.2054e-02, -5.4943e-01,\n","           9.5155e-02,  7.9492e-02,  2.1279e-01,  2.0832e-01,  4.7892e-02,\n","          -6.7200e-27],\n","         [ 3.8873e-02, -5.0817e-02, -1.4268e-01, -7.4167e-02, -2.8227e-01,\n","           5.2649e-02,  2.8785e-03, -1.4103e-01, -9.2791e-02,  1.1757e-01,\n","           6.6182e-03,  1.2436e-02, -9.5645e-02, -2.1466e-02,  1.5951e-39,\n","          -1.1278e-39],\n","         [-1.8528e-01,  1.7918e-01, -1.8343e-01, -1.3853e-01,  1.0355e-01,\n","           1.1963e-01,  1.7407e-01,  1.8224e-01, -2.0043e-01, -2.7810e-01,\n","           5.1250e-02,  1.0279e-01, -1.0027e-01,  1.9745e-01, -1.0466e-01,\n","          -2.0103e-39],\n","         [ 2.0549e-01,  6.5658e-02, -1.3102e-01,  8.5056e-02, -2.4395e-01,\n","           3.1849e-02,  2.6828e-01, -2.4689e-01, -1.4587e-01,  1.8576e-01,\n","          -2.5671e-01,  7.7818e-02, -1.2387e-01, -2.4977e-02,  9.3262e-03,\n","           7.5199e-17],\n","         [-1.8444e-03, -2.2900e-01, -1.4795e-01, -5.2664e-01, -4.6520e-01,\n","           7.1504e-03,  2.4067e-03, -1.2344e-01, -4.9097e-02,  1.4935e-02,\n","           1.5449e-01,  8.0964e-02,  2.4671e-01,  5.4196e-02,  6.4334e-03,\n","          -2.6830e-39],\n","         [ 1.2932e-01, -1.2377e-02, -2.1009e-01,  1.2493e-01, -1.6684e-01,\n","           1.6048e-01,  1.2819e-01,  2.9236e-02, -3.5023e-01,  1.7442e-01,\n","          -8.7945e-02,  2.1084e-01, -9.2592e-02, -2.7955e-01,  9.8007e-33,\n","          -2.7782e-41],\n","         [ 1.4559e-01, -1.1482e-01,  8.7098e-03, -1.1984e-01, -3.4568e-02,\n","          -3.9706e-01, -1.6487e-02,  6.2642e-02,  1.9796e-01, -1.1487e-01,\n","           3.2406e-01,  1.9426e-01,  4.6608e-02, -3.3101e-01, -8.1050e-03,\n","           4.4770e-03],\n","         [-1.4297e-01,  2.8289e-01,  5.6302e-02, -1.2575e-01, -1.1237e-01,\n","           7.2427e-02, -7.5998e-02,  9.7050e-02, -1.3584e-01, -1.2872e-02,\n","           4.6903e-02,  1.6364e-01, -2.0080e-01,  4.1371e-02, -6.6963e-02,\n","          -6.8266e-38],\n","         [-3.4674e-02,  2.2440e-01,  3.1307e-02, -1.0451e-01, -1.3313e-01,\n","          -1.7296e-01, -1.2501e-01, -2.2637e-01, -2.8757e-01,  1.7212e-01,\n","           1.2446e-01,  4.8967e-02, -3.0293e-01, -2.2962e-01, -5.2240e-39,\n","           1.7615e-39],\n","         [-9.2723e-04, -4.2562e-39,  2.0502e-06, -4.8014e-39,  3.1782e-04,\n","          -1.6443e-04, -3.7410e-39, -4.3216e-39, -1.4926e-02, -2.6397e-06,\n","          -6.0599e-04, -2.3104e-04, -6.8412e-03, -2.7218e-39, -5.0867e-39,\n","          -2.7407e-39]], requires_grad=True), Parameter containing:\n"," tensor([ 6.9338e-02, -3.1760e-01, -1.1634e+00,  8.1080e-01, -5.0610e-01,\n","          4.7708e-07, -1.9306e-01, -5.0379e-04,  2.5780e-01,  7.5436e-01,\n","          5.1211e-01,  3.2217e-01, -7.2673e-01,  5.8393e-01,  2.7073e-01,\n","          4.0791e-40], requires_grad=True), Parameter containing:\n"," tensor([[-0.1547, -0.1001, -0.1063,  0.1304, -0.1782,  0.0090, -0.1582, -0.0029,\n","           0.1662,  0.1856,  0.3107,  0.1825, -0.0946,  0.1792,  0.1510, -0.0072]],\n","        requires_grad=True), Parameter containing:\n"," tensor([1.1599], requires_grad=True)]"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UC750PPFa3DQ","executionInfo":{"status":"ok","timestamp":1634668503757,"user_tz":180,"elapsed":31,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"7284241c-a632-4708-ae22-ebe8dd02524d"},"source":["len(params)"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_hM0pJJaKIP","executionInfo":{"status":"ok","timestamp":1634668503758,"user_tz":180,"elapsed":28,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"ab889e04-0fd9-4940-cf96-c87ea5e30719"},"source":["# A posição 0 corresponde aos pesos da conexão da camada de entrada com primeira oculta\n","# 30 -> 16\n","\n","pesos0 = params[0]\n","print(\"Qtd de conexões: \")\n","print(pesos0.shape)\n","print(\"------------\")\n","print(\"Pesos encontrados na conexão da camada de entrada com primeira oculta: \")\n","print(pesos0)"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Qtd de conexões: \n","torch.Size([16, 30])\n","------------\n","Pesos encontrados na conexão da camada de entrada com primeira oculta: \n","Parameter containing:\n","tensor([[-1.5219e-01, -2.8663e-01, -2.7835e-01,  9.7514e-02, -2.5460e-02,\n","          1.3026e-01,  5.4066e-02,  4.5641e-02, -1.3902e-01,  2.2695e-01,\n","          3.7599e-02,  5.3864e-02, -1.2807e-01, -4.9886e-02,  5.1757e-04,\n","         -2.5215e-01, -5.4503e-01, -2.3041e-02,  3.3099e-01,  2.1247e-03,\n","          3.5348e-02, -2.7691e-01, -1.4833e-01,  1.3639e-01,  7.6148e-01,\n","          1.0100e-01, -4.5419e-01,  8.2761e-02,  2.9650e-01,  1.6057e-01],\n","        [ 3.0091e-01,  1.5744e-01,  4.4858e-01,  9.5206e-02, -6.7210e-01,\n","         -9.2926e-02, -6.0004e-02, -2.7866e-01, -6.3077e-02,  2.3376e-01,\n","         -2.2981e-02, -5.2111e-02, -2.9425e-02,  1.7792e-01, -1.4984e-02,\n","          2.5385e-02,  1.0317e-01,  3.5367e-02, -2.4259e-01, -2.0004e-02,\n","          2.2576e-01, -9.8207e-02,  3.1511e-01, -1.8928e-03, -1.2241e-01,\n","         -2.6312e-01, -2.7559e-01, -4.0362e-02, -1.0538e-01, -1.8205e-01],\n","        [-3.8333e-02, -1.3197e-01, -3.0389e-01, -1.1665e-01, -3.2271e-04,\n","          1.7129e-02,  4.1207e-04, -1.8165e-06, -3.7978e-02,  4.3800e-01,\n","          2.7020e-01,  9.0042e-02, -1.6705e-01,  4.9125e-02, -4.5594e-06,\n","         -3.2012e-01,  1.5129e-04, -9.6748e-06,  4.7978e-01, -1.1008e-06,\n","          9.6249e-03, -2.7563e-01, -1.2891e-01, -1.1772e-03, -3.5994e-01,\n","         -1.4027e-01, -3.9661e-02,  1.3735e-01, -3.7336e-02, -8.8231e-04],\n","        [-5.0298e-01,  1.6417e-01, -2.5407e-01,  1.1442e-01,  1.4973e-02,\n","         -1.0147e-01,  1.7842e-02,  6.4655e-02,  5.3317e-02, -2.6022e-01,\n","          2.4025e-01, -1.4729e-01,  3.1651e-02,  1.0017e-02,  2.4064e-03,\n","          3.7913e-02,  5.2601e-02, -4.6696e-02,  2.4741e-04,  3.9556e-03,\n","         -6.7142e-02,  3.1955e-02, -1.7413e-01,  3.1532e-02,  2.5992e-01,\n","          6.6922e-02,  4.2831e-02,  4.5729e-01,  1.7880e-01,  4.0295e-01],\n","        [-6.5223e-01,  7.8615e-02, -2.9221e-01, -1.6812e-01,  5.1924e-01,\n","          1.9634e-01,  2.5524e-01, -3.3773e-01, -3.6250e-01,  3.5765e-01,\n","         -2.0992e-01,  1.6928e-02, -1.5454e-02,  5.7535e-02,  3.6397e-02,\n","         -3.8280e-01, -7.5282e-01,  1.5196e-03,  6.4620e-01,  2.2266e-01,\n","         -4.5388e-01,  3.3893e-01, -2.3644e-01,  2.8639e-01,  3.5337e-02,\n","         -1.3401e-01, -5.2628e-01, -2.1448e-01,  7.0732e-02,  7.0328e-01],\n","        [ 9.5341e-02, -1.7877e-01,  1.1296e-01,  1.2520e-01,  1.3019e-01,\n","          6.2422e-01,  3.8577e-01,  4.0012e-01,  6.0232e-01, -2.3571e-01,\n","          2.5678e-01,  1.9470e-01, -1.2193e-01,  2.9211e-01, -3.9464e-04,\n","          1.6804e-01,  4.9213e-01, -1.4884e-02, -3.9771e-01, -1.1770e-01,\n","          6.1630e-02, -4.8565e-01, -4.3758e-02, -5.5648e-02, -1.5309e-01,\n","         -1.5647e-02, -2.1978e-01,  3.9491e-01,  9.5198e-02, -3.4350e-01],\n","        [ 9.1775e-02, -6.5537e-02,  4.2392e-01, -1.5725e-01, -7.7070e-02,\n","         -5.4610e-01, -1.2411e-01, -1.3080e-01,  2.9534e-01,  4.1558e-02,\n","         -1.0211e-01, -5.0872e-01,  6.7746e-02,  4.4086e-02, -2.9322e-04,\n","         -4.3042e-02,  1.3691e-03, -6.0374e-03,  3.4052e-01, -7.6622e-03,\n","          1.7668e-01, -2.6639e-01,  3.2566e-01, -1.2630e-01, -5.7096e-01,\n","          1.8170e-01,  2.8195e-01, -2.5778e-01, -3.0362e-01, -9.3164e-02],\n","        [-4.3656e-01,  3.2681e-01, -2.5440e-01, -1.8811e-01,  3.8971e-01,\n","          1.4980e-01, -1.2276e-01,  2.2233e-01,  2.7457e-01,  1.3311e-02,\n","         -7.3168e-02, -1.3055e-01,  6.9752e-02,  2.0289e-01,  4.8390e-03,\n","          4.2540e-02,  1.4611e-02,  1.0241e-02, -2.0573e-01,  9.0421e-03,\n","         -3.2267e-01,  5.6052e-01, -3.7252e-01,  1.2438e-01,  5.5468e-02,\n","         -4.5992e-01,  8.2997e-03,  3.2850e-01, -8.9922e-02,  2.3193e-01],\n","        [-1.3925e-01, -2.4844e-01, -6.0752e-01, -4.7778e-02,  1.2915e-01,\n","          2.1318e-01, -5.2104e-01,  1.1379e-01,  1.3596e-01,  3.5684e-01,\n","          1.8792e-01, -7.0373e-03,  5.9099e-02,  1.5135e-01,  1.1820e-02,\n","         -3.3743e-02,  2.1822e-02, -9.7780e-02,  6.3134e-01,  5.8588e-02,\n","         -5.1335e-01, -4.1686e-03, -4.8141e-01,  2.1346e-01,  1.5952e-01,\n","          1.5827e-01, -1.1645e-01,  2.4201e-01, -1.1156e-02,  3.0939e-01],\n","        [ 8.8502e-02, -1.1163e-01,  4.2568e-01,  2.6709e-02, -3.2864e-01,\n","          8.1217e-02, -1.1011e-01,  1.7948e-01,  9.9221e-02,  3.5070e-01,\n","          9.7116e-02, -1.4705e-01,  1.2016e-01, -2.1537e-01, -1.4490e-02,\n","         -8.9496e-02,  7.0144e-01,  8.0938e-02,  2.4143e-01, -1.6034e-01,\n","          2.7490e-01, -5.7408e-01,  3.9104e-01, -1.1225e-01,  4.7199e-01,\n","         -1.3729e-02,  2.1907e-02, -8.9975e-02,  1.2451e-01, -3.9331e-01],\n","        [-2.3351e-01, -2.5963e-02, -5.7990e-02,  1.3569e-02, -9.6894e-03,\n","         -1.6127e-01, -3.4257e-01,  3.2755e-03,  4.7772e-01, -6.3169e-02,\n","         -1.5603e-01,  6.1569e-02, -1.1362e-01,  7.7997e-02,  2.3070e-04,\n","         -1.0751e-01, -3.3241e-02, -2.3461e-02, -3.0227e-01,  1.8765e-06,\n","         -2.7574e-01,  4.6144e-02, -1.4112e-02,  1.5517e-01,  2.8199e-01,\n","         -1.7713e-01,  4.0584e-01,  9.0912e-02, -1.5209e-01,  9.6924e-05],\n","        [ 1.7665e-01,  1.4831e-01,  2.8369e-01,  1.2757e-01,  2.4037e-01,\n","          2.8481e-01, -2.2547e-01,  2.7457e-01,  3.3006e-01, -2.4481e-01,\n","          2.2336e-02,  8.4590e-02, -2.4660e-02, -4.3737e-01, -2.0586e-03,\n","          3.9953e-01,  2.1350e-01,  4.9722e-02, -4.9407e-01, -1.4854e-01,\n","          3.5213e-01, -5.5583e-03,  3.9870e-01, -1.8134e-01, -2.9974e-01,\n","          1.5989e-01,  1.8004e-01,  5.7986e-02,  2.6818e-01, -1.5903e-01],\n","        [ 9.2654e-02,  3.3353e-01, -3.3818e-01, -1.6140e-01,  8.1584e-02,\n","          1.5840e-01,  5.2894e-01, -3.2218e-02, -2.0304e-01,  2.0654e-02,\n","          2.7720e-02, -4.4582e-02,  8.2496e-02, -5.4012e-02, -3.0758e-03,\n","          2.5535e-02, -1.9191e-01,  2.8451e-02, -1.8522e-01,  1.5308e-01,\n","          3.8315e-02,  5.6305e-01, -5.1872e-02,  1.2856e-02, -1.9122e-01,\n","          3.9338e-01,  2.3204e-01, -2.4992e-01,  1.5480e-01,  2.2738e-01],\n","        [ 4.1685e-02, -3.5299e-01, -1.9509e-01,  3.0834e-02, -1.0760e-02,\n","          5.5105e-02,  4.4350e-02,  1.8554e-02,  2.6848e-03, -1.5190e-01,\n","          2.0446e-01, -9.7698e-02, -1.8749e-01,  1.5218e-01,  6.4165e-04,\n","          9.8993e-03,  2.0292e-02, -9.2119e-03,  5.0615e-01,  1.8782e-03,\n","          5.6182e-02, -3.1338e-01, -1.8965e-01,  1.3333e-01, -1.8143e-02,\n","         -3.4034e-01, -1.1177e-02,  1.4116e-01,  1.0018e-01, -7.8555e-03],\n","        [ 5.6000e-02, -2.1272e-10,  3.9767e-04, -4.4700e-02,  1.8816e-39,\n","          4.0853e-39, -2.3082e-40, -9.7318e-40, -8.4461e-04, -1.0360e-39,\n","         -1.4410e-39, -1.7284e-02, -2.3408e-02, -2.1227e-02,  2.0858e-39,\n","          1.5876e-39, -2.2136e-03, -1.0430e-39,  2.1490e-39, -1.3229e-40,\n","          6.7788e-02,  5.1916e-08, -1.5505e-03, -7.1841e-02,  1.2716e-39,\n","         -1.7530e-39,  2.8057e-39,  7.5476e-40, -4.1344e-40,  5.8864e-39],\n","        [ 8.1623e-40, -1.9525e-39,  1.6446e-39, -3.0187e-09,  3.2149e-39,\n","          5.9565e-39,  3.6897e-40, -3.5876e-38,  2.7101e-39, -6.1409e-39,\n","         -3.7483e-39, -2.1865e-04, -6.9873e-04,  4.0764e-39, -1.7756e-41,\n","         -1.6650e-39,  5.4067e-40, -9.8553e-40,  6.3672e-39, -7.3117e-38,\n","         -4.7829e-39, -1.2328e-39,  8.4285e-41, -4.0982e-08,  1.6493e-39,\n","          1.9038e-39,  2.8472e-39, -4.0593e-40, -5.3171e-40,  2.3630e-38]],\n","       requires_grad=True)\n"]}]},{"cell_type":"code","metadata":{"id":"1i-_BJutk45N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634668503758,"user_tz":180,"elapsed":26,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"d65ba982-7f11-4a5d-af50-97845e5cbb6c"},"source":["# A posição do params 1 corresponderá ao bias do viés que foi colocado em nossa conexão\n","# 16 \n","bias0 = params[1]\n","\n","# São colocados 1 bias enviezando cada um dos neurônios\n","print(\"Qtd de bias: \")\n","print(bias0.shape)\n","print(\"Pesos dos bias: \")\n","print(bias0)"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Qtd de bias: \n","torch.Size([16])\n","Pesos dos bias: \n","Parameter containing:\n","tensor([-2.8432e-01,  5.9234e-01, -9.0008e-02, -3.5412e-01, -9.9234e-01,\n","         2.1540e-01,  3.8939e-01, -4.1536e-01, -7.2422e-01,  6.1096e-01,\n","        -2.0880e-01,  5.5659e-01, -2.1991e-01, -1.3701e-01, -3.1705e-39,\n","        -2.4359e-39], requires_grad=True)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4ZwFwltcYAg","executionInfo":{"status":"ok","timestamp":1634668503761,"user_tz":180,"elapsed":26,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"be548130-7259-4290-baa3-9f8b4ff6cf1c"},"source":["# A posição 2 do params serão os pesos das conexões da primeira camada oculta com a segunda\n","# 16 -> 16\n","\n","pesos1 = params[2]\n","print(\"Qtd de conexões: \")\n","print(pesos1.shape)\n","print(\"Pesos das conexões: \")\n","print(pesos1)"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Qtd de conexões: \n","torch.Size([16, 16])\n","Pesos das conexões: \n","Parameter containing:\n","tensor([[-6.3681e-02, -4.8449e-02, -6.3586e-03,  2.5297e-02,  9.4734e-02,\n","         -6.9399e-03,  7.8855e-02, -4.8707e-03, -1.6284e-01, -1.7232e-01,\n","         -1.8392e-01,  8.2747e-02,  2.3962e-01,  1.7831e-01,  3.0197e-02,\n","         -2.1995e-39],\n","        [ 9.4150e-02, -1.8014e-01,  5.8955e-02,  5.8698e-02,  1.2071e-02,\n","          1.3112e-01, -5.7402e-02, -7.6053e-02,  7.7211e-02, -6.5195e-01,\n","         -3.5181e-02, -2.2403e-02, -2.1229e-01,  2.3939e-01,  2.2949e-39,\n","         -2.6386e-38],\n","        [ 2.9954e-01, -9.2536e-02,  1.5944e-01,  1.3779e-01,  3.7058e-01,\n","         -1.5070e-01, -1.6270e-01, -7.8700e-02,  2.2496e-01,  3.0755e-03,\n","          5.5925e-02, -3.3806e-02,  2.2197e-01,  7.3978e-02,  5.5628e-02,\n","          8.7401e-03],\n","        [-2.2965e-01,  9.7447e-02,  1.3305e-01, -2.0226e-01, -8.1174e-02,\n","          1.7744e-01,  1.3421e-01, -8.6750e-02,  1.7639e-01,  9.7940e-02,\n","         -3.5949e-01,  2.9451e-01,  1.3046e-01,  1.4173e-01,  8.8684e-02,\n","         -1.1966e-02],\n","        [ 4.0625e-01, -2.1518e-01, -1.4657e-39, -2.4775e-01,  1.0892e-02,\n","         -9.3838e-01,  1.7595e-01,  4.3564e-01,  7.4495e-02, -4.7411e-02,\n","         -2.3258e-01,  2.2633e-01, -5.8265e-02, -5.0619e-18, -9.7328e-21,\n","          2.7365e-03],\n","        [ 5.0820e-02, -2.7745e-02, -5.5128e-02, -1.9810e-13, -8.5867e-02,\n","         -3.2323e-03, -1.0533e-39,  1.0492e-39, -1.3312e-01, -7.0476e-27,\n","         -1.3018e-01,  6.4464e-02, -1.9173e-03,  4.4490e-02,  2.7347e-39,\n","          1.2500e-39],\n","        [-8.7086e-02, -5.2787e-02,  4.9350e-02,  2.2539e-02,  2.4789e-01,\n","          1.8019e-01, -7.6949e-03, -1.8313e-01, -9.2054e-02, -5.4943e-01,\n","          9.5155e-02,  7.9492e-02,  2.1279e-01,  2.0832e-01,  4.7892e-02,\n","         -6.7200e-27],\n","        [ 3.8873e-02, -5.0817e-02, -1.4268e-01, -7.4167e-02, -2.8227e-01,\n","          5.2649e-02,  2.8785e-03, -1.4103e-01, -9.2791e-02,  1.1757e-01,\n","          6.6182e-03,  1.2436e-02, -9.5645e-02, -2.1466e-02,  1.5951e-39,\n","         -1.1278e-39],\n","        [-1.8528e-01,  1.7918e-01, -1.8343e-01, -1.3853e-01,  1.0355e-01,\n","          1.1963e-01,  1.7407e-01,  1.8224e-01, -2.0043e-01, -2.7810e-01,\n","          5.1250e-02,  1.0279e-01, -1.0027e-01,  1.9745e-01, -1.0466e-01,\n","         -2.0103e-39],\n","        [ 2.0549e-01,  6.5658e-02, -1.3102e-01,  8.5056e-02, -2.4395e-01,\n","          3.1849e-02,  2.6828e-01, -2.4689e-01, -1.4587e-01,  1.8576e-01,\n","         -2.5671e-01,  7.7818e-02, -1.2387e-01, -2.4977e-02,  9.3262e-03,\n","          7.5199e-17],\n","        [-1.8444e-03, -2.2900e-01, -1.4795e-01, -5.2664e-01, -4.6520e-01,\n","          7.1504e-03,  2.4067e-03, -1.2344e-01, -4.9097e-02,  1.4935e-02,\n","          1.5449e-01,  8.0964e-02,  2.4671e-01,  5.4196e-02,  6.4334e-03,\n","         -2.6830e-39],\n","        [ 1.2932e-01, -1.2377e-02, -2.1009e-01,  1.2493e-01, -1.6684e-01,\n","          1.6048e-01,  1.2819e-01,  2.9236e-02, -3.5023e-01,  1.7442e-01,\n","         -8.7945e-02,  2.1084e-01, -9.2592e-02, -2.7955e-01,  9.8007e-33,\n","         -2.7782e-41],\n","        [ 1.4559e-01, -1.1482e-01,  8.7098e-03, -1.1984e-01, -3.4568e-02,\n","         -3.9706e-01, -1.6487e-02,  6.2642e-02,  1.9796e-01, -1.1487e-01,\n","          3.2406e-01,  1.9426e-01,  4.6608e-02, -3.3101e-01, -8.1050e-03,\n","          4.4770e-03],\n","        [-1.4297e-01,  2.8289e-01,  5.6302e-02, -1.2575e-01, -1.1237e-01,\n","          7.2427e-02, -7.5998e-02,  9.7050e-02, -1.3584e-01, -1.2872e-02,\n","          4.6903e-02,  1.6364e-01, -2.0080e-01,  4.1371e-02, -6.6963e-02,\n","         -6.8266e-38],\n","        [-3.4674e-02,  2.2440e-01,  3.1307e-02, -1.0451e-01, -1.3313e-01,\n","         -1.7296e-01, -1.2501e-01, -2.2637e-01, -2.8757e-01,  1.7212e-01,\n","          1.2446e-01,  4.8967e-02, -3.0293e-01, -2.2962e-01, -5.2240e-39,\n","          1.7615e-39],\n","        [-9.2723e-04, -4.2562e-39,  2.0502e-06, -4.8014e-39,  3.1782e-04,\n","         -1.6443e-04, -3.7410e-39, -4.3216e-39, -1.4926e-02, -2.6397e-06,\n","         -6.0599e-04, -2.3104e-04, -6.8412e-03, -2.7218e-39, -5.0867e-39,\n","         -2.7407e-39]], requires_grad=True)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R9dDgkL6dmqq","executionInfo":{"status":"ok","timestamp":1634668503761,"user_tz":180,"elapsed":24,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"c728a476-5498-4df0-ec92-a0766f50eea2"},"source":["# O params[3] na sequência será o bias da 2º camada oculta\n","# 16\n","\n","bias1 = params[3]\n","print(\"Qtd de bias enviezando a camada: \")\n","print(bias1.shape)\n","print(\"Pesos bias: \")\n","print(bias1)"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Qtd de bias enviezando a camada: \n","torch.Size([16])\n","Pesos bias: \n","Parameter containing:\n","tensor([ 6.9338e-02, -3.1760e-01, -1.1634e+00,  8.1080e-01, -5.0610e-01,\n","         4.7708e-07, -1.9306e-01, -5.0379e-04,  2.5780e-01,  7.5436e-01,\n","         5.1211e-01,  3.2217e-01, -7.2673e-01,  5.8393e-01,  2.7073e-01,\n","         4.0791e-40], requires_grad=True)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XGDSwbAGd8cY","executionInfo":{"status":"ok","timestamp":1634668503762,"user_tz":180,"elapsed":22,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"23c226de-33df-471d-d150-72d539e26227"},"source":["# O params[4] indica o peso das conexões da 2º oculta com a camada de saída\n","# 16 -> 1\n","\n","pesos2 = params[4]\n","print(\"Qtd de conexões: \")\n","print(pesos2.shape)\n","print(\"Pesos: \")\n","print(pesos2)"],"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Qtd de conexões: \n","torch.Size([1, 16])\n","Pesos: \n","Parameter containing:\n","tensor([[-0.1547, -0.1001, -0.1063,  0.1304, -0.1782,  0.0090, -0.1582, -0.0029,\n","          0.1662,  0.1856,  0.3107,  0.1825, -0.0946,  0.1792,  0.1510, -0.0072]],\n","       requires_grad=True)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFkIEVxXeL3G","executionInfo":{"status":"ok","timestamp":1634668503762,"user_tz":180,"elapsed":20,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"d161b581-dd09-4594-f3a0-1cee3c17d4f9"},"source":["# O params[5] indica o bias da camada de saída\n","# 1\n","\n","bias3 = params[5]\n","print(\"Qtd de bias: \")\n","print(bias3.shape)\n","print(\"Peso bias: \")\n","print(bias3)"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Qtd de bias: \n","torch.Size([1])\n","Peso bias: \n","Parameter containing:\n","tensor([1.1599], requires_grad=True)\n"]}]},{"cell_type":"markdown","metadata":{"id":"AyTjLzELSdQF"},"source":["## Etapa 7: Avaliação do modelo"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A24CrCp6gs_o","executionInfo":{"status":"ok","timestamp":1634668503763,"user_tz":180,"elapsed":20,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"04af4d94-02da-4962-dd43-d1f47a858145"},"source":["rede_neural.eval()"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=30, out_features=16, bias=True)\n","  (1): ReLU()\n","  (2): Linear(in_features=16, out_features=16, bias=True)\n","  (3): ReLU()\n","  (4): Linear(in_features=16, out_features=1, bias=True)\n","  (5): Sigmoid()\n",")"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FKpY-LF3gvOX","executionInfo":{"status":"ok","timestamp":1634668503763,"user_tz":180,"elapsed":18,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"56fa8d26-0797-455c-bfe4-05a318b8f336"},"source":["type(previsores_teste)"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pandas.core.frame.DataFrame"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"FhDrCMXKgzco","executionInfo":{"status":"ok","timestamp":1634668590046,"user_tz":180,"elapsed":340,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}}},"source":["previsores_teste = torch.tensor(np.array(previsores_teste), dtype=torch.float)"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EP6nJ7cW1WUC","executionInfo":{"status":"ok","timestamp":1634668608918,"user_tz":180,"elapsed":416,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"593c8fee-ea3a-4c88-a864-513ae7ea8df6"},"source":["type(previsores_teste)"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Tensor"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"EQUwiz6f1ZIm","executionInfo":{"status":"ok","timestamp":1634668768082,"user_tz":180,"elapsed":344,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}}},"source":["# Para que possamos fazer matriz de confusão e verificar acurácia, \n","# previsamos instanciar a rede dando um forward() nos previsores de teste\n","\n","# O código a seguir retoranará a probabilidade sigmoid\n","previsoes = rede_neural.forward(previsores_teste)"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6cc2VCu1cci","executionInfo":{"status":"ok","timestamp":1634668772631,"user_tz":180,"elapsed":4,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"f0d3fc95-7eaf-42f5-e2f3-c79a4583498a"},"source":["previsoes"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[9.9888e-01],\n","        [1.0000e+00],\n","        [4.6478e-01],\n","        [9.9988e-01],\n","        [3.0534e-07],\n","        [8.3659e-01],\n","        [9.8567e-01],\n","        [1.0000e+00],\n","        [6.2798e-01],\n","        [9.1996e-01],\n","        [9.9470e-01],\n","        [9.9998e-01],\n","        [1.5480e-06],\n","        [9.9970e-01],\n","        [9.9991e-01],\n","        [9.4866e-01],\n","        [9.9995e-01],\n","        [1.0000e+00],\n","        [4.1580e-01],\n","        [1.0000e+00],\n","        [1.0280e-09],\n","        [3.6484e-06],\n","        [4.6095e-01],\n","        [1.0000e+00],\n","        [8.7034e-01],\n","        [5.0372e-03],\n","        [9.9951e-01],\n","        [1.0000e+00],\n","        [1.2245e-06],\n","        [9.9997e-01],\n","        [1.3550e-01],\n","        [1.0000e+00],\n","        [9.6781e-01],\n","        [9.9599e-01],\n","        [8.1900e-01],\n","        [9.9995e-01],\n","        [4.3892e-01],\n","        [1.0000e+00],\n","        [9.9999e-01],\n","        [1.0475e-04],\n","        [4.8550e-03],\n","        [9.7630e-01],\n","        [8.9874e-07],\n","        [1.6105e-01],\n","        [7.2443e-08],\n","        [8.8065e-01],\n","        [2.4250e-05],\n","        [0.0000e+00],\n","        [7.8821e-01],\n","        [5.2571e-03],\n","        [9.9961e-01],\n","        [8.2905e-21],\n","        [9.9481e-01],\n","        [9.9965e-01],\n","        [9.9971e-01],\n","        [1.6187e-01],\n","        [9.9995e-01],\n","        [7.5448e-08],\n","        [1.0047e-12],\n","        [9.9918e-01],\n","        [4.8390e-05],\n","        [9.9975e-01],\n","        [9.9997e-01],\n","        [9.9981e-01],\n","        [6.8880e-01],\n","        [9.9139e-11],\n","        [1.0000e+00],\n","        [1.0000e+00],\n","        [1.0000e+00],\n","        [7.3566e-01],\n","        [1.0000e+00],\n","        [9.9986e-01],\n","        [7.2709e-02],\n","        [9.7968e-01],\n","        [7.5049e-04],\n","        [9.9945e-01],\n","        [9.8764e-01],\n","        [1.9988e-10],\n","        [6.8553e-09],\n","        [4.5122e-02],\n","        [9.9762e-01],\n","        [3.3465e-08],\n","        [3.0680e-07],\n","        [9.9987e-01],\n","        [1.0000e+00],\n","        [1.0000e+00],\n","        [4.9259e-02],\n","        [9.9961e-01],\n","        [8.2349e-04],\n","        [2.8785e-01],\n","        [2.2268e-03],\n","        [9.9691e-01],\n","        [1.0000e+00],\n","        [4.7824e-04],\n","        [9.9983e-01],\n","        [1.0000e+00],\n","        [9.9999e-01],\n","        [1.0000e+00],\n","        [7.1832e-05],\n","        [1.0000e+00],\n","        [1.0000e+00],\n","        [1.0000e+00],\n","        [9.9801e-01],\n","        [9.9898e-01],\n","        [9.8746e-01],\n","        [1.0000e+00],\n","        [1.0000e+00],\n","        [9.9996e-01],\n","        [1.0000e+00],\n","        [9.9996e-01],\n","        [1.0000e+00],\n","        [1.0000e+00],\n","        [8.0346e-01],\n","        [1.2247e-11],\n","        [7.5468e-01],\n","        [3.4275e-05],\n","        [9.9999e-01],\n","        [8.7703e-04],\n","        [9.9995e-01],\n","        [9.9990e-01],\n","        [4.8534e-01],\n","        [9.9268e-01],\n","        [1.0000e+00],\n","        [1.0000e+00],\n","        [2.7894e-13],\n","        [9.9987e-01],\n","        [1.6913e-04],\n","        [1.3506e-02],\n","        [1.0000e+00],\n","        [9.9739e-01],\n","        [1.9877e-20],\n","        [9.9996e-01],\n","        [1.0000e+00],\n","        [4.4734e-04],\n","        [2.3863e-18],\n","        [9.9890e-01],\n","        [9.9874e-01],\n","        [9.9928e-01],\n","        [5.5584e-02],\n","        [2.5244e-06],\n","        [1.2070e-05],\n","        [9.9942e-01],\n","        [2.9279e-12]], grad_fn=<SigmoidBackward>)"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DdEBBSX32URq","executionInfo":{"status":"ok","timestamp":1634668828396,"user_tz":180,"elapsed":396,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"ae7f0d1d-6971-4f21-f2da-db2661ad6cbd"},"source":["# Verificaremos a possibilidade acima de 0.5\n","previsoes = np.array(previsoes > 0.5)\n","previsoes"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [False],\n","       [False],\n","       [False],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [False],\n","       [False],\n","       [ True],\n","       [False],\n","       [False],\n","       [False],\n","       [ True],\n","       [False],\n","       [False],\n","       [ True],\n","       [False],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [False],\n","       [False],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [False],\n","       [False],\n","       [False],\n","       [ True],\n","       [False],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [False],\n","       [False],\n","       [False],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [False],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [False],\n","       [False],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [False],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [False],\n","       [False],\n","       [ True],\n","       [False]])"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"bKNPFAdH2tH6","executionInfo":{"status":"ok","timestamp":1634668841945,"user_tz":180,"elapsed":670,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"ad4c9eb3-3180-4e7c-9e4d-bfc81e11776b"},"source":["classe_teste"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>333</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>273</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>201</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>178</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>230</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>282</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>535</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>436</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>236</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>143 rows × 1 columns</p>\n","</div>"],"text/plain":["     0\n","333  1\n","273  1\n","201  0\n","178  1\n","85   0\n","..  ..\n","230  0\n","282  0\n","535  0\n","436  1\n","236  0\n","\n","[143 rows x 1 columns]"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7eZ9pyeX2wKa","executionInfo":{"status":"ok","timestamp":1634668869490,"user_tz":180,"elapsed":500,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"03a3b99a-c5cf-4e98-f42f-982573ac8ef9"},"source":["taxa_acerto = accuracy_score(classe_teste, previsoes)\n","taxa_acerto"],"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8881118881118881"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9TBhVYRb23OK","executionInfo":{"status":"ok","timestamp":1634668896265,"user_tz":180,"elapsed":439,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"fba11d15-1b69-4ef4-a30b-9544b5e5e274"},"source":["matriz_confusao = confusion_matrix(classe_teste, previsoes)\n","matriz_confusao"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[45,  9],\n","       [ 7, 82]])"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"LjIhyogt29mJ","executionInfo":{"status":"ok","timestamp":1634668924864,"user_tz":180,"elapsed":447,"user":{"displayName":"Nicolas Marcos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597892784849901748"}},"outputId":"a776df34-ed63-4def-bc0b-66223622d4fe"},"source":["sns.heatmap(matriz_confusao, annot=True);"],"execution_count":58,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]}]}