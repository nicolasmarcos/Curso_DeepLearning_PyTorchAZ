{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MEU Projeto #3 Classificação binária breast cancer com tuning de parâmetros.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_RSER5Lkb5"
      },
      "source": [
        "# Projeto 3: Classificação binária brest cancer com tuning dos parâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tP2BcEILoLB"
      },
      "source": [
        "## Etapa 1: Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGW4fwZmkw6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfcf252c-04f0-47d6-c4d9-9f130b98e7e6"
      },
      "source": [
        "!pip install skorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skorch\n",
            "  Downloading skorch-0.11.0-py3-none-any.whl (155 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 30 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 40 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 51 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 61 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 71 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 81 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 92 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 102 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 112 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 122 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 133 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 143 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 153 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 155 kB 11.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.62.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.19.5)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.1.0)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf0FpJ35Lf-Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5cabf4fc-aa99-4c6c-98f3-146d78aa1c25"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from skorch import NeuralNetBinaryClassifier \n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0SD4dJ4MDMN"
      },
      "source": [
        "## Etapa 2: Base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9aIu62WMGo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "259a6095-e6a9-4a5e-81d4-9521e820dddd"
      },
      "source": [
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd7b912fd10>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u49yuDE9MJs6"
      },
      "source": [
        "previsores = pd.read_csv('/content/entradas_breast.csv')\n",
        "classe = pd.read_csv('/content/saidas_breast.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fQ_cVSei2Bp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff0b0e4-aa3b-4c5a-c21a-00eba04088b8"
      },
      "source": [
        "previsores.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "7qx_Bw3OApYi",
        "outputId": "2bd55a73-2b89-4e29-ba84-95e642a8aaa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave_points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1095.0000</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8589.0</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3398.0</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4585.0</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1156.0000</td>\n",
              "      <td>3445.0</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.0000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5438.0</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>205.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    radius_mean   texture_mean  ...   symmetry_worst   fractal_dimension_worst\n",
              "0         17.99          10.38  ...           0.4601                   0.11890\n",
              "1         20.57          17.77  ...         275.0000                   0.08902\n",
              "2         19.69          21.25  ...           0.3613                   0.08758\n",
              "3         11.42          20.38  ...           0.6638                 173.00000\n",
              "4         20.29          14.34  ...           0.2364                   0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6taWVK8i_PW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d582201-448e-400b-c625-e9fbf9c01900"
      },
      "source": [
        "classe.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeQ3eYXfjByQ"
      },
      "source": [
        "# Precisamos converter de pandas para numpy que é o formato aceito pelo pytorch\n",
        "\n",
        "previsores = np.array(previsores, dtype='float32')\n",
        "classe = np.array(classe, dtype='float32').squeeze(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJBL30K6BSxj",
        "outputId": "b95f976c-3612-45dd-8301-b052b273008e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
              "       1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "       1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
              "       0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
              "       1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MI0xnzWjSJg"
      },
      "source": [
        "## Etapa 3: Classe para estrutura da rede neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5WkE5vmQjjX"
      },
      "source": [
        "# Aqui instanciamos a rede neural\n",
        "# É necessário invocar o nn.Module \n",
        "class classificador_torch(nn.Module):\n",
        "  # Vamos passar listas de parâmetros e o gridSearch escolherá o melhor resultado\n",
        "  # activation será a lista de funções de ativação q usaremos\n",
        "  # neurons qtd de neurônios\n",
        "  # Initializer é o inicializador dos pesos\n",
        "  def __init__(self, activation, neurons, initializer):\n",
        "    super().__init__()\n",
        "    # 30 -> 16 -> 16 -> 1\n",
        "    self.dense0 = nn.Linear(30, neurons)\n",
        "    initializer(self.dense0.weight)\n",
        "    self.activation0 = activation\n",
        "    self.dense1 = nn.Linear(neurons, neurons)\n",
        "    initializer(self.dense1.weight)\n",
        "    self.activation1 = activation\n",
        "    self.dense2 = nn.Linear(neurons, 1)\n",
        "    initializer(self.dense2.weight)\n",
        "    self.output = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.dense0(X)\n",
        "    X = self.activation0(X)\n",
        "    X = self.dense1(X)\n",
        "    X = self.activation1(X)\n",
        "    X = self.dense2(X)\n",
        "    X = self.output(X)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kstsTBpKj3yO"
      },
      "source": [
        "## Etapa 4: Skorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXdmN9NxSGQo"
      },
      "source": [
        "# Vamos instanciar a rede em que no module passaremos nossa função\n",
        "classificador_sklearn = NeuralNetBinaryClassifier(module = classificador_torch, lr = 0.001, optimizer__weight_decay = 0.0001, train_split = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzxX25OfpQsc"
      },
      "source": [
        "## Etapa 5: Tuning dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjDt9Ob5SwH4"
      },
      "source": [
        "# Precisamos instanciar uma variável no formato de dicionário com os campos que queremos fazer o gridSearch\n",
        "\n",
        "params = {'batch_size': [10,30],\n",
        "          'max_epochs':[50,100],\n",
        "          'optimizer': [torch.optim.Adam, torch.optim.SGD], # SGD é a descida estocástica clássica\n",
        "          'criterion': [torch.nn.BCELoss, torch.nn.HingeEmbeddingLoss],\n",
        "          'module__activation': [F.relu, F.tanh],\n",
        "          'module__neurons': [8,16],\n",
        "          'module__initializer': [torch.nn.init.uniform_, torch.nn.init.normal_]\n",
        "    \n",
        "\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'batch_size': [10],\n",
        "          'max_epochs': [100],\n",
        "          'optimizer': [torch.optim.Adam, torch.optim.SGD],\n",
        "          'criterion': [torch.nn.BCELoss], #, torch.nn.HingeEmbeddingLoss],\n",
        "          'module__activation': [F.relu, F.tanh],\n",
        "          'module__neurons': [8, 16], \n",
        "          'module__initializer': [torch.nn.init.uniform]} # _, torch.nn.init.normal_]}"
      ],
      "metadata": {
        "id": "4P3FYaqVLpRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A melhor estratégia é testar cada um dos parâmetros um por um para saber a melhor combinação de valores. Ou seja, testa primeiro o melhor batch_size, depois o melhor max_epochs..."
      ],
      "metadata": {
        "id": "x6GdTr5JIOiL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ6R_ve1UKDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb633465-a497-4bc8-a807-eff30d327f53"
      },
      "source": [
        "params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': [10, 30],\n",
              " 'criterion': [torch.nn.modules.loss.BCELoss,\n",
              "  torch.nn.modules.loss.HingeEmbeddingLoss],\n",
              " 'max_epochs': [50, 100],\n",
              " 'module__activation': [<function torch.nn.functional.relu>,\n",
              "  <function torch.nn.functional.tanh>],\n",
              " 'module__initializer': [<function torch.nn.init.uniform_>,\n",
              "  <function torch.nn.init.normal_>],\n",
              " 'module__neurons': [8, 16],\n",
              " 'optimizer': [torch.optim.adam.Adam, torch.optim.sgd.SGD]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL_8ya40UMy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a3fbc6-6d0b-4fee-c253-6f9a62b41d00"
      },
      "source": [
        "# Vamos instanciar o objeto gridSearch\n",
        "grid_search = GridSearchCV(estimator=classificador_sklearn, param_grid = params, scoring = 'accuracy', cv = 10)\n",
        "\n",
        "# Agora damos o fit\n",
        "grid_search = grid_search.fit(previsores, classe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.2908\n",
            "      2       37.1094  0.0715\n",
            "      3       37.1094  0.0699\n",
            "      4       37.1094  0.0695\n",
            "      5       37.1094  0.0697\n",
            "      6       37.1094  0.0832\n",
            "      7       37.1094  0.0696\n",
            "      8       37.1094  0.0751\n",
            "      9       37.1094  0.0711\n",
            "     10       37.1094  0.0706\n",
            "     11       37.1094  0.0699\n",
            "     12       37.1094  0.0714\n",
            "     13       37.1094  0.0759\n",
            "     14       37.1094  0.0701\n",
            "     15       37.1094  0.0699\n",
            "     16       37.1094  0.0707\n",
            "     17       37.1094  0.0751\n",
            "     18       37.1094  0.0714\n",
            "     19       37.1094  0.0739\n",
            "     20       37.1094  0.0705\n",
            "     21       37.1094  0.0706\n",
            "     22       \u001b[36m13.5593\u001b[0m  0.0769\n",
            "     23        \u001b[36m0.6080\u001b[0m  0.0731\n",
            "     24        \u001b[36m0.5856\u001b[0m  0.0728\n",
            "     25        \u001b[36m0.5634\u001b[0m  0.0716\n",
            "     26        \u001b[36m0.5449\u001b[0m  0.0778\n",
            "     27        \u001b[36m0.5280\u001b[0m  0.0764\n",
            "     28        \u001b[36m0.5103\u001b[0m  0.0651\n",
            "     29        \u001b[36m0.4914\u001b[0m  0.0741\n",
            "     30        \u001b[36m0.4733\u001b[0m  0.0706\n",
            "     31        \u001b[36m0.4508\u001b[0m  0.0719\n",
            "     32        \u001b[36m0.4090\u001b[0m  0.0702\n",
            "     33        0.4203  0.0700\n",
            "     34        \u001b[36m0.3990\u001b[0m  0.0802\n",
            "     35        \u001b[36m0.3747\u001b[0m  0.0713\n",
            "     36        \u001b[36m0.3564\u001b[0m  0.0696\n",
            "     37        \u001b[36m0.3399\u001b[0m  0.0695\n",
            "     38        \u001b[36m0.3270\u001b[0m  0.0704\n",
            "     39        \u001b[36m0.3118\u001b[0m  0.0760\n",
            "     40        \u001b[36m0.3063\u001b[0m  0.0763\n",
            "     41        \u001b[36m0.2920\u001b[0m  0.0808\n",
            "     42        \u001b[36m0.2906\u001b[0m  0.0794\n",
            "     43        \u001b[36m0.2833\u001b[0m  0.0722\n",
            "     44        \u001b[36m0.2740\u001b[0m  0.0701\n",
            "     45        \u001b[36m0.2709\u001b[0m  0.0689\n",
            "     46        \u001b[36m0.2548\u001b[0m  0.0666\n",
            "     47        \u001b[36m0.2535\u001b[0m  0.0684\n",
            "     48        \u001b[36m0.2397\u001b[0m  0.0709\n",
            "     49        0.2472  0.0745\n",
            "     50        0.2462  0.0775\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0665\n",
            "      2       37.1094  0.0723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.1094  0.0720\n",
            "      4       37.1094  0.0774\n",
            "      5       37.1094  0.0697\n",
            "      6       37.1094  0.0699\n",
            "      7       37.1094  0.0718\n",
            "      8       37.1094  0.0771\n",
            "      9       37.1094  0.0736\n",
            "     10       37.1094  0.0728\n",
            "     11       37.1094  0.0716\n",
            "     12       37.1094  0.0723\n",
            "     13       37.1094  0.0718\n",
            "     14       37.1094  0.0722\n",
            "     15       37.1094  0.0713\n",
            "     16       37.1094  0.0861\n",
            "     17       37.1094  0.0792\n",
            "     18       37.1094  0.0692\n",
            "     19       37.1094  0.0699\n",
            "     20       37.1094  0.0697\n",
            "     21       \u001b[36m23.9451\u001b[0m  0.0717\n",
            "     22        \u001b[36m0.5928\u001b[0m  0.0701\n",
            "     23        \u001b[36m0.5412\u001b[0m  0.0759\n",
            "     24        \u001b[36m0.5097\u001b[0m  0.0762\n",
            "     25        \u001b[36m0.5010\u001b[0m  0.0725\n",
            "     26        \u001b[36m0.4902\u001b[0m  0.0686\n",
            "     27        \u001b[36m0.4865\u001b[0m  0.0705\n",
            "     28        \u001b[36m0.4632\u001b[0m  0.0711\n",
            "     29        \u001b[36m0.4465\u001b[0m  0.0716\n",
            "     30        \u001b[36m0.4157\u001b[0m  0.0709\n",
            "     31        \u001b[36m0.3892\u001b[0m  0.0766\n",
            "     32        0.3969  0.0691\n",
            "     33        \u001b[36m0.3617\u001b[0m  0.0749\n",
            "     34        \u001b[36m0.3490\u001b[0m  0.0694\n",
            "     35        \u001b[36m0.3474\u001b[0m  0.0700\n",
            "     36        \u001b[36m0.3454\u001b[0m  0.0734\n",
            "     37        \u001b[36m0.3220\u001b[0m  0.0688\n",
            "     38        \u001b[36m0.3055\u001b[0m  0.0683\n",
            "     39        \u001b[36m0.2982\u001b[0m  0.0710\n",
            "     40        \u001b[36m0.2858\u001b[0m  0.0680\n",
            "     41        \u001b[36m0.2759\u001b[0m  0.0778\n",
            "     42        \u001b[36m0.2655\u001b[0m  0.0734\n",
            "     43        \u001b[36m0.2580\u001b[0m  0.0742\n",
            "     44        \u001b[36m0.2486\u001b[0m  0.0740\n",
            "     45        \u001b[36m0.2455\u001b[0m  0.0800\n",
            "     46        \u001b[36m0.2394\u001b[0m  0.0703\n",
            "     47        \u001b[36m0.2364\u001b[0m  0.0706\n",
            "     48        \u001b[36m0.2343\u001b[0m  0.0715\n",
            "     49        \u001b[36m0.2290\u001b[0m  0.0777\n",
            "     50        \u001b[36m0.2259\u001b[0m  0.0764\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0678\n",
            "      2       37.3047  0.0727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0723\n",
            "      4       37.3047  0.0671\n",
            "      5       37.3047  0.0697\n",
            "      6       37.3047  0.0681\n",
            "      7       37.3047  0.0682\n",
            "      8       37.3047  0.0740\n",
            "      9       37.3047  0.0682\n",
            "     10       37.3047  0.0687\n",
            "     11       37.3047  0.0676\n",
            "     12       37.3047  0.0681\n",
            "     13       37.3047  0.0692\n",
            "     14       37.3047  0.0659\n",
            "     15       37.3047  0.0738\n",
            "     16       37.3047  0.0687\n",
            "     17       37.3047  0.0758\n",
            "     18       37.3047  0.0679\n",
            "     19       37.3047  0.0715\n",
            "     20       \u001b[36m12.3071\u001b[0m  0.0701\n",
            "     21        \u001b[36m0.6852\u001b[0m  0.0672\n",
            "     22        \u001b[36m0.6808\u001b[0m  0.0689\n",
            "     23        \u001b[36m0.6776\u001b[0m  0.0793\n",
            "     24        \u001b[36m0.6751\u001b[0m  0.0705\n",
            "     25        \u001b[36m0.6732\u001b[0m  0.0692\n",
            "     26        \u001b[36m0.6716\u001b[0m  0.0718\n",
            "     27        \u001b[36m0.6703\u001b[0m  0.0780\n",
            "     28        \u001b[36m0.6692\u001b[0m  0.0718\n",
            "     29        \u001b[36m0.6682\u001b[0m  0.0707\n",
            "     30        \u001b[36m0.6674\u001b[0m  0.0715\n",
            "     31        \u001b[36m0.6667\u001b[0m  0.0693\n",
            "     32        \u001b[36m0.6661\u001b[0m  0.0725\n",
            "     33        \u001b[36m0.6655\u001b[0m  0.0684\n",
            "     34        \u001b[36m0.6650\u001b[0m  0.0688\n",
            "     35        \u001b[36m0.6646\u001b[0m  0.0749\n",
            "     36        \u001b[36m0.6642\u001b[0m  0.0834\n",
            "     37        \u001b[36m0.6639\u001b[0m  0.0791\n",
            "     38        \u001b[36m0.6636\u001b[0m  0.0709\n",
            "     39        \u001b[36m0.6633\u001b[0m  0.0737\n",
            "     40        \u001b[36m0.6630\u001b[0m  0.0698\n",
            "     41        \u001b[36m0.6628\u001b[0m  0.0683\n",
            "     42        \u001b[36m0.6626\u001b[0m  0.0694\n",
            "     43        \u001b[36m0.6624\u001b[0m  0.0687\n",
            "     44        \u001b[36m0.6622\u001b[0m  0.0752\n",
            "     45        \u001b[36m0.6621\u001b[0m  0.0692\n",
            "     46        \u001b[36m0.6619\u001b[0m  0.0714\n",
            "     47        \u001b[36m0.6618\u001b[0m  0.0695\n",
            "     48        \u001b[36m0.6617\u001b[0m  0.0704\n",
            "     49        \u001b[36m0.6616\u001b[0m  0.0692\n",
            "     50        \u001b[36m0.6614\u001b[0m  0.0765\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0676\n",
            "      2       37.3047  0.0705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0759\n",
            "      4       37.3047  0.0686\n",
            "      5       37.3047  0.0709\n",
            "      6       37.3047  0.0787\n",
            "      7       37.3047  0.0714\n",
            "      8       37.3047  0.0705\n",
            "      9       37.3047  0.0710\n",
            "     10       37.3047  0.0692\n",
            "     11       37.3047  0.0688\n",
            "     12       37.3047  0.0695\n",
            "     13       37.3047  0.0721\n",
            "     14       37.3047  0.0777\n",
            "     15       37.3047  0.0688\n",
            "     16       37.3047  0.0707\n",
            "     17       37.3047  0.0686\n",
            "     18       37.3047  0.0792\n",
            "     19       37.3047  0.0708\n",
            "     20       37.3047  0.0697\n",
            "     21       37.3047  0.0694\n",
            "     22       37.3047  0.0702\n",
            "     23       \u001b[36m10.2067\u001b[0m  0.0717\n",
            "     24        \u001b[36m0.5958\u001b[0m  0.0726\n",
            "     25        \u001b[36m0.5756\u001b[0m  0.0697\n",
            "     26        \u001b[36m0.5633\u001b[0m  0.0689\n",
            "     27        \u001b[36m0.5510\u001b[0m  0.0674\n",
            "     28        \u001b[36m0.5393\u001b[0m  0.0789\n",
            "     29        \u001b[36m0.5279\u001b[0m  0.0689\n",
            "     30        \u001b[36m0.5160\u001b[0m  0.0734\n",
            "     31        \u001b[36m0.5045\u001b[0m  0.0793\n",
            "     32        \u001b[36m0.4897\u001b[0m  0.0696\n",
            "     33        \u001b[36m0.4740\u001b[0m  0.0710\n",
            "     34        \u001b[36m0.4597\u001b[0m  0.0698\n",
            "     35        \u001b[36m0.4434\u001b[0m  0.0701\n",
            "     36        \u001b[36m0.4244\u001b[0m  0.0717\n",
            "     37        \u001b[36m0.4085\u001b[0m  0.0692\n",
            "     38        \u001b[36m0.3958\u001b[0m  0.0703\n",
            "     39        \u001b[36m0.3838\u001b[0m  0.0704\n",
            "     40        \u001b[36m0.3701\u001b[0m  0.0693\n",
            "     41        \u001b[36m0.3615\u001b[0m  0.0732\n",
            "     42        \u001b[36m0.3451\u001b[0m  0.0760\n",
            "     43        \u001b[36m0.3354\u001b[0m  0.0699\n",
            "     44        \u001b[36m0.3127\u001b[0m  0.0696\n",
            "     45        0.3304  0.0702\n",
            "     46        \u001b[36m0.2996\u001b[0m  0.0701\n",
            "     47        \u001b[36m0.2983\u001b[0m  0.0739\n",
            "     48        \u001b[36m0.2939\u001b[0m  0.0706\n",
            "     49        \u001b[36m0.2874\u001b[0m  0.0796\n",
            "     50        \u001b[36m0.2848\u001b[0m  0.0728\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0667\n",
            "      2       37.3047  0.0727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0727\n",
            "      4       37.3047  0.0689\n",
            "      5       37.3047  0.0793\n",
            "      6       37.3047  0.0707\n",
            "      7       37.3047  0.0700\n",
            "      8       37.3047  0.0784\n",
            "      9       37.3047  0.0687\n",
            "     10       37.3047  0.0761\n",
            "     11       37.3047  0.0699\n",
            "     12       37.3047  0.0707\n",
            "     13       37.3047  0.0717\n",
            "     14       37.3047  0.0739\n",
            "     15       37.3047  0.0702\n",
            "     16       37.3047  0.0683\n",
            "     17       37.3047  0.0702\n",
            "     18       37.3047  0.0697\n",
            "     19       \u001b[36m16.4160\u001b[0m  0.0793\n",
            "     20        \u001b[36m0.6181\u001b[0m  0.0698\n",
            "     21        \u001b[36m0.5818\u001b[0m  0.0762\n",
            "     22        \u001b[36m0.5568\u001b[0m  0.0720\n",
            "     23        0.5593  0.0725\n",
            "     24        \u001b[36m0.4925\u001b[0m  0.0767\n",
            "     25        0.4965  0.0725\n",
            "     26        \u001b[36m0.4507\u001b[0m  0.0738\n",
            "     27        \u001b[36m0.4452\u001b[0m  0.0697\n",
            "     28        \u001b[36m0.4308\u001b[0m  0.0707\n",
            "     29        \u001b[36m0.4166\u001b[0m  0.0745\n",
            "     30        \u001b[36m0.3958\u001b[0m  0.0702\n",
            "     31        \u001b[36m0.3793\u001b[0m  0.0702\n",
            "     32        \u001b[36m0.3664\u001b[0m  0.0821\n",
            "     33        \u001b[36m0.3583\u001b[0m  0.0730\n",
            "     34        \u001b[36m0.3449\u001b[0m  0.0708\n",
            "     35        \u001b[36m0.3400\u001b[0m  0.0733\n",
            "     36        \u001b[36m0.3281\u001b[0m  0.0714\n",
            "     37        \u001b[36m0.3186\u001b[0m  0.0776\n",
            "     38        \u001b[36m0.3104\u001b[0m  0.0794\n",
            "     39        \u001b[36m0.3034\u001b[0m  0.0686\n",
            "     40        \u001b[36m0.2960\u001b[0m  0.0735\n",
            "     41        \u001b[36m0.2890\u001b[0m  0.0755\n",
            "     42        \u001b[36m0.2834\u001b[0m  0.0721\n",
            "     43        \u001b[36m0.2790\u001b[0m  0.0718\n",
            "     44        \u001b[36m0.2725\u001b[0m  0.0712\n",
            "     45        \u001b[36m0.2714\u001b[0m  0.0696\n",
            "     46        \u001b[36m0.2690\u001b[0m  0.0792\n",
            "     47        \u001b[36m0.2652\u001b[0m  0.0711\n",
            "     48        \u001b[36m0.2621\u001b[0m  0.0702\n",
            "     49        \u001b[36m0.2606\u001b[0m  0.0787\n",
            "     50        \u001b[36m0.2557\u001b[0m  0.0709\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0673\n",
            "      2       37.3047  0.0789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0778\n",
            "      4       37.3047  0.0716\n",
            "      5       37.3047  0.0699\n",
            "      6       37.3047  0.0691\n",
            "      7       37.3047  0.0684\n",
            "      8       37.3047  0.0672\n",
            "      9       37.3047  0.0761\n",
            "     10       37.3047  0.0678\n",
            "     11       37.3047  0.0789\n",
            "     12       37.3047  0.0679\n",
            "     13       37.3047  0.0693\n",
            "     14       37.3047  0.0709\n",
            "     15       37.3047  0.0725\n",
            "     16       37.3047  0.0713\n",
            "     17       37.3047  0.0691\n",
            "     18       37.3047  0.0704\n",
            "     19       37.3047  0.0688\n",
            "     20       37.3047  0.0702\n",
            "     21       \u001b[36m19.9621\u001b[0m  0.0674\n",
            "     22        \u001b[36m0.6884\u001b[0m  0.0682\n",
            "     23        \u001b[36m0.6253\u001b[0m  0.0764\n",
            "     24        \u001b[36m0.6055\u001b[0m  0.0669\n",
            "     25        \u001b[36m0.5749\u001b[0m  0.0679\n",
            "     26        \u001b[36m0.5520\u001b[0m  0.0670\n",
            "     27        \u001b[36m0.5418\u001b[0m  0.0756\n",
            "     28        \u001b[36m0.5323\u001b[0m  0.0679\n",
            "     29        \u001b[36m0.5231\u001b[0m  0.0701\n",
            "     30        \u001b[36m0.5113\u001b[0m  0.0812\n",
            "     31        \u001b[36m0.5006\u001b[0m  0.0690\n",
            "     32        \u001b[36m0.4861\u001b[0m  0.0848\n",
            "     33        \u001b[36m0.4621\u001b[0m  0.0703\n",
            "     34        \u001b[36m0.4386\u001b[0m  0.0699\n",
            "     35        \u001b[36m0.3948\u001b[0m  0.0699\n",
            "     36        \u001b[36m0.3689\u001b[0m  0.0701\n",
            "     37        0.3708  0.0763\n",
            "     38        \u001b[36m0.3605\u001b[0m  0.0743\n",
            "     39        \u001b[36m0.3486\u001b[0m  0.0798\n",
            "     40        \u001b[36m0.3480\u001b[0m  0.0722\n",
            "     41        0.3503  0.0729\n",
            "     42        0.3690  0.0722\n",
            "     43        \u001b[36m0.3413\u001b[0m  0.0742\n",
            "     44        \u001b[36m0.3410\u001b[0m  0.0698\n",
            "     45        \u001b[36m0.3253\u001b[0m  0.0699\n",
            "     46        \u001b[36m0.3163\u001b[0m  0.0712\n",
            "     47        \u001b[36m0.3103\u001b[0m  0.0690\n",
            "     48        \u001b[36m0.3062\u001b[0m  0.0695\n",
            "     49        \u001b[36m0.2950\u001b[0m  0.0689\n",
            "     50        0.2956  0.0703\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0762\n",
            "      2       37.3047  0.0703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0753\n",
            "      4       37.3047  0.0748\n",
            "      5       37.3047  0.0700\n",
            "      6       37.3047  0.0689\n",
            "      7       37.3047  0.0705\n",
            "      8       37.3047  0.0704\n",
            "      9       37.3047  0.0716\n",
            "     10       37.3047  0.0685\n",
            "     11       37.3047  0.0692\n",
            "     12       37.3047  0.0693\n",
            "     13       37.3047  0.0689\n",
            "     14       37.3047  0.0799\n",
            "     15       37.3047  0.0662\n",
            "     16       37.3047  0.0731\n",
            "     17       37.3047  0.0707\n",
            "     18       \u001b[36m31.3002\u001b[0m  0.0709\n",
            "     19        \u001b[36m0.7999\u001b[0m  0.0684\n",
            "     20        \u001b[36m0.5418\u001b[0m  0.0717\n",
            "     21        \u001b[36m0.5263\u001b[0m  0.0685\n",
            "     22        \u001b[36m0.5115\u001b[0m  0.0694\n",
            "     23        \u001b[36m0.4748\u001b[0m  0.0733\n",
            "     24        \u001b[36m0.4548\u001b[0m  0.0672\n",
            "     25        \u001b[36m0.4322\u001b[0m  0.0676\n",
            "     26        \u001b[36m0.4098\u001b[0m  0.0671\n",
            "     27        \u001b[36m0.3896\u001b[0m  0.0673\n",
            "     28        \u001b[36m0.3692\u001b[0m  0.0747\n",
            "     29        \u001b[36m0.3539\u001b[0m  0.0679\n",
            "     30        \u001b[36m0.3413\u001b[0m  0.0792\n",
            "     31        \u001b[36m0.3282\u001b[0m  0.0691\n",
            "     32        \u001b[36m0.3155\u001b[0m  0.0744\n",
            "     33        \u001b[36m0.3044\u001b[0m  0.0725\n",
            "     34        \u001b[36m0.2952\u001b[0m  0.0747\n",
            "     35        \u001b[36m0.2856\u001b[0m  0.0696\n",
            "     36        \u001b[36m0.2751\u001b[0m  0.0700\n",
            "     37        \u001b[36m0.2689\u001b[0m  0.0717\n",
            "     38        \u001b[36m0.2608\u001b[0m  0.0708\n",
            "     39        \u001b[36m0.2545\u001b[0m  0.0762\n",
            "     40        \u001b[36m0.2495\u001b[0m  0.0708\n",
            "     41        \u001b[36m0.2433\u001b[0m  0.0690\n",
            "     42        \u001b[36m0.2378\u001b[0m  0.0847\n",
            "     43        \u001b[36m0.2325\u001b[0m  0.0694\n",
            "     44        \u001b[36m0.2302\u001b[0m  0.0683\n",
            "     45        \u001b[36m0.2230\u001b[0m  0.0688\n",
            "     46        \u001b[36m0.2156\u001b[0m  0.0725\n",
            "     47        \u001b[36m0.2121\u001b[0m  0.0716\n",
            "     48        \u001b[36m0.2072\u001b[0m  0.0668\n",
            "     49        \u001b[36m0.2046\u001b[0m  0.0675\n",
            "     50        \u001b[36m0.2007\u001b[0m  0.0689\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0637\n",
            "      2       37.3047  0.0702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0780\n",
            "      4       37.3047  0.0686\n",
            "      5       37.3047  0.0751\n",
            "      6       37.3047  0.0730\n",
            "      7       37.3047  0.0689\n",
            "      8       37.3047  0.0708\n",
            "      9       37.3047  0.0683\n",
            "     10       37.3047  0.0704\n",
            "     11       37.3047  0.0729\n",
            "     12       37.3047  0.0678\n",
            "     13       37.3047  0.0729\n",
            "     14       37.3047  0.0711\n",
            "     15       37.3047  0.0726\n",
            "     16       37.3047  0.0727\n",
            "     17       37.3047  0.0731\n",
            "     18       37.3047  0.0727\n",
            "     19       37.3047  0.0731\n",
            "     20       \u001b[36m17.0807\u001b[0m  0.0850\n",
            "     21        \u001b[36m0.5698\u001b[0m  0.0767\n",
            "     22        \u001b[36m0.5295\u001b[0m  0.0719\n",
            "     23        \u001b[36m0.5089\u001b[0m  0.0706\n",
            "     24        \u001b[36m0.4939\u001b[0m  0.0740\n",
            "     25        \u001b[36m0.4819\u001b[0m  0.0685\n",
            "     26        \u001b[36m0.4685\u001b[0m  0.0666\n",
            "     27        \u001b[36m0.4557\u001b[0m  0.0705\n",
            "     28        \u001b[36m0.4444\u001b[0m  0.0710\n",
            "     29        \u001b[36m0.4336\u001b[0m  0.0768\n",
            "     30        \u001b[36m0.4219\u001b[0m  0.0708\n",
            "     31        \u001b[36m0.4162\u001b[0m  0.0700\n",
            "     32        \u001b[36m0.4048\u001b[0m  0.0698\n",
            "     33        \u001b[36m0.3980\u001b[0m  0.0869\n",
            "     34        \u001b[36m0.3871\u001b[0m  0.0711\n",
            "     35        \u001b[36m0.3809\u001b[0m  0.0712\n",
            "     36        \u001b[36m0.3695\u001b[0m  0.0701\n",
            "     37        \u001b[36m0.3647\u001b[0m  0.0694\n",
            "     38        \u001b[36m0.3603\u001b[0m  0.0713\n",
            "     39        \u001b[36m0.3502\u001b[0m  0.0750\n",
            "     40        \u001b[36m0.3476\u001b[0m  0.0707\n",
            "     41        \u001b[36m0.3417\u001b[0m  0.0705\n",
            "     42        \u001b[36m0.3311\u001b[0m  0.0671\n",
            "     43        \u001b[36m0.3290\u001b[0m  0.0694\n",
            "     44        \u001b[36m0.3261\u001b[0m  0.0709\n",
            "     45        \u001b[36m0.3216\u001b[0m  0.0789\n",
            "     46        \u001b[36m0.3167\u001b[0m  0.0671\n",
            "     47        \u001b[36m0.3112\u001b[0m  0.0766\n",
            "     48        \u001b[36m0.3074\u001b[0m  0.0692\n",
            "     49        \u001b[36m0.3057\u001b[0m  0.0748\n",
            "     50        \u001b[36m0.3040\u001b[0m  0.0713\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0702\n",
            "      2       37.3047  0.0649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0733\n",
            "      4       37.3047  0.0679\n",
            "      5       37.3047  0.0670\n",
            "      6       37.3047  0.0676\n",
            "      7       37.3047  0.0690\n",
            "      8       37.3047  0.0670\n",
            "      9       37.3047  0.0688\n",
            "     10       37.3047  0.0726\n",
            "     11       37.3047  0.0749\n",
            "     12       37.3047  0.0710\n",
            "     13       37.3047  0.0704\n",
            "     14       37.3047  0.0700\n",
            "     15       37.3047  0.0727\n",
            "     16       37.3047  0.0680\n",
            "     17       37.3047  0.0693\n",
            "     18       37.3047  0.0705\n",
            "     19       37.3047  0.0727\n",
            "     20       37.3047  0.0700\n",
            "     21       37.3047  0.0699\n",
            "     22       37.3047  0.0732\n",
            "     23       \u001b[36m20.4670\u001b[0m  0.0689\n",
            "     24        \u001b[36m0.5644\u001b[0m  0.0760\n",
            "     25        \u001b[36m0.5454\u001b[0m  0.0896\n",
            "     26        \u001b[36m0.5347\u001b[0m  0.0703\n",
            "     27        \u001b[36m0.5178\u001b[0m  0.0697\n",
            "     28        \u001b[36m0.5047\u001b[0m  0.0718\n",
            "     29        \u001b[36m0.4945\u001b[0m  0.0767\n",
            "     30        \u001b[36m0.4838\u001b[0m  0.0694\n",
            "     31        \u001b[36m0.4770\u001b[0m  0.0698\n",
            "     32        \u001b[36m0.4663\u001b[0m  0.0685\n",
            "     33        \u001b[36m0.4493\u001b[0m  0.0747\n",
            "     34        \u001b[36m0.4392\u001b[0m  0.0703\n",
            "     35        \u001b[36m0.4307\u001b[0m  0.0680\n",
            "     36        \u001b[36m0.4200\u001b[0m  0.0724\n",
            "     37        \u001b[36m0.4087\u001b[0m  0.0756\n",
            "     38        \u001b[36m0.3960\u001b[0m  0.0794\n",
            "     39        \u001b[36m0.3830\u001b[0m  0.0714\n",
            "     40        \u001b[36m0.3703\u001b[0m  0.0689\n",
            "     41        \u001b[36m0.3606\u001b[0m  0.0695\n",
            "     42        \u001b[36m0.3497\u001b[0m  0.0733\n",
            "     43        \u001b[36m0.3433\u001b[0m  0.0694\n",
            "     44        \u001b[36m0.3381\u001b[0m  0.0707\n",
            "     45        \u001b[36m0.3328\u001b[0m  0.0673\n",
            "     46        \u001b[36m0.3278\u001b[0m  0.0793\n",
            "     47        \u001b[36m0.3225\u001b[0m  0.0722\n",
            "     48        \u001b[36m0.3187\u001b[0m  0.0726\n",
            "     49        \u001b[36m0.3136\u001b[0m  0.0704\n",
            "     50        \u001b[36m0.3100\u001b[0m  0.0697\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.2320\u001b[0m  0.0668\n",
            "      2       37.2320  0.0874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.2320  0.0758\n",
            "      4       37.2320  0.0727\n",
            "      5       37.2320  0.0778\n",
            "      6       37.2320  0.0704\n",
            "      7       37.2320  0.0688\n",
            "      8       37.2320  0.0691\n",
            "      9       37.2320  0.0721\n",
            "     10       37.2320  0.0693\n",
            "     11       37.2320  0.0748\n",
            "     12       37.2320  0.0743\n",
            "     13       37.2320  0.0707\n",
            "     14       37.2320  0.0756\n",
            "     15       37.2320  0.0852\n",
            "     16       37.2320  0.0740\n",
            "     17       37.2320  0.0712\n",
            "     18       \u001b[36m23.1795\u001b[0m  0.0745\n",
            "     19        \u001b[36m1.7471\u001b[0m  0.0691\n",
            "     20        \u001b[36m0.6410\u001b[0m  0.0699\n",
            "     21        \u001b[36m0.6015\u001b[0m  0.0711\n",
            "     22        \u001b[36m0.5432\u001b[0m  0.0717\n",
            "     23        \u001b[36m0.5170\u001b[0m  0.0759\n",
            "     24        \u001b[36m0.4971\u001b[0m  0.0720\n",
            "     25        \u001b[36m0.4827\u001b[0m  0.0706\n",
            "     26        \u001b[36m0.4659\u001b[0m  0.0758\n",
            "     27        \u001b[36m0.4542\u001b[0m  0.0740\n",
            "     28        \u001b[36m0.4419\u001b[0m  0.0725\n",
            "     29        \u001b[36m0.4330\u001b[0m  0.0792\n",
            "     30        \u001b[36m0.4212\u001b[0m  0.0706\n",
            "     31        \u001b[36m0.4091\u001b[0m  0.0713\n",
            "     32        \u001b[36m0.3983\u001b[0m  0.0689\n",
            "     33        \u001b[36m0.3914\u001b[0m  0.0731\n",
            "     34        \u001b[36m0.3810\u001b[0m  0.0676\n",
            "     35        \u001b[36m0.3744\u001b[0m  0.0686\n",
            "     36        \u001b[36m0.3658\u001b[0m  0.0692\n",
            "     37        \u001b[36m0.3597\u001b[0m  0.0682\n",
            "     38        \u001b[36m0.3532\u001b[0m  0.0705\n",
            "     39        \u001b[36m0.3479\u001b[0m  0.0673\n",
            "     40        \u001b[36m0.3390\u001b[0m  0.0684\n",
            "     41        \u001b[36m0.3343\u001b[0m  0.0672\n",
            "     42        \u001b[36m0.3301\u001b[0m  0.0684\n",
            "     43        \u001b[36m0.3263\u001b[0m  0.0822\n",
            "     44        \u001b[36m0.3182\u001b[0m  0.0704\n",
            "     45        \u001b[36m0.3141\u001b[0m  0.0733\n",
            "     46        \u001b[36m0.3091\u001b[0m  0.0687\n",
            "     47        \u001b[36m0.3062\u001b[0m  0.0695\n",
            "     48        \u001b[36m0.2996\u001b[0m  0.0743\n",
            "     49        \u001b[36m0.2930\u001b[0m  0.0691\n",
            "     50        \u001b[36m0.2896\u001b[0m  0.0705\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0513\n",
            "      2       37.1094  0.0573\n",
            "      3       37.1094  0.0547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.1094  0.0586\n",
            "      5       37.1094  0.0551\n",
            "      6       37.1094  0.0623\n",
            "      7       37.1094  0.0561\n",
            "      8       37.1094  0.0633\n",
            "      9       37.1094  0.0554\n",
            "     10       37.1094  0.0617\n",
            "     11       37.1094  0.0594\n",
            "     12       37.1094  0.0555\n",
            "     13       37.1094  0.0544\n",
            "     14       37.1094  0.0564\n",
            "     15       37.1094  0.0547\n",
            "     16       37.1094  0.0563\n",
            "     17       37.1094  0.0561\n",
            "     18       37.1094  0.0544\n",
            "     19       37.1094  0.0546\n",
            "     20       37.1094  0.0547\n",
            "     21       37.1094  0.0637\n",
            "     22       37.1094  0.0601\n",
            "     23       37.1094  0.0564\n",
            "     24       37.1094  0.0546\n",
            "     25       37.1094  0.0614\n",
            "     26       37.1094  0.0565\n",
            "     27       37.1094  0.0554\n",
            "     28       37.1094  0.0605\n",
            "     29       37.1094  0.0556\n",
            "     30       37.1094  0.0558\n",
            "     31       37.1094  0.0553\n",
            "     32       37.1094  0.0550\n",
            "     33       37.1094  0.0626\n",
            "     34       37.1094  0.0553\n",
            "     35       37.1094  0.0560\n",
            "     36       37.1094  0.0557\n",
            "     37       37.1094  0.0554\n",
            "     38       37.1094  0.0548\n",
            "     39       37.1094  0.0582\n",
            "     40       37.1094  0.0552\n",
            "     41       37.1094  0.0623\n",
            "     42       37.1094  0.0641\n",
            "     43       37.1094  0.0551\n",
            "     44       37.1094  0.0631\n",
            "     45       37.1094  0.0555\n",
            "     46       37.1094  0.0575\n",
            "     47       37.1094  0.0541\n",
            "     48       37.1094  0.0599\n",
            "     49       37.1094  0.0567\n",
            "     50       37.1094  0.0543\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0506\n",
            "      2       37.1094  0.0545\n",
            "      3       37.1094  0.0537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.1094  0.0596\n",
            "      5       37.1094  0.0602\n",
            "      6       37.1094  0.0627\n",
            "      7       37.1094  0.0545\n",
            "      8       37.1094  0.0541\n",
            "      9       37.1094  0.0610\n",
            "     10       37.1094  0.0563\n",
            "     11       37.1094  0.0569\n",
            "     12       37.1094  0.0537\n",
            "     13       37.1094  0.0552\n",
            "     14       37.1094  0.0549\n",
            "     15       37.1094  0.0548\n",
            "     16       37.1094  0.0578\n",
            "     17       37.1094  0.0604\n",
            "     18       37.1094  0.0572\n",
            "     19       37.1094  0.0543\n",
            "     20       37.1094  0.0563\n",
            "     21       37.1094  0.0541\n",
            "     22       37.1094  0.0640\n",
            "     23       37.1094  0.0546\n",
            "     24       37.1094  0.0555\n",
            "     25       37.1094  0.0562\n",
            "     26       37.1094  0.0623\n",
            "     27       37.1094  0.0595\n",
            "     28       37.1094  0.0639\n",
            "     29       37.1094  0.0541\n",
            "     30       37.1094  0.0545\n",
            "     31       37.1094  0.0531\n",
            "     32       37.1094  0.0554\n",
            "     33       37.1094  0.0556\n",
            "     34       37.1094  0.0546\n",
            "     35       37.1094  0.0540\n",
            "     36       37.1094  0.0593\n",
            "     37       37.1094  0.0671\n",
            "     38       37.1094  0.0540\n",
            "     39       37.1094  0.0589\n",
            "     40       37.1094  0.0539\n",
            "     41       37.1094  0.0544\n",
            "     42       37.1094  0.0548\n",
            "     43       37.1094  0.0559\n",
            "     44       37.1094  0.0576\n",
            "     45       37.1094  0.0567\n",
            "     46       37.1094  0.0555\n",
            "     47       37.1094  0.0560\n",
            "     48       37.1094  0.0557\n",
            "     49       37.1094  0.0599\n",
            "     50       37.1094  0.0601\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0520\n",
            "      2       37.3047  0.0573\n",
            "      3       37.3047  0.0554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0598\n",
            "      5       37.3047  0.0550\n",
            "      6       37.3047  0.0550\n",
            "      7       37.3047  0.0640\n",
            "      8       37.3047  0.0575\n",
            "      9       37.3047  0.0596\n",
            "     10       37.3047  0.0561\n",
            "     11       37.3047  0.0689\n",
            "     12       37.3047  0.0548\n",
            "     13       37.3047  0.0564\n",
            "     14       37.3047  0.0543\n",
            "     15       37.3047  0.0555\n",
            "     16       37.3047  0.0558\n",
            "     17       37.3047  0.0559\n",
            "     18       37.3047  0.0548\n",
            "     19       37.3047  0.0564\n",
            "     20       37.3047  0.0553\n",
            "     21       37.3047  0.0562\n",
            "     22       37.3047  0.0604\n",
            "     23       37.3047  0.0559\n",
            "     24       37.3047  0.0566\n",
            "     25       37.3047  0.0555\n",
            "     26       37.3047  0.0544\n",
            "     27       37.3047  0.0557\n",
            "     28       37.3047  0.0673\n",
            "     29       37.3047  0.0567\n",
            "     30       37.3047  0.0556\n",
            "     31       37.3047  0.0564\n",
            "     32       37.3047  0.0632\n",
            "     33       37.3047  0.0546\n",
            "     34       37.3047  0.0555\n",
            "     35       37.3047  0.0554\n",
            "     36       37.3047  0.0563\n",
            "     37       37.3047  0.0562\n",
            "     38       37.3047  0.0637\n",
            "     39       37.3047  0.0536\n",
            "     40       37.3047  0.0571\n",
            "     41       37.3047  0.0550\n",
            "     42       37.3047  0.0549\n",
            "     43       37.3047  0.0587\n",
            "     44       37.3047  0.0568\n",
            "     45       37.3047  0.0639\n",
            "     46       37.3047  0.0551\n",
            "     47       37.3047  0.0530\n",
            "     48       37.3047  0.0543\n",
            "     49       37.3047  0.0544\n",
            "     50       37.3047  0.0582\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0533\n",
            "      2       37.3047  0.0547\n",
            "      3       37.3047  0.0576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0571\n",
            "      5       37.3047  0.0548\n",
            "      6       37.3047  0.0580\n",
            "      7       37.3047  0.0539\n",
            "      8       37.3047  0.0623\n",
            "      9       37.3047  0.0545\n",
            "     10       37.3047  0.0579\n",
            "     11       37.3047  0.0565\n",
            "     12       37.3047  0.0625\n",
            "     13       37.3047  0.0558\n",
            "     14       37.3047  0.0571\n",
            "     15       37.3047  0.0543\n",
            "     16       37.3047  0.0564\n",
            "     17       37.3047  0.0568\n",
            "     18       37.3047  0.0543\n",
            "     19       37.3047  0.0559\n",
            "     20       37.3047  0.0545\n",
            "     21       37.3047  0.0538\n",
            "     22       37.3047  0.0545\n",
            "     23       37.3047  0.0654\n",
            "     24       37.3047  0.0572\n",
            "     25       37.3047  0.0593\n",
            "     26       37.3047  0.0562\n",
            "     27       37.3047  0.0621\n",
            "     28       37.3047  0.0584\n",
            "     29       37.3047  0.0655\n",
            "     30       37.3047  0.0660\n",
            "     31       37.3047  0.0551\n",
            "     32       37.3047  0.0546\n",
            "     33       37.3047  0.0564\n",
            "     34       37.3047  0.0537\n",
            "     35       37.3047  0.0576\n",
            "     36       37.3047  0.0546\n",
            "     37       37.3047  0.0542\n",
            "     38       37.3047  0.0613\n",
            "     39       37.3047  0.0555\n",
            "     40       37.3047  0.0582\n",
            "     41       37.3047  0.0551\n",
            "     42       37.3047  0.0565\n",
            "     43       37.3047  0.0571\n",
            "     44       37.3047  0.0558\n",
            "     45       37.3047  0.0569\n",
            "     46       37.3047  0.0586\n",
            "     47       37.3047  0.0612\n",
            "     48       37.3047  0.0559\n",
            "     49       37.3047  0.0620\n",
            "     50       37.3047  0.0575\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0523\n",
            "      2       37.3047  0.0574\n",
            "      3       37.3047  0.0559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0604\n",
            "      5       37.3047  0.0561\n",
            "      6       37.3047  0.0551\n",
            "      7       37.3047  0.0557\n",
            "      8       37.3047  0.0592\n",
            "      9       37.3047  0.0642\n",
            "     10       37.3047  0.0553\n",
            "     11       37.3047  0.0571\n",
            "     12       37.3047  0.0584\n",
            "     13       37.3047  0.0589\n",
            "     14       37.3047  0.0621\n",
            "     15       37.3047  0.0560\n",
            "     16       37.3047  0.0730\n",
            "     17       37.3047  0.0575\n",
            "     18       37.3047  0.0602\n",
            "     19       37.3047  0.0608\n",
            "     20       37.3047  0.0568\n",
            "     21       37.3047  0.0550\n",
            "     22       37.3047  0.0570\n",
            "     23       37.3047  0.0652\n",
            "     24       37.3047  0.0599\n",
            "     25       37.3047  0.0569\n",
            "     26       37.3047  0.0583\n",
            "     27       37.3047  0.0547\n",
            "     28       37.3047  0.0634\n",
            "     29       37.3047  0.0552\n",
            "     30       37.3047  0.0619\n",
            "     31       37.3047  0.0548\n",
            "     32       37.3047  0.0526\n",
            "     33       37.3047  0.0580\n",
            "     34       37.3047  0.0535\n",
            "     35       37.3047  0.0547\n",
            "     36       37.3047  0.0535\n",
            "     37       37.3047  0.0535\n",
            "     38       37.3047  0.0540\n",
            "     39       37.3047  0.0634\n",
            "     40       37.3047  0.0535\n",
            "     41       37.3047  0.0599\n",
            "     42       37.3047  0.0558\n",
            "     43       37.3047  0.0567\n",
            "     44       37.3047  0.0558\n",
            "     45       37.3047  0.0559\n",
            "     46       37.3047  0.0567\n",
            "     47       37.3047  0.0602\n",
            "     48       37.3047  0.0598\n",
            "     49       37.3047  0.0584\n",
            "     50       37.3047  0.0583\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0517\n",
            "      2       37.3047  0.0555\n",
            "      3       37.3047  0.0546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0586\n",
            "      5       37.3047  0.0525\n",
            "      6       37.3047  0.0541\n",
            "      7       37.3047  0.0637\n",
            "      8       37.3047  0.0552\n",
            "      9       37.3047  0.0603\n",
            "     10       37.3047  0.0537\n",
            "     11       37.3047  0.0570\n",
            "     12       37.3047  0.0614\n",
            "     13       37.3047  0.0593\n",
            "     14       37.3047  0.0776\n",
            "     15       37.3047  0.0568\n",
            "     16       37.3047  0.0604\n",
            "     17       37.3047  0.0568\n",
            "     18       37.3047  0.0559\n",
            "     19       37.3047  0.0575\n",
            "     20       37.3047  0.0566\n",
            "     21       37.3047  0.0570\n",
            "     22       37.3047  0.0560\n",
            "     23       37.3047  0.0561\n",
            "     24       37.3047  0.0621\n",
            "     25       37.3047  0.0634\n",
            "     26       37.3047  0.0573\n",
            "     27       37.3047  0.0569\n",
            "     28       37.3047  0.0596\n",
            "     29       37.3047  0.0575\n",
            "     30       37.3047  0.0560\n",
            "     31       37.3047  0.0647\n",
            "     32       37.3047  0.0577\n",
            "     33       37.3047  0.0582\n",
            "     34       37.3047  0.0633\n",
            "     35       37.3047  0.0579\n",
            "     36       37.3047  0.0573\n",
            "     37       37.3047  0.0563\n",
            "     38       37.3047  0.0627\n",
            "     39       37.3047  0.0560\n",
            "     40       37.3047  0.0552\n",
            "     41       37.3047  0.0561\n",
            "     42       37.3047  0.0614\n",
            "     43       37.3047  0.0557\n",
            "     44       37.3047  0.0573\n",
            "     45       37.3047  0.0591\n",
            "     46       37.3047  0.0539\n",
            "     47       37.3047  0.0540\n",
            "     48       37.3047  0.0613\n",
            "     49       37.3047  0.0561\n",
            "     50       37.3047  0.0542\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0507\n",
            "      2       37.3047  0.0611\n",
            "      3       37.3047  0.0555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0663\n",
            "      5       37.3047  0.0540\n",
            "      6       37.3047  0.0533\n",
            "      7       37.3047  0.0550\n",
            "      8       37.3047  0.0568\n",
            "      9       37.3047  0.0569\n",
            "     10       37.3047  0.0560\n",
            "     11       37.3047  0.0541\n",
            "     12       37.3047  0.0585\n",
            "     13       37.3047  0.0599\n",
            "     14       37.3047  0.0525\n",
            "     15       37.3047  0.0604\n",
            "     16       37.3047  0.0564\n",
            "     17       37.3047  0.0534\n",
            "     18       37.3047  0.0551\n",
            "     19       37.3047  0.0536\n",
            "     20       37.3047  0.0537\n",
            "     21       37.3047  0.0542\n",
            "     22       37.3047  0.0549\n",
            "     23       37.3047  0.0578\n",
            "     24       37.3047  0.0630\n",
            "     25       37.3047  0.0541\n",
            "     26       37.3047  0.0540\n",
            "     27       37.3047  0.0548\n",
            "     28       37.3047  0.0567\n",
            "     29       37.3047  0.0591\n",
            "     30       37.3047  0.0583\n",
            "     31       37.3047  0.0556\n",
            "     32       37.3047  0.0605\n",
            "     33       37.3047  0.0586\n",
            "     34       37.3047  0.0559\n",
            "     35       37.3047  0.0542\n",
            "     36       37.3047  0.0537\n",
            "     37       37.3047  0.0539\n",
            "     38       37.3047  0.0555\n",
            "     39       37.3047  0.0539\n",
            "     40       37.3047  0.0590\n",
            "     41       37.3047  0.0546\n",
            "     42       37.3047  0.0553\n",
            "     43       37.3047  0.0597\n",
            "     44       37.3047  0.0529\n",
            "     45       37.3047  0.0530\n",
            "     46       37.3047  0.0614\n",
            "     47       37.3047  0.0534\n",
            "     48       37.3047  0.0537\n",
            "     49       37.3047  0.0538\n",
            "     50       37.3047  0.0603\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0504\n",
            "      2       37.3047  0.0611\n",
            "      3       37.3047  0.0581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0585\n",
            "      5       37.3047  0.0599\n",
            "      6       37.3047  0.0532\n",
            "      7       37.3047  0.0544\n",
            "      8       37.3047  0.0571\n",
            "      9       37.3047  0.0549\n",
            "     10       37.3047  0.0549\n",
            "     11       37.3047  0.0584\n",
            "     12       37.3047  0.0583\n",
            "     13       37.3047  0.0574\n",
            "     14       37.3047  0.0545\n",
            "     15       37.3047  0.0552\n",
            "     16       37.3047  0.0562\n",
            "     17       37.3047  0.0621\n",
            "     18       37.3047  0.0588\n",
            "     19       37.3047  0.0550\n",
            "     20       37.3047  0.0567\n",
            "     21       37.3047  0.0539\n",
            "     22       37.3047  0.0585\n",
            "     23       37.3047  0.0572\n",
            "     24       37.3047  0.0564\n",
            "     25       37.3047  0.0551\n",
            "     26       37.3047  0.0622\n",
            "     27       37.3047  0.0599\n",
            "     28       37.3047  0.0567\n",
            "     29       37.3047  0.0571\n",
            "     30       37.3047  0.0558\n",
            "     31       37.3047  0.0527\n",
            "     32       37.3047  0.0531\n",
            "     33       37.3047  0.0541\n",
            "     34       37.3047  0.0534\n",
            "     35       37.3047  0.0670\n",
            "     36       37.3047  0.0595\n",
            "     37       37.3047  0.0562\n",
            "     38       37.3047  0.0549\n",
            "     39       37.3047  0.0533\n",
            "     40       37.3047  0.0535\n",
            "     41       37.3047  0.0620\n",
            "     42       37.3047  0.0543\n",
            "     43       37.3047  0.0549\n",
            "     44       37.3047  0.0549\n",
            "     45       37.3047  0.0560\n",
            "     46       37.3047  0.0603\n",
            "     47       37.3047  0.0564\n",
            "     48       37.3047  0.0545\n",
            "     49       37.3047  0.0538\n",
            "     50       37.3047  0.0559\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0491\n",
            "      2       37.3047  0.0641\n",
            "      3       37.3047  0.0528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0571\n",
            "      5       37.3047  0.0543\n",
            "      6       37.3047  0.0522\n",
            "      7       37.3047  0.0543\n",
            "      8       37.3047  0.0576\n",
            "      9       37.3047  0.0542\n",
            "     10       37.3047  0.0549\n",
            "     11       37.3047  0.0567\n",
            "     12       37.3047  0.0557\n",
            "     13       37.3047  0.0553\n",
            "     14       37.3047  0.0569\n",
            "     15       37.3047  0.0558\n",
            "     16       37.3047  0.0546\n",
            "     17       37.3047  0.0549\n",
            "     18       37.3047  0.0564\n",
            "     19       37.3047  0.0621\n",
            "     20       37.3047  0.0624\n",
            "     21       37.3047  0.0556\n",
            "     22       37.3047  0.0568\n",
            "     23       37.3047  0.0546\n",
            "     24       37.3047  0.0575\n",
            "     25       37.3047  0.0552\n",
            "     26       37.3047  0.0554\n",
            "     27       37.3047  0.0627\n",
            "     28       37.3047  0.0557\n",
            "     29       37.3047  0.0540\n",
            "     30       37.3047  0.0574\n",
            "     31       37.3047  0.0580\n",
            "     32       37.3047  0.0563\n",
            "     33       37.3047  0.0538\n",
            "     34       37.3047  0.0539\n",
            "     35       37.3047  0.0561\n",
            "     36       37.3047  0.0570\n",
            "     37       37.3047  0.0634\n",
            "     38       37.3047  0.0558\n",
            "     39       37.3047  0.0553\n",
            "     40       37.3047  0.0583\n",
            "     41       37.3047  0.0555\n",
            "     42       37.3047  0.0557\n",
            "     43       37.3047  0.0713\n",
            "     44       37.3047  0.0562\n",
            "     45       37.3047  0.0635\n",
            "     46       37.3047  0.0557\n",
            "     47       37.3047  0.0540\n",
            "     48       37.3047  0.0613\n",
            "     49       37.3047  0.0520\n",
            "     50       37.3047  0.0554\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.2320\u001b[0m  0.0493\n",
            "      2       37.2320  0.0527\n",
            "      3       37.2320  0.0561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.2320  0.0665\n",
            "      5       37.2320  0.0516\n",
            "      6       37.2320  0.0529\n",
            "      7       37.2320  0.0537\n",
            "      8       37.2320  0.0594\n",
            "      9       37.2320  0.0528\n",
            "     10       37.2320  0.0531\n",
            "     11       37.2320  0.0551\n",
            "     12       37.2320  0.0588\n",
            "     13       37.2320  0.0595\n",
            "     14       37.2320  0.0570\n",
            "     15       37.2320  0.0602\n",
            "     16       37.2320  0.0554\n",
            "     17       37.2320  0.0547\n",
            "     18       37.2320  0.0578\n",
            "     19       37.2320  0.0540\n",
            "     20       37.2320  0.0563\n",
            "     21       37.2320  0.0617\n",
            "     22       37.2320  0.0551\n",
            "     23       37.2320  0.0631\n",
            "     24       37.2320  0.0554\n",
            "     25       37.2320  0.0544\n",
            "     26       37.2320  0.0556\n",
            "     27       37.2320  0.0542\n",
            "     28       37.2320  0.0603\n",
            "     29       37.2320  0.0570\n",
            "     30       37.2320  0.0554\n",
            "     31       37.2320  0.0573\n",
            "     32       37.2320  0.0554\n",
            "     33       37.2320  0.0548\n",
            "     34       37.2320  0.0547\n",
            "     35       37.2320  0.0539\n",
            "     36       37.2320  0.0621\n",
            "     37       37.2320  0.0562\n",
            "     38       37.2320  0.0628\n",
            "     39       37.2320  0.0552\n",
            "     40       37.2320  0.0540\n",
            "     41       37.2320  0.0561\n",
            "     42       37.2320  0.0541\n",
            "     43       37.2320  0.0542\n",
            "     44       37.2320  0.0614\n",
            "     45       37.2320  0.0559\n",
            "     46       37.2320  0.0582\n",
            "     47       37.2320  0.0570\n",
            "     48       37.2320  0.0656\n",
            "     49       37.2320  0.0588\n",
            "     50       37.2320  0.0571\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0646\n",
            "      2       37.1094  0.0689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.1094  0.0762\n",
            "      4       37.1094  0.0802\n",
            "      5       37.1094  0.0696\n",
            "      6       37.1094  0.0699\n",
            "      7       37.1094  0.0803\n",
            "      8       37.1094  0.0721\n",
            "      9       37.1094  0.0758\n",
            "     10       37.1094  0.0695\n",
            "     11       37.1094  0.0735\n",
            "     12       37.1094  0.0731\n",
            "     13       37.1094  0.0691\n",
            "     14       37.1094  0.0691\n",
            "     15       37.1094  0.0716\n",
            "     16       37.1094  0.0748\n",
            "     17       37.1094  0.0705\n",
            "     18       37.1094  0.0827\n",
            "     19       37.1094  0.0782\n",
            "     20       37.1094  0.0730\n",
            "     21       37.1094  0.0680\n",
            "     22       37.1094  0.0702\n",
            "     23       37.1094  0.0709\n",
            "     24       \u001b[36m13.5064\u001b[0m  0.0691\n",
            "     25        \u001b[36m0.5641\u001b[0m  0.0750\n",
            "     26        \u001b[36m0.5128\u001b[0m  0.0708\n",
            "     27        \u001b[36m0.4995\u001b[0m  0.0731\n",
            "     28        \u001b[36m0.4910\u001b[0m  0.0702\n",
            "     29        \u001b[36m0.4833\u001b[0m  0.0708\n",
            "     30        \u001b[36m0.4746\u001b[0m  0.0709\n",
            "     31        \u001b[36m0.4673\u001b[0m  0.0793\n",
            "     32        \u001b[36m0.4587\u001b[0m  0.0744\n",
            "     33        \u001b[36m0.4515\u001b[0m  0.0716\n",
            "     34        \u001b[36m0.4431\u001b[0m  0.0683\n",
            "     35        \u001b[36m0.4348\u001b[0m  0.0791\n",
            "     36        \u001b[36m0.4240\u001b[0m  0.0718\n",
            "     37        \u001b[36m0.4145\u001b[0m  0.0710\n",
            "     38        \u001b[36m0.4051\u001b[0m  0.0684\n",
            "     39        \u001b[36m0.3997\u001b[0m  0.0710\n",
            "     40        \u001b[36m0.3874\u001b[0m  0.0682\n",
            "     41        \u001b[36m0.3830\u001b[0m  0.0738\n",
            "     42        \u001b[36m0.3741\u001b[0m  0.0668\n",
            "     43        \u001b[36m0.3608\u001b[0m  0.0682\n",
            "     44        \u001b[36m0.3586\u001b[0m  0.0686\n",
            "     45        \u001b[36m0.3447\u001b[0m  0.0751\n",
            "     46        \u001b[36m0.3416\u001b[0m  0.0687\n",
            "     47        \u001b[36m0.3335\u001b[0m  0.0715\n",
            "     48        \u001b[36m0.3279\u001b[0m  0.0692\n",
            "     49        \u001b[36m0.3175\u001b[0m  0.0687\n",
            "     50        \u001b[36m0.3090\u001b[0m  0.0717\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0659\n",
            "      2       37.1094  0.0737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.1094  0.0732\n",
            "      4       37.1094  0.0673\n",
            "      5       37.1094  0.0682\n",
            "      6       37.1094  0.0679\n",
            "      7       37.1094  0.0695\n",
            "      8       37.1094  0.0712\n",
            "      9       37.1094  0.0813\n",
            "     10       37.1094  0.0752\n",
            "     11       37.1094  0.0685\n",
            "     12       37.1094  0.0772\n",
            "     13       37.1094  0.0705\n",
            "     14       37.1094  0.0714\n",
            "     15       37.1094  0.0698\n",
            "     16       37.1094  0.0703\n",
            "     17       37.1094  0.0689\n",
            "     18       37.1094  0.0711\n",
            "     19       37.1094  0.0758\n",
            "     20       37.1094  0.0693\n",
            "     21       37.1094  0.0700\n",
            "     22       37.1094  0.0694\n",
            "     23       37.1094  0.0773\n",
            "     24       \u001b[36m14.8170\u001b[0m  0.0721\n",
            "     25        \u001b[36m0.6002\u001b[0m  0.0689\n",
            "     26        \u001b[36m0.5360\u001b[0m  0.0784\n",
            "     27        \u001b[36m0.5142\u001b[0m  0.0704\n",
            "     28        \u001b[36m0.5044\u001b[0m  0.0714\n",
            "     29        \u001b[36m0.4902\u001b[0m  0.0719\n",
            "     30        \u001b[36m0.4793\u001b[0m  0.0745\n",
            "     31        \u001b[36m0.4678\u001b[0m  0.0717\n",
            "     32        \u001b[36m0.4568\u001b[0m  0.0743\n",
            "     33        \u001b[36m0.4447\u001b[0m  0.0703\n",
            "     34        \u001b[36m0.4254\u001b[0m  0.0732\n",
            "     35        \u001b[36m0.4153\u001b[0m  0.0726\n",
            "     36        \u001b[36m0.4014\u001b[0m  0.0784\n",
            "     37        \u001b[36m0.3896\u001b[0m  0.0740\n",
            "     38        \u001b[36m0.3759\u001b[0m  0.0800\n",
            "     39        \u001b[36m0.3651\u001b[0m  0.0705\n",
            "     40        \u001b[36m0.3528\u001b[0m  0.0721\n",
            "     41        \u001b[36m0.3428\u001b[0m  0.0728\n",
            "     42        \u001b[36m0.3345\u001b[0m  0.0754\n",
            "     43        \u001b[36m0.3323\u001b[0m  0.0707\n",
            "     44        \u001b[36m0.3216\u001b[0m  0.0687\n",
            "     45        \u001b[36m0.3137\u001b[0m  0.0715\n",
            "     46        \u001b[36m0.3127\u001b[0m  0.0691\n",
            "     47        \u001b[36m0.3046\u001b[0m  0.0858\n",
            "     48        \u001b[36m0.2967\u001b[0m  0.0703\n",
            "     49        \u001b[36m0.2946\u001b[0m  0.0754\n",
            "     50        \u001b[36m0.2896\u001b[0m  0.0837\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0652\n",
            "      2       37.3047  0.0750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0757\n",
            "      4       37.3047  0.0715\n",
            "      5       37.3047  0.0711\n",
            "      6       37.3047  0.0724\n",
            "      7       37.3047  0.0682\n",
            "      8       37.3047  0.0732\n",
            "      9       37.3047  0.0722\n",
            "     10       37.3047  0.0715\n",
            "     11       37.3047  0.0721\n",
            "     12       37.3047  0.0707\n",
            "     13       37.3047  0.0770\n",
            "     14       37.3047  0.0683\n",
            "     15       37.3047  0.0684\n",
            "     16       37.3047  0.0746\n",
            "     17       37.3047  0.0732\n",
            "     18       37.3047  0.0767\n",
            "     19       37.3047  0.0739\n",
            "     20       37.3047  0.0715\n",
            "     21       37.3047  0.0691\n",
            "     22       37.3047  0.0702\n",
            "     23       37.3047  0.0732\n",
            "     24       37.3047  0.0760\n",
            "     25       \u001b[36m13.3729\u001b[0m  0.0689\n",
            "     26        \u001b[36m0.5890\u001b[0m  0.0694\n",
            "     27        \u001b[36m0.5753\u001b[0m  0.0804\n",
            "     28        \u001b[36m0.5267\u001b[0m  0.0767\n",
            "     29        \u001b[36m0.5064\u001b[0m  0.0708\n",
            "     30        \u001b[36m0.4867\u001b[0m  0.0698\n",
            "     31        \u001b[36m0.4694\u001b[0m  0.0709\n",
            "     32        \u001b[36m0.4531\u001b[0m  0.0703\n",
            "     33        \u001b[36m0.4367\u001b[0m  0.0753\n",
            "     34        \u001b[36m0.4206\u001b[0m  0.0705\n",
            "     35        \u001b[36m0.4101\u001b[0m  0.0708\n",
            "     36        \u001b[36m0.4028\u001b[0m  0.0711\n",
            "     37        \u001b[36m0.3972\u001b[0m  0.0719\n",
            "     38        \u001b[36m0.3901\u001b[0m  0.0710\n",
            "     39        \u001b[36m0.3823\u001b[0m  0.0714\n",
            "     40        \u001b[36m0.3765\u001b[0m  0.0833\n",
            "     41        \u001b[36m0.3615\u001b[0m  0.0703\n",
            "     42        \u001b[36m0.3523\u001b[0m  0.0773\n",
            "     43        \u001b[36m0.3424\u001b[0m  0.0700\n",
            "     44        \u001b[36m0.3299\u001b[0m  0.0687\n",
            "     45        \u001b[36m0.3150\u001b[0m  0.0706\n",
            "     46        \u001b[36m0.3036\u001b[0m  0.0733\n",
            "     47        \u001b[36m0.2959\u001b[0m  0.0704\n",
            "     48        \u001b[36m0.2927\u001b[0m  0.0692\n",
            "     49        \u001b[36m0.2856\u001b[0m  0.0796\n",
            "     50        \u001b[36m0.2811\u001b[0m  0.0792\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0660\n",
            "      2       37.3047  0.0707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0785\n",
            "      4       37.3047  0.0808\n",
            "      5       37.3047  0.0698\n",
            "      6       37.3047  0.0750\n",
            "      7       37.3047  0.0733\n",
            "      8       37.3047  0.0682\n",
            "      9       37.3047  0.0785\n",
            "     10       37.3047  0.0699\n",
            "     11       37.3047  0.0723\n",
            "     12       37.3047  0.0759\n",
            "     13       37.3047  0.0711\n",
            "     14       37.3047  0.0705\n",
            "     15       37.3047  0.0688\n",
            "     16       37.3047  0.0713\n",
            "     17       37.3047  0.0847\n",
            "     18       37.3047  0.0772\n",
            "     19       37.3047  0.0706\n",
            "     20       37.3047  0.0704\n",
            "     21       37.3047  0.0700\n",
            "     22       37.3047  0.0761\n",
            "     23       37.3047  0.0687\n",
            "     24       37.3047  0.0681\n",
            "     25       37.3047  0.0769\n",
            "     26       37.3047  0.0681\n",
            "     27       37.3047  0.0712\n",
            "     28       37.3047  0.0699\n",
            "     29       37.3047  0.0692\n",
            "     30       37.3047  0.0771\n",
            "     31       37.3047  0.0776\n",
            "     32       37.3047  0.0694\n",
            "     33       37.3047  0.0718\n",
            "     34       37.3047  0.0754\n",
            "     35       37.3047  0.0704\n",
            "     36       37.3047  0.0746\n",
            "     37       37.3047  0.0688\n",
            "     38       37.3047  0.0727\n",
            "     39       37.3047  0.0704\n",
            "     40       37.3047  0.0702\n",
            "     41       37.3047  0.0699\n",
            "     42       37.3047  0.0745\n",
            "     43       37.3047  0.0705\n",
            "     44       37.3047  0.0752\n",
            "     45       37.3047  0.0752\n",
            "     46       37.3047  0.0835\n",
            "     47       37.3047  0.0746\n",
            "     48       37.3047  0.0700\n",
            "     49       37.3047  0.0723\n",
            "     50       37.3047  0.0717\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0675\n",
            "      2       37.3047  0.0724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0744\n",
            "      4       37.3047  0.0778\n",
            "      5       37.3047  0.0730\n",
            "      6       37.3047  0.0701\n",
            "      7       37.3047  0.0697\n",
            "      8       37.3047  0.0907\n",
            "      9       37.3047  0.0704\n",
            "     10       37.3047  0.0699\n",
            "     11       37.3047  0.0690\n",
            "     12       37.3047  0.0735\n",
            "     13       37.3047  0.0772\n",
            "     14       37.3047  0.0712\n",
            "     15       37.3047  0.0694\n",
            "     16       37.3047  0.0694\n",
            "     17       37.3047  0.0724\n",
            "     18       37.3047  0.0719\n",
            "     19       37.3047  0.0715\n",
            "     20       37.3047  0.0778\n",
            "     21       37.3047  0.0804\n",
            "     22       37.3047  0.0699\n",
            "     23       37.3047  0.0756\n",
            "     24       37.3047  0.0710\n",
            "     25       37.3047  0.0704\n",
            "     26       \u001b[36m16.2558\u001b[0m  0.0715\n",
            "     27        \u001b[36m0.5590\u001b[0m  0.0696\n",
            "     28        0.5729  0.0706\n",
            "     29        \u001b[36m0.5109\u001b[0m  0.0708\n",
            "     30        \u001b[36m0.4990\u001b[0m  0.0742\n",
            "     31        \u001b[36m0.4875\u001b[0m  0.0700\n",
            "     32        \u001b[36m0.4718\u001b[0m  0.0711\n",
            "     33        \u001b[36m0.4607\u001b[0m  0.0754\n",
            "     34        \u001b[36m0.4484\u001b[0m  0.0701\n",
            "     35        \u001b[36m0.4321\u001b[0m  0.0807\n",
            "     36        \u001b[36m0.4171\u001b[0m  0.0793\n",
            "     37        \u001b[36m0.4011\u001b[0m  0.0694\n",
            "     38        \u001b[36m0.3911\u001b[0m  0.0754\n",
            "     39        \u001b[36m0.3792\u001b[0m  0.0842\n",
            "     40        \u001b[36m0.3738\u001b[0m  0.0712\n",
            "     41        \u001b[36m0.3609\u001b[0m  0.0661\n",
            "     42        \u001b[36m0.3523\u001b[0m  0.0672\n",
            "     43        \u001b[36m0.3452\u001b[0m  0.0746\n",
            "     44        \u001b[36m0.3391\u001b[0m  0.0699\n",
            "     45        \u001b[36m0.3353\u001b[0m  0.0688\n",
            "     46        \u001b[36m0.3290\u001b[0m  0.0679\n",
            "     47        \u001b[36m0.3232\u001b[0m  0.0721\n",
            "     48        \u001b[36m0.3179\u001b[0m  0.0746\n",
            "     49        \u001b[36m0.3170\u001b[0m  0.0714\n",
            "     50        \u001b[36m0.3105\u001b[0m  0.0696\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0652\n",
            "      2       37.3047  0.0732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0767\n",
            "      4       37.3047  0.0727\n",
            "      5       37.3047  0.0690\n",
            "      6       37.3047  0.0714\n",
            "      7       37.3047  0.0737\n",
            "      8       37.3047  0.0712\n",
            "      9       37.3047  0.0737\n",
            "     10       37.3047  0.0773\n",
            "     11       37.3047  0.0714\n",
            "     12       37.3047  0.0789\n",
            "     13       37.3047  0.0715\n",
            "     14       37.3047  0.0710\n",
            "     15       37.3047  0.0805\n",
            "     16       37.3047  0.0723\n",
            "     17       37.3047  0.0688\n",
            "     18       37.3047  0.0721\n",
            "     19       37.3047  0.0700\n",
            "     20       37.3047  0.0725\n",
            "     21       37.3047  0.0716\n",
            "     22       37.3047  0.0800\n",
            "     23       37.3047  0.0684\n",
            "     24       \u001b[36m34.8091\u001b[0m  0.0742\n",
            "     25        \u001b[36m0.5615\u001b[0m  0.0710\n",
            "     26        \u001b[36m0.5390\u001b[0m  0.0789\n",
            "     27        \u001b[36m0.5065\u001b[0m  0.0692\n",
            "     28        \u001b[36m0.4894\u001b[0m  0.0699\n",
            "     29        \u001b[36m0.4693\u001b[0m  0.0731\n",
            "     30        \u001b[36m0.4523\u001b[0m  0.0701\n",
            "     31        \u001b[36m0.4297\u001b[0m  0.0693\n",
            "     32        \u001b[36m0.4202\u001b[0m  0.0686\n",
            "     33        \u001b[36m0.3939\u001b[0m  0.0766\n",
            "     34        \u001b[36m0.3792\u001b[0m  0.0683\n",
            "     35        \u001b[36m0.3637\u001b[0m  0.0745\n",
            "     36        \u001b[36m0.3488\u001b[0m  0.0708\n",
            "     37        \u001b[36m0.3395\u001b[0m  0.0696\n",
            "     38        \u001b[36m0.3392\u001b[0m  0.0695\n",
            "     39        0.3488  0.0883\n",
            "     40        0.3548  0.0699\n",
            "     41        0.3584  0.0693\n",
            "     42        \u001b[36m0.3239\u001b[0m  0.0731\n",
            "     43        \u001b[36m0.3125\u001b[0m  0.0717\n",
            "     44        \u001b[36m0.2984\u001b[0m  0.0740\n",
            "     45        \u001b[36m0.2977\u001b[0m  0.0698\n",
            "     46        \u001b[36m0.2936\u001b[0m  0.0733\n",
            "     47        \u001b[36m0.2847\u001b[0m  0.0713\n",
            "     48        \u001b[36m0.2777\u001b[0m  0.0703\n",
            "     49        \u001b[36m0.2757\u001b[0m  0.0709\n",
            "     50        \u001b[36m0.2678\u001b[0m  0.0687\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0718\n",
            "      2       37.3047  0.0719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0818\n",
            "      4       37.3047  0.0724\n",
            "      5       37.3047  0.0694\n",
            "      6       37.3047  0.0726\n",
            "      7       37.3047  0.0691\n",
            "      8       37.3047  0.0716\n",
            "      9       37.3047  0.0687\n",
            "     10       37.3047  0.0717\n",
            "     11       37.3047  0.0694\n",
            "     12       37.3047  0.0717\n",
            "     13       37.3047  0.0736\n",
            "     14       37.3047  0.0690\n",
            "     15       37.3047  0.0765\n",
            "     16       37.3047  0.0819\n",
            "     17       37.3047  0.0677\n",
            "     18       37.3047  0.0693\n",
            "     19       37.3047  0.0725\n",
            "     20       37.3047  0.0711\n",
            "     21       37.3047  0.0741\n",
            "     22       37.3047  0.0739\n",
            "     23       37.3047  0.0694\n",
            "     24       37.3047  0.0718\n",
            "     25       37.3047  0.0682\n",
            "     26       \u001b[36m15.8552\u001b[0m  0.0709\n",
            "     27        \u001b[36m0.5489\u001b[0m  0.0704\n",
            "     28        \u001b[36m0.5207\u001b[0m  0.0707\n",
            "     29        \u001b[36m0.4965\u001b[0m  0.0748\n",
            "     30        \u001b[36m0.4758\u001b[0m  0.0778\n",
            "     31        \u001b[36m0.4521\u001b[0m  0.0751\n",
            "     32        \u001b[36m0.4307\u001b[0m  0.0727\n",
            "     33        \u001b[36m0.4071\u001b[0m  0.0702\n",
            "     34        \u001b[36m0.3871\u001b[0m  0.0683\n",
            "     35        \u001b[36m0.3703\u001b[0m  0.0718\n",
            "     36        \u001b[36m0.3516\u001b[0m  0.0729\n",
            "     37        \u001b[36m0.3338\u001b[0m  0.0719\n",
            "     38        \u001b[36m0.3210\u001b[0m  0.0680\n",
            "     39        \u001b[36m0.3091\u001b[0m  0.0705\n",
            "     40        \u001b[36m0.2982\u001b[0m  0.0690\n",
            "     41        \u001b[36m0.2880\u001b[0m  0.0763\n",
            "     42        \u001b[36m0.2781\u001b[0m  0.0706\n",
            "     43        \u001b[36m0.2698\u001b[0m  0.0694\n",
            "     44        \u001b[36m0.2677\u001b[0m  0.0870\n",
            "     45        \u001b[36m0.2546\u001b[0m  0.0694\n",
            "     46        \u001b[36m0.2492\u001b[0m  0.0741\n",
            "     47        \u001b[36m0.2392\u001b[0m  0.0696\n",
            "     48        \u001b[36m0.2356\u001b[0m  0.0695\n",
            "     49        \u001b[36m0.2349\u001b[0m  0.0718\n",
            "     50        \u001b[36m0.2302\u001b[0m  0.0698\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0661\n",
            "      2       37.3047  0.0734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0866\n",
            "      4       37.3047  0.0762\n",
            "      5       37.3047  0.0711\n",
            "      6       37.3047  0.0700\n",
            "      7       37.3047  0.0816\n",
            "      8       37.3047  0.0788\n",
            "      9       37.3047  0.0756\n",
            "     10       37.3047  0.0714\n",
            "     11       37.3047  0.0778\n",
            "     12       37.3047  0.0704\n",
            "     13       37.3047  0.0724\n",
            "     14       37.3047  0.0745\n",
            "     15       37.3047  0.0705\n",
            "     16       37.3047  0.0685\n",
            "     17       37.3047  0.0698\n",
            "     18       37.3047  0.0724\n",
            "     19       37.3047  0.0766\n",
            "     20       37.3047  0.0751\n",
            "     21       37.3047  0.0709\n",
            "     22       37.3047  0.0721\n",
            "     23       37.3047  0.0689\n",
            "     24       \u001b[36m18.6503\u001b[0m  0.0746\n",
            "     25        \u001b[36m0.6191\u001b[0m  0.0690\n",
            "     26        \u001b[36m0.5406\u001b[0m  0.0705\n",
            "     27        \u001b[36m0.5243\u001b[0m  0.0727\n",
            "     28        \u001b[36m0.5169\u001b[0m  0.0724\n",
            "     29        \u001b[36m0.5017\u001b[0m  0.0690\n",
            "     30        \u001b[36m0.4919\u001b[0m  0.0707\n",
            "     31        \u001b[36m0.4811\u001b[0m  0.0759\n",
            "     32        \u001b[36m0.4709\u001b[0m  0.0702\n",
            "     33        \u001b[36m0.4607\u001b[0m  0.0872\n",
            "     34        \u001b[36m0.4508\u001b[0m  0.0803\n",
            "     35        \u001b[36m0.4388\u001b[0m  0.0768\n",
            "     36        \u001b[36m0.4284\u001b[0m  0.0700\n",
            "     37        \u001b[36m0.4177\u001b[0m  0.0692\n",
            "     38        \u001b[36m0.4080\u001b[0m  0.0699\n",
            "     39        \u001b[36m0.3999\u001b[0m  0.0694\n",
            "     40        \u001b[36m0.3895\u001b[0m  0.0712\n",
            "     41        \u001b[36m0.3788\u001b[0m  0.0727\n",
            "     42        \u001b[36m0.3688\u001b[0m  0.0735\n",
            "     43        \u001b[36m0.3596\u001b[0m  0.0770\n",
            "     44        \u001b[36m0.3499\u001b[0m  0.0689\n",
            "     45        \u001b[36m0.3416\u001b[0m  0.0700\n",
            "     46        \u001b[36m0.3367\u001b[0m  0.0736\n",
            "     47        \u001b[36m0.3295\u001b[0m  0.0724\n",
            "     48        \u001b[36m0.3226\u001b[0m  0.0774\n",
            "     49        \u001b[36m0.3173\u001b[0m  0.0732\n",
            "     50        \u001b[36m0.3123\u001b[0m  0.0713\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0744\n",
            "      2       37.3047  0.0708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0760\n",
            "      4       37.3047  0.0696\n",
            "      5       37.3047  0.0723\n",
            "      6       37.3047  0.0700\n",
            "      7       37.3047  0.0724\n",
            "      8       37.3047  0.0705\n",
            "      9       37.3047  0.0749\n",
            "     10       37.3047  0.0770\n",
            "     11       37.3047  0.0813\n",
            "     12       37.3047  0.0728\n",
            "     13       37.3047  0.0692\n",
            "     14       37.3047  0.0701\n",
            "     15       37.3047  0.0741\n",
            "     16       37.3047  0.0710\n",
            "     17       37.3047  0.0736\n",
            "     18       37.3047  0.0751\n",
            "     19       37.3047  0.0723\n",
            "     20       37.3047  0.0708\n",
            "     21       37.3047  0.0776\n",
            "     22       37.3047  0.0701\n",
            "     23       37.3047  0.0777\n",
            "     24       \u001b[36m17.8001\u001b[0m  0.0690\n",
            "     25        \u001b[36m0.6075\u001b[0m  0.0792\n",
            "     26        \u001b[36m0.5343\u001b[0m  0.0706\n",
            "     27        \u001b[36m0.5178\u001b[0m  0.0690\n",
            "     28        \u001b[36m0.4996\u001b[0m  0.0720\n",
            "     29        \u001b[36m0.4863\u001b[0m  0.0700\n",
            "     30        \u001b[36m0.4743\u001b[0m  0.0734\n",
            "     31        \u001b[36m0.4629\u001b[0m  0.0725\n",
            "     32        \u001b[36m0.4510\u001b[0m  0.0702\n",
            "     33        \u001b[36m0.4414\u001b[0m  0.0815\n",
            "     34        \u001b[36m0.4276\u001b[0m  0.0700\n",
            "     35        \u001b[36m0.4204\u001b[0m  0.0716\n",
            "     36        \u001b[36m0.4083\u001b[0m  0.0781\n",
            "     37        \u001b[36m0.3968\u001b[0m  0.0703\n",
            "     38        \u001b[36m0.3852\u001b[0m  0.0819\n",
            "     39        \u001b[36m0.3749\u001b[0m  0.0754\n",
            "     40        \u001b[36m0.3632\u001b[0m  0.0683\n",
            "     41        \u001b[36m0.3540\u001b[0m  0.0710\n",
            "     42        \u001b[36m0.3428\u001b[0m  0.0681\n",
            "     43        \u001b[36m0.3346\u001b[0m  0.0719\n",
            "     44        \u001b[36m0.3300\u001b[0m  0.0732\n",
            "     45        \u001b[36m0.3213\u001b[0m  0.0837\n",
            "     46        \u001b[36m0.3141\u001b[0m  0.0706\n",
            "     47        \u001b[36m0.3065\u001b[0m  0.0717\n",
            "     48        \u001b[36m0.2993\u001b[0m  0.0696\n",
            "     49        \u001b[36m0.2929\u001b[0m  0.0711\n",
            "     50        \u001b[36m0.2856\u001b[0m  0.0704\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.2320\u001b[0m  0.0646\n",
            "      2       37.2320  0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.2320  0.0776\n",
            "      4       37.2320  0.0701\n",
            "      5       37.2320  0.0748\n",
            "      6       37.2320  0.0726\n",
            "      7       37.2320  0.0722\n",
            "      8       37.2320  0.0715\n",
            "      9       37.2320  0.0709\n",
            "     10       37.2320  0.0742\n",
            "     11       37.2320  0.0835\n",
            "     12       37.2320  0.0741\n",
            "     13       37.2320  0.0715\n",
            "     14       37.2320  0.0722\n",
            "     15       37.2320  0.0845\n",
            "     16       37.2320  0.0691\n",
            "     17       37.2320  0.0698\n",
            "     18       37.2320  0.0719\n",
            "     19       37.2320  0.0721\n",
            "     20       37.2320  0.0719\n",
            "     21       37.2320  0.0784\n",
            "     22       37.2320  0.0705\n",
            "     23       37.2320  0.0801\n",
            "     24       37.2320  0.0714\n",
            "     25       \u001b[36m17.1932\u001b[0m  0.0716\n",
            "     26        \u001b[36m0.6580\u001b[0m  0.0752\n",
            "     27        \u001b[36m0.5697\u001b[0m  0.0712\n",
            "     28        \u001b[36m0.5235\u001b[0m  0.0809\n",
            "     29        \u001b[36m0.5066\u001b[0m  0.0728\n",
            "     30        \u001b[36m0.4814\u001b[0m  0.0699\n",
            "     31        \u001b[36m0.4686\u001b[0m  0.0700\n",
            "     32        \u001b[36m0.4380\u001b[0m  0.0827\n",
            "     33        \u001b[36m0.4322\u001b[0m  0.0800\n",
            "     34        \u001b[36m0.3948\u001b[0m  0.0698\n",
            "     35        \u001b[36m0.3801\u001b[0m  0.0765\n",
            "     36        \u001b[36m0.3676\u001b[0m  0.0719\n",
            "     37        \u001b[36m0.3495\u001b[0m  0.0747\n",
            "     38        \u001b[36m0.3367\u001b[0m  0.0700\n",
            "     39        \u001b[36m0.3302\u001b[0m  0.0712\n",
            "     40        \u001b[36m0.3224\u001b[0m  0.0712\n",
            "     41        \u001b[36m0.3106\u001b[0m  0.0761\n",
            "     42        \u001b[36m0.3016\u001b[0m  0.0769\n",
            "     43        \u001b[36m0.2980\u001b[0m  0.0696\n",
            "     44        \u001b[36m0.2890\u001b[0m  0.0785\n",
            "     45        \u001b[36m0.2823\u001b[0m  0.0726\n",
            "     46        \u001b[36m0.2759\u001b[0m  0.0728\n",
            "     47        \u001b[36m0.2692\u001b[0m  0.0705\n",
            "     48        \u001b[36m0.2630\u001b[0m  0.0716\n",
            "     49        \u001b[36m0.2592\u001b[0m  0.0714\n",
            "     50        \u001b[36m0.2549\u001b[0m  0.0701\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0577\n",
            "      2       37.1094  0.0593\n",
            "      3       37.1094  0.0561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.1094  0.0627\n",
            "      5       37.1094  0.0665\n",
            "      6       37.1094  0.0665\n",
            "      7       37.1094  0.0560\n",
            "      8       37.1094  0.0567\n",
            "      9       37.1094  0.0540\n",
            "     10       37.1094  0.0541\n",
            "     11       37.1094  0.0612\n",
            "     12       37.1094  0.0555\n",
            "     13       37.1094  0.0551\n",
            "     14       37.1094  0.0552\n",
            "     15       37.1094  0.0560\n",
            "     16       37.1094  0.0615\n",
            "     17       37.1094  0.0568\n",
            "     18       37.1094  0.0562\n",
            "     19       37.1094  0.0568\n",
            "     20       37.1094  0.0575\n",
            "     21       37.1094  0.0566\n",
            "     22       37.1094  0.0594\n",
            "     23       37.1094  0.0625\n",
            "     24       37.1094  0.0539\n",
            "     25       37.1094  0.0543\n",
            "     26       37.1094  0.0555\n",
            "     27       37.1094  0.0532\n",
            "     28       37.1094  0.0569\n",
            "     29       37.1094  0.0537\n",
            "     30       37.1094  0.0623\n",
            "     31       37.1094  0.0609\n",
            "     32       37.1094  0.0608\n",
            "     33       37.1094  0.0539\n",
            "     34       37.1094  0.0636\n",
            "     35       37.1094  0.0656\n",
            "     36       37.1094  0.0592\n",
            "     37       37.1094  0.0559\n",
            "     38       37.1094  0.0565\n",
            "     39       37.1094  0.0532\n",
            "     40       37.1094  0.0606\n",
            "     41       37.1094  0.0563\n",
            "     42       37.1094  0.0542\n",
            "     43       37.1094  0.0546\n",
            "     44       37.1094  0.0573\n",
            "     45       37.1094  0.0551\n",
            "     46       37.1094  0.0543\n",
            "     47       37.1094  0.0545\n",
            "     48       37.1094  0.0586\n",
            "     49       37.1094  0.0538\n",
            "     50       37.1094  0.0545\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0547\n",
            "      2       37.1094  0.0549\n",
            "      3       37.1094  0.0562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.1094  0.0657\n",
            "      5       37.1094  0.0598\n",
            "      6       37.1094  0.0596\n",
            "      7       37.1094  0.0614\n",
            "      8       37.1094  0.0588\n",
            "      9       37.1094  0.0569\n",
            "     10       37.1094  0.0642\n",
            "     11       37.1094  0.0596\n",
            "     12       37.1094  0.0628\n",
            "     13       37.1094  0.0564\n",
            "     14       37.1094  0.0554\n",
            "     15       37.1094  0.0580\n",
            "     16       37.1094  0.0643\n",
            "     17       37.1094  0.0556\n",
            "     18       37.1094  0.0580\n",
            "     19       37.1094  0.0571\n",
            "     20       37.1094  0.0571\n",
            "     21       37.1094  0.0616\n",
            "     22       37.1094  0.0673\n",
            "     23       37.1094  0.0551\n",
            "     24       37.1094  0.0625\n",
            "     25       37.1094  0.0574\n",
            "     26       37.1094  0.0540\n",
            "     27       37.1094  0.0587\n",
            "     28       37.1094  0.0583\n",
            "     29       37.1094  0.0567\n",
            "     30       37.1094  0.0608\n",
            "     31       37.1094  0.0629\n",
            "     32       37.1094  0.0556\n",
            "     33       37.1094  0.0568\n",
            "     34       37.1094  0.0569\n",
            "     35       37.1094  0.0552\n",
            "     36       37.1094  0.0566\n",
            "     37       37.1094  0.0563\n",
            "     38       37.1094  0.0582\n",
            "     39       37.1094  0.0530\n",
            "     40       37.1094  0.0575\n",
            "     41       37.1094  0.0660\n",
            "     42       37.1094  0.0553\n",
            "     43       37.1094  0.0560\n",
            "     44       37.1094  0.0564\n",
            "     45       37.1094  0.0618\n",
            "     46       37.1094  0.0585\n",
            "     47       37.1094  0.0564\n",
            "     48       37.1094  0.0561\n",
            "     49       37.1094  0.0540\n",
            "     50       37.1094  0.0543\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0575\n",
            "      2       37.3047  0.0606\n",
            "      3       37.3047  0.0661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0587\n",
            "      5       37.3047  0.0614\n",
            "      6       37.3047  0.0559\n",
            "      7       37.3047  0.0549\n",
            "      8       37.3047  0.0632\n",
            "      9       37.3047  0.0531\n",
            "     10       37.3047  0.0579\n",
            "     11       37.3047  0.0559\n",
            "     12       37.3047  0.0543\n",
            "     13       37.3047  0.0526\n",
            "     14       37.3047  0.0547\n",
            "     15       37.3047  0.0531\n",
            "     16       37.3047  0.0597\n",
            "     17       37.3047  0.0549\n",
            "     18       37.3047  0.0579\n",
            "     19       37.3047  0.0562\n",
            "     20       37.3047  0.0571\n",
            "     21       37.3047  0.0597\n",
            "     22       37.3047  0.0665\n",
            "     23       37.3047  0.0588\n",
            "     24       37.3047  0.0578\n",
            "     25       37.3047  0.0654\n",
            "     26       37.3047  0.0596\n",
            "     27       37.3047  0.0579\n",
            "     28       37.3047  0.0587\n",
            "     29       37.3047  0.0614\n",
            "     30       37.3047  0.0578\n",
            "     31       37.3047  0.0649\n",
            "     32       37.3047  0.0616\n",
            "     33       37.3047  0.0592\n",
            "     34       37.3047  0.0565\n",
            "     35       37.3047  0.0588\n",
            "     36       37.3047  0.0574\n",
            "     37       37.3047  0.0586\n",
            "     38       37.3047  0.0589\n",
            "     39       37.3047  0.0542\n",
            "     40       37.3047  0.0543\n",
            "     41       37.3047  0.0665\n",
            "     42       37.3047  0.0553\n",
            "     43       37.3047  0.0549\n",
            "     44       37.3047  0.0567\n",
            "     45       37.3047  0.0568\n",
            "     46       37.3047  0.0553\n",
            "     47       37.3047  0.0549\n",
            "     48       37.3047  0.0547\n",
            "     49       37.3047  0.0614\n",
            "     50       37.3047  0.0544\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0547\n",
            "      2       37.3047  0.0610\n",
            "      3       37.3047  0.0559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0627\n",
            "      5       37.3047  0.0545\n",
            "      6       37.3047  0.0575\n",
            "      7       37.3047  0.0576\n",
            "      8       37.3047  0.0640\n",
            "      9       37.3047  0.0539\n",
            "     10       37.3047  0.0546\n",
            "     11       37.3047  0.0549\n",
            "     12       37.3047  0.0523\n",
            "     13       37.3047  0.0644\n",
            "     14       37.3047  0.0541\n",
            "     15       37.3047  0.0550\n",
            "     16       37.3047  0.0635\n",
            "     17       37.3047  0.0563\n",
            "     18       37.3047  0.0590\n",
            "     19       37.3047  0.0578\n",
            "     20       37.3047  0.0553\n",
            "     21       37.3047  0.0579\n",
            "     22       37.3047  0.0543\n",
            "     23       37.3047  0.0556\n",
            "     24       37.3047  0.0596\n",
            "     25       37.3047  0.0612\n",
            "     26       37.3047  0.0565\n",
            "     27       37.3047  0.0609\n",
            "     28       37.3047  0.0582\n",
            "     29       37.3047  0.0565\n",
            "     30       37.3047  0.0543\n",
            "     31       37.3047  0.0616\n",
            "     32       37.3047  0.0551\n",
            "     33       37.3047  0.0569\n",
            "     34       37.3047  0.0577\n",
            "     35       37.3047  0.0583\n",
            "     36       37.3047  0.0593\n",
            "     37       37.3047  0.0536\n",
            "     38       37.3047  0.0560\n",
            "     39       37.3047  0.0549\n",
            "     40       37.3047  0.0568\n",
            "     41       37.3047  0.0559\n",
            "     42       37.3047  0.0622\n",
            "     43       37.3047  0.0541\n",
            "     44       37.3047  0.0647\n",
            "     45       37.3047  0.0550\n",
            "     46       37.3047  0.0641\n",
            "     47       37.3047  0.0547\n",
            "     48       37.3047  0.0552\n",
            "     49       37.3047  0.0584\n",
            "     50       37.3047  0.0563\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0512\n",
            "      2       37.3047  0.0542\n",
            "      3       37.3047  0.0579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0636\n",
            "      5       37.3047  0.0538\n",
            "      6       37.3047  0.0560\n",
            "      7       37.3047  0.0566\n",
            "      8       37.3047  0.0575\n",
            "      9       37.3047  0.0647\n",
            "     10       37.3047  0.0614\n",
            "     11       37.3047  0.0593\n",
            "     12       37.3047  0.0575\n",
            "     13       37.3047  0.0560\n",
            "     14       37.3047  0.0714\n",
            "     15       37.3047  0.0600\n",
            "     16       37.3047  0.0658\n",
            "     17       37.3047  0.0574\n",
            "     18       37.3047  0.0591\n",
            "     19       37.3047  0.0582\n",
            "     20       37.3047  0.0618\n",
            "     21       37.3047  0.0562\n",
            "     22       37.3047  0.0604\n",
            "     23       37.3047  0.0568\n",
            "     24       37.3047  0.0571\n",
            "     25       37.3047  0.0645\n",
            "     26       37.3047  0.0580\n",
            "     27       37.3047  0.0570\n",
            "     28       37.3047  0.0553\n",
            "     29       37.3047  0.0545\n",
            "     30       37.3047  0.0558\n",
            "     31       37.3047  0.0622\n",
            "     32       37.3047  0.0581\n",
            "     33       37.3047  0.0641\n",
            "     34       37.3047  0.0570\n",
            "     35       37.3047  0.0579\n",
            "     36       37.3047  0.0587\n",
            "     37       37.3047  0.0623\n",
            "     38       37.3047  0.0582\n",
            "     39       37.3047  0.0582\n",
            "     40       37.3047  0.0575\n",
            "     41       37.3047  0.0602\n",
            "     42       37.3047  0.0624\n",
            "     43       37.3047  0.0577\n",
            "     44       37.3047  0.0542\n",
            "     45       37.3047  0.0550\n",
            "     46       37.3047  0.0517\n",
            "     47       37.3047  0.0560\n",
            "     48       37.3047  0.0631\n",
            "     49       37.3047  0.0559\n",
            "     50       37.3047  0.0586\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0536\n",
            "      2       37.3047  0.0585\n",
            "      3       37.3047  0.0588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0636\n",
            "      5       37.3047  0.0561\n",
            "      6       37.3047  0.0617\n",
            "      7       37.3047  0.0551\n",
            "      8       37.3047  0.0559\n",
            "      9       37.3047  0.0631\n",
            "     10       37.3047  0.0562\n",
            "     11       37.3047  0.0688\n",
            "     12       37.3047  0.0559\n",
            "     13       37.3047  0.0571\n",
            "     14       37.3047  0.0563\n",
            "     15       37.3047  0.0641\n",
            "     16       37.3047  0.0595\n",
            "     17       37.3047  0.0545\n",
            "     18       37.3047  0.0554\n",
            "     19       37.3047  0.0536\n",
            "     20       37.3047  0.0581\n",
            "     21       37.3047  0.0603\n",
            "     22       37.3047  0.0529\n",
            "     23       37.3047  0.0583\n",
            "     24       37.3047  0.0546\n",
            "     25       37.3047  0.0550\n",
            "     26       37.3047  0.0630\n",
            "     27       37.3047  0.0544\n",
            "     28       37.3047  0.0559\n",
            "     29       37.3047  0.0555\n",
            "     30       37.3047  0.0545\n",
            "     31       37.3047  0.0596\n",
            "     32       37.3047  0.0549\n",
            "     33       37.3047  0.0564\n",
            "     34       37.3047  0.0560\n",
            "     35       37.3047  0.0594\n",
            "     36       37.3047  0.0557\n",
            "     37       37.3047  0.0660\n",
            "     38       37.3047  0.0545\n",
            "     39       37.3047  0.0556\n",
            "     40       37.3047  0.0563\n",
            "     41       37.3047  0.0597\n",
            "     42       37.3047  0.0537\n",
            "     43       37.3047  0.0647\n",
            "     44       37.3047  0.0568\n",
            "     45       37.3047  0.0565\n",
            "     46       37.3047  0.0657\n",
            "     47       37.3047  0.0570\n",
            "     48       37.3047  0.0551\n",
            "     49       37.3047  0.0557\n",
            "     50       37.3047  0.0605\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0519\n",
            "      2       37.3047  0.0597\n",
            "      3       37.3047  0.0587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0636\n",
            "      5       37.3047  0.0554\n",
            "      6       37.3047  0.0564\n",
            "      7       37.3047  0.0560\n",
            "      8       37.3047  0.0558\n",
            "      9       37.3047  0.0562\n",
            "     10       37.3047  0.0633\n",
            "     11       37.3047  0.0602\n",
            "     12       37.3047  0.0562\n",
            "     13       37.3047  0.0555\n",
            "     14       37.3047  0.0600\n",
            "     15       37.3047  0.0562\n",
            "     16       37.3047  0.0648\n",
            "     17       37.3047  0.0559\n",
            "     18       37.3047  0.0562\n",
            "     19       37.3047  0.0568\n",
            "     20       37.3047  0.0585\n",
            "     21       37.3047  0.0563\n",
            "     22       37.3047  0.0565\n",
            "     23       37.3047  0.0566\n",
            "     24       37.3047  0.0545\n",
            "     25       37.3047  0.0613\n",
            "     26       37.3047  0.0600\n",
            "     27       37.3047  0.0599\n",
            "     28       37.3047  0.0561\n",
            "     29       37.3047  0.0569\n",
            "     30       37.3047  0.0562\n",
            "     31       37.3047  0.0655\n",
            "     32       37.3047  0.0572\n",
            "     33       37.3047  0.0577\n",
            "     34       37.3047  0.0566\n",
            "     35       37.3047  0.0568\n",
            "     36       37.3047  0.0623\n",
            "     37       37.3047  0.0580\n",
            "     38       37.3047  0.0556\n",
            "     39       37.3047  0.0601\n",
            "     40       37.3047  0.0602\n",
            "     41       37.3047  0.0582\n",
            "     42       37.3047  0.0573\n",
            "     43       37.3047  0.0643\n",
            "     44       37.3047  0.0558\n",
            "     45       37.3047  0.0568\n",
            "     46       37.3047  0.0643\n",
            "     47       37.3047  0.0590\n",
            "     48       37.3047  0.0569\n",
            "     49       37.3047  0.0575\n",
            "     50       37.3047  0.0587\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0524\n",
            "      2       37.3047  0.0569\n",
            "      3       37.3047  0.0560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0610\n",
            "      5       37.3047  0.0570\n",
            "      6       37.3047  0.0581\n",
            "      7       37.3047  0.0577\n",
            "      8       37.3047  0.0563\n",
            "      9       37.3047  0.0569\n",
            "     10       37.3047  0.0648\n",
            "     11       37.3047  0.0557\n",
            "     12       37.3047  0.0620\n",
            "     13       37.3047  0.0563\n",
            "     14       37.3047  0.0560\n",
            "     15       37.3047  0.0598\n",
            "     16       37.3047  0.0594\n",
            "     17       37.3047  0.0562\n",
            "     18       37.3047  0.0578\n",
            "     19       37.3047  0.0594\n",
            "     20       37.3047  0.0572\n",
            "     21       37.3047  0.0596\n",
            "     22       37.3047  0.0545\n",
            "     23       37.3047  0.0553\n",
            "     24       37.3047  0.0577\n",
            "     25       37.3047  0.0558\n",
            "     26       37.3047  0.0621\n",
            "     27       37.3047  0.0631\n",
            "     28       37.3047  0.0551\n",
            "     29       37.3047  0.0564\n",
            "     30       37.3047  0.0554\n",
            "     31       37.3047  0.0619\n",
            "     32       37.3047  0.0568\n",
            "     33       37.3047  0.0570\n",
            "     34       37.3047  0.0574\n",
            "     35       37.3047  0.0575\n",
            "     36       37.3047  0.0623\n",
            "     37       37.3047  0.0595\n",
            "     38       37.3047  0.0563\n",
            "     39       37.3047  0.0570\n",
            "     40       37.3047  0.0564\n",
            "     41       37.3047  0.0560\n",
            "     42       37.3047  0.0570\n",
            "     43       37.3047  0.0559\n",
            "     44       37.3047  0.0651\n",
            "     45       37.3047  0.0537\n",
            "     46       37.3047  0.0609\n",
            "     47       37.3047  0.0606\n",
            "     48       37.3047  0.0563\n",
            "     49       37.3047  0.0802\n",
            "     50       37.3047  0.0572\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0539\n",
            "      2       37.3047  0.0590\n",
            "      3       37.3047  0.0558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0615\n",
            "      5       37.3047  0.0596\n",
            "      6       37.3047  0.0566\n",
            "      7       37.3047  0.0600\n",
            "      8       37.3047  0.0581\n",
            "      9       37.3047  0.0582\n",
            "     10       37.3047  0.0616\n",
            "     11       37.3047  0.0525\n",
            "     12       37.3047  0.0551\n",
            "     13       37.3047  0.0559\n",
            "     14       37.3047  0.0537\n",
            "     15       37.3047  0.0596\n",
            "     16       37.3047  0.0572\n",
            "     17       37.3047  0.0536\n",
            "     18       37.3047  0.0549\n",
            "     19       37.3047  0.0631\n",
            "     20       37.3047  0.0546\n",
            "     21       37.3047  0.0555\n",
            "     22       37.3047  0.0560\n",
            "     23       37.3047  0.0544\n",
            "     24       37.3047  0.0558\n",
            "     25       37.3047  0.0552\n",
            "     26       37.3047  0.0554\n",
            "     27       37.3047  0.0601\n",
            "     28       37.3047  0.0607\n",
            "     29       37.3047  0.0555\n",
            "     30       37.3047  0.0629\n",
            "     31       37.3047  0.0548\n",
            "     32       37.3047  0.0605\n",
            "     33       37.3047  0.0561\n",
            "     34       37.3047  0.0568\n",
            "     35       37.3047  0.0598\n",
            "     36       37.3047  0.0558\n",
            "     37       37.3047  0.0564\n",
            "     38       37.3047  0.0551\n",
            "     39       37.3047  0.0548\n",
            "     40       37.3047  0.0559\n",
            "     41       37.3047  0.0559\n",
            "     42       37.3047  0.0582\n",
            "     43       37.3047  0.0587\n",
            "     44       37.3047  0.0566\n",
            "     45       37.3047  0.0629\n",
            "     46       37.3047  0.0692\n",
            "     47       37.3047  0.0559\n",
            "     48       37.3047  0.0571\n",
            "     49       37.3047  0.0623\n",
            "     50       37.3047  0.0571\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.2320\u001b[0m  0.0524\n",
            "      2       37.2320  0.0597\n",
            "      3       37.2320  0.0552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.2320  0.0629\n",
            "      5       37.2320  0.0566\n",
            "      6       37.2320  0.0556\n",
            "      7       37.2320  0.0555\n",
            "      8       37.2320  0.0591\n",
            "      9       37.2320  0.0614\n",
            "     10       37.2320  0.0628\n",
            "     11       37.2320  0.0654\n",
            "     12       37.2320  0.0582\n",
            "     13       37.2320  0.0599\n",
            "     14       37.2320  0.0569\n",
            "     15       37.2320  0.0578\n",
            "     16       37.2320  0.0546\n",
            "     17       37.2320  0.0560\n",
            "     18       37.2320  0.0601\n",
            "     19       37.2320  0.0599\n",
            "     20       37.2320  0.0573\n",
            "     21       37.2320  0.0550\n",
            "     22       37.2320  0.0587\n",
            "     23       37.2320  0.0554\n",
            "     24       37.2320  0.0561\n",
            "     25       37.2320  0.0585\n",
            "     26       37.2320  0.0576\n",
            "     27       37.2320  0.0556\n",
            "     28       37.2320  0.0595\n",
            "     29       37.2320  0.0557\n",
            "     30       37.2320  0.0635\n",
            "     31       37.2320  0.0583\n",
            "     32       37.2320  0.0605\n",
            "     33       37.2320  0.0566\n",
            "     34       37.2320  0.0578\n",
            "     35       37.2320  0.0644\n",
            "     36       37.2320  0.0555\n",
            "     37       37.2320  0.0567\n",
            "     38       37.2320  0.0567\n",
            "     39       37.2320  0.0546\n",
            "     40       37.2320  0.0570\n",
            "     41       37.2320  0.0569\n",
            "     42       37.2320  0.0568\n",
            "     43       37.2320  0.0574\n",
            "     44       37.2320  0.0576\n",
            "     45       37.2320  0.0715\n",
            "     46       37.2320  0.0556\n",
            "     47       37.2320  0.0554\n",
            "     48       37.2320  0.0597\n",
            "     49       37.2320  0.0603\n",
            "     50       37.2320  0.0554\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m51.8628\u001b[0m  0.0679\n",
            "      2       \u001b[36m50.7816\u001b[0m  0.0709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m49.8211\u001b[0m  0.0745\n",
            "      4       \u001b[36m49.5212\u001b[0m  0.0729\n",
            "      5       \u001b[36m47.2245\u001b[0m  0.0702\n",
            "      6       47.3891  0.0696\n",
            "      7       \u001b[36m47.1331\u001b[0m  0.0713\n",
            "      8       \u001b[36m46.3659\u001b[0m  0.0757\n",
            "      9       \u001b[36m45.5652\u001b[0m  0.0827\n",
            "     10       45.7187  0.0725\n",
            "     11       45.7176  0.0718\n",
            "     12       45.7168  0.0764\n",
            "     13       45.7160  0.0734\n",
            "     14       45.7151  0.0727\n",
            "     15       45.7141  0.0694\n",
            "     16       \u001b[36m45.5177\u001b[0m  0.0680\n",
            "     17       \u001b[36m43.2741\u001b[0m  0.0702\n",
            "     18       \u001b[36m40.5197\u001b[0m  0.0699\n",
            "     19       \u001b[36m40.2403\u001b[0m  0.0693\n",
            "     20       \u001b[36m39.9901\u001b[0m  0.0730\n",
            "     21       \u001b[36m39.7840\u001b[0m  0.0737\n",
            "     22       \u001b[36m39.7743\u001b[0m  0.0697\n",
            "     23       \u001b[36m39.7740\u001b[0m  0.0776\n",
            "     24       \u001b[36m39.7737\u001b[0m  0.0804\n",
            "     25       \u001b[36m39.7704\u001b[0m  0.0720\n",
            "     26       \u001b[36m39.7661\u001b[0m  0.0695\n",
            "     27       \u001b[36m39.7628\u001b[0m  0.0710\n",
            "     28       \u001b[36m39.7593\u001b[0m  0.0748\n",
            "     29       \u001b[36m39.7512\u001b[0m  0.0712\n",
            "     30       39.7760  0.0706\n",
            "     31       \u001b[36m38.5388\u001b[0m  0.0702\n",
            "     32       \u001b[36m38.4840\u001b[0m  0.0762\n",
            "     33       38.5173  0.0689\n",
            "     34       38.5305  0.0696\n",
            "     35       39.8109  0.0707\n",
            "     36       38.5735  0.0702\n",
            "     37       \u001b[36m36.2691\u001b[0m  0.0855\n",
            "     38       37.0499  0.0707\n",
            "     39       37.1366  0.0693\n",
            "     40       36.9719  0.0781\n",
            "     41       \u001b[36m36.0912\u001b[0m  0.0762\n",
            "     42       36.1771  0.0712\n",
            "     43       \u001b[36m34.9596\u001b[0m  0.0681\n",
            "     44       35.7822  0.0694\n",
            "     45       35.8706  0.0692\n",
            "     46       \u001b[36m34.6723\u001b[0m  0.0699\n",
            "     47       35.1906  0.0775\n",
            "     48       35.1202  0.0732\n",
            "     49       35.0988  0.0782\n",
            "     50       35.0988  0.0725\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m58.6325\u001b[0m  0.0737\n",
            "      2       \u001b[36m58.3392\u001b[0m  0.0718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m58.0651\u001b[0m  0.0750\n",
            "      4       \u001b[36m58.0614\u001b[0m  0.0748\n",
            "      5       \u001b[36m58.0600\u001b[0m  0.0672\n",
            "      6       \u001b[36m58.0584\u001b[0m  0.0658\n",
            "      7       \u001b[36m58.0567\u001b[0m  0.0680\n",
            "      8       \u001b[36m58.0548\u001b[0m  0.0689\n",
            "      9       \u001b[36m58.0528\u001b[0m  0.0678\n",
            "     10       \u001b[36m58.0506\u001b[0m  0.0680\n",
            "     11       \u001b[36m58.0483\u001b[0m  0.0755\n",
            "     12       \u001b[36m58.0459\u001b[0m  0.0676\n",
            "     13       \u001b[36m58.0433\u001b[0m  0.0816\n",
            "     14       \u001b[36m58.0406\u001b[0m  0.0762\n",
            "     15       \u001b[36m58.0378\u001b[0m  0.0806\n",
            "     16       \u001b[36m58.0348\u001b[0m  0.0726\n",
            "     17       \u001b[36m57.8364\u001b[0m  0.0711\n",
            "     18       \u001b[36m57.8332\u001b[0m  0.0733\n",
            "     19       \u001b[36m57.4392\u001b[0m  0.0816\n",
            "     20       \u001b[36m57.4357\u001b[0m  0.0698\n",
            "     21       \u001b[36m57.4321\u001b[0m  0.0699\n",
            "     22       \u001b[36m57.4283\u001b[0m  0.0713\n",
            "     23       \u001b[36m57.4244\u001b[0m  0.0718\n",
            "     24       \u001b[36m57.2464\u001b[0m  0.0706\n",
            "     25       \u001b[36m56.0096\u001b[0m  0.0708\n",
            "     26       \u001b[36m55.9950\u001b[0m  0.0693\n",
            "     27       \u001b[36m55.9900\u001b[0m  0.0760\n",
            "     28       \u001b[36m55.9850\u001b[0m  0.0759\n",
            "     29       \u001b[36m55.9798\u001b[0m  0.0739\n",
            "     30       \u001b[36m55.9746\u001b[0m  0.0709\n",
            "     31       \u001b[36m55.9693\u001b[0m  0.0752\n",
            "     32       \u001b[36m55.9640\u001b[0m  0.0686\n",
            "     33       \u001b[36m55.9585\u001b[0m  0.0702\n",
            "     34       \u001b[36m55.9531\u001b[0m  0.0701\n",
            "     35       \u001b[36m55.9475\u001b[0m  0.0702\n",
            "     36       \u001b[36m55.9419\u001b[0m  0.0712\n",
            "     37       \u001b[36m55.9362\u001b[0m  0.0733\n",
            "     38       \u001b[36m55.9298\u001b[0m  0.0764\n",
            "     39       \u001b[36m50.8236\u001b[0m  0.0770\n",
            "     40       \u001b[36m23.7793\u001b[0m  0.0722\n",
            "     41       37.1094  0.0821\n",
            "     42       37.1094  0.0747\n",
            "     43       37.1094  0.0756\n",
            "     44       37.1094  0.0743\n",
            "     45       37.1094  0.0728\n",
            "     46       37.1094  0.0703\n",
            "     47       37.1094  0.0798\n",
            "     48       37.1094  0.0706\n",
            "     49       37.1094  0.0694\n",
            "     50       37.1094  0.0694\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m62.6953\u001b[0m  0.0642\n",
            "      2       62.6953  0.0693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       62.6953  0.0736\n",
            "      4       62.6953  0.0683\n",
            "      5       62.6953  0.0841\n",
            "      6       62.6953  0.0694\n",
            "      7       62.6953  0.0753\n",
            "      8       62.6953  0.0735\n",
            "      9       62.6953  0.0702\n",
            "     10       62.6953  0.0700\n",
            "     11       62.6953  0.0694\n",
            "     12       62.6953  0.0685\n",
            "     13       62.6953  0.0710\n",
            "     14       62.6953  0.0702\n",
            "     15       62.6953  0.0679\n",
            "     16       62.6953  0.0683\n",
            "     17       62.6953  0.0794\n",
            "     18       62.6953  0.0686\n",
            "     19       62.6953  0.0826\n",
            "     20       62.6953  0.0687\n",
            "     21       62.6953  0.0720\n",
            "     22       \u001b[36m62.6620\u001b[0m  0.0674\n",
            "     23       \u001b[36m62.6314\u001b[0m  0.0661\n",
            "     24       \u001b[36m62.5765\u001b[0m  0.0721\n",
            "     25       \u001b[36m62.1808\u001b[0m  0.0665\n",
            "     26       \u001b[36m55.1168\u001b[0m  0.0687\n",
            "     27        \u001b[36m8.9470\u001b[0m  0.0698\n",
            "     28        \u001b[36m3.6883\u001b[0m  0.0777\n",
            "     29        \u001b[36m3.3272\u001b[0m  0.0747\n",
            "     30        \u001b[36m2.6171\u001b[0m  0.0697\n",
            "     31        \u001b[36m2.0591\u001b[0m  0.0685\n",
            "     32        \u001b[36m1.6415\u001b[0m  0.0693\n",
            "     33        \u001b[36m1.1507\u001b[0m  0.0745\n",
            "     34        \u001b[36m0.4981\u001b[0m  0.0715\n",
            "     35        0.5371  0.0727\n",
            "     36        \u001b[36m0.4235\u001b[0m  0.0680\n",
            "     37        0.4743  0.0685\n",
            "     38        \u001b[36m0.4046\u001b[0m  0.0688\n",
            "     39        0.4500  0.0673\n",
            "     40        \u001b[36m0.4000\u001b[0m  0.0746\n",
            "     41        0.4195  0.0708\n",
            "     42        \u001b[36m0.3929\u001b[0m  0.0735\n",
            "     43        \u001b[36m0.3896\u001b[0m  0.0686\n",
            "     44        \u001b[36m0.3826\u001b[0m  0.0691\n",
            "     45        \u001b[36m0.3719\u001b[0m  0.0693\n",
            "     46        \u001b[36m0.3662\u001b[0m  0.0866\n",
            "     47        \u001b[36m0.3564\u001b[0m  0.0751\n",
            "     48        \u001b[36m0.3413\u001b[0m  0.0752\n",
            "     49        \u001b[36m0.3278\u001b[0m  0.0704\n",
            "     50        \u001b[36m0.2979\u001b[0m  0.0774\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m57.0312\u001b[0m  0.0640\n",
            "      2       \u001b[36m56.8355\u001b[0m  0.0723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       57.0836  0.0771\n",
            "      4       57.0065  0.0729\n",
            "      5       57.0057  0.0745\n",
            "      6       57.0058  0.0728\n",
            "      7       57.0059  0.0720\n",
            "      8       56.9129  0.0827\n",
            "      9       56.8865  0.0713\n",
            "     10       \u001b[36m56.8095\u001b[0m  0.0812\n",
            "     11       \u001b[36m56.8094\u001b[0m  0.0743\n",
            "     12       \u001b[36m56.8093\u001b[0m  0.0711\n",
            "     13       \u001b[36m56.8091\u001b[0m  0.0747\n",
            "     14       \u001b[36m56.8088\u001b[0m  0.0713\n",
            "     15       \u001b[36m56.8084\u001b[0m  0.0679\n",
            "     16       \u001b[36m56.8080\u001b[0m  0.0737\n",
            "     17       \u001b[36m56.8076\u001b[0m  0.0750\n",
            "     18       \u001b[36m56.8070\u001b[0m  0.0705\n",
            "     19       \u001b[36m56.8064\u001b[0m  0.0687\n",
            "     20       \u001b[36m56.8058\u001b[0m  0.0752\n",
            "     21       \u001b[36m56.8050\u001b[0m  0.0740\n",
            "     22       \u001b[36m56.8042\u001b[0m  0.0710\n",
            "     23       \u001b[36m56.8034\u001b[0m  0.0775\n",
            "     24       \u001b[36m56.8024\u001b[0m  0.0690\n",
            "     25       \u001b[36m56.7091\u001b[0m  0.0795\n",
            "     26       \u001b[36m56.6758\u001b[0m  0.0699\n",
            "     27       \u001b[36m56.6684\u001b[0m  0.0677\n",
            "     28       \u001b[36m56.6622\u001b[0m  0.0692\n",
            "     29       \u001b[36m56.6567\u001b[0m  0.0692\n",
            "     30       \u001b[36m56.6518\u001b[0m  0.0684\n",
            "     31       \u001b[36m56.6474\u001b[0m  0.0691\n",
            "     32       \u001b[36m56.6434\u001b[0m  0.0767\n",
            "     33       \u001b[36m56.6395\u001b[0m  0.0730\n",
            "     34       \u001b[36m56.6351\u001b[0m  0.0755\n",
            "     35       \u001b[36m56.6268\u001b[0m  0.0677\n",
            "     36       \u001b[36m56.5362\u001b[0m  0.0709\n",
            "     37       \u001b[36m56.4768\u001b[0m  0.0791\n",
            "     38       \u001b[36m56.4698\u001b[0m  0.0743\n",
            "     39       56.4705  0.0695\n",
            "     40       56.4711  0.0696\n",
            "     41       56.4717  0.0705\n",
            "     42       56.4722  0.0704\n",
            "     43       56.4726  0.0752\n",
            "     44       56.4730  0.0780\n",
            "     45       56.4734  0.0716\n",
            "     46       56.4736  0.0716\n",
            "     47       56.4737  0.0706\n",
            "     48       56.4737  0.0787\n",
            "     49       56.4735  0.0716\n",
            "     50       56.4729  0.0806\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.8906\u001b[0m  0.0663\n",
            "      2       38.2812  0.0741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       39.0625  0.0720\n",
            "      4       39.4531  0.0681\n",
            "      5       39.4531  0.0679\n",
            "      6       39.6484  0.0704\n",
            "      7       39.7032  0.0682\n",
            "      8       39.4531  0.0726\n",
            "      9       39.4531  0.0694\n",
            "     10       39.4531  0.0760\n",
            "     11       39.4531  0.0881\n",
            "     12       39.4531  0.0735\n",
            "     13       39.4531  0.0755\n",
            "     14       39.4531  0.0794\n",
            "     15       39.4531  0.0788\n",
            "     16       38.8673  0.0705\n",
            "     17       37.8906  0.0713\n",
            "     18       37.8906  0.0717\n",
            "     19       37.8906  0.0708\n",
            "     20       37.8906  0.0740\n",
            "     21       37.8906  0.0719\n",
            "     22       37.8906  0.0776\n",
            "     23       37.8906  0.0713\n",
            "     24       37.8906  0.0718\n",
            "     25       37.8906  0.0747\n",
            "     26       37.8906  0.0722\n",
            "     27       37.8906  0.0790\n",
            "     28       37.8906  0.0739\n",
            "     29       37.8906  0.0731\n",
            "     30       37.8906  0.0703\n",
            "     31       37.8906  0.0691\n",
            "     32       37.8906  0.0705\n",
            "     33       37.8906  0.0775\n",
            "     34       37.8906  0.0733\n",
            "     35       37.8906  0.0730\n",
            "     36       37.8906  0.0710\n",
            "     37       37.8906  0.0690\n",
            "     38       37.8906  0.0763\n",
            "     39       37.8906  0.0722\n",
            "     40       37.8906  0.0762\n",
            "     41       \u001b[36m37.7230\u001b[0m  0.0808\n",
            "     42       \u001b[36m37.6953\u001b[0m  0.0685\n",
            "     43       37.6953  0.0708\n",
            "     44       37.6953  0.0704\n",
            "     45       37.6953  0.0725\n",
            "     46       37.6953  0.0709\n",
            "     47       37.6953  0.0729\n",
            "     48       37.6953  0.0755\n",
            "     49       37.6953  0.0696\n",
            "     50       37.6953  0.0754\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m62.3047\u001b[0m  0.0711\n",
            "      2       62.5000  0.0706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       62.6953  0.0846\n",
            "      4       62.6953  0.0828\n",
            "      5       62.6953  0.0700\n",
            "      6       62.6953  0.0692\n",
            "      7       62.6953  0.0732\n",
            "      8       62.6249  0.0699\n",
            "      9       \u001b[36m61.5616\u001b[0m  0.0762\n",
            "     10       \u001b[36m60.3516\u001b[0m  0.0733\n",
            "     11       \u001b[36m60.1562\u001b[0m  0.0768\n",
            "     12       60.1562  0.0750\n",
            "     13       \u001b[36m59.9609\u001b[0m  0.0749\n",
            "     14       \u001b[36m59.5709\u001b[0m  0.0729\n",
            "     15       \u001b[36m59.2687\u001b[0m  0.0727\n",
            "     16       \u001b[36m59.0136\u001b[0m  0.0711\n",
            "     17       \u001b[36m57.3736\u001b[0m  0.0879\n",
            "     18       \u001b[36m55.9385\u001b[0m  0.0729\n",
            "     19       \u001b[36m54.3311\u001b[0m  0.0709\n",
            "     20       \u001b[36m51.7596\u001b[0m  0.0710\n",
            "     21       51.9630  0.0703\n",
            "     22       \u001b[36m45.7694\u001b[0m  0.0722\n",
            "     23       \u001b[36m36.6698\u001b[0m  0.0762\n",
            "     24       37.3047  0.0716\n",
            "     25       37.3047  0.0697\n",
            "     26       37.3047  0.0684\n",
            "     27       37.3047  0.0822\n",
            "     28       37.3047  0.0735\n",
            "     29       37.3047  0.0717\n",
            "     30       37.3047  0.0743\n",
            "     31       37.3047  0.0784\n",
            "     32       37.3047  0.0695\n",
            "     33       37.3047  0.0700\n",
            "     34       37.3047  0.0795\n",
            "     35       37.3047  0.0719\n",
            "     36       37.3047  0.0712\n",
            "     37       37.3047  0.0725\n",
            "     38       37.3047  0.0706\n",
            "     39       37.3047  0.0792\n",
            "     40       37.3047  0.0701\n",
            "     41       37.3047  0.0736\n",
            "     42       37.3047  0.0697\n",
            "     43       37.3047  0.0721\n",
            "     44       37.3047  0.0842\n",
            "     45       37.3047  0.0713\n",
            "     46       37.3047  0.0706\n",
            "     47       37.3047  0.0688\n",
            "     48       37.3047  0.0705\n",
            "     49       37.3047  0.0698\n",
            "     50       37.3047  0.0720\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m42.2945\u001b[0m  0.0764\n",
            "      2       \u001b[36m42.2888\u001b[0m  0.0684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m41.8397\u001b[0m  0.0737\n",
            "      4       \u001b[36m41.8141\u001b[0m  0.0699\n",
            "      5       \u001b[36m41.8006\u001b[0m  0.0683\n",
            "      6       \u001b[36m41.6043\u001b[0m  0.0718\n",
            "      7       41.6272  0.0770\n",
            "      8       41.6043  0.0787\n",
            "      9       41.6043  0.0710\n",
            "     10       \u001b[36m41.4090\u001b[0m  0.0785\n",
            "     11       41.6043  0.0702\n",
            "     12       41.6043  0.0691\n",
            "     13       41.6043  0.0705\n",
            "     14       41.6043  0.0740\n",
            "     15       41.6043  0.0715\n",
            "     16       41.6043  0.0730\n",
            "     17       41.6043  0.0768\n",
            "     18       41.6043  0.0756\n",
            "     19       41.6043  0.0699\n",
            "     20       41.6043  0.0739\n",
            "     21       41.7440  0.0791\n",
            "     22       41.8449  0.0711\n",
            "     23       41.5241  0.0705\n",
            "     24       41.5289  0.0703\n",
            "     25       41.5337  0.0711\n",
            "     26       41.5352  0.0700\n",
            "     27       41.5352  0.0746\n",
            "     28       41.5352  0.0711\n",
            "     29       41.5351  0.0742\n",
            "     30       \u001b[36m41.2449\u001b[0m  0.0705\n",
            "     31       41.6043  0.0761\n",
            "     32       41.6043  0.0712\n",
            "     33       41.6043  0.0693\n",
            "     34       41.6043  0.0717\n",
            "     35       41.6043  0.0879\n",
            "     36       41.6043  0.0738\n",
            "     37       41.6043  0.0710\n",
            "     38       41.6043  0.0707\n",
            "     39       41.6043  0.0708\n",
            "     40       41.6043  0.0715\n",
            "     41       41.6043  0.0769\n",
            "     42       41.6043  0.0734\n",
            "     43       41.6043  0.0790\n",
            "     44       41.6043  0.0728\n",
            "     45       41.6043  0.0718\n",
            "     46       41.6043  0.0710\n",
            "     47       41.6043  0.0741\n",
            "     48       41.6043  0.0757\n",
            "     49       41.6043  0.0814\n",
            "     50       41.6043  0.0745\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.6953\u001b[0m  0.0654\n",
            "      2       \u001b[36m37.5000\u001b[0m  0.0731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.6953  0.0775\n",
            "      4       37.6953  0.0690\n",
            "      5       37.6953  0.0768\n",
            "      6       37.6953  0.0798\n",
            "      7       37.6953  0.0826\n",
            "      8       37.5956  0.0693\n",
            "      9       37.8946  0.0755\n",
            "     10       \u001b[36m37.3047\u001b[0m  0.0715\n",
            "     11       37.3047  0.0733\n",
            "     12       37.3047  0.0775\n",
            "     13       37.3047  0.0711\n",
            "     14       37.3047  0.0700\n",
            "     15       37.3047  0.0726\n",
            "     16       37.3047  0.0774\n",
            "     17       37.3047  0.0728\n",
            "     18       37.3047  0.0716\n",
            "     19       37.3047  0.0818\n",
            "     20       37.3047  0.0704\n",
            "     21       37.3047  0.0700\n",
            "     22       37.3047  0.0710\n",
            "     23       37.3047  0.0727\n",
            "     24       37.3047  0.0707\n",
            "     25       37.3047  0.0781\n",
            "     26       37.3047  0.0763\n",
            "     27       37.3047  0.0683\n",
            "     28       37.3047  0.0745\n",
            "     29       37.3047  0.0709\n",
            "     30       37.3047  0.0700\n",
            "     31       37.3047  0.0721\n",
            "     32       37.3047  0.0739\n",
            "     33       37.3047  0.0714\n",
            "     34       37.3047  0.0690\n",
            "     35       37.3047  0.0749\n",
            "     36       37.3047  0.0727\n",
            "     37       37.3047  0.0738\n",
            "     38       37.3047  0.0789\n",
            "     39       37.3047  0.0843\n",
            "     40       37.3047  0.0722\n",
            "     41       37.3047  0.0722\n",
            "     42       37.3047  0.0719\n",
            "     43       37.3047  0.0790\n",
            "     44       37.3047  0.0743\n",
            "     45       37.3047  0.0718\n",
            "     46       37.3047  0.0776\n",
            "     47       37.3047  0.0719\n",
            "     48       37.3047  0.0708\n",
            "     49       37.3047  0.0754\n",
            "     50       37.3047  0.0693\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m36.7638\u001b[0m  0.0651\n",
            "      2       \u001b[36m35.8738\u001b[0m  0.0771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       36.2834  0.0746\n",
            "      4       37.1104  0.0772\n",
            "      5       36.5546  0.0687\n",
            "      6       36.1338  0.0704\n",
            "      7       \u001b[36m35.8554\u001b[0m  0.0712\n",
            "      8       36.5845  0.0697\n",
            "      9       36.2796  0.0790\n",
            "     10       \u001b[36m35.4587\u001b[0m  0.0711\n",
            "     11       35.7739  0.0692\n",
            "     12       36.9548  0.0694\n",
            "     13       36.9141  0.0781\n",
            "     14       36.5234  0.0712\n",
            "     15       36.5234  0.0682\n",
            "     16       36.5234  0.0773\n",
            "     17       36.5234  0.0702\n",
            "     18       36.5234  0.0734\n",
            "     19       36.5234  0.0702\n",
            "     20       36.5234  0.0768\n",
            "     21       36.1639  0.0764\n",
            "     22       35.5469  0.0738\n",
            "     23       \u001b[36m35.3516\u001b[0m  0.0729\n",
            "     24       35.3516  0.0704\n",
            "     25       35.3516  0.0712\n",
            "     26       35.3516  0.0728\n",
            "     27       35.3516  0.0692\n",
            "     28       35.3516  0.0701\n",
            "     29       35.3516  0.0795\n",
            "     30       35.3516  0.0698\n",
            "     31       35.3516  0.0696\n",
            "     32       35.3516  0.0766\n",
            "     33       35.3516  0.0753\n",
            "     34       35.3516  0.0729\n",
            "     35       35.3516  0.0703\n",
            "     36       35.3516  0.0702\n",
            "     37       35.3516  0.0712\n",
            "     38       35.3516  0.0700\n",
            "     39       35.3516  0.0758\n",
            "     40       35.3516  0.0743\n",
            "     41       35.3516  0.0692\n",
            "     42       35.3516  0.0683\n",
            "     43       35.3516  0.0801\n",
            "     44       35.3516  0.0709\n",
            "     45       35.3516  0.0702\n",
            "     46       35.3516  0.0717\n",
            "     47       35.3516  0.0730\n",
            "     48       35.3516  0.0794\n",
            "     49       35.3516  0.0792\n",
            "     50       35.3516  0.0802\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m36.7452\u001b[0m  0.0677\n",
            "      2       \u001b[36m33.4658\u001b[0m  0.0745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m33.2355\u001b[0m  0.0788\n",
            "      4       34.3689  0.0690\n",
            "      5       35.1095  0.0738\n",
            "      6       34.5142  0.0784\n",
            "      7       34.1868  0.0760\n",
            "      8       34.7938  0.0779\n",
            "      9       34.8623  0.0729\n",
            "     10       33.7049  0.0703\n",
            "     11       \u001b[36m32.2798\u001b[0m  0.0756\n",
            "     12       \u001b[36m31.0721\u001b[0m  0.0710\n",
            "     13       \u001b[36m29.7333\u001b[0m  0.0744\n",
            "     14       32.8890  0.0709\n",
            "     15       32.6513  0.0712\n",
            "     16       30.0364  0.0728\n",
            "     17       33.2667  0.0700\n",
            "     18       33.3550  0.0748\n",
            "     19       34.6500  0.0788\n",
            "     20       \u001b[36m29.4659\u001b[0m  0.0740\n",
            "     21       33.2159  0.0698\n",
            "     22       31.3304  0.0729\n",
            "     23       \u001b[36m25.9746\u001b[0m  0.0780\n",
            "     24       31.9300  0.0700\n",
            "     25       31.4104  0.0707\n",
            "     26       34.0620  0.0754\n",
            "     27       33.7232  0.0722\n",
            "     28       33.7232  0.0767\n",
            "     29       33.7232  0.0736\n",
            "     30       33.7232  0.0725\n",
            "     31       33.7232  0.0707\n",
            "     32       33.7232  0.0713\n",
            "     33       33.7232  0.0783\n",
            "     34       33.7232  0.0748\n",
            "     35       33.7232  0.0716\n",
            "     36       33.7232  0.0708\n",
            "     37       33.7232  0.0771\n",
            "     38       33.7232  0.0739\n",
            "     39       33.7232  0.0847\n",
            "     40       33.7232  0.0730\n",
            "     41       33.7232  0.0734\n",
            "     42       33.7232  0.0765\n",
            "     43       33.7232  0.0711\n",
            "     44       33.7232  0.0690\n",
            "     45       33.7232  0.0720\n",
            "     46       33.7232  0.0758\n",
            "     47       33.7232  0.0867\n",
            "     48       33.7232  0.0785\n",
            "     49       33.7232  0.0741\n",
            "     50       33.7232  0.0783\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m51.4317\u001b[0m  0.0510\n",
            "      2       \u001b[36m51.0576\u001b[0m  0.0587\n",
            "      3       \u001b[36m51.0575\u001b[0m  0.0548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       \u001b[36m51.0575\u001b[0m  0.0629\n",
            "      5       \u001b[36m51.0574\u001b[0m  0.0550\n",
            "      6       \u001b[36m51.0573\u001b[0m  0.0600\n",
            "      7       \u001b[36m51.0573\u001b[0m  0.0533\n",
            "      8       \u001b[36m51.0572\u001b[0m  0.0593\n",
            "      9       \u001b[36m51.0571\u001b[0m  0.0540\n",
            "     10       \u001b[36m51.0571\u001b[0m  0.0569\n",
            "     11       \u001b[36m51.0570\u001b[0m  0.0547\n",
            "     12       \u001b[36m51.0569\u001b[0m  0.0665\n",
            "     13       \u001b[36m51.0569\u001b[0m  0.0583\n",
            "     14       \u001b[36m51.0568\u001b[0m  0.0576\n",
            "     15       \u001b[36m51.0567\u001b[0m  0.0621\n",
            "     16       \u001b[36m51.0567\u001b[0m  0.0571\n",
            "     17       \u001b[36m51.0566\u001b[0m  0.0571\n",
            "     18       \u001b[36m51.0565\u001b[0m  0.0600\n",
            "     19       \u001b[36m51.0565\u001b[0m  0.0564\n",
            "     20       \u001b[36m51.0564\u001b[0m  0.0563\n",
            "     21       \u001b[36m51.0563\u001b[0m  0.0587\n",
            "     22       \u001b[36m51.0562\u001b[0m  0.0602\n",
            "     23       \u001b[36m51.0562\u001b[0m  0.0616\n",
            "     24       \u001b[36m51.0561\u001b[0m  0.0580\n",
            "     25       \u001b[36m51.0560\u001b[0m  0.0585\n",
            "     26       \u001b[36m51.0560\u001b[0m  0.0554\n",
            "     27       \u001b[36m51.0559\u001b[0m  0.0564\n",
            "     28       \u001b[36m51.0558\u001b[0m  0.0572\n",
            "     29       \u001b[36m51.0558\u001b[0m  0.0628\n",
            "     30       \u001b[36m51.0557\u001b[0m  0.0605\n",
            "     31       \u001b[36m51.0556\u001b[0m  0.0571\n",
            "     32       \u001b[36m51.0556\u001b[0m  0.0571\n",
            "     33       \u001b[36m51.0555\u001b[0m  0.0662\n",
            "     34       \u001b[36m51.0554\u001b[0m  0.0571\n",
            "     35       \u001b[36m51.0554\u001b[0m  0.0601\n",
            "     36       \u001b[36m51.0553\u001b[0m  0.0599\n",
            "     37       \u001b[36m51.0552\u001b[0m  0.0563\n",
            "     38       \u001b[36m51.0552\u001b[0m  0.0577\n",
            "     39       \u001b[36m51.0551\u001b[0m  0.0626\n",
            "     40       \u001b[36m51.0550\u001b[0m  0.0568\n",
            "     41       \u001b[36m51.0550\u001b[0m  0.0553\n",
            "     42       \u001b[36m51.0549\u001b[0m  0.0568\n",
            "     43       \u001b[36m51.0548\u001b[0m  0.0558\n",
            "     44       \u001b[36m51.0548\u001b[0m  0.0552\n",
            "     45       \u001b[36m51.0547\u001b[0m  0.0633\n",
            "     46       \u001b[36m51.0546\u001b[0m  0.0579\n",
            "     47       \u001b[36m51.0545\u001b[0m  0.0571\n",
            "     48       \u001b[36m51.0545\u001b[0m  0.0559\n",
            "     49       \u001b[36m51.0544\u001b[0m  0.0560\n",
            "     50       \u001b[36m51.0543\u001b[0m  0.0618\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m36.3706\u001b[0m  0.0517\n",
            "      2       36.9141  0.0578\n",
            "      3       36.9141  0.0572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       36.9141  0.0653\n",
            "      5       36.9141  0.0578\n",
            "      6       36.9141  0.0571\n",
            "      7       36.9141  0.0562\n",
            "      8       36.9141  0.0609\n",
            "      9       36.9141  0.0552\n",
            "     10       36.9141  0.0559\n",
            "     11       36.9141  0.0596\n",
            "     12       36.9141  0.0622\n",
            "     13       36.9141  0.0569\n",
            "     14       36.9141  0.0560\n",
            "     15       36.9141  0.0608\n",
            "     16       36.9141  0.0553\n",
            "     17       36.9141  0.0567\n",
            "     18       36.9141  0.0598\n",
            "     19       36.9141  0.0565\n",
            "     20       36.9141  0.0624\n",
            "     21       36.9141  0.0572\n",
            "     22       36.9141  0.0611\n",
            "     23       36.9141  0.0564\n",
            "     24       36.9141  0.0566\n",
            "     25       36.9141  0.0567\n",
            "     26       36.9141  0.0579\n",
            "     27       36.9141  0.0538\n",
            "     28       36.9141  0.0560\n",
            "     29       36.9141  0.0632\n",
            "     30       36.9141  0.0575\n",
            "     31       36.9141  0.0598\n",
            "     32       36.9141  0.0546\n",
            "     33       36.9141  0.0552\n",
            "     34       36.9141  0.0569\n",
            "     35       36.9141  0.0635\n",
            "     36       36.9141  0.0566\n",
            "     37       36.9141  0.0594\n",
            "     38       36.9141  0.0585\n",
            "     39       36.9141  0.0538\n",
            "     40       36.9141  0.0567\n",
            "     41       36.9141  0.0559\n",
            "     42       36.9141  0.0548\n",
            "     43       36.9141  0.0618\n",
            "     44       36.9141  0.0566\n",
            "     45       36.9141  0.0580\n",
            "     46       36.9141  0.0642\n",
            "     47       36.9141  0.0575\n",
            "     48       36.9141  0.0559\n",
            "     49       36.9141  0.0566\n",
            "     50       36.9141  0.0619\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m60.1562\u001b[0m  0.0532\n",
            "      2       60.1562  0.0601\n",
            "      3       60.1562  0.0554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       60.1562  0.0622\n",
            "      5       60.1562  0.0609\n",
            "      6       60.1562  0.0556\n",
            "      7       60.1562  0.0552\n",
            "      8       60.1562  0.0585\n",
            "      9       60.1562  0.0558\n",
            "     10       60.1562  0.0551\n",
            "     11       60.1562  0.0564\n",
            "     12       60.1562  0.0559\n",
            "     13       60.1562  0.0628\n",
            "     14       60.1562  0.0549\n",
            "     15       60.1562  0.0614\n",
            "     16       60.1562  0.0536\n",
            "     17       60.1562  0.0606\n",
            "     18       60.1562  0.0618\n",
            "     19       60.1562  0.0568\n",
            "     20       60.1562  0.0594\n",
            "     21       60.1562  0.0559\n",
            "     22       60.1562  0.0626\n",
            "     23       60.1562  0.0555\n",
            "     24       60.1562  0.0548\n",
            "     25       60.1562  0.0566\n",
            "     26       60.1562  0.0600\n",
            "     27       60.1562  0.0608\n",
            "     28       60.1562  0.0578\n",
            "     29       60.1562  0.0561\n",
            "     30       60.1562  0.0650\n",
            "     31       60.1562  0.0593\n",
            "     32       60.1562  0.0571\n",
            "     33       60.1562  0.0562\n",
            "     34       60.1562  0.0597\n",
            "     35       60.1562  0.0609\n",
            "     36       60.1562  0.0576\n",
            "     37       60.1562  0.0567\n",
            "     38       60.1562  0.0627\n",
            "     39       60.1562  0.0588\n",
            "     40       60.1562  0.0558\n",
            "     41       60.1562  0.0548\n",
            "     42       60.1562  0.0567\n",
            "     43       60.1562  0.0541\n",
            "     44       60.1562  0.0548\n",
            "     45       60.1562  0.0540\n",
            "     46       60.1562  0.0570\n",
            "     47       60.1562  0.0638\n",
            "     48       60.1562  0.0605\n",
            "     49       60.1562  0.0546\n",
            "     50       60.1562  0.0626\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m57.8125\u001b[0m  0.0518\n",
            "      2       57.8125  0.0554\n",
            "      3       57.8125  0.0570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       57.8125  0.0617\n",
            "      5       57.8125  0.0593\n",
            "      6       57.8125  0.0579\n",
            "      7       57.8125  0.0536\n",
            "      8       57.8125  0.0552\n",
            "      9       57.8125  0.0617\n",
            "     10       57.8125  0.0567\n",
            "     11       57.8125  0.0562\n",
            "     12       57.8125  0.0564\n",
            "     13       57.8125  0.0570\n",
            "     14       57.8125  0.0627\n",
            "     15       57.8125  0.0684\n",
            "     16       57.8125  0.0577\n",
            "     17       57.8125  0.0566\n",
            "     18       57.8125  0.0560\n",
            "     19       57.8125  0.0552\n",
            "     20       57.8125  0.0589\n",
            "     21       57.8125  0.0612\n",
            "     22       57.8125  0.0707\n",
            "     23       57.8125  0.0588\n",
            "     24       57.8125  0.0562\n",
            "     25       57.8125  0.0615\n",
            "     26       57.8125  0.0555\n",
            "     27       57.8125  0.0562\n",
            "     28       57.8125  0.0552\n",
            "     29       57.8125  0.0570\n",
            "     30       57.8125  0.0713\n",
            "     31       57.8125  0.0559\n",
            "     32       57.8125  0.0564\n",
            "     33       57.8125  0.0562\n",
            "     34       57.8125  0.0564\n",
            "     35       57.8125  0.0585\n",
            "     36       57.8125  0.0599\n",
            "     37       57.8125  0.0582\n",
            "     38       57.8125  0.0561\n",
            "     39       57.8125  0.0593\n",
            "     40       57.8125  0.0557\n",
            "     41       57.8125  0.0555\n",
            "     42       57.8125  0.0566\n",
            "     43       57.8125  0.0575\n",
            "     44       57.8125  0.0607\n",
            "     45       57.8125  0.0576\n",
            "     46       57.8125  0.0584\n",
            "     47       57.8125  0.0625\n",
            "     48       57.8125  0.0576\n",
            "     49       57.8125  0.0628\n",
            "     50       57.8125  0.0652\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0517\n",
            "      2       37.3047  0.0589\n",
            "      3       37.3047  0.0570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0684\n",
            "      5       37.3047  0.0560\n",
            "      6       37.3047  0.0572\n",
            "      7       37.3047  0.0553\n",
            "      8       37.3047  0.0559\n",
            "      9       37.3047  0.0633\n",
            "     10       37.3047  0.0580\n",
            "     11       37.3047  0.0574\n",
            "     12       37.3047  0.0566\n",
            "     13       37.3047  0.0596\n",
            "     14       37.3047  0.0693\n",
            "     15       37.3047  0.0582\n",
            "     16       37.3047  0.0569\n",
            "     17       37.3047  0.0580\n",
            "     18       37.3047  0.0574\n",
            "     19       37.3047  0.0731\n",
            "     20       37.3047  0.0619\n",
            "     21       37.3047  0.0580\n",
            "     22       37.3047  0.0576\n",
            "     23       37.3047  0.0560\n",
            "     24       37.3047  0.0580\n",
            "     25       37.3047  0.0562\n",
            "     26       37.3047  0.0580\n",
            "     27       37.3047  0.0589\n",
            "     28       37.3047  0.0562\n",
            "     29       37.3047  0.0666\n",
            "     30       37.3047  0.0671\n",
            "     31       37.3047  0.0588\n",
            "     32       37.3047  0.0568\n",
            "     33       37.3047  0.0576\n",
            "     34       37.3047  0.0579\n",
            "     35       37.3047  0.0594\n",
            "     36       37.3047  0.0598\n",
            "     37       37.3047  0.0577\n",
            "     38       37.3047  0.0578\n",
            "     39       37.3047  0.0575\n",
            "     40       37.3047  0.0685\n",
            "     41       37.3047  0.0550\n",
            "     42       37.3047  0.0574\n",
            "     43       37.3047  0.0551\n",
            "     44       37.3047  0.0556\n",
            "     45       37.3047  0.0552\n",
            "     46       37.3047  0.0531\n",
            "     47       37.3047  0.0613\n",
            "     48       37.3047  0.0550\n",
            "     49       37.3047  0.0655\n",
            "     50       37.3047  0.0566\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m31.3523\u001b[0m  0.0511\n",
            "      2       35.9102  0.0604\n",
            "      3       35.9102  0.0571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       35.9102  0.0619\n",
            "      5       35.9102  0.0544\n",
            "      6       35.9102  0.0525\n",
            "      7       35.9102  0.0524\n",
            "      8       35.9102  0.0527\n",
            "      9       35.9102  0.0556\n",
            "     10       35.9102  0.0536\n",
            "     11       35.9102  0.0572\n",
            "     12       35.9101  0.0650\n",
            "     13       35.9101  0.0551\n",
            "     14       35.9101  0.0673\n",
            "     15       35.9101  0.0567\n",
            "     16       35.9101  0.0562\n",
            "     17       35.9101  0.0571\n",
            "     18       35.9101  0.0570\n",
            "     19       35.9101  0.0569\n",
            "     20       35.9101  0.0576\n",
            "     21       35.9101  0.0552\n",
            "     22       35.9101  0.0553\n",
            "     23       35.9101  0.0562\n",
            "     24       35.9101  0.0574\n",
            "     25       35.9101  0.0604\n",
            "     26       35.9101  0.0559\n",
            "     27       35.9101  0.0573\n",
            "     28       35.9101  0.0609\n",
            "     29       35.9101  0.0712\n",
            "     30       35.9101  0.0586\n",
            "     31       35.9101  0.0612\n",
            "     32       35.9101  0.0596\n",
            "     33       35.9101  0.0557\n",
            "     34       35.9101  0.0556\n",
            "     35       35.9100  0.0613\n",
            "     36       35.9100  0.0613\n",
            "     37       35.9100  0.0562\n",
            "     38       35.9100  0.0552\n",
            "     39       35.9100  0.0563\n",
            "     40       35.9100  0.0567\n",
            "     41       35.9100  0.0592\n",
            "     42       35.9100  0.0562\n",
            "     43       35.9100  0.0550\n",
            "     44       35.9100  0.0573\n",
            "     45       35.9100  0.0570\n",
            "     46       35.9100  0.0618\n",
            "     47       35.9100  0.0577\n",
            "     48       35.9100  0.0626\n",
            "     49       35.9100  0.0649\n",
            "     50       35.9100  0.0555\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m60.1562\u001b[0m  0.0496\n",
            "      2       60.1562  0.0577\n",
            "      3       60.1562  0.0580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       60.1562  0.0643\n",
            "      5       60.1562  0.0547\n",
            "      6       60.1562  0.0560\n",
            "      7       60.1562  0.0621\n",
            "      8       60.1562  0.0563\n",
            "      9       60.1562  0.0555\n",
            "     10       60.1562  0.0568\n",
            "     11       60.1562  0.0553\n",
            "     12       60.1562  0.0576\n",
            "     13       60.1562  0.0562\n",
            "     14       60.1562  0.0644\n",
            "     15       60.1562  0.0585\n",
            "     16       60.1562  0.0608\n",
            "     17       60.1562  0.0627\n",
            "     18       60.1562  0.0559\n",
            "     19       60.1562  0.0600\n",
            "     20       60.1562  0.0582\n",
            "     21       60.1562  0.0593\n",
            "     22       60.1562  0.0548\n",
            "     23       60.1562  0.0568\n",
            "     24       60.1562  0.0568\n",
            "     25       60.1562  0.0550\n",
            "     26       60.1562  0.0592\n",
            "     27       60.1562  0.0571\n",
            "     28       60.1562  0.0572\n",
            "     29       60.1562  0.0684\n",
            "     30       60.1562  0.0575\n",
            "     31       60.1562  0.0646\n",
            "     32       60.1562  0.0564\n",
            "     33       60.1562  0.0563\n",
            "     34       60.1562  0.0555\n",
            "     35       60.1562  0.0560\n",
            "     36       60.1562  0.0609\n",
            "     37       60.1562  0.0594\n",
            "     38       60.1562  0.0579\n",
            "     39       60.1562  0.0551\n",
            "     40       60.1562  0.0571\n",
            "     41       60.1562  0.0592\n",
            "     42       60.1562  0.0559\n",
            "     43       60.1562  0.0561\n",
            "     44       60.1562  0.0573\n",
            "     45       60.1562  0.0646\n",
            "     46       60.1562  0.0560\n",
            "     47       60.1562  0.0559\n",
            "     48       60.1562  0.0635\n",
            "     49       60.1562  0.0634\n",
            "     50       60.1562  0.0722\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m35.3295\u001b[0m  0.0509\n",
            "      2       43.1891  0.0586\n",
            "      3       42.5781  0.0532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       42.5781  0.0615\n",
            "      5       42.5781  0.0542\n",
            "      6       42.5781  0.0640\n",
            "      7       42.5781  0.0560\n",
            "      8       42.5781  0.0575\n",
            "      9       42.5781  0.0581\n",
            "     10       42.5781  0.0610\n",
            "     11       42.5781  0.0573\n",
            "     12       42.5781  0.0572\n",
            "     13       42.5781  0.0581\n",
            "     14       42.5781  0.0682\n",
            "     15       42.5781  0.0571\n",
            "     16       42.5781  0.0619\n",
            "     17       42.5781  0.0566\n",
            "     18       42.5781  0.0619\n",
            "     19       42.5781  0.0581\n",
            "     20       42.5781  0.0571\n",
            "     21       42.5781  0.0567\n",
            "     22       42.5781  0.0586\n",
            "     23       42.5781  0.0561\n",
            "     24       42.5781  0.0578\n",
            "     25       42.5781  0.0594\n",
            "     26       42.5781  0.0563\n",
            "     27       42.5781  0.0609\n",
            "     28       42.5781  0.0636\n",
            "     29       42.5781  0.0584\n",
            "     30       42.5781  0.0568\n",
            "     31       42.5781  0.0656\n",
            "     32       42.5781  0.0599\n",
            "     33       42.5781  0.0562\n",
            "     34       42.5781  0.0554\n",
            "     35       42.5781  0.0595\n",
            "     36       42.5781  0.0572\n",
            "     37       42.5781  0.0570\n",
            "     38       42.5781  0.0556\n",
            "     39       42.5781  0.0575\n",
            "     40       42.5781  0.0591\n",
            "     41       42.5781  0.0612\n",
            "     42       42.5781  0.0574\n",
            "     43       42.5781  0.0639\n",
            "     44       42.5781  0.0576\n",
            "     45       42.5781  0.0585\n",
            "     46       42.5781  0.1155\n",
            "     47       42.5781  0.0655\n",
            "     48       42.5781  0.0573\n",
            "     49       42.5781  0.0632\n",
            "     50       42.5781  0.0588\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m43.4617\u001b[0m  0.0536\n",
            "      2       \u001b[36m39.9420\u001b[0m  0.0575\n",
            "      3       \u001b[36m39.9420\u001b[0m  0.0591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       \u001b[36m39.9420\u001b[0m  0.0601\n",
            "      5       \u001b[36m39.9420\u001b[0m  0.0558\n",
            "      6       \u001b[36m39.9419\u001b[0m  0.0567\n",
            "      7       \u001b[36m39.9419\u001b[0m  0.0614\n",
            "      8       \u001b[36m39.9419\u001b[0m  0.0578\n",
            "      9       \u001b[36m39.9418\u001b[0m  0.0569\n",
            "     10       \u001b[36m39.9418\u001b[0m  0.0654\n",
            "     11       \u001b[36m39.9418\u001b[0m  0.0568\n",
            "     12       \u001b[36m39.9418\u001b[0m  0.0649\n",
            "     13       \u001b[36m39.9417\u001b[0m  0.0651\n",
            "     14       \u001b[36m39.9417\u001b[0m  0.0599\n",
            "     15       \u001b[36m39.9417\u001b[0m  0.0564\n",
            "     16       \u001b[36m39.9417\u001b[0m  0.0559\n",
            "     17       \u001b[36m39.9416\u001b[0m  0.0545\n",
            "     18       \u001b[36m39.9416\u001b[0m  0.0545\n",
            "     19       \u001b[36m39.9416\u001b[0m  0.0540\n",
            "     20       \u001b[36m39.9416\u001b[0m  0.0614\n",
            "     21       \u001b[36m39.9415\u001b[0m  0.0574\n",
            "     22       \u001b[36m39.9415\u001b[0m  0.0608\n",
            "     23       \u001b[36m39.9415\u001b[0m  0.0572\n",
            "     24       \u001b[36m39.9414\u001b[0m  0.0576\n",
            "     25       \u001b[36m39.9414\u001b[0m  0.0590\n",
            "     26       \u001b[36m39.9414\u001b[0m  0.0577\n",
            "     27       \u001b[36m39.9414\u001b[0m  0.0635\n",
            "     28       \u001b[36m39.9413\u001b[0m  0.0605\n",
            "     29       \u001b[36m39.9413\u001b[0m  0.0624\n",
            "     30       \u001b[36m39.9413\u001b[0m  0.0676\n",
            "     31       \u001b[36m39.9413\u001b[0m  0.0549\n",
            "     32       \u001b[36m39.9412\u001b[0m  0.0577\n",
            "     33       \u001b[36m39.9412\u001b[0m  0.0605\n",
            "     34       \u001b[36m39.9412\u001b[0m  0.0562\n",
            "     35       \u001b[36m39.9412\u001b[0m  0.0532\n",
            "     36       \u001b[36m39.9411\u001b[0m  0.0579\n",
            "     37       \u001b[36m39.9411\u001b[0m  0.0552\n",
            "     38       \u001b[36m39.9411\u001b[0m  0.0560\n",
            "     39       \u001b[36m39.9410\u001b[0m  0.0544\n",
            "     40       \u001b[36m39.9410\u001b[0m  0.0543\n",
            "     41       \u001b[36m39.9410\u001b[0m  0.0603\n",
            "     42       \u001b[36m39.9410\u001b[0m  0.0658\n",
            "     43       \u001b[36m39.9409\u001b[0m  0.0620\n",
            "     44       \u001b[36m39.9409\u001b[0m  0.0575\n",
            "     45       \u001b[36m39.9409\u001b[0m  0.0580\n",
            "     46       \u001b[36m39.9409\u001b[0m  0.0564\n",
            "     47       \u001b[36m39.9408\u001b[0m  0.0627\n",
            "     48       \u001b[36m39.9408\u001b[0m  0.0588\n",
            "     49       \u001b[36m39.9408\u001b[0m  0.0585\n",
            "     50       \u001b[36m39.9408\u001b[0m  0.0561\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m62.7680\u001b[0m  0.0493\n",
            "      2       62.7680  0.0613\n",
            "      3       62.7680  0.0532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       62.7680  0.0607\n",
            "      5       62.7680  0.0548\n",
            "      6       62.7680  0.0543\n",
            "      7       62.7680  0.0551\n",
            "      8       62.7680  0.0569\n",
            "      9       62.7680  0.0553\n",
            "     10       62.7680  0.0549\n",
            "     11       62.7680  0.0535\n",
            "     12       62.7680  0.0643\n",
            "     13       62.7680  0.0593\n",
            "     14       62.7680  0.0697\n",
            "     15       62.7680  0.0541\n",
            "     16       62.7680  0.0569\n",
            "     17       62.7680  0.0546\n",
            "     18       62.7680  0.0565\n",
            "     19       62.7680  0.0540\n",
            "     20       62.7680  0.0530\n",
            "     21       62.7680  0.0542\n",
            "     22       62.7680  0.0613\n",
            "     23       62.7680  0.0562\n",
            "     24       62.7680  0.0551\n",
            "     25       62.7680  0.0577\n",
            "     26       62.7680  0.0554\n",
            "     27       62.7680  0.0637\n",
            "     28       62.7680  0.0580\n",
            "     29       62.7680  0.0566\n",
            "     30       62.7680  0.0546\n",
            "     31       62.7680  0.0643\n",
            "     32       62.7680  0.0614\n",
            "     33       62.7680  0.0619\n",
            "     34       62.7680  0.0563\n",
            "     35       62.7680  0.0569\n",
            "     36       62.7680  0.0558\n",
            "     37       62.7680  0.0590\n",
            "     38       62.7680  0.0580\n",
            "     39       62.7680  0.0545\n",
            "     40       62.7680  0.0546\n",
            "     41       62.7680  0.0596\n",
            "     42       62.7680  0.0615\n",
            "     43       62.7680  0.0622\n",
            "     44       62.7680  0.0564\n",
            "     45       62.7680  0.0552\n",
            "     46       62.7680  0.0592\n",
            "     47       62.7680  0.0585\n",
            "     48       62.7680  0.0648\n",
            "     49       62.7680  0.0582\n",
            "     50       62.7680  0.0547\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m62.6668\u001b[0m  0.0637\n",
            "      2       \u001b[36m59.0877\u001b[0m  0.0698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       62.6968  0.0729\n",
            "      4       62.6953  0.0742\n",
            "      5       62.6953  0.0675\n",
            "      6       62.6953  0.0694\n",
            "      7       62.6953  0.0696\n",
            "      8       62.6953  0.0688\n",
            "      9       62.6953  0.0734\n",
            "     10       62.6953  0.0781\n",
            "     11       62.6953  0.0753\n",
            "     12       62.6953  0.0814\n",
            "     13       62.6953  0.0726\n",
            "     14       62.6953  0.0730\n",
            "     15       62.6953  0.0715\n",
            "     16       62.6953  0.0733\n",
            "     17       62.6953  0.0728\n",
            "     18       62.6953  0.0821\n",
            "     19       62.6953  0.0798\n",
            "     20       62.6953  0.0805\n",
            "     21       62.6953  0.0708\n",
            "     22       62.6953  0.0721\n",
            "     23       62.6953  0.0751\n",
            "     24       62.6953  0.0702\n",
            "     25       62.6953  0.0781\n",
            "     26       62.6953  0.0730\n",
            "     27       62.6953  0.0696\n",
            "     28       62.6953  0.0738\n",
            "     29       62.6953  0.0733\n",
            "     30       62.6953  0.0732\n",
            "     31       62.6953  0.0707\n",
            "     32       62.6953  0.0709\n",
            "     33       62.6953  0.0719\n",
            "     34       62.6953  0.0790\n",
            "     35       62.6953  0.0734\n",
            "     36       62.6953  0.0742\n",
            "     37       62.6953  0.0739\n",
            "     38       62.6953  0.0802\n",
            "     39       62.6953  0.0821\n",
            "     40       62.6953  0.0715\n",
            "     41       62.6953  0.0757\n",
            "     42       62.6953  0.0732\n",
            "     43       62.6953  0.0765\n",
            "     44       62.6953  0.0760\n",
            "     45       62.6953  0.0838\n",
            "     46       62.6953  0.0726\n",
            "     47       62.6953  0.0743\n",
            "     48       62.6953  0.0735\n",
            "     49       62.6953  0.0846\n",
            "     50       62.6953  0.0754\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m61.5234\u001b[0m  0.0703\n",
            "      2       61.9141  0.0698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       61.7188  0.0760\n",
            "      4       61.9141  0.0682\n",
            "      5       62.1293  0.0689\n",
            "      6       64.1881  0.0694\n",
            "      7       63.8672  0.0716\n",
            "      8       63.6929  0.0702\n",
            "      9       62.3047  0.0693\n",
            "     10       62.3047  0.0775\n",
            "     11       62.3047  0.0750\n",
            "     12       62.3047  0.0727\n",
            "     13       62.2144  0.0727\n",
            "     14       62.1899  0.0711\n",
            "     15       61.7760  0.0833\n",
            "     16       \u001b[36m61.0170\u001b[0m  0.0705\n",
            "     17       \u001b[36m60.9375\u001b[0m  0.0703\n",
            "     18       \u001b[36m60.7058\u001b[0m  0.0698\n",
            "     19       \u001b[36m58.7896\u001b[0m  0.0724\n",
            "     20       \u001b[36m48.7347\u001b[0m  0.0765\n",
            "     21       \u001b[36m48.3495\u001b[0m  0.0714\n",
            "     22       \u001b[36m46.1116\u001b[0m  0.0711\n",
            "     23       \u001b[36m46.0938\u001b[0m  0.0781\n",
            "     24       46.0938  0.0701\n",
            "     25       46.0938  0.0729\n",
            "     26       46.0938  0.0713\n",
            "     27       46.0938  0.0728\n",
            "     28       46.0938  0.0749\n",
            "     29       46.0938  0.0796\n",
            "     30       46.0938  0.0768\n",
            "     31       46.0938  0.0706\n",
            "     32       46.0938  0.0729\n",
            "     33       46.0938  0.0742\n",
            "     34       46.0938  0.0742\n",
            "     35       46.0938  0.0789\n",
            "     36       46.0938  0.0701\n",
            "     37       46.0938  0.0727\n",
            "     38       46.0938  0.0700\n",
            "     39       46.0938  0.0706\n",
            "     40       46.0938  0.0722\n",
            "     41       46.0938  0.0778\n",
            "     42       46.0938  0.0779\n",
            "     43       46.0938  0.0680\n",
            "     44       46.0938  0.0695\n",
            "     45       46.0938  0.0731\n",
            "     46       46.0938  0.0734\n",
            "     47       46.0938  0.0727\n",
            "     48       46.0938  0.0721\n",
            "     49       46.0938  0.0725\n",
            "     50       46.0938  0.0760\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0725\n",
            "      2       37.3047  0.0706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0815\n",
            "      4       37.3047  0.0743\n",
            "      5       37.3047  0.0752\n",
            "      6       37.3047  0.0747\n",
            "      7       37.3047  0.0698\n",
            "      8       37.3047  0.0688\n",
            "      9       37.3047  0.0709\n",
            "     10       37.3047  0.0793\n",
            "     11       37.3047  0.0698\n",
            "     12       37.3047  0.0713\n",
            "     13       37.3047  0.0785\n",
            "     14       37.3047  0.0709\n",
            "     15       37.3047  0.0739\n",
            "     16       37.3047  0.0698\n",
            "     17       37.3047  0.0720\n",
            "     18       37.3047  0.0757\n",
            "     19       37.3047  0.0834\n",
            "     20       37.3047  0.0726\n",
            "     21       37.3047  0.0713\n",
            "     22       37.3047  0.0715\n",
            "     23       37.3047  0.0689\n",
            "     24       37.3047  0.0749\n",
            "     25       37.3047  0.0774\n",
            "     26       37.3047  0.0713\n",
            "     27       37.3047  0.0750\n",
            "     28       \u001b[36m36.9547\u001b[0m  0.0761\n",
            "     29       \u001b[36m36.7188\u001b[0m  0.0766\n",
            "     30       36.7188  0.0719\n",
            "     31       36.7188  0.0746\n",
            "     32       36.7188  0.0769\n",
            "     33       36.7188  0.0735\n",
            "     34       36.7188  0.0695\n",
            "     35       36.7188  0.0702\n",
            "     36       36.7188  0.0799\n",
            "     37       36.7188  0.0698\n",
            "     38       36.7188  0.0697\n",
            "     39       36.7188  0.0742\n",
            "     40       36.7188  0.0728\n",
            "     41       36.7188  0.0793\n",
            "     42       36.7188  0.0709\n",
            "     43       36.7188  0.0797\n",
            "     44       36.7188  0.0837\n",
            "     45       36.7188  0.0745\n",
            "     46       36.7188  0.0784\n",
            "     47       36.7188  0.0751\n",
            "     48       36.7188  0.0733\n",
            "     49       36.7188  0.0764\n",
            "     50       36.7188  0.0740\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m36.6598\u001b[0m  0.0725\n",
            "      2       38.2768  0.0808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m35.4668\u001b[0m  0.0793\n",
            "      4       36.3250  0.0715\n",
            "      5       36.3728  0.0694\n",
            "      6       38.9470  0.0731\n",
            "      7       35.4978  0.0734\n",
            "      8       36.7158  0.0771\n",
            "      9       36.7636  0.0802\n",
            "     10       36.4893  0.0876\n",
            "     11       37.7844  0.0736\n",
            "     12       40.6441  0.0730\n",
            "     13       40.4297  0.0710\n",
            "     14       39.7319  0.0788\n",
            "     15       40.6582  0.0749\n",
            "     16       38.3335  0.0750\n",
            "     17       39.2294  0.0730\n",
            "     18       38.7757  0.0734\n",
            "     19       38.7630  0.0720\n",
            "     20       38.7630  0.0718\n",
            "     21       38.7630  0.0726\n",
            "     22       38.7630  0.0784\n",
            "     23       38.7630  0.0723\n",
            "     24       38.7630  0.0721\n",
            "     25       38.7631  0.0735\n",
            "     26       38.7631  0.0785\n",
            "     27       38.7631  0.0704\n",
            "     28       38.7632  0.0745\n",
            "     29       38.7633  0.0714\n",
            "     30       38.7634  0.0786\n",
            "     31       38.7635  0.0736\n",
            "     32       38.7636  0.0731\n",
            "     33       38.7637  0.0756\n",
            "     34       38.7637  0.0747\n",
            "     35       38.7638  0.0811\n",
            "     36       38.7639  0.0765\n",
            "     37       38.7639  0.0723\n",
            "     38       38.7640  0.0715\n",
            "     39       38.7640  0.0758\n",
            "     40       38.7641  0.0712\n",
            "     41       38.7641  0.0818\n",
            "     42       38.7642  0.0742\n",
            "     43       38.7642  0.0784\n",
            "     44       38.7643  0.0740\n",
            "     45       38.7643  0.0779\n",
            "     46       38.7644  0.0734\n",
            "     47       38.7645  0.0729\n",
            "     48       38.7646  0.0778\n",
            "     49       38.7646  0.0801\n",
            "     50       38.7647  0.0718\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0651\n",
            "      2       37.3047  0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0887\n",
            "      4       37.3047  0.0717\n",
            "      5       37.3047  0.0713\n",
            "      6       37.3047  0.0712\n",
            "      7       37.3047  0.0701\n",
            "      8       37.3047  0.0729\n",
            "      9       37.3047  0.0702\n",
            "     10       37.3047  0.0694\n",
            "     11       37.3047  0.0707\n",
            "     12       37.3047  0.0788\n",
            "     13       37.3047  0.0748\n",
            "     14       37.3047  0.0768\n",
            "     15       37.3047  0.0722\n",
            "     16       37.3047  0.0718\n",
            "     17       \u001b[36m36.3122\u001b[0m  0.0728\n",
            "     18       \u001b[36m29.3175\u001b[0m  0.0715\n",
            "     19       36.7205  0.0771\n",
            "     20       37.4727  0.0755\n",
            "     21       35.9920  0.0699\n",
            "     22       35.8239  0.0738\n",
            "     23       36.8829  0.0753\n",
            "     24       36.1328  0.0704\n",
            "     25       36.3281  0.0842\n",
            "     26       36.3281  0.0720\n",
            "     27       36.3281  0.0718\n",
            "     28       36.3281  0.0711\n",
            "     29       36.3281  0.0714\n",
            "     30       36.3281  0.0736\n",
            "     31       36.3281  0.0763\n",
            "     32       36.3281  0.0751\n",
            "     33       36.3281  0.0713\n",
            "     34       36.3281  0.0714\n",
            "     35       36.3281  0.0774\n",
            "     36       36.3281  0.0694\n",
            "     37       36.3281  0.0710\n",
            "     38       36.3281  0.0744\n",
            "     39       36.3281  0.0807\n",
            "     40       36.3281  0.0740\n",
            "     41       36.3281  0.0776\n",
            "     42       36.3281  0.0732\n",
            "     43       36.3281  0.0802\n",
            "     44       36.3281  0.0740\n",
            "     45       36.3281  0.0738\n",
            "     46       36.3281  0.0742\n",
            "     47       36.3281  0.0732\n",
            "     48       36.3281  0.0753\n",
            "     49       36.3281  0.0707\n",
            "     50       36.3281  0.0735\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m48.2674\u001b[0m  0.0671\n",
            "      2       49.2609  0.0806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       48.8281  0.0771\n",
            "      4       49.2188  0.0737\n",
            "      5       49.2188  0.0694\n",
            "      6       49.2188  0.0722\n",
            "      7       49.2188  0.0740\n",
            "      8       49.2188  0.0797\n",
            "      9       49.2188  0.0713\n",
            "     10       49.0234  0.0738\n",
            "     11       49.0234  0.0830\n",
            "     12       49.0234  0.0730\n",
            "     13       49.0234  0.0716\n",
            "     14       51.4753  0.0720\n",
            "     15       50.0000  0.0784\n",
            "     16       50.0000  0.0794\n",
            "     17       50.0000  0.0700\n",
            "     18       50.0000  0.0678\n",
            "     19       50.0000  0.0764\n",
            "     20       50.0000  0.0811\n",
            "     21       50.0000  0.0726\n",
            "     22       50.0000  0.0719\n",
            "     23       50.0000  0.0743\n",
            "     24       50.0000  0.0751\n",
            "     25       50.0000  0.0722\n",
            "     26       50.0000  0.0702\n",
            "     27       50.0000  0.0702\n",
            "     28       50.0000  0.0801\n",
            "     29       50.0000  0.0764\n",
            "     30       50.0000  0.0730\n",
            "     31       50.0000  0.0836\n",
            "     32       50.0000  0.0832\n",
            "     33       50.0000  0.0762\n",
            "     34       50.0000  0.0736\n",
            "     35       50.0000  0.0738\n",
            "     36       50.0000  0.0737\n",
            "     37       50.0000  0.0793\n",
            "     38       50.0000  0.0735\n",
            "     39       50.0000  0.0736\n",
            "     40       50.0000  0.0724\n",
            "     41       50.0000  0.0800\n",
            "     42       50.0000  0.0753\n",
            "     43       50.0000  0.0825\n",
            "     44       50.0000  0.0729\n",
            "     45       50.0000  0.0774\n",
            "     46       50.0000  0.0748\n",
            "     47       50.0000  0.0741\n",
            "     48       49.8047  0.0742\n",
            "     49       49.8047  0.0784\n",
            "     50       49.8047  0.0729\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0808\n",
            "      2       37.3047  0.0720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0878\n",
            "      4       37.3047  0.0785\n",
            "      5       37.3047  0.0745\n",
            "      6       37.3047  0.0796\n",
            "      7       37.3047  0.0749\n",
            "      8       37.3047  0.0753\n",
            "      9       37.3047  0.0728\n",
            "     10       37.3047  0.0700\n",
            "     11       37.3047  0.0789\n",
            "     12       37.3047  0.0743\n",
            "     13       37.3047  0.0769\n",
            "     14       37.3047  0.0705\n",
            "     15       37.3047  0.0716\n",
            "     16       37.3047  0.0712\n",
            "     17       37.3047  0.0788\n",
            "     18       37.3047  0.0738\n",
            "     19       37.3047  0.0780\n",
            "     20       37.3047  0.0823\n",
            "     21       37.3047  0.0733\n",
            "     22       37.3047  0.0723\n",
            "     23       37.3047  0.0708\n",
            "     24       37.3047  0.0723\n",
            "     25       37.3047  0.0810\n",
            "     26       37.3047  0.0732\n",
            "     27       37.3047  0.0716\n",
            "     28       37.3047  0.0707\n",
            "     29       37.3047  0.0726\n",
            "     30       37.3047  0.0816\n",
            "     31       37.3047  0.0729\n",
            "     32       37.3047  0.0775\n",
            "     33       37.3047  0.0746\n",
            "     34       37.3047  0.0797\n",
            "     35       37.3047  0.0749\n",
            "     36       37.3047  0.0730\n",
            "     37       37.3047  0.0840\n",
            "     38       37.3047  0.0779\n",
            "     39       37.3047  0.0708\n",
            "     40       37.3047  0.0709\n",
            "     41       37.3047  0.0734\n",
            "     42       37.3047  0.0786\n",
            "     43       37.3047  0.0781\n",
            "     44       37.3047  0.0723\n",
            "     45       37.3047  0.0723\n",
            "     46       37.3047  0.0768\n",
            "     47       37.3047  0.0721\n",
            "     48       37.3047  0.0757\n",
            "     49       37.3047  0.0716\n",
            "     50       37.3047  0.0753\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m59.1797\u001b[0m  0.0742\n",
            "      2       59.1797  0.0715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       59.1797  0.0779\n",
            "      4       59.1797  0.0702\n",
            "      5       59.1797  0.0711\n",
            "      6       59.1797  0.0722\n",
            "      7       59.1797  0.0785\n",
            "      8       59.1797  0.0715\n",
            "      9       59.1797  0.0848\n",
            "     10       59.1797  0.0743\n",
            "     11       59.1797  0.0702\n",
            "     12       59.1797  0.0721\n",
            "     13       59.1797  0.0716\n",
            "     14       59.1797  0.0741\n",
            "     15       59.1797  0.0724\n",
            "     16       59.1797  0.0734\n",
            "     17       59.1797  0.0685\n",
            "     18       59.1797  0.0721\n",
            "     19       59.1797  0.0714\n",
            "     20       59.1797  0.0801\n",
            "     21       59.1797  0.0803\n",
            "     22       59.1797  0.0731\n",
            "     23       59.1797  0.0754\n",
            "     24       59.1797  0.0772\n",
            "     25       59.1797  0.0715\n",
            "     26       \u001b[36m58.6564\u001b[0m  0.0725\n",
            "     27       \u001b[36m35.0736\u001b[0m  0.0780\n",
            "     28       37.3047  0.0786\n",
            "     29       37.3047  0.0707\n",
            "     30       37.3047  0.0793\n",
            "     31       37.3047  0.0740\n",
            "     32       37.3047  0.0721\n",
            "     33       37.3047  0.0817\n",
            "     34       37.3047  0.0722\n",
            "     35       37.3047  0.0733\n",
            "     36       37.3047  0.0726\n",
            "     37       37.3047  0.0833\n",
            "     38       37.3047  0.0720\n",
            "     39       37.3047  0.0715\n",
            "     40       37.3047  0.0792\n",
            "     41       37.3047  0.0758\n",
            "     42       37.3047  0.0721\n",
            "     43       37.3047  0.0715\n",
            "     44       37.3047  0.0747\n",
            "     45       37.3047  0.0799\n",
            "     46       37.3047  0.0839\n",
            "     47       37.3047  0.0744\n",
            "     48       37.3047  0.0854\n",
            "     49       37.3047  0.0739\n",
            "     50       37.3047  0.0714\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m43.5547\u001b[0m  0.0658\n",
            "      2       \u001b[36m40.9718\u001b[0m  0.0752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m39.4531\u001b[0m  0.0831\n",
            "      4       \u001b[36m35.9456\u001b[0m  0.0734\n",
            "      5       36.8157  0.0805\n",
            "      6       36.4545  0.0731\n",
            "      7       36.5234  0.0726\n",
            "      8       \u001b[36m35.5470\u001b[0m  0.0718\n",
            "      9       \u001b[36m32.2992\u001b[0m  0.0822\n",
            "     10       \u001b[36m31.2500\u001b[0m  0.0809\n",
            "     11       32.0312  0.0783\n",
            "     12       32.0312  0.0767\n",
            "     13       32.2266  0.0735\n",
            "     14       32.2266  0.0734\n",
            "     15       32.2266  0.0796\n",
            "     16       32.2266  0.0731\n",
            "     17       31.6244  0.0790\n",
            "     18       33.9844  0.0737\n",
            "     19       33.9844  0.0752\n",
            "     20       33.9844  0.0725\n",
            "     21       33.9844  0.0714\n",
            "     22       33.9844  0.0814\n",
            "     23       34.1304  0.0729\n",
            "     24       34.8203  0.0829\n",
            "     25       32.3134  0.0804\n",
            "     26       \u001b[36m31.2018\u001b[0m  0.0705\n",
            "     27       32.4219  0.0788\n",
            "     28       32.4219  0.0748\n",
            "     29       32.4219  0.0724\n",
            "     30       32.4219  0.0754\n",
            "     31       32.4219  0.0708\n",
            "     32       32.4219  0.0740\n",
            "     33       32.4219  0.0723\n",
            "     34       32.4219  0.0711\n",
            "     35       32.4219  0.0806\n",
            "     36       32.4219  0.0780\n",
            "     37       32.4219  0.0775\n",
            "     38       32.4219  0.0783\n",
            "     39       32.4219  0.0805\n",
            "     40       32.4219  0.0750\n",
            "     41       32.9617  0.0784\n",
            "     42       33.8969  0.0753\n",
            "     43       33.5944  0.0771\n",
            "     44       34.1159  0.0729\n",
            "     45       34.1150  0.0770\n",
            "     46       34.1263  0.0738\n",
            "     47       34.1485  0.0719\n",
            "     48       34.1797  0.0875\n",
            "     49       34.1797  0.0753\n",
            "     50       34.1797  0.0751\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m62.7680\u001b[0m  0.0686\n",
            "      2       62.7680  0.0794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       62.7680  0.0814\n",
            "      4       62.7680  0.0741\n",
            "      5       62.7680  0.0760\n",
            "      6       62.7680  0.0724\n",
            "      7       62.7680  0.0719\n",
            "      8       62.7680  0.0724\n",
            "      9       62.7680  0.0753\n",
            "     10       62.7680  0.0735\n",
            "     11       62.7680  0.0797\n",
            "     12       62.7680  0.0753\n",
            "     13       62.7680  0.0745\n",
            "     14       62.7680  0.0791\n",
            "     15       62.7680  0.0725\n",
            "     16       62.7680  0.0787\n",
            "     17       62.7680  0.0725\n",
            "     18       62.7680  0.0709\n",
            "     19       62.7680  0.0711\n",
            "     20       62.7680  0.0723\n",
            "     21       62.7680  0.0696\n",
            "     22       62.7680  0.0725\n",
            "     23       62.7680  0.0727\n",
            "     24       62.7680  0.0783\n",
            "     25       62.7680  0.0733\n",
            "     26       62.7680  0.0919\n",
            "     27       62.7680  0.0728\n",
            "     28       62.7680  0.0740\n",
            "     29       62.7680  0.0761\n",
            "     30       62.7680  0.0734\n",
            "     31       62.7680  0.0730\n",
            "     32       \u001b[36m62.6915\u001b[0m  0.0722\n",
            "     33       \u001b[36m62.4769\u001b[0m  0.0733\n",
            "     34       \u001b[36m61.5460\u001b[0m  0.0749\n",
            "     35       \u001b[36m59.0080\u001b[0m  0.0709\n",
            "     36       \u001b[36m15.8989\u001b[0m  0.0750\n",
            "     37        \u001b[36m5.4517\u001b[0m  0.0702\n",
            "     38        \u001b[36m5.0120\u001b[0m  0.0790\n",
            "     39        \u001b[36m4.7739\u001b[0m  0.0716\n",
            "     40        \u001b[36m4.7538\u001b[0m  0.0711\n",
            "     41        \u001b[36m4.7433\u001b[0m  0.0821\n",
            "     42        \u001b[36m4.7109\u001b[0m  0.0755\n",
            "     43        \u001b[36m4.7013\u001b[0m  0.0738\n",
            "     44        \u001b[36m4.6791\u001b[0m  0.0732\n",
            "     45        4.6850  0.0738\n",
            "     46        4.6801  0.0725\n",
            "     47        \u001b[36m4.6478\u001b[0m  0.0709\n",
            "     48        \u001b[36m4.6331\u001b[0m  0.0715\n",
            "     49        4.6395  0.0849\n",
            "     50        \u001b[36m4.6186\u001b[0m  0.0724\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m41.7721\u001b[0m  0.0600\n",
            "      2       41.7727  0.0575\n",
            "      3       41.7732  0.0577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       41.7735  0.0633\n",
            "      5       41.7738  0.0616\n",
            "      6       41.7741  0.0582\n",
            "      7       41.7744  0.0614\n",
            "      8       41.7746  0.0598\n",
            "      9       41.7748  0.0653\n",
            "     10       41.7969  0.0576\n",
            "     11       41.7969  0.0579\n",
            "     12       41.7969  0.0563\n",
            "     13       41.7969  0.0585\n",
            "     14       41.7969  0.0577\n",
            "     15       41.7969  0.0581\n",
            "     16       41.7969  0.0557\n",
            "     17       41.7969  0.0679\n",
            "     18       41.7969  0.0661\n",
            "     19       41.7969  0.0614\n",
            "     20       41.7969  0.0570\n",
            "     21       41.7969  0.0605\n",
            "     22       41.7969  0.0565\n",
            "     23       41.7969  0.0609\n",
            "     24       41.7969  0.0594\n",
            "     25       41.7969  0.0563\n",
            "     26       41.7969  0.0569\n",
            "     27       41.7969  0.0575\n",
            "     28       41.7969  0.0572\n",
            "     29       41.7969  0.0636\n",
            "     30       41.7969  0.0574\n",
            "     31       41.7969  0.0588\n",
            "     32       41.7969  0.0563\n",
            "     33       41.7969  0.0646\n",
            "     34       41.7969  0.0628\n",
            "     35       41.7969  0.0596\n",
            "     36       41.7969  0.0565\n",
            "     37       41.7969  0.0567\n",
            "     38       41.7969  0.0571\n",
            "     39       41.7969  0.0668\n",
            "     40       41.7969  0.0562\n",
            "     41       41.7969  0.0583\n",
            "     42       41.7969  0.0597\n",
            "     43       41.7969  0.0561\n",
            "     44       41.7969  0.0563\n",
            "     45       41.7969  0.0567\n",
            "     46       41.7969  0.0577\n",
            "     47       41.7969  0.0579\n",
            "     48       41.7969  0.0673\n",
            "     49       41.7969  0.0614\n",
            "     50       41.7969  0.0649\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m53.8235\u001b[0m  0.0572\n",
            "      2       \u001b[36m36.9565\u001b[0m  0.0588\n",
            "      3       37.1094  0.0554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.1094  0.0655\n",
            "      5       37.1094  0.0609\n",
            "      6       37.1094  0.0552\n",
            "      7       37.1094  0.0608\n",
            "      8       37.1094  0.0589\n",
            "      9       37.1094  0.0640\n",
            "     10       37.1094  0.0605\n",
            "     11       37.1094  0.0565\n",
            "     12       37.1094  0.0558\n",
            "     13       37.1094  0.0596\n",
            "     14       37.1094  0.0559\n",
            "     15       37.1094  0.0556\n",
            "     16       37.1094  0.0611\n",
            "     17       37.1094  0.0686\n",
            "     18       37.1094  0.0625\n",
            "     19       37.1094  0.0557\n",
            "     20       37.1094  0.0582\n",
            "     21       37.1094  0.0616\n",
            "     22       37.1094  0.0563\n",
            "     23       37.1094  0.0582\n",
            "     24       37.1094  0.0562\n",
            "     25       37.1094  0.0572\n",
            "     26       37.1094  0.0569\n",
            "     27       37.1094  0.0554\n",
            "     28       37.1094  0.0593\n",
            "     29       37.1094  0.0583\n",
            "     30       37.1094  0.0553\n",
            "     31       37.1094  0.0560\n",
            "     32       37.1094  0.0666\n",
            "     33       37.1094  0.0636\n",
            "     34       37.1094  0.0577\n",
            "     35       37.1094  0.0600\n",
            "     36       37.1094  0.0572\n",
            "     37       37.1094  0.0633\n",
            "     38       37.1094  0.0570\n",
            "     39       37.1094  0.0576\n",
            "     40       37.1094  0.0561\n",
            "     41       37.1094  0.0568\n",
            "     42       37.1094  0.0573\n",
            "     43       37.1094  0.0560\n",
            "     44       37.1094  0.0567\n",
            "     45       37.1094  0.0579\n",
            "     46       37.1094  0.0566\n",
            "     47       37.1094  0.0602\n",
            "     48       37.1094  0.0774\n",
            "     49       37.1094  0.0579\n",
            "     50       37.1094  0.0748\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m50.8364\u001b[0m  0.0521\n",
            "      2       \u001b[36m48.0469\u001b[0m  0.0590\n",
            "      3       48.0469  0.0608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       48.0469  0.0625\n",
            "      5       48.0469  0.0616\n",
            "      6       48.0469  0.0573\n",
            "      7       48.0469  0.0568\n",
            "      8       48.0469  0.0576\n",
            "      9       48.0469  0.0613\n",
            "     10       48.0469  0.0576\n",
            "     11       48.0469  0.0628\n",
            "     12       48.0469  0.0576\n",
            "     13       48.0469  0.0593\n",
            "     14       48.0469  0.0573\n",
            "     15       48.0469  0.0578\n",
            "     16       48.0469  0.0739\n",
            "     17       48.0469  0.0591\n",
            "     18       48.0469  0.0559\n",
            "     19       48.0469  0.0582\n",
            "     20       48.0469  0.0623\n",
            "     21       48.0469  0.0619\n",
            "     22       48.0469  0.0557\n",
            "     23       48.0469  0.0576\n",
            "     24       48.0469  0.0581\n",
            "     25       48.0469  0.0570\n",
            "     26       48.0469  0.0582\n",
            "     27       48.0469  0.0578\n",
            "     28       48.0469  0.0574\n",
            "     29       48.0469  0.0603\n",
            "     30       48.0469  0.0621\n",
            "     31       48.0469  0.0594\n",
            "     32       48.0469  0.0628\n",
            "     33       48.0469  0.0596\n",
            "     34       48.0469  0.0572\n",
            "     35       48.0469  0.0593\n",
            "     36       48.0469  0.0601\n",
            "     37       48.0469  0.0574\n",
            "     38       48.0469  0.0564\n",
            "     39       48.0469  0.0557\n",
            "     40       48.0469  0.0566\n",
            "     41       48.0469  0.0610\n",
            "     42       48.0469  0.0571\n",
            "     43       48.0469  0.0644\n",
            "     44       48.0469  0.0581\n",
            "     45       48.0469  0.0754\n",
            "     46       48.0469  0.0596\n",
            "     47       48.0469  0.0606\n",
            "     48       48.0469  0.0593\n",
            "     49       48.0469  0.0649\n",
            "     50       48.0469  0.0627\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m61.5234\u001b[0m  0.0524\n",
            "      2       61.5234  0.0614\n",
            "      3       61.5234  0.0597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       61.5234  0.0630\n",
            "      5       61.5234  0.0566\n",
            "      6       61.5234  0.0586\n",
            "      7       61.5234  0.0588\n",
            "      8       61.5234  0.0587\n",
            "      9       61.5234  0.0620\n",
            "     10       61.5234  0.0589\n",
            "     11       61.5234  0.0595\n",
            "     12       61.5234  0.0574\n",
            "     13       61.5234  0.0587\n",
            "     14       61.5234  0.0630\n",
            "     15       61.5234  0.0663\n",
            "     16       61.5234  0.0572\n",
            "     17       61.5234  0.0583\n",
            "     18       61.5234  0.0603\n",
            "     19       61.5234  0.0570\n",
            "     20       61.5234  0.0536\n",
            "     21       61.5234  0.0560\n",
            "     22       61.5234  0.0561\n",
            "     23       61.5234  0.0565\n",
            "     24       61.5234  0.0571\n",
            "     25       61.5234  0.0620\n",
            "     26       61.5234  0.0571\n",
            "     27       61.5234  0.0578\n",
            "     28       61.5234  0.0567\n",
            "     29       61.5234  0.0665\n",
            "     30       61.5234  0.0646\n",
            "     31       61.5234  0.0616\n",
            "     32       61.5234  0.0643\n",
            "     33       61.5234  0.0582\n",
            "     34       61.5234  0.0615\n",
            "     35       61.5234  0.0596\n",
            "     36       61.5234  0.0554\n",
            "     37       61.5234  0.0599\n",
            "     38       61.5234  0.0578\n",
            "     39       61.5234  0.0572\n",
            "     40       61.5234  0.0634\n",
            "     41       61.5234  0.0574\n",
            "     42       61.5234  0.0585\n",
            "     43       61.5234  0.0580\n",
            "     44       61.5234  0.0638\n",
            "     45       61.5234  0.0606\n",
            "     46       61.5234  0.0618\n",
            "     47       61.5234  0.0577\n",
            "     48       61.5234  0.0645\n",
            "     49       61.5234  0.0577\n",
            "     50       61.5234  0.0609\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m50.3461\u001b[0m  0.0501\n",
            "      2       50.7813  0.0618\n",
            "      3       50.3906  0.0608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       50.3906  0.0644\n",
            "      5       50.3906  0.0564\n",
            "      6       50.3906  0.0566\n",
            "      7       50.3906  0.0592\n",
            "      8       50.3906  0.0581\n",
            "      9       50.3906  0.0574\n",
            "     10       50.3906  0.0579\n",
            "     11       50.3906  0.0586\n",
            "     12       50.3906  0.0565\n",
            "     13       50.3906  0.0682\n",
            "     14       50.3906  0.0606\n",
            "     15       50.3906  0.0626\n",
            "     16       50.3906  0.0603\n",
            "     17       50.3906  0.0565\n",
            "     18       50.3906  0.0570\n",
            "     19       50.3906  0.0588\n",
            "     20       50.3906  0.0569\n",
            "     21       50.3906  0.0575\n",
            "     22       50.3906  0.0548\n",
            "     23       50.3906  0.0563\n",
            "     24       50.3906  0.0591\n",
            "     25       50.3906  0.0617\n",
            "     26       50.3906  0.0582\n",
            "     27       50.3906  0.0570\n",
            "     28       50.3906  0.0624\n",
            "     29       50.3906  0.0591\n",
            "     30       50.3906  0.0587\n",
            "     31       50.3906  0.0621\n",
            "     32       50.3906  0.0564\n",
            "     33       50.3906  0.0592\n",
            "     34       50.3906  0.0594\n",
            "     35       50.3906  0.0624\n",
            "     36       50.3906  0.0586\n",
            "     37       50.3906  0.0584\n",
            "     38       50.3906  0.0576\n",
            "     39       50.3906  0.0573\n",
            "     40       50.3906  0.0580\n",
            "     41       50.3906  0.0613\n",
            "     42       50.3906  0.0593\n",
            "     43       50.3906  0.0658\n",
            "     44       50.3906  0.0645\n",
            "     45       50.3906  0.0575\n",
            "     46       50.3906  0.0658\n",
            "     47       50.3906  0.0598\n",
            "     48       50.3906  0.0623\n",
            "     49       50.3906  0.0593\n",
            "     50       50.3906  0.0552\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0495\n",
            "      2       37.3047  0.0563\n",
            "      3       37.3047  0.0562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0654\n",
            "      5       37.3047  0.0556\n",
            "      6       37.3047  0.0610\n",
            "      7       37.3047  0.0614\n",
            "      8       37.3047  0.0598\n",
            "      9       37.3047  0.0578\n",
            "     10       37.3047  0.0624\n",
            "     11       37.3047  0.0567\n",
            "     12       37.3047  0.0583\n",
            "     13       37.3047  0.0578\n",
            "     14       37.3047  0.0690\n",
            "     15       37.3047  0.0601\n",
            "     16       37.3047  0.0613\n",
            "     17       37.3047  0.0555\n",
            "     18       37.3047  0.0567\n",
            "     19       37.3047  0.0603\n",
            "     20       37.3047  0.0702\n",
            "     21       37.3047  0.0579\n",
            "     22       37.3047  0.0582\n",
            "     23       37.3047  0.0565\n",
            "     24       37.3047  0.0573\n",
            "     25       37.3047  0.0605\n",
            "     26       37.3047  0.0590\n",
            "     27       37.3047  0.0655\n",
            "     28       37.3047  0.0584\n",
            "     29       37.3047  0.0569\n",
            "     30       37.3047  0.0593\n",
            "     31       37.3047  0.0679\n",
            "     32       37.3047  0.0670\n",
            "     33       37.3047  0.0597\n",
            "     34       37.3047  0.0563\n",
            "     35       37.3047  0.0560\n",
            "     36       37.3047  0.0577\n",
            "     37       37.3047  0.0578\n",
            "     38       37.3047  0.0564\n",
            "     39       37.3047  0.0624\n",
            "     40       37.3047  0.0572\n",
            "     41       37.3047  0.0625\n",
            "     42       37.3047  0.0629\n",
            "     43       37.3047  0.0566\n",
            "     44       37.3047  0.0579\n",
            "     45       37.3047  0.0578\n",
            "     46       37.3047  0.0605\n",
            "     47       37.3047  0.0674\n",
            "     48       37.3047  0.0585\n",
            "     49       37.3047  0.0571\n",
            "     50       37.3047  0.0599\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m54.6875\u001b[0m  0.0525\n",
            "      2       54.6875  0.0584\n",
            "      3       54.6875  0.0608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       54.6875  0.0622\n",
            "      5       54.6875  0.0559\n",
            "      6       54.6875  0.0605\n",
            "      7       54.6875  0.0549\n",
            "      8       54.6875  0.0580\n",
            "      9       54.6875  0.0574\n",
            "     10       54.6875  0.0558\n",
            "     11       54.6875  0.0615\n",
            "     12       54.6875  0.0576\n",
            "     13       54.6875  0.0573\n",
            "     14       54.6875  0.0653\n",
            "     15       54.6875  0.0557\n",
            "     16       54.6875  0.0586\n",
            "     17       54.6875  0.0570\n",
            "     18       54.6875  0.0583\n",
            "     19       54.6875  0.0568\n",
            "     20       54.6875  0.0597\n",
            "     21       54.6875  0.0566\n",
            "     22       54.6875  0.0564\n",
            "     23       54.6875  0.0589\n",
            "     24       54.6875  0.0583\n",
            "     25       54.6875  0.0589\n",
            "     26       54.6875  0.0647\n",
            "     27       54.6875  0.0593\n",
            "     28       54.6875  0.0588\n",
            "     29       54.6875  0.0559\n",
            "     30       54.6875  0.0644\n",
            "     31       54.6875  0.0581\n",
            "     32       54.6875  0.0582\n",
            "     33       54.6875  0.0576\n",
            "     34       54.6875  0.0616\n",
            "     35       54.6875  0.0590\n",
            "     36       54.6875  0.0570\n",
            "     37       54.6875  0.0552\n",
            "     38       54.6875  0.0573\n",
            "     39       54.6875  0.0582\n",
            "     40       54.6875  0.0557\n",
            "     41       54.6875  0.0630\n",
            "     42       54.6875  0.0565\n",
            "     43       54.6875  0.0589\n",
            "     44       54.6875  0.0601\n",
            "     45       54.6875  0.0590\n",
            "     46       54.6875  0.0645\n",
            "     47       54.6875  0.0632\n",
            "     48       54.6875  0.0594\n",
            "     49       54.6875  0.0558\n",
            "     50       54.6875  0.0577\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m56.8359\u001b[0m  0.0515\n",
            "      2       56.8359  0.0569\n",
            "      3       56.8359  0.0558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       56.8359  0.0622\n",
            "      5       56.8359  0.0686\n",
            "      6       56.8359  0.0559\n",
            "      7       56.8359  0.0590\n",
            "      8       56.8359  0.0563\n",
            "      9       56.8359  0.0562\n",
            "     10       56.8359  0.0567\n",
            "     11       56.8359  0.0606\n",
            "     12       56.8359  0.0573\n",
            "     13       56.8359  0.0607\n",
            "     14       56.8359  0.0678\n",
            "     15       56.8359  0.0619\n",
            "     16       56.8359  0.0562\n",
            "     17       56.8359  0.0583\n",
            "     18       56.8359  0.0583\n",
            "     19       56.8359  0.0587\n",
            "     20       56.8359  0.0584\n",
            "     21       56.8359  0.0587\n",
            "     22       56.8359  0.0601\n",
            "     23       56.8359  0.0591\n",
            "     24       56.8359  0.0587\n",
            "     25       56.8359  0.0606\n",
            "     26       56.8359  0.0642\n",
            "     27       56.8359  0.0581\n",
            "     28       56.8359  0.0572\n",
            "     29       56.8359  0.0587\n",
            "     30       56.8359  0.0635\n",
            "     31       56.8359  0.0587\n",
            "     32       56.8359  0.0565\n",
            "     33       56.8359  0.0595\n",
            "     34       56.8359  0.0553\n",
            "     35       56.8359  0.0575\n",
            "     36       56.8359  0.0572\n",
            "     37       56.8359  0.0568\n",
            "     38       56.8359  0.0611\n",
            "     39       56.8359  0.0573\n",
            "     40       56.8359  0.0665\n",
            "     41       56.8359  0.0578\n",
            "     42       56.8359  0.0562\n",
            "     43       56.8359  0.0564\n",
            "     44       56.8359  0.0589\n",
            "     45       56.8359  0.0615\n",
            "     46       56.8359  0.0583\n",
            "     47       56.8359  0.0646\n",
            "     48       56.8359  0.0560\n",
            "     49       56.8359  0.0637\n",
            "     50       56.8359  0.0588\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m56.0547\u001b[0m  0.0538\n",
            "      2       56.0547  0.0582\n",
            "      3       56.0547  0.0588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       56.0547  0.0709\n",
            "      5       56.0547  0.0585\n",
            "      6       56.0547  0.0579\n",
            "      7       56.0547  0.0582\n",
            "      8       56.0547  0.0566\n",
            "      9       56.0547  0.0589\n",
            "     10       56.0547  0.0574\n",
            "     11       56.0547  0.0651\n",
            "     12       56.0547  0.0568\n",
            "     13       56.0547  0.0578\n",
            "     14       56.0547  0.0614\n",
            "     15       56.0547  0.0572\n",
            "     16       56.0547  0.0560\n",
            "     17       56.0547  0.0568\n",
            "     18       56.0547  0.0570\n",
            "     19       56.0547  0.0572\n",
            "     20       56.0547  0.0570\n",
            "     21       56.0547  0.0556\n",
            "     22       56.0547  0.0601\n",
            "     23       56.0547  0.0599\n",
            "     24       56.0547  0.0623\n",
            "     25       56.0547  0.0586\n",
            "     26       56.0547  0.0573\n",
            "     27       56.0547  0.0561\n",
            "     28       56.0547  0.0626\n",
            "     29       56.0547  0.0551\n",
            "     30       56.0547  0.0551\n",
            "     31       56.0547  0.0619\n",
            "     32       56.0547  0.0547\n",
            "     33       56.0547  0.0578\n",
            "     34       56.0547  0.0550\n",
            "     35       56.0547  0.0550\n",
            "     36       56.0547  0.0545\n",
            "     37       56.0547  0.0560\n",
            "     38       56.0547  0.0572\n",
            "     39       56.0547  0.0600\n",
            "     40       56.0547  0.0600\n",
            "     41       56.0547  0.0579\n",
            "     42       56.0547  0.0562\n",
            "     43       56.0547  0.0739\n",
            "     44       56.0547  0.0608\n",
            "     45       56.0547  0.0566\n",
            "     46       56.0547  0.0576\n",
            "     47       56.0547  0.0601\n",
            "     48       56.0547  0.0555\n",
            "     49       56.0547  0.0582\n",
            "     50       56.0547  0.0644\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.2320\u001b[0m  0.0537\n",
            "      2       37.2320  0.0618\n",
            "      3       37.2320  0.0556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.2320  0.0722\n",
            "      5       37.2320  0.0558\n",
            "      6       37.2320  0.0563\n",
            "      7       37.2320  0.0556\n",
            "      8       37.2320  0.0583\n",
            "      9       37.2320  0.0598\n",
            "     10       37.2320  0.0578\n",
            "     11       37.2320  0.0586\n",
            "     12       37.2320  0.0552\n",
            "     13       37.2320  0.0543\n",
            "     14       37.2320  0.0607\n",
            "     15       37.2320  0.0554\n",
            "     16       37.2320  0.0581\n",
            "     17       37.2320  0.0562\n",
            "     18       37.2320  0.0545\n",
            "     19       37.2320  0.0559\n",
            "     20       37.2320  0.0597\n",
            "     21       37.2320  0.0585\n",
            "     22       37.2320  0.0565\n",
            "     23       37.2320  0.0607\n",
            "     24       37.2320  0.0611\n",
            "     25       37.2320  0.0553\n",
            "     26       37.2320  0.0576\n",
            "     27       37.2320  0.0600\n",
            "     28       37.2320  0.0600\n",
            "     29       37.2320  0.0607\n",
            "     30       37.2320  0.0575\n",
            "     31       37.2320  0.0624\n",
            "     32       37.2320  0.0568\n",
            "     33       37.2320  0.0564\n",
            "     34       37.2320  0.0590\n",
            "     35       37.2320  0.0564\n",
            "     36       37.2320  0.0597\n",
            "     37       37.2320  0.0564\n",
            "     38       37.2320  0.0568\n",
            "     39       37.2320  0.0674\n",
            "     40       37.2320  0.0659\n",
            "     41       37.2320  0.0549\n",
            "     42       37.2320  0.0574\n",
            "     43       37.2320  0.0578\n",
            "     44       37.2320  0.0631\n",
            "     45       37.2320  0.0561\n",
            "     46       37.2320  0.0570\n",
            "     47       37.2320  0.0614\n",
            "     48       37.2320  0.0570\n",
            "     49       37.2320  0.0569\n",
            "     50       37.2320  0.0617\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4314\u001b[0m  0.0747\n",
            "      2        \u001b[36m1.3152\u001b[0m  0.0720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.1900\u001b[0m  0.0805\n",
            "      4        \u001b[36m1.0397\u001b[0m  0.0731\n",
            "      5        \u001b[36m0.8375\u001b[0m  0.0698\n",
            "      6        \u001b[36m0.7026\u001b[0m  0.0705\n",
            "      7        \u001b[36m0.6741\u001b[0m  0.0720\n",
            "      8        \u001b[36m0.6701\u001b[0m  0.0736\n",
            "      9        \u001b[36m0.6690\u001b[0m  0.0781\n",
            "     10        \u001b[36m0.6683\u001b[0m  0.0698\n",
            "     11        \u001b[36m0.6679\u001b[0m  0.0763\n",
            "     12        \u001b[36m0.6676\u001b[0m  0.0753\n",
            "     13        \u001b[36m0.6674\u001b[0m  0.0718\n",
            "     14        \u001b[36m0.6672\u001b[0m  0.0718\n",
            "     15        \u001b[36m0.6671\u001b[0m  0.0813\n",
            "     16        \u001b[36m0.6618\u001b[0m  0.0724\n",
            "     17        0.6739  0.0745\n",
            "     18        0.6691  0.0759\n",
            "     19        0.6679  0.0748\n",
            "     20        0.6673  0.0745\n",
            "     21        0.6668  0.0741\n",
            "     22        0.6665  0.0729\n",
            "     23        0.6662  0.0713\n",
            "     24        0.6662  0.0715\n",
            "     25        0.6658  0.0775\n",
            "     26        0.6657  0.0746\n",
            "     27        0.6656  0.0742\n",
            "     28        0.6657  0.0744\n",
            "     29        0.6654  0.0719\n",
            "     30        0.6653  0.0726\n",
            "     31        0.6653  0.0791\n",
            "     32        0.6652  0.0763\n",
            "     33        0.6652  0.0724\n",
            "     34        0.6651  0.0743\n",
            "     35        0.6651  0.0713\n",
            "     36        0.6651  0.0679\n",
            "     37        0.6651  0.0792\n",
            "     38        0.6650  0.0773\n",
            "     39        0.6650  0.0687\n",
            "     40        0.6650  0.0690\n",
            "     41        0.6650  0.0704\n",
            "     42        0.6650  0.0683\n",
            "     43        0.6649  0.0723\n",
            "     44        0.6649  0.0712\n",
            "     45        0.6649  0.0739\n",
            "     46        0.6649  0.0715\n",
            "     47        0.6649  0.0720\n",
            "     48        0.6649  0.0742\n",
            "     49        0.6648  0.0752\n",
            "     50        0.6648  0.0721\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4080\u001b[0m  0.0712\n",
            "      2        \u001b[36m1.2752\u001b[0m  0.0872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.1130\u001b[0m  0.0780\n",
            "      4        \u001b[36m0.9093\u001b[0m  0.0733\n",
            "      5        \u001b[36m0.7450\u001b[0m  0.0816\n",
            "      6        \u001b[36m0.6841\u001b[0m  0.0731\n",
            "      7        \u001b[36m0.6706\u001b[0m  0.0735\n",
            "      8        \u001b[36m0.6677\u001b[0m  0.0709\n",
            "      9        \u001b[36m0.6668\u001b[0m  0.0696\n",
            "     10        \u001b[36m0.6664\u001b[0m  0.0784\n",
            "     11        \u001b[36m0.6662\u001b[0m  0.0714\n",
            "     12        \u001b[36m0.6660\u001b[0m  0.0761\n",
            "     13        \u001b[36m0.6659\u001b[0m  0.0713\n",
            "     14        \u001b[36m0.6658\u001b[0m  0.0728\n",
            "     15        \u001b[36m0.6657\u001b[0m  0.0803\n",
            "     16        \u001b[36m0.6657\u001b[0m  0.0714\n",
            "     17        \u001b[36m0.6656\u001b[0m  0.0738\n",
            "     18        \u001b[36m0.6656\u001b[0m  0.0698\n",
            "     19        \u001b[36m0.6655\u001b[0m  0.0702\n",
            "     20        \u001b[36m0.6655\u001b[0m  0.0883\n",
            "     21        \u001b[36m0.6654\u001b[0m  0.0705\n",
            "     22        \u001b[36m0.6654\u001b[0m  0.0713\n",
            "     23        0.6654  0.0756\n",
            "     24        \u001b[36m0.6654\u001b[0m  0.0741\n",
            "     25        \u001b[36m0.6653\u001b[0m  0.0791\n",
            "     26        \u001b[36m0.6653\u001b[0m  0.0734\n",
            "     27        \u001b[36m0.6653\u001b[0m  0.0740\n",
            "     28        \u001b[36m0.6652\u001b[0m  0.0803\n",
            "     29        \u001b[36m0.6652\u001b[0m  0.0803\n",
            "     30        \u001b[36m0.6652\u001b[0m  0.0719\n",
            "     31        \u001b[36m0.6651\u001b[0m  0.0730\n",
            "     32        \u001b[36m0.6651\u001b[0m  0.0769\n",
            "     33        \u001b[36m0.6650\u001b[0m  0.0751\n",
            "     34        0.6650  0.0716\n",
            "     35        \u001b[36m0.6556\u001b[0m  0.0757\n",
            "     36        \u001b[36m0.6503\u001b[0m  0.0831\n",
            "     37        \u001b[36m0.6251\u001b[0m  0.0741\n",
            "     38        0.6531  0.0741\n",
            "     39        \u001b[36m0.6130\u001b[0m  0.0758\n",
            "     40        0.6194  0.0747\n",
            "     41        \u001b[36m0.5995\u001b[0m  0.0801\n",
            "     42        0.6106  0.0769\n",
            "     43        0.6055  0.0770\n",
            "     44        \u001b[36m0.5990\u001b[0m  0.0786\n",
            "     45        0.6005  0.0746\n",
            "     46        \u001b[36m0.5930\u001b[0m  0.0954\n",
            "     47        \u001b[36m0.5838\u001b[0m  0.0736\n",
            "     48        0.5936  0.0730\n",
            "     49        \u001b[36m0.5833\u001b[0m  0.0725\n",
            "     50        0.5911  0.0694\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.6919\u001b[0m  0.0680\n",
            "      2        \u001b[36m1.5580\u001b[0m  0.0743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.3870\u001b[0m  0.0771\n",
            "      4        \u001b[36m1.1223\u001b[0m  0.0756\n",
            "      5        \u001b[36m0.8065\u001b[0m  0.0717\n",
            "      6        \u001b[36m0.6875\u001b[0m  0.0712\n",
            "      7        \u001b[36m0.6732\u001b[0m  0.0677\n",
            "      8        \u001b[36m0.6715\u001b[0m  0.0691\n",
            "      9        \u001b[36m0.6707\u001b[0m  0.0825\n",
            "     10        \u001b[36m0.6703\u001b[0m  0.0739\n",
            "     11        \u001b[36m0.6699\u001b[0m  0.0767\n",
            "     12        \u001b[36m0.6697\u001b[0m  0.0789\n",
            "     13        \u001b[36m0.6695\u001b[0m  0.0749\n",
            "     14        \u001b[36m0.6694\u001b[0m  0.0726\n",
            "     15        \u001b[36m0.6693\u001b[0m  0.0736\n",
            "     16        \u001b[36m0.6692\u001b[0m  0.0732\n",
            "     17        \u001b[36m0.6691\u001b[0m  0.0799\n",
            "     18        \u001b[36m0.6690\u001b[0m  0.0717\n",
            "     19        \u001b[36m0.6689\u001b[0m  0.0743\n",
            "     20        \u001b[36m0.6689\u001b[0m  0.0774\n",
            "     21        \u001b[36m0.6688\u001b[0m  0.0790\n",
            "     22        \u001b[36m0.6688\u001b[0m  0.0741\n",
            "     23        \u001b[36m0.6687\u001b[0m  0.0712\n",
            "     24        \u001b[36m0.6687\u001b[0m  0.0731\n",
            "     25        0.6699  0.0743\n",
            "     26        \u001b[36m0.6686\u001b[0m  0.0704\n",
            "     27        \u001b[36m0.6686\u001b[0m  0.0733\n",
            "     28        \u001b[36m0.6685\u001b[0m  0.0789\n",
            "     29        \u001b[36m0.6685\u001b[0m  0.0748\n",
            "     30        \u001b[36m0.6684\u001b[0m  0.0724\n",
            "     31        \u001b[36m0.6684\u001b[0m  0.0796\n",
            "     32        \u001b[36m0.6684\u001b[0m  0.0836\n",
            "     33        \u001b[36m0.6684\u001b[0m  0.0725\n",
            "     34        \u001b[36m0.6683\u001b[0m  0.0755\n",
            "     35        \u001b[36m0.6683\u001b[0m  0.0749\n",
            "     36        0.6686  0.0780\n",
            "     37        \u001b[36m0.6682\u001b[0m  0.0806\n",
            "     38        \u001b[36m0.6682\u001b[0m  0.0686\n",
            "     39        \u001b[36m0.6682\u001b[0m  0.0725\n",
            "     40        \u001b[36m0.6681\u001b[0m  0.0725\n",
            "     41        \u001b[36m0.6681\u001b[0m  0.0773\n",
            "     42        \u001b[36m0.6681\u001b[0m  0.0750\n",
            "     43        \u001b[36m0.6681\u001b[0m  0.0710\n",
            "     44        \u001b[36m0.6680\u001b[0m  0.0836\n",
            "     45        \u001b[36m0.6680\u001b[0m  0.0759\n",
            "     46        \u001b[36m0.6680\u001b[0m  0.0710\n",
            "     47        \u001b[36m0.6679\u001b[0m  0.0723\n",
            "     48        \u001b[36m0.6679\u001b[0m  0.0742\n",
            "     49        \u001b[36m0.6679\u001b[0m  0.0795\n",
            "     50        \u001b[36m0.6679\u001b[0m  0.0801\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.1625\u001b[0m  0.0656\n",
            "      2        \u001b[36m1.0627\u001b[0m  0.0741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.9659\u001b[0m  0.0791\n",
            "      4        \u001b[36m0.8727\u001b[0m  0.0738\n",
            "      5        \u001b[36m0.7780\u001b[0m  0.0732\n",
            "      6        \u001b[36m0.7037\u001b[0m  0.0740\n",
            "      7        \u001b[36m0.6756\u001b[0m  0.0883\n",
            "      8        \u001b[36m0.6690\u001b[0m  0.0751\n",
            "      9        \u001b[36m0.6673\u001b[0m  0.0795\n",
            "     10        \u001b[36m0.6666\u001b[0m  0.0789\n",
            "     11        \u001b[36m0.6662\u001b[0m  0.0720\n",
            "     12        \u001b[36m0.6660\u001b[0m  0.0773\n",
            "     13        \u001b[36m0.6659\u001b[0m  0.0731\n",
            "     14        \u001b[36m0.6657\u001b[0m  0.0767\n",
            "     15        \u001b[36m0.6656\u001b[0m  0.0731\n",
            "     16        \u001b[36m0.6656\u001b[0m  0.0705\n",
            "     17        \u001b[36m0.6655\u001b[0m  0.0759\n",
            "     18        \u001b[36m0.6655\u001b[0m  0.0731\n",
            "     19        \u001b[36m0.6654\u001b[0m  0.0725\n",
            "     20        \u001b[36m0.6654\u001b[0m  0.0792\n",
            "     21        \u001b[36m0.6653\u001b[0m  0.0767\n",
            "     22        \u001b[36m0.6649\u001b[0m  0.0751\n",
            "     23        0.6650  0.0756\n",
            "     24        \u001b[36m0.6631\u001b[0m  0.0719\n",
            "     25        \u001b[36m0.6610\u001b[0m  0.0740\n",
            "     26        \u001b[36m0.6481\u001b[0m  0.0770\n",
            "     27        0.6605  0.0764\n",
            "     28        0.6556  0.0736\n",
            "     29        \u001b[36m0.6391\u001b[0m  0.0736\n",
            "     30        \u001b[36m0.6184\u001b[0m  0.0738\n",
            "     31        0.6335  0.0716\n",
            "     32        \u001b[36m0.6141\u001b[0m  0.0727\n",
            "     33        0.6348  0.0927\n",
            "     34        0.6395  0.0718\n",
            "     35        0.6406  0.0723\n",
            "     36        0.6409  0.0770\n",
            "     37        0.6409  0.0722\n",
            "     38        0.6407  0.0725\n",
            "     39        0.6405  0.0764\n",
            "     40        0.6404  0.0719\n",
            "     41        0.6402  0.0723\n",
            "     42        0.6401  0.0729\n",
            "     43        0.6400  0.0706\n",
            "     44        0.6215  0.0719\n",
            "     45        \u001b[36m0.6128\u001b[0m  0.0709\n",
            "     46        0.6301  0.0809\n",
            "     47        0.6616  0.0717\n",
            "     48        0.6525  0.0752\n",
            "     49        0.6515  0.0837\n",
            "     50        0.6215  0.0706\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.7526\u001b[0m  0.0660\n",
            "      2        \u001b[36m1.6192\u001b[0m  0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.4641\u001b[0m  0.0778\n",
            "      4        \u001b[36m1.2234\u001b[0m  0.0697\n",
            "      5        \u001b[36m0.8416\u001b[0m  0.0776\n",
            "      6        \u001b[36m0.6831\u001b[0m  0.0730\n",
            "      7        \u001b[36m0.6710\u001b[0m  0.0696\n",
            "      8        \u001b[36m0.6701\u001b[0m  0.0717\n",
            "      9        \u001b[36m0.6695\u001b[0m  0.0746\n",
            "     10        \u001b[36m0.6690\u001b[0m  0.0800\n",
            "     11        \u001b[36m0.6687\u001b[0m  0.0758\n",
            "     12        \u001b[36m0.6685\u001b[0m  0.0742\n",
            "     13        \u001b[36m0.6684\u001b[0m  0.0733\n",
            "     14        \u001b[36m0.6683\u001b[0m  0.0729\n",
            "     15        \u001b[36m0.6681\u001b[0m  0.0747\n",
            "     16        \u001b[36m0.6681\u001b[0m  0.0734\n",
            "     17        \u001b[36m0.6680\u001b[0m  0.0821\n",
            "     18        \u001b[36m0.6679\u001b[0m  0.0769\n",
            "     19        \u001b[36m0.6679\u001b[0m  0.0757\n",
            "     20        \u001b[36m0.6678\u001b[0m  0.0719\n",
            "     21        \u001b[36m0.6678\u001b[0m  0.0661\n",
            "     22        \u001b[36m0.6677\u001b[0m  0.0770\n",
            "     23        \u001b[36m0.6677\u001b[0m  0.0765\n",
            "     24        \u001b[36m0.6677\u001b[0m  0.0757\n",
            "     25        \u001b[36m0.6676\u001b[0m  0.0754\n",
            "     26        \u001b[36m0.6676\u001b[0m  0.0738\n",
            "     27        \u001b[36m0.6676\u001b[0m  0.0739\n",
            "     28        \u001b[36m0.6675\u001b[0m  0.0765\n",
            "     29        \u001b[36m0.6675\u001b[0m  0.0734\n",
            "     30        \u001b[36m0.6675\u001b[0m  0.0738\n",
            "     31        \u001b[36m0.6510\u001b[0m  0.0736\n",
            "     32        0.6836  0.0744\n",
            "     33        0.6684  0.0867\n",
            "     34        0.6666  0.0721\n",
            "     35        0.6661  0.0708\n",
            "     36        0.6660  0.0811\n",
            "     37        0.6659  0.0789\n",
            "     38        0.6659  0.0751\n",
            "     39        0.6659  0.0731\n",
            "     40        0.6659  0.0769\n",
            "     41        0.6660  0.0802\n",
            "     42        0.6660  0.0770\n",
            "     43        0.6660  0.0759\n",
            "     44        0.6660  0.0740\n",
            "     45        0.6660  0.0744\n",
            "     46        0.6660  0.0773\n",
            "     47        0.6660  0.0712\n",
            "     48        0.6660  0.0700\n",
            "     49        0.6660  0.0834\n",
            "     50        0.6660  0.0842\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.1736\u001b[0m  0.0682\n",
            "      2        \u001b[36m1.0615\u001b[0m  0.0747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.9425\u001b[0m  0.0848\n",
            "      4        \u001b[36m0.8117\u001b[0m  0.0729\n",
            "      5        \u001b[36m0.7091\u001b[0m  0.0722\n",
            "      6        \u001b[36m0.6743\u001b[0m  0.0700\n",
            "      7        \u001b[36m0.6675\u001b[0m  0.0744\n",
            "      8        \u001b[36m0.6661\u001b[0m  0.0706\n",
            "      9        \u001b[36m0.6656\u001b[0m  0.0711\n",
            "     10        \u001b[36m0.6654\u001b[0m  0.0734\n",
            "     11        \u001b[36m0.6653\u001b[0m  0.0772\n",
            "     12        \u001b[36m0.6652\u001b[0m  0.0826\n",
            "     13        \u001b[36m0.6651\u001b[0m  0.0736\n",
            "     14        \u001b[36m0.6650\u001b[0m  0.0798\n",
            "     15        \u001b[36m0.6649\u001b[0m  0.0716\n",
            "     16        \u001b[36m0.6648\u001b[0m  0.0741\n",
            "     17        \u001b[36m0.6647\u001b[0m  0.0728\n",
            "     18        \u001b[36m0.6647\u001b[0m  0.0719\n",
            "     19        \u001b[36m0.6647\u001b[0m  0.0750\n",
            "     20        \u001b[36m0.6647\u001b[0m  0.0755\n",
            "     21        \u001b[36m0.6646\u001b[0m  0.0787\n",
            "     22        \u001b[36m0.6646\u001b[0m  0.0729\n",
            "     23        \u001b[36m0.6646\u001b[0m  0.0710\n",
            "     24        \u001b[36m0.6646\u001b[0m  0.0714\n",
            "     25        \u001b[36m0.6646\u001b[0m  0.0834\n",
            "     26        \u001b[36m0.6646\u001b[0m  0.0794\n",
            "     27        \u001b[36m0.6646\u001b[0m  0.0763\n",
            "     28        \u001b[36m0.6645\u001b[0m  0.0730\n",
            "     29        \u001b[36m0.6645\u001b[0m  0.0752\n",
            "     30        \u001b[36m0.6600\u001b[0m  0.0724\n",
            "     31        \u001b[36m0.6580\u001b[0m  0.0754\n",
            "     32        \u001b[36m0.6550\u001b[0m  0.0750\n",
            "     33        \u001b[36m0.6533\u001b[0m  0.0706\n",
            "     34        \u001b[36m0.6519\u001b[0m  0.0759\n",
            "     35        \u001b[36m0.6504\u001b[0m  0.0725\n",
            "     36        \u001b[36m0.6492\u001b[0m  0.0730\n",
            "     37        \u001b[36m0.6477\u001b[0m  0.0712\n",
            "     38        \u001b[36m0.6467\u001b[0m  0.0855\n",
            "     39        \u001b[36m0.6459\u001b[0m  0.0747\n",
            "     40        \u001b[36m0.6452\u001b[0m  0.0783\n",
            "     41        \u001b[36m0.6446\u001b[0m  0.0727\n",
            "     42        \u001b[36m0.6440\u001b[0m  0.0729\n",
            "     43        \u001b[36m0.6435\u001b[0m  0.0735\n",
            "     44        \u001b[36m0.6430\u001b[0m  0.0703\n",
            "     45        \u001b[36m0.6426\u001b[0m  0.0692\n",
            "     46        \u001b[36m0.6422\u001b[0m  0.0710\n",
            "     47        \u001b[36m0.6418\u001b[0m  0.0708\n",
            "     48        \u001b[36m0.6414\u001b[0m  0.0776\n",
            "     49        \u001b[36m0.6411\u001b[0m  0.0722\n",
            "     50        \u001b[36m0.6408\u001b[0m  0.0771\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4216\u001b[0m  0.0652\n",
            "      2        \u001b[36m1.3028\u001b[0m  0.0863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.1823\u001b[0m  0.0797\n",
            "      4        \u001b[36m1.0585\u001b[0m  0.0742\n",
            "      5        \u001b[36m0.9036\u001b[0m  0.0735\n",
            "      6        \u001b[36m0.7375\u001b[0m  0.0719\n",
            "      7        \u001b[36m0.6783\u001b[0m  0.0725\n",
            "      8        \u001b[36m0.6690\u001b[0m  0.0709\n",
            "      9        \u001b[36m0.6674\u001b[0m  0.0721\n",
            "     10        \u001b[36m0.6668\u001b[0m  0.0787\n",
            "     11        \u001b[36m0.6664\u001b[0m  0.0740\n",
            "     12        \u001b[36m0.6662\u001b[0m  0.0800\n",
            "     13        \u001b[36m0.6660\u001b[0m  0.0690\n",
            "     14        \u001b[36m0.6659\u001b[0m  0.0705\n",
            "     15        \u001b[36m0.6658\u001b[0m  0.0804\n",
            "     16        \u001b[36m0.6657\u001b[0m  0.0792\n",
            "     17        \u001b[36m0.6656\u001b[0m  0.0720\n",
            "     18        \u001b[36m0.6656\u001b[0m  0.0716\n",
            "     19        \u001b[36m0.6655\u001b[0m  0.0756\n",
            "     20        \u001b[36m0.6655\u001b[0m  0.0736\n",
            "     21        \u001b[36m0.6654\u001b[0m  0.0689\n",
            "     22        \u001b[36m0.6654\u001b[0m  0.0776\n",
            "     23        \u001b[36m0.6653\u001b[0m  0.0725\n",
            "     24        \u001b[36m0.6653\u001b[0m  0.0719\n",
            "     25        \u001b[36m0.6605\u001b[0m  0.0705\n",
            "     26        \u001b[36m0.6582\u001b[0m  0.0740\n",
            "     27        \u001b[36m0.6508\u001b[0m  0.0704\n",
            "     28        \u001b[36m0.6497\u001b[0m  0.0835\n",
            "     29        \u001b[36m0.6463\u001b[0m  0.0754\n",
            "     30        0.6570  0.0705\n",
            "     31        0.6527  0.0708\n",
            "     32        0.6504  0.0789\n",
            "     33        0.6489  0.0747\n",
            "     34        0.6478  0.0745\n",
            "     35        0.6469  0.0715\n",
            "     36        \u001b[36m0.6460\u001b[0m  0.0760\n",
            "     37        \u001b[36m0.6452\u001b[0m  0.0761\n",
            "     38        \u001b[36m0.6444\u001b[0m  0.0731\n",
            "     39        \u001b[36m0.6436\u001b[0m  0.0757\n",
            "     40        \u001b[36m0.6429\u001b[0m  0.0728\n",
            "     41        \u001b[36m0.6422\u001b[0m  0.0866\n",
            "     42        \u001b[36m0.6415\u001b[0m  0.0737\n",
            "     43        \u001b[36m0.6409\u001b[0m  0.0713\n",
            "     44        \u001b[36m0.6403\u001b[0m  0.0722\n",
            "     45        \u001b[36m0.6397\u001b[0m  0.0722\n",
            "     46        \u001b[36m0.6391\u001b[0m  0.0708\n",
            "     47        \u001b[36m0.6386\u001b[0m  0.0701\n",
            "     48        \u001b[36m0.6381\u001b[0m  0.0741\n",
            "     49        \u001b[36m0.6376\u001b[0m  0.0720\n",
            "     50        \u001b[36m0.6371\u001b[0m  0.0709\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4815\u001b[0m  0.0663\n",
            "      2        \u001b[36m1.3600\u001b[0m  0.0732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.2297\u001b[0m  0.0771\n",
            "      4        \u001b[36m1.0727\u001b[0m  0.0793\n",
            "      5        \u001b[36m0.8631\u001b[0m  0.0839\n",
            "      6        \u001b[36m0.7151\u001b[0m  0.0697\n",
            "      7        \u001b[36m0.6772\u001b[0m  0.0729\n",
            "      8        \u001b[36m0.6708\u001b[0m  0.0779\n",
            "      9        \u001b[36m0.6693\u001b[0m  0.0703\n",
            "     10        \u001b[36m0.6687\u001b[0m  0.0707\n",
            "     11        \u001b[36m0.6683\u001b[0m  0.0689\n",
            "     12        \u001b[36m0.6680\u001b[0m  0.0748\n",
            "     13        \u001b[36m0.6678\u001b[0m  0.0695\n",
            "     14        \u001b[36m0.6676\u001b[0m  0.0756\n",
            "     15        \u001b[36m0.6675\u001b[0m  0.0712\n",
            "     16        \u001b[36m0.6673\u001b[0m  0.0695\n",
            "     17        \u001b[36m0.6672\u001b[0m  0.0798\n",
            "     18        \u001b[36m0.6671\u001b[0m  0.0798\n",
            "     19        \u001b[36m0.6671\u001b[0m  0.0715\n",
            "     20        \u001b[36m0.6670\u001b[0m  0.0708\n",
            "     21        \u001b[36m0.6669\u001b[0m  0.0741\n",
            "     22        \u001b[36m0.6669\u001b[0m  0.0712\n",
            "     23        \u001b[36m0.6584\u001b[0m  0.0710\n",
            "     24        \u001b[36m0.6522\u001b[0m  0.0757\n",
            "     25        \u001b[36m0.6514\u001b[0m  0.0705\n",
            "     26        \u001b[36m0.6492\u001b[0m  0.0726\n",
            "     27        \u001b[36m0.6478\u001b[0m  0.0718\n",
            "     28        \u001b[36m0.6472\u001b[0m  0.0857\n",
            "     29        \u001b[36m0.6465\u001b[0m  0.0831\n",
            "     30        \u001b[36m0.6459\u001b[0m  0.0725\n",
            "     31        \u001b[36m0.6453\u001b[0m  0.0837\n",
            "     32        \u001b[36m0.6447\u001b[0m  0.0772\n",
            "     33        \u001b[36m0.6442\u001b[0m  0.0727\n",
            "     34        \u001b[36m0.6437\u001b[0m  0.0771\n",
            "     35        \u001b[36m0.6349\u001b[0m  0.0709\n",
            "     36        \u001b[36m0.6274\u001b[0m  0.0763\n",
            "     37        \u001b[36m0.6149\u001b[0m  0.0719\n",
            "     38        0.6329  0.0740\n",
            "     39        0.6170  0.0713\n",
            "     40        0.6378  0.0715\n",
            "     41        \u001b[36m0.6130\u001b[0m  0.0779\n",
            "     42        \u001b[36m0.6009\u001b[0m  0.0751\n",
            "     43        \u001b[36m0.5960\u001b[0m  0.0728\n",
            "     44        0.6052  0.0785\n",
            "     45        \u001b[36m0.5948\u001b[0m  0.0774\n",
            "     46        0.6103  0.0707\n",
            "     47        \u001b[36m0.5896\u001b[0m  0.0754\n",
            "     48        0.6074  0.0734\n",
            "     49        0.6053  0.0685\n",
            "     50        0.6160  0.0715\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.9241\u001b[0m  0.0700\n",
            "      2        \u001b[36m1.7920\u001b[0m  0.0728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.6389\u001b[0m  0.0811\n",
            "      4        \u001b[36m1.4229\u001b[0m  0.0733\n",
            "      5        \u001b[36m1.1106\u001b[0m  0.0758\n",
            "      6        \u001b[36m0.8171\u001b[0m  0.0785\n",
            "      7        \u001b[36m0.6924\u001b[0m  0.0756\n",
            "      8        \u001b[36m0.6741\u001b[0m  0.0799\n",
            "      9        \u001b[36m0.6718\u001b[0m  0.0723\n",
            "     10        \u001b[36m0.6708\u001b[0m  0.0746\n",
            "     11        \u001b[36m0.6702\u001b[0m  0.0698\n",
            "     12        \u001b[36m0.6698\u001b[0m  0.0714\n",
            "     13        \u001b[36m0.6695\u001b[0m  0.0720\n",
            "     14        \u001b[36m0.6693\u001b[0m  0.0713\n",
            "     15        \u001b[36m0.6691\u001b[0m  0.0693\n",
            "     16        \u001b[36m0.6689\u001b[0m  0.0684\n",
            "     17        \u001b[36m0.6688\u001b[0m  0.0723\n",
            "     18        \u001b[36m0.6687\u001b[0m  0.0760\n",
            "     19        \u001b[36m0.6686\u001b[0m  0.0731\n",
            "     20        \u001b[36m0.6685\u001b[0m  0.0729\n",
            "     21        \u001b[36m0.6685\u001b[0m  0.0814\n",
            "     22        \u001b[36m0.6684\u001b[0m  0.0715\n",
            "     23        \u001b[36m0.6683\u001b[0m  0.0811\n",
            "     24        \u001b[36m0.6683\u001b[0m  0.0732\n",
            "     25        \u001b[36m0.6682\u001b[0m  0.0731\n",
            "     26        \u001b[36m0.6682\u001b[0m  0.0732\n",
            "     27        \u001b[36m0.6681\u001b[0m  0.0748\n",
            "     28        \u001b[36m0.6681\u001b[0m  0.0739\n",
            "     29        \u001b[36m0.6572\u001b[0m  0.0743\n",
            "     30        0.6808  0.0790\n",
            "     31        0.6688  0.0763\n",
            "     32        0.6791  0.0755\n",
            "     33        0.6634  0.0774\n",
            "     34        0.6610  0.0813\n",
            "     35        0.6572  0.0727\n",
            "     36        \u001b[36m0.6545\u001b[0m  0.0753\n",
            "     37        \u001b[36m0.6520\u001b[0m  0.0732\n",
            "     38        \u001b[36m0.6500\u001b[0m  0.0787\n",
            "     39        \u001b[36m0.6484\u001b[0m  0.0734\n",
            "     40        \u001b[36m0.6469\u001b[0m  0.0736\n",
            "     41        \u001b[36m0.6457\u001b[0m  0.0726\n",
            "     42        \u001b[36m0.6445\u001b[0m  0.0714\n",
            "     43        \u001b[36m0.6435\u001b[0m  0.0703\n",
            "     44        \u001b[36m0.6425\u001b[0m  0.0714\n",
            "     45        \u001b[36m0.6417\u001b[0m  0.0754\n",
            "     46        \u001b[36m0.6409\u001b[0m  0.0745\n",
            "     47        \u001b[36m0.6402\u001b[0m  0.0745\n",
            "     48        \u001b[36m0.6395\u001b[0m  0.0819\n",
            "     49        \u001b[36m0.6389\u001b[0m  0.0757\n",
            "     50        \u001b[36m0.6383\u001b[0m  0.0723\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4212\u001b[0m  0.0701\n",
            "      2        \u001b[36m1.3040\u001b[0m  0.0734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.1832\u001b[0m  0.0842\n",
            "      4        \u001b[36m1.0507\u001b[0m  0.0731\n",
            "      5        \u001b[36m0.8794\u001b[0m  0.0721\n",
            "      6        \u001b[36m0.7258\u001b[0m  0.0712\n",
            "      7        \u001b[36m0.6761\u001b[0m  0.0772\n",
            "      8        \u001b[36m0.6687\u001b[0m  0.0745\n",
            "      9        \u001b[36m0.6673\u001b[0m  0.0793\n",
            "     10        \u001b[36m0.6667\u001b[0m  0.0719\n",
            "     11        \u001b[36m0.6664\u001b[0m  0.0785\n",
            "     12        \u001b[36m0.6661\u001b[0m  0.0740\n",
            "     13        \u001b[36m0.6660\u001b[0m  0.0716\n",
            "     14        \u001b[36m0.6659\u001b[0m  0.0727\n",
            "     15        \u001b[36m0.6658\u001b[0m  0.0714\n",
            "     16        \u001b[36m0.6657\u001b[0m  0.0779\n",
            "     17        \u001b[36m0.6656\u001b[0m  0.0716\n",
            "     18        \u001b[36m0.6656\u001b[0m  0.0719\n",
            "     19        \u001b[36m0.6656\u001b[0m  0.0796\n",
            "     20        \u001b[36m0.6655\u001b[0m  0.0728\n",
            "     21        \u001b[36m0.6655\u001b[0m  0.0716\n",
            "     22        \u001b[36m0.6654\u001b[0m  0.0714\n",
            "     23        \u001b[36m0.6654\u001b[0m  0.0718\n",
            "     24        \u001b[36m0.6654\u001b[0m  0.0782\n",
            "     25        \u001b[36m0.6654\u001b[0m  0.0772\n",
            "     26        \u001b[36m0.6654\u001b[0m  0.0725\n",
            "     27        \u001b[36m0.6653\u001b[0m  0.0709\n",
            "     28        \u001b[36m0.6653\u001b[0m  0.0753\n",
            "     29        0.6663  0.0699\n",
            "     30        \u001b[36m0.6653\u001b[0m  0.0712\n",
            "     31        \u001b[36m0.6653\u001b[0m  0.0725\n",
            "     32        \u001b[36m0.6652\u001b[0m  0.0743\n",
            "     33        \u001b[36m0.6652\u001b[0m  0.0735\n",
            "     34        \u001b[36m0.6556\u001b[0m  0.0717\n",
            "     35        0.6778  0.0791\n",
            "     36        0.6693  0.0732\n",
            "     37        0.6664  0.0748\n",
            "     38        0.6655  0.0772\n",
            "     39        0.6651  0.0705\n",
            "     40        0.6649  0.0729\n",
            "     41        0.6647  0.0696\n",
            "     42        0.6646  0.0786\n",
            "     43        0.6646  0.0719\n",
            "     44        0.6645  0.0699\n",
            "     45        0.6645  0.0710\n",
            "     46        0.6644  0.0720\n",
            "     47        0.6644  0.0754\n",
            "     48        0.6644  0.0716\n",
            "     49        0.6643  0.0733\n",
            "     50        0.6643  0.0718\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.9480\u001b[0m  0.0623\n",
            "      2        \u001b[36m1.8853\u001b[0m  0.0594\n",
            "      3        \u001b[36m1.8230\u001b[0m  0.0559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.7611\u001b[0m  0.0651\n",
            "      5        \u001b[36m1.6997\u001b[0m  0.0549\n",
            "      6        \u001b[36m1.6390\u001b[0m  0.0686\n",
            "      7        \u001b[36m1.5789\u001b[0m  0.0591\n",
            "      8        \u001b[36m1.5196\u001b[0m  0.0586\n",
            "      9        \u001b[36m1.4613\u001b[0m  0.0596\n",
            "     10        \u001b[36m1.4041\u001b[0m  0.0676\n",
            "     11        \u001b[36m1.3481\u001b[0m  0.0617\n",
            "     12        \u001b[36m1.2935\u001b[0m  0.0575\n",
            "     13        \u001b[36m1.2405\u001b[0m  0.0654\n",
            "     14        \u001b[36m1.1893\u001b[0m  0.0652\n",
            "     15        \u001b[36m1.1401\u001b[0m  0.0580\n",
            "     16        \u001b[36m1.0931\u001b[0m  0.0593\n",
            "     17        \u001b[36m1.0484\u001b[0m  0.0708\n",
            "     18        \u001b[36m1.0063\u001b[0m  0.0605\n",
            "     19        \u001b[36m0.9669\u001b[0m  0.0577\n",
            "     20        \u001b[36m0.9303\u001b[0m  0.0601\n",
            "     21        \u001b[36m0.8966\u001b[0m  0.0613\n",
            "     22        \u001b[36m0.8659\u001b[0m  0.0613\n",
            "     23        \u001b[36m0.8380\u001b[0m  0.0606\n",
            "     24        \u001b[36m0.8131\u001b[0m  0.0622\n",
            "     25        \u001b[36m0.7908\u001b[0m  0.0788\n",
            "     26        \u001b[36m0.7713\u001b[0m  0.0587\n",
            "     27        \u001b[36m0.7541\u001b[0m  0.0680\n",
            "     28        \u001b[36m0.7393\u001b[0m  0.0597\n",
            "     29        \u001b[36m0.7265\u001b[0m  0.0675\n",
            "     30        \u001b[36m0.7155\u001b[0m  0.0602\n",
            "     31        \u001b[36m0.7062\u001b[0m  0.0629\n",
            "     32        \u001b[36m0.6983\u001b[0m  0.0629\n",
            "     33        \u001b[36m0.6917\u001b[0m  0.0676\n",
            "     34        \u001b[36m0.6861\u001b[0m  0.0604\n",
            "     35        \u001b[36m0.6815\u001b[0m  0.0603\n",
            "     36        \u001b[36m0.6776\u001b[0m  0.0602\n",
            "     37        \u001b[36m0.6745\u001b[0m  0.0606\n",
            "     38        \u001b[36m0.6718\u001b[0m  0.0664\n",
            "     39        \u001b[36m0.6697\u001b[0m  0.0609\n",
            "     40        \u001b[36m0.6679\u001b[0m  0.0606\n",
            "     41        \u001b[36m0.6664\u001b[0m  0.0614\n",
            "     42        \u001b[36m0.6652\u001b[0m  0.0602\n",
            "     43        \u001b[36m0.6642\u001b[0m  0.0697\n",
            "     44        \u001b[36m0.6634\u001b[0m  0.0606\n",
            "     45        \u001b[36m0.6628\u001b[0m  0.0610\n",
            "     46        \u001b[36m0.6622\u001b[0m  0.0583\n",
            "     47        \u001b[36m0.6618\u001b[0m  0.0587\n",
            "     48        \u001b[36m0.6614\u001b[0m  0.0621\n",
            "     49        \u001b[36m0.6612\u001b[0m  0.0654\n",
            "     50        \u001b[36m0.6609\u001b[0m  0.0589\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.3521\u001b[0m  0.0534\n",
            "      2        \u001b[36m1.2977\u001b[0m  0.0609\n",
            "      3        \u001b[36m1.2449\u001b[0m  0.0633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.1938\u001b[0m  0.0716\n",
            "      5        \u001b[36m1.1447\u001b[0m  0.0583\n",
            "      6        \u001b[36m1.0977\u001b[0m  0.0583\n",
            "      7        \u001b[36m1.0530\u001b[0m  0.0620\n",
            "      8        \u001b[36m1.0109\u001b[0m  0.0657\n",
            "      9        \u001b[36m0.9714\u001b[0m  0.0630\n",
            "     10        \u001b[36m0.9346\u001b[0m  0.0594\n",
            "     11        \u001b[36m0.9008\u001b[0m  0.0603\n",
            "     12        \u001b[36m0.8698\u001b[0m  0.0624\n",
            "     13        \u001b[36m0.8417\u001b[0m  0.0608\n",
            "     14        \u001b[36m0.8165\u001b[0m  0.0587\n",
            "     15        \u001b[36m0.7940\u001b[0m  0.0661\n",
            "     16        \u001b[36m0.7741\u001b[0m  0.0575\n",
            "     17        \u001b[36m0.7567\u001b[0m  0.0598\n",
            "     18        \u001b[36m0.7415\u001b[0m  0.0617\n",
            "     19        \u001b[36m0.7285\u001b[0m  0.0565\n",
            "     20        \u001b[36m0.7172\u001b[0m  0.0586\n",
            "     21        \u001b[36m0.7077\u001b[0m  0.0599\n",
            "     22        \u001b[36m0.6996\u001b[0m  0.0563\n",
            "     23        \u001b[36m0.6928\u001b[0m  0.0566\n",
            "     24        \u001b[36m0.6871\u001b[0m  0.0587\n",
            "     25        \u001b[36m0.6823\u001b[0m  0.0582\n",
            "     26        \u001b[36m0.6783\u001b[0m  0.0642\n",
            "     27        \u001b[36m0.6750\u001b[0m  0.0627\n",
            "     28        \u001b[36m0.6723\u001b[0m  0.0584\n",
            "     29        \u001b[36m0.6700\u001b[0m  0.0605\n",
            "     30        \u001b[36m0.6682\u001b[0m  0.0589\n",
            "     31        \u001b[36m0.6667\u001b[0m  0.0673\n",
            "     32        \u001b[36m0.6654\u001b[0m  0.0589\n",
            "     33        \u001b[36m0.6644\u001b[0m  0.0625\n",
            "     34        \u001b[36m0.6635\u001b[0m  0.0573\n",
            "     35        \u001b[36m0.6629\u001b[0m  0.0593\n",
            "     36        \u001b[36m0.6623\u001b[0m  0.0581\n",
            "     37        \u001b[36m0.6618\u001b[0m  0.0597\n",
            "     38        \u001b[36m0.6615\u001b[0m  0.0584\n",
            "     39        \u001b[36m0.6612\u001b[0m  0.0603\n",
            "     40        \u001b[36m0.6609\u001b[0m  0.0596\n",
            "     41        \u001b[36m0.6607\u001b[0m  0.0647\n",
            "     42        \u001b[36m0.6605\u001b[0m  0.0652\n",
            "     43        \u001b[36m0.6604\u001b[0m  0.0590\n",
            "     44        \u001b[36m0.6603\u001b[0m  0.0592\n",
            "     45        \u001b[36m0.6602\u001b[0m  0.0636\n",
            "     46        \u001b[36m0.6601\u001b[0m  0.0591\n",
            "     47        \u001b[36m0.6601\u001b[0m  0.0646\n",
            "     48        \u001b[36m0.6600\u001b[0m  0.0590\n",
            "     49        \u001b[36m0.6600\u001b[0m  0.0619\n",
            "     50        \u001b[36m0.6599\u001b[0m  0.0587\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4491\u001b[0m  0.0524\n",
            "      2        \u001b[36m1.3917\u001b[0m  0.0594\n",
            "      3        \u001b[36m1.3357\u001b[0m  0.0577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.2811\u001b[0m  0.0645\n",
            "      5        \u001b[36m1.2282\u001b[0m  0.0714\n",
            "      6        \u001b[36m1.1772\u001b[0m  0.0573\n",
            "      7        \u001b[36m1.1283\u001b[0m  0.0577\n",
            "      8        \u001b[36m1.0816\u001b[0m  0.0585\n",
            "      9        \u001b[36m1.0374\u001b[0m  0.0585\n",
            "     10        \u001b[36m0.9958\u001b[0m  0.0602\n",
            "     11        \u001b[36m0.9570\u001b[0m  0.0639\n",
            "     12        \u001b[36m0.9211\u001b[0m  0.0584\n",
            "     13        \u001b[36m0.8881\u001b[0m  0.0646\n",
            "     14        \u001b[36m0.8581\u001b[0m  0.0570\n",
            "     15        \u001b[36m0.8310\u001b[0m  0.0574\n",
            "     16        \u001b[36m0.8068\u001b[0m  0.0604\n",
            "     17        \u001b[36m0.7854\u001b[0m  0.0598\n",
            "     18        \u001b[36m0.7665\u001b[0m  0.0561\n",
            "     19        \u001b[36m0.7501\u001b[0m  0.0560\n",
            "     20        \u001b[36m0.7359\u001b[0m  0.0627\n",
            "     21        \u001b[36m0.7237\u001b[0m  0.0570\n",
            "     22        \u001b[36m0.7132\u001b[0m  0.0582\n",
            "     23        \u001b[36m0.7044\u001b[0m  0.0583\n",
            "     24        \u001b[36m0.6969\u001b[0m  0.0579\n",
            "     25        \u001b[36m0.6907\u001b[0m  0.0629\n",
            "     26        \u001b[36m0.6854\u001b[0m  0.0597\n",
            "     27        \u001b[36m0.6811\u001b[0m  0.0611\n",
            "     28        \u001b[36m0.6775\u001b[0m  0.0647\n",
            "     29        \u001b[36m0.6745\u001b[0m  0.0633\n",
            "     30        \u001b[36m0.6720\u001b[0m  0.0648\n",
            "     31        \u001b[36m0.6700\u001b[0m  0.0567\n",
            "     32        \u001b[36m0.6684\u001b[0m  0.0591\n",
            "     33        \u001b[36m0.6670\u001b[0m  0.0645\n",
            "     34        \u001b[36m0.6659\u001b[0m  0.0598\n",
            "     35        \u001b[36m0.6650\u001b[0m  0.0583\n",
            "     36        \u001b[36m0.6642\u001b[0m  0.0577\n",
            "     37        \u001b[36m0.6636\u001b[0m  0.0594\n",
            "     38        \u001b[36m0.6631\u001b[0m  0.0575\n",
            "     39        \u001b[36m0.6627\u001b[0m  0.0683\n",
            "     40        \u001b[36m0.6624\u001b[0m  0.0659\n",
            "     41        \u001b[36m0.6621\u001b[0m  0.0561\n",
            "     42        \u001b[36m0.6619\u001b[0m  0.0568\n",
            "     43        \u001b[36m0.6617\u001b[0m  0.0613\n",
            "     44        \u001b[36m0.6616\u001b[0m  0.0597\n",
            "     45        \u001b[36m0.6614\u001b[0m  0.0587\n",
            "     46        \u001b[36m0.6613\u001b[0m  0.0670\n",
            "     47        \u001b[36m0.6613\u001b[0m  0.0562\n",
            "     48        \u001b[36m0.6612\u001b[0m  0.0581\n",
            "     49        \u001b[36m0.6611\u001b[0m  0.0585\n",
            "     50        \u001b[36m0.6611\u001b[0m  0.0673\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.6038\u001b[0m  0.0511\n",
            "      2        \u001b[36m1.5436\u001b[0m  0.0567\n",
            "      3        \u001b[36m1.4843\u001b[0m  0.0651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.4261\u001b[0m  0.0643\n",
            "      5        \u001b[36m1.3692\u001b[0m  0.0566\n",
            "      6        \u001b[36m1.3135\u001b[0m  0.0574\n",
            "      7        \u001b[36m1.2595\u001b[0m  0.0579\n",
            "      8        \u001b[36m1.2072\u001b[0m  0.0583\n",
            "      9        \u001b[36m1.1569\u001b[0m  0.0581\n",
            "     10        \u001b[36m1.1088\u001b[0m  0.0576\n",
            "     11        \u001b[36m1.0630\u001b[0m  0.0584\n",
            "     12        \u001b[36m1.0197\u001b[0m  0.0631\n",
            "     13        \u001b[36m0.9792\u001b[0m  0.0559\n",
            "     14        \u001b[36m0.9415\u001b[0m  0.0555\n",
            "     15        \u001b[36m0.9067\u001b[0m  0.0580\n",
            "     16        \u001b[36m0.8749\u001b[0m  0.0561\n",
            "     17        \u001b[36m0.8461\u001b[0m  0.0558\n",
            "     18        \u001b[36m0.8202\u001b[0m  0.0654\n",
            "     19        \u001b[36m0.7972\u001b[0m  0.0581\n",
            "     20        \u001b[36m0.7768\u001b[0m  0.0573\n",
            "     21        \u001b[36m0.7590\u001b[0m  0.0593\n",
            "     22        \u001b[36m0.7435\u001b[0m  0.0590\n",
            "     23        \u001b[36m0.7302\u001b[0m  0.0599\n",
            "     24        \u001b[36m0.7188\u001b[0m  0.0613\n",
            "     25        \u001b[36m0.7090\u001b[0m  0.0546\n",
            "     26        \u001b[36m0.7008\u001b[0m  0.0614\n",
            "     27        \u001b[36m0.6939\u001b[0m  0.0589\n",
            "     28        \u001b[36m0.6881\u001b[0m  0.0563\n",
            "     29        \u001b[36m0.6833\u001b[0m  0.0625\n",
            "     30        \u001b[36m0.6793\u001b[0m  0.0571\n",
            "     31        \u001b[36m0.6760\u001b[0m  0.0558\n",
            "     32        \u001b[36m0.6733\u001b[0m  0.0551\n",
            "     33        \u001b[36m0.6710\u001b[0m  0.0557\n",
            "     34        \u001b[36m0.6692\u001b[0m  0.0591\n",
            "     35        \u001b[36m0.6677\u001b[0m  0.0558\n",
            "     36        \u001b[36m0.6664\u001b[0m  0.0582\n",
            "     37        \u001b[36m0.6654\u001b[0m  0.0587\n",
            "     38        \u001b[36m0.6646\u001b[0m  0.0605\n",
            "     39        \u001b[36m0.6639\u001b[0m  0.0606\n",
            "     40        \u001b[36m0.6633\u001b[0m  0.0572\n",
            "     41        \u001b[36m0.6629\u001b[0m  0.0574\n",
            "     42        \u001b[36m0.6625\u001b[0m  0.0620\n",
            "     43        \u001b[36m0.6622\u001b[0m  0.0580\n",
            "     44        \u001b[36m0.6620\u001b[0m  0.0618\n",
            "     45        \u001b[36m0.6618\u001b[0m  0.0576\n",
            "     46        \u001b[36m0.6616\u001b[0m  0.0690\n",
            "     47        \u001b[36m0.6615\u001b[0m  0.0603\n",
            "     48        \u001b[36m0.6614\u001b[0m  0.0583\n",
            "     49        \u001b[36m0.6613\u001b[0m  0.0617\n",
            "     50        \u001b[36m0.6612\u001b[0m  0.0589\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.3936\u001b[0m  0.0511\n",
            "      2        \u001b[36m1.3376\u001b[0m  0.0603\n",
            "      3        \u001b[36m1.2831\u001b[0m  0.0557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.2302\u001b[0m  0.0647\n",
            "      5        \u001b[36m1.1792\u001b[0m  0.0648\n",
            "      6        \u001b[36m1.1303\u001b[0m  0.0584\n",
            "      7        \u001b[36m1.0836\u001b[0m  0.0568\n",
            "      8        \u001b[36m1.0394\u001b[0m  0.0588\n",
            "      9        \u001b[36m0.9977\u001b[0m  0.0565\n",
            "     10        \u001b[36m0.9589\u001b[0m  0.0569\n",
            "     11        \u001b[36m0.9229\u001b[0m  0.0569\n",
            "     12        \u001b[36m0.8898\u001b[0m  0.0648\n",
            "     13        \u001b[36m0.8597\u001b[0m  0.0563\n",
            "     14        \u001b[36m0.8325\u001b[0m  0.0594\n",
            "     15        \u001b[36m0.8082\u001b[0m  0.0579\n",
            "     16        \u001b[36m0.7866\u001b[0m  0.0595\n",
            "     17        \u001b[36m0.7676\u001b[0m  0.0685\n",
            "     18        \u001b[36m0.7510\u001b[0m  0.0566\n",
            "     19        \u001b[36m0.7367\u001b[0m  0.0558\n",
            "     20        \u001b[36m0.7244\u001b[0m  0.0609\n",
            "     21        \u001b[36m0.7138\u001b[0m  0.0572\n",
            "     22        \u001b[36m0.7049\u001b[0m  0.0612\n",
            "     23        \u001b[36m0.6974\u001b[0m  0.0569\n",
            "     24        \u001b[36m0.6910\u001b[0m  0.0593\n",
            "     25        \u001b[36m0.6857\u001b[0m  0.0606\n",
            "     26        \u001b[36m0.6813\u001b[0m  0.0582\n",
            "     27        \u001b[36m0.6776\u001b[0m  0.0606\n",
            "     28        \u001b[36m0.6746\u001b[0m  0.0652\n",
            "     29        \u001b[36m0.6721\u001b[0m  0.0572\n",
            "     30        \u001b[36m0.6701\u001b[0m  0.0585\n",
            "     31        \u001b[36m0.6684\u001b[0m  0.0619\n",
            "     32        \u001b[36m0.6670\u001b[0m  0.0615\n",
            "     33        \u001b[36m0.6659\u001b[0m  0.0580\n",
            "     34        \u001b[36m0.6649\u001b[0m  0.0567\n",
            "     35        \u001b[36m0.6642\u001b[0m  0.0568\n",
            "     36        \u001b[36m0.6636\u001b[0m  0.0565\n",
            "     37        \u001b[36m0.6630\u001b[0m  0.0621\n",
            "     38        \u001b[36m0.6626\u001b[0m  0.0583\n",
            "     39        \u001b[36m0.6623\u001b[0m  0.0561\n",
            "     40        \u001b[36m0.6620\u001b[0m  0.0572\n",
            "     41        \u001b[36m0.6618\u001b[0m  0.0573\n",
            "     42        \u001b[36m0.6616\u001b[0m  0.0574\n",
            "     43        \u001b[36m0.6615\u001b[0m  0.0567\n",
            "     44        \u001b[36m0.6614\u001b[0m  0.0587\n",
            "     45        \u001b[36m0.6613\u001b[0m  0.0698\n",
            "     46        \u001b[36m0.6612\u001b[0m  0.0573\n",
            "     47        \u001b[36m0.6611\u001b[0m  0.0584\n",
            "     48        \u001b[36m0.6611\u001b[0m  0.0556\n",
            "     49        \u001b[36m0.6610\u001b[0m  0.0588\n",
            "     50        \u001b[36m0.6610\u001b[0m  0.0588\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0443\u001b[0m  0.0587\n",
            "      2        \u001b[36m1.0022\u001b[0m  0.0589\n",
            "      3        \u001b[36m0.9630\u001b[0m  0.0616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.9265\u001b[0m  0.0629\n",
            "      5        \u001b[36m0.8931\u001b[0m  0.0575\n",
            "      6        \u001b[36m0.8626\u001b[0m  0.0614\n",
            "      7        \u001b[36m0.8350\u001b[0m  0.0586\n",
            "      8        \u001b[36m0.8103\u001b[0m  0.0618\n",
            "      9        \u001b[36m0.7884\u001b[0m  0.0577\n",
            "     10        \u001b[36m0.7692\u001b[0m  0.0595\n",
            "     11        \u001b[36m0.7524\u001b[0m  0.0657\n",
            "     12        \u001b[36m0.7378\u001b[0m  0.0587\n",
            "     13        \u001b[36m0.7253\u001b[0m  0.0583\n",
            "     14        \u001b[36m0.7146\u001b[0m  0.0574\n",
            "     15        \u001b[36m0.7055\u001b[0m  0.0597\n",
            "     16        \u001b[36m0.6979\u001b[0m  0.0630\n",
            "     17        \u001b[36m0.6914\u001b[0m  0.0563\n",
            "     18        \u001b[36m0.6861\u001b[0m  0.0637\n",
            "     19        \u001b[36m0.6816\u001b[0m  0.0569\n",
            "     20        \u001b[36m0.6779\u001b[0m  0.0572\n",
            "     21        \u001b[36m0.6748\u001b[0m  0.0616\n",
            "     22        \u001b[36m0.6723\u001b[0m  0.0648\n",
            "     23        \u001b[36m0.6702\u001b[0m  0.0582\n",
            "     24        \u001b[36m0.6685\u001b[0m  0.0573\n",
            "     25        \u001b[36m0.6671\u001b[0m  0.0582\n",
            "     26        \u001b[36m0.6659\u001b[0m  0.0586\n",
            "     27        \u001b[36m0.6650\u001b[0m  0.0644\n",
            "     28        \u001b[36m0.6642\u001b[0m  0.0604\n",
            "     29        \u001b[36m0.6636\u001b[0m  0.0583\n",
            "     30        \u001b[36m0.6631\u001b[0m  0.0612\n",
            "     31        \u001b[36m0.6627\u001b[0m  0.0577\n",
            "     32        \u001b[36m0.6623\u001b[0m  0.0570\n",
            "     33        \u001b[36m0.6621\u001b[0m  0.0646\n",
            "     34        \u001b[36m0.6618\u001b[0m  0.0583\n",
            "     35        \u001b[36m0.6617\u001b[0m  0.0649\n",
            "     36        \u001b[36m0.6615\u001b[0m  0.0580\n",
            "     37        \u001b[36m0.6614\u001b[0m  0.0567\n",
            "     38        \u001b[36m0.6613\u001b[0m  0.0624\n",
            "     39        \u001b[36m0.6612\u001b[0m  0.0562\n",
            "     40        \u001b[36m0.6611\u001b[0m  0.0560\n",
            "     41        \u001b[36m0.6611\u001b[0m  0.0553\n",
            "     42        \u001b[36m0.6610\u001b[0m  0.0582\n",
            "     43        \u001b[36m0.6610\u001b[0m  0.0560\n",
            "     44        \u001b[36m0.6610\u001b[0m  0.0645\n",
            "     45        \u001b[36m0.6609\u001b[0m  0.0576\n",
            "     46        \u001b[36m0.6609\u001b[0m  0.0595\n",
            "     47        \u001b[36m0.6609\u001b[0m  0.0586\n",
            "     48        \u001b[36m0.6609\u001b[0m  0.0574\n",
            "     49        \u001b[36m0.6609\u001b[0m  0.0584\n",
            "     50        \u001b[36m0.6609\u001b[0m  0.0696\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0901\u001b[0m  0.0538\n",
            "      2        \u001b[36m1.0454\u001b[0m  0.0595\n",
            "      3        \u001b[36m1.0032\u001b[0m  0.0589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.9638\u001b[0m  0.0629\n",
            "      5        \u001b[36m0.9273\u001b[0m  0.0593\n",
            "      6        \u001b[36m0.8937\u001b[0m  0.0550\n",
            "      7        \u001b[36m0.8632\u001b[0m  0.0551\n",
            "      8        \u001b[36m0.8355\u001b[0m  0.0570\n",
            "      9        \u001b[36m0.8108\u001b[0m  0.0591\n",
            "     10        \u001b[36m0.7888\u001b[0m  0.0548\n",
            "     11        \u001b[36m0.7695\u001b[0m  0.0628\n",
            "     12        \u001b[36m0.7526\u001b[0m  0.0658\n",
            "     13        \u001b[36m0.7380\u001b[0m  0.0585\n",
            "     14        \u001b[36m0.7255\u001b[0m  0.0559\n",
            "     15        \u001b[36m0.7147\u001b[0m  0.0609\n",
            "     16        \u001b[36m0.7056\u001b[0m  0.0580\n",
            "     17        \u001b[36m0.6979\u001b[0m  0.0586\n",
            "     18        \u001b[36m0.6915\u001b[0m  0.0579\n",
            "     19        \u001b[36m0.6861\u001b[0m  0.0606\n",
            "     20        \u001b[36m0.6816\u001b[0m  0.0572\n",
            "     21        \u001b[36m0.6779\u001b[0m  0.0584\n",
            "     22        \u001b[36m0.6748\u001b[0m  0.0592\n",
            "     23        \u001b[36m0.6723\u001b[0m  0.0623\n",
            "     24        \u001b[36m0.6702\u001b[0m  0.0582\n",
            "     25        \u001b[36m0.6685\u001b[0m  0.0594\n",
            "     26        \u001b[36m0.6671\u001b[0m  0.0587\n",
            "     27        \u001b[36m0.6659\u001b[0m  0.0641\n",
            "     28        \u001b[36m0.6650\u001b[0m  0.0627\n",
            "     29        \u001b[36m0.6642\u001b[0m  0.0656\n",
            "     30        \u001b[36m0.6636\u001b[0m  0.0591\n",
            "     31        \u001b[36m0.6631\u001b[0m  0.0592\n",
            "     32        \u001b[36m0.6627\u001b[0m  0.0634\n",
            "     33        \u001b[36m0.6623\u001b[0m  0.0605\n",
            "     34        \u001b[36m0.6621\u001b[0m  0.0610\n",
            "     35        \u001b[36m0.6618\u001b[0m  0.0610\n",
            "     36        \u001b[36m0.6617\u001b[0m  0.0557\n",
            "     37        \u001b[36m0.6615\u001b[0m  0.0596\n",
            "     38        \u001b[36m0.6614\u001b[0m  0.0583\n",
            "     39        \u001b[36m0.6613\u001b[0m  0.0587\n",
            "     40        \u001b[36m0.6612\u001b[0m  0.0631\n",
            "     41        \u001b[36m0.6611\u001b[0m  0.0571\n",
            "     42        \u001b[36m0.6611\u001b[0m  0.0567\n",
            "     43        \u001b[36m0.6610\u001b[0m  0.0639\n",
            "     44        \u001b[36m0.6610\u001b[0m  0.0634\n",
            "     45        \u001b[36m0.6610\u001b[0m  0.0592\n",
            "     46        \u001b[36m0.6609\u001b[0m  0.0561\n",
            "     47        \u001b[36m0.6609\u001b[0m  0.0606\n",
            "     48        \u001b[36m0.6609\u001b[0m  0.0589\n",
            "     49        \u001b[36m0.6609\u001b[0m  0.0660\n",
            "     50        \u001b[36m0.6609\u001b[0m  0.0606\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.5210\u001b[0m  0.0508\n",
            "      2        \u001b[36m1.4627\u001b[0m  0.0570\n",
            "      3        \u001b[36m1.4054\u001b[0m  0.0606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.3494\u001b[0m  0.0698\n",
            "      5        \u001b[36m1.2948\u001b[0m  0.0611\n",
            "      6        \u001b[36m1.2419\u001b[0m  0.0584\n",
            "      7        \u001b[36m1.1907\u001b[0m  0.0572\n",
            "      8        \u001b[36m1.1415\u001b[0m  0.0582\n",
            "      9        \u001b[36m1.0945\u001b[0m  0.0611\n",
            "     10        \u001b[36m1.0499\u001b[0m  0.0644\n",
            "     11        \u001b[36m1.0079\u001b[0m  0.0601\n",
            "     12        \u001b[36m0.9685\u001b[0m  0.0589\n",
            "     13        \u001b[36m0.9320\u001b[0m  0.0660\n",
            "     14        \u001b[36m0.8983\u001b[0m  0.0600\n",
            "     15        \u001b[36m0.8675\u001b[0m  0.0620\n",
            "     16        \u001b[36m0.8397\u001b[0m  0.0610\n",
            "     17        \u001b[36m0.8147\u001b[0m  0.0689\n",
            "     18        \u001b[36m0.7925\u001b[0m  0.0614\n",
            "     19        \u001b[36m0.7729\u001b[0m  0.0626\n",
            "     20        \u001b[36m0.7558\u001b[0m  0.0732\n",
            "     21        \u001b[36m0.7409\u001b[0m  0.0587\n",
            "     22        \u001b[36m0.7280\u001b[0m  0.0620\n",
            "     23        \u001b[36m0.7170\u001b[0m  0.0580\n",
            "     24        \u001b[36m0.7076\u001b[0m  0.0576\n",
            "     25        \u001b[36m0.6997\u001b[0m  0.0577\n",
            "     26        \u001b[36m0.6931\u001b[0m  0.0645\n",
            "     27        \u001b[36m0.6875\u001b[0m  0.0666\n",
            "     28        \u001b[36m0.6828\u001b[0m  0.0570\n",
            "     29        \u001b[36m0.6789\u001b[0m  0.0640\n",
            "     30        \u001b[36m0.6757\u001b[0m  0.0593\n",
            "     31        \u001b[36m0.6730\u001b[0m  0.0620\n",
            "     32        \u001b[36m0.6709\u001b[0m  0.0597\n",
            "     33        \u001b[36m0.6690\u001b[0m  0.0578\n",
            "     34        \u001b[36m0.6676\u001b[0m  0.0594\n",
            "     35        \u001b[36m0.6663\u001b[0m  0.0607\n",
            "     36        \u001b[36m0.6654\u001b[0m  0.0569\n",
            "     37        \u001b[36m0.6645\u001b[0m  0.0569\n",
            "     38        \u001b[36m0.6639\u001b[0m  0.0610\n",
            "     39        \u001b[36m0.6633\u001b[0m  0.0581\n",
            "     40        \u001b[36m0.6629\u001b[0m  0.0634\n",
            "     41        \u001b[36m0.6625\u001b[0m  0.0582\n",
            "     42        \u001b[36m0.6622\u001b[0m  0.0656\n",
            "     43        \u001b[36m0.6620\u001b[0m  0.0592\n",
            "     44        \u001b[36m0.6618\u001b[0m  0.0567\n",
            "     45        \u001b[36m0.6616\u001b[0m  0.0561\n",
            "     46        \u001b[36m0.6615\u001b[0m  0.0595\n",
            "     47        \u001b[36m0.6614\u001b[0m  0.0612\n",
            "     48        \u001b[36m0.6613\u001b[0m  0.0578\n",
            "     49        \u001b[36m0.6612\u001b[0m  0.0593\n",
            "     50        \u001b[36m0.6611\u001b[0m  0.0580\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.2908\u001b[0m  0.0579\n",
            "      2        \u001b[36m1.2376\u001b[0m  0.0685\n",
            "      3        \u001b[36m1.1863\u001b[0m  0.0579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.1370\u001b[0m  0.0620\n",
            "      5        \u001b[36m1.0900\u001b[0m  0.0563\n",
            "      6        \u001b[36m1.0454\u001b[0m  0.0589\n",
            "      7        \u001b[36m1.0034\u001b[0m  0.0588\n",
            "      8        \u001b[36m0.9641\u001b[0m  0.0642\n",
            "      9        \u001b[36m0.9277\u001b[0m  0.0559\n",
            "     10        \u001b[36m0.8942\u001b[0m  0.0570\n",
            "     11        \u001b[36m0.8637\u001b[0m  0.0634\n",
            "     12        \u001b[36m0.8361\u001b[0m  0.0576\n",
            "     13        \u001b[36m0.8114\u001b[0m  0.0585\n",
            "     14        \u001b[36m0.7894\u001b[0m  0.0606\n",
            "     15        \u001b[36m0.7701\u001b[0m  0.0589\n",
            "     16        \u001b[36m0.7532\u001b[0m  0.0646\n",
            "     17        \u001b[36m0.7386\u001b[0m  0.0561\n",
            "     18        \u001b[36m0.7260\u001b[0m  0.0650\n",
            "     19        \u001b[36m0.7153\u001b[0m  0.0570\n",
            "     20        \u001b[36m0.7062\u001b[0m  0.0575\n",
            "     21        \u001b[36m0.6984\u001b[0m  0.0599\n",
            "     22        \u001b[36m0.6920\u001b[0m  0.0571\n",
            "     23        \u001b[36m0.6865\u001b[0m  0.0588\n",
            "     24        \u001b[36m0.6820\u001b[0m  0.0590\n",
            "     25        \u001b[36m0.6783\u001b[0m  0.0761\n",
            "     26        \u001b[36m0.6752\u001b[0m  0.0591\n",
            "     27        \u001b[36m0.6726\u001b[0m  0.0582\n",
            "     28        \u001b[36m0.6705\u001b[0m  0.0586\n",
            "     29        \u001b[36m0.6687\u001b[0m  0.0745\n",
            "     30        \u001b[36m0.6673\u001b[0m  0.0561\n",
            "     31        \u001b[36m0.6661\u001b[0m  0.0554\n",
            "     32        \u001b[36m0.6652\u001b[0m  0.0650\n",
            "     33        \u001b[36m0.6644\u001b[0m  0.0563\n",
            "     34        \u001b[36m0.6638\u001b[0m  0.0607\n",
            "     35        \u001b[36m0.6632\u001b[0m  0.0576\n",
            "     36        \u001b[36m0.6628\u001b[0m  0.0571\n",
            "     37        \u001b[36m0.6625\u001b[0m  0.0596\n",
            "     38        \u001b[36m0.6622\u001b[0m  0.0587\n",
            "     39        \u001b[36m0.6619\u001b[0m  0.0620\n",
            "     40        \u001b[36m0.6618\u001b[0m  0.0573\n",
            "     41        \u001b[36m0.6616\u001b[0m  0.0682\n",
            "     42        \u001b[36m0.6615\u001b[0m  0.0577\n",
            "     43        \u001b[36m0.6614\u001b[0m  0.0594\n",
            "     44        \u001b[36m0.6613\u001b[0m  0.0589\n",
            "     45        \u001b[36m0.6612\u001b[0m  0.0627\n",
            "     46        \u001b[36m0.6612\u001b[0m  0.0602\n",
            "     47        \u001b[36m0.6611\u001b[0m  0.0583\n",
            "     48        \u001b[36m0.6611\u001b[0m  0.0617\n",
            "     49        \u001b[36m0.6610\u001b[0m  0.0579\n",
            "     50        \u001b[36m0.6610\u001b[0m  0.0627\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.2970\u001b[0m  0.0507\n",
            "      2        \u001b[36m1.2457\u001b[0m  0.0590\n",
            "      3        \u001b[36m1.1961\u001b[0m  0.0583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.1483\u001b[0m  0.0655\n",
            "      5        \u001b[36m1.1027\u001b[0m  0.0568\n",
            "      6        \u001b[36m1.0592\u001b[0m  0.0567\n",
            "      7        \u001b[36m1.0182\u001b[0m  0.0632\n",
            "      8        \u001b[36m0.9797\u001b[0m  0.0592\n",
            "      9        \u001b[36m0.9437\u001b[0m  0.0627\n",
            "     10        \u001b[36m0.9105\u001b[0m  0.0582\n",
            "     11        \u001b[36m0.8800\u001b[0m  0.0643\n",
            "     12        \u001b[36m0.8522\u001b[0m  0.0591\n",
            "     13        \u001b[36m0.8271\u001b[0m  0.0578\n",
            "     14        \u001b[36m0.8046\u001b[0m  0.0617\n",
            "     15        \u001b[36m0.7846\u001b[0m  0.0569\n",
            "     16        \u001b[36m0.7669\u001b[0m  0.0587\n",
            "     17        \u001b[36m0.7513\u001b[0m  0.0582\n",
            "     18        \u001b[36m0.7378\u001b[0m  0.0583\n",
            "     19        \u001b[36m0.7261\u001b[0m  0.0590\n",
            "     20        \u001b[36m0.7160\u001b[0m  0.0614\n",
            "     21        \u001b[36m0.7074\u001b[0m  0.0586\n",
            "     22        \u001b[36m0.7000\u001b[0m  0.0588\n",
            "     23        \u001b[36m0.6937\u001b[0m  0.0598\n",
            "     24        \u001b[36m0.6884\u001b[0m  0.0692\n",
            "     25        \u001b[36m0.6840\u001b[0m  0.0628\n",
            "     26        \u001b[36m0.6802\u001b[0m  0.0574\n",
            "     27        \u001b[36m0.6770\u001b[0m  0.0596\n",
            "     28        \u001b[36m0.6744\u001b[0m  0.0607\n",
            "     29        \u001b[36m0.6722\u001b[0m  0.0585\n",
            "     30        \u001b[36m0.6703\u001b[0m  0.0568\n",
            "     31        \u001b[36m0.6688\u001b[0m  0.0562\n",
            "     32        \u001b[36m0.6675\u001b[0m  0.0553\n",
            "     33        \u001b[36m0.6664\u001b[0m  0.0587\n",
            "     34        \u001b[36m0.6655\u001b[0m  0.0577\n",
            "     35        \u001b[36m0.6647\u001b[0m  0.0564\n",
            "     36        \u001b[36m0.6641\u001b[0m  0.0571\n",
            "     37        \u001b[36m0.6636\u001b[0m  0.0607\n",
            "     38        \u001b[36m0.6631\u001b[0m  0.0635\n",
            "     39        \u001b[36m0.6627\u001b[0m  0.0570\n",
            "     40        \u001b[36m0.6624\u001b[0m  0.0636\n",
            "     41        \u001b[36m0.6622\u001b[0m  0.0604\n",
            "     42        \u001b[36m0.6619\u001b[0m  0.0583\n",
            "     43        \u001b[36m0.6618\u001b[0m  0.0634\n",
            "     44        \u001b[36m0.6616\u001b[0m  0.0586\n",
            "     45        \u001b[36m0.6615\u001b[0m  0.0574\n",
            "     46        \u001b[36m0.6614\u001b[0m  0.0567\n",
            "     47        \u001b[36m0.6613\u001b[0m  0.0596\n",
            "     48        \u001b[36m0.6612\u001b[0m  0.0625\n",
            "     49        \u001b[36m0.6611\u001b[0m  0.0591\n",
            "     50        \u001b[36m0.6610\u001b[0m  0.0577\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.1705\u001b[0m  0.0691\n",
            "      2        \u001b[36m2.9326\u001b[0m  0.0772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m2.6790\u001b[0m  0.0804\n",
            "      4        \u001b[36m2.3896\u001b[0m  0.0738\n",
            "      5        \u001b[36m1.8225\u001b[0m  0.0818\n",
            "      6        \u001b[36m1.2543\u001b[0m  0.0845\n",
            "      7        \u001b[36m0.7243\u001b[0m  0.0759\n",
            "      8        \u001b[36m0.6874\u001b[0m  0.0752\n",
            "      9        \u001b[36m0.6789\u001b[0m  0.0759\n",
            "     10        \u001b[36m0.6763\u001b[0m  0.0774\n",
            "     11        \u001b[36m0.6748\u001b[0m  0.0722\n",
            "     12        \u001b[36m0.6738\u001b[0m  0.0724\n",
            "     13        \u001b[36m0.6731\u001b[0m  0.0724\n",
            "     14        \u001b[36m0.6725\u001b[0m  0.0709\n",
            "     15        \u001b[36m0.6720\u001b[0m  0.0772\n",
            "     16        \u001b[36m0.6716\u001b[0m  0.0794\n",
            "     17        \u001b[36m0.6713\u001b[0m  0.0694\n",
            "     18        \u001b[36m0.6710\u001b[0m  0.0844\n",
            "     19        \u001b[36m0.6707\u001b[0m  0.0719\n",
            "     20        \u001b[36m0.6704\u001b[0m  0.0775\n",
            "     21        \u001b[36m0.6677\u001b[0m  0.0735\n",
            "     22        0.6745  0.0737\n",
            "     23        0.6719  0.0737\n",
            "     24        0.6706  0.0695\n",
            "     25        0.6693  0.0750\n",
            "     26        \u001b[36m0.6602\u001b[0m  0.0785\n",
            "     27        0.7010  0.0716\n",
            "     28        0.6692  0.0723\n",
            "     29        0.6641  0.0725\n",
            "     30        0.6635  0.0732\n",
            "     31        0.6631  0.0728\n",
            "     32        0.6625  0.0803\n",
            "     33        \u001b[36m0.6601\u001b[0m  0.0731\n",
            "     34        \u001b[36m0.6566\u001b[0m  0.0791\n",
            "     35        0.6632  0.0756\n",
            "     36        0.6592  0.0811\n",
            "     37        \u001b[36m0.6542\u001b[0m  0.0832\n",
            "     38        \u001b[36m0.6494\u001b[0m  0.0757\n",
            "     39        0.6598  0.0749\n",
            "     40        0.6508  0.0772\n",
            "     41        \u001b[36m0.6492\u001b[0m  0.0729\n",
            "     42        \u001b[36m0.6471\u001b[0m  0.0742\n",
            "     43        \u001b[36m0.6449\u001b[0m  0.0707\n",
            "     44        \u001b[36m0.6447\u001b[0m  0.0773\n",
            "     45        \u001b[36m0.6447\u001b[0m  0.0870\n",
            "     46        \u001b[36m0.6436\u001b[0m  0.0762\n",
            "     47        \u001b[36m0.6427\u001b[0m  0.0746\n",
            "     48        \u001b[36m0.6420\u001b[0m  0.0770\n",
            "     49        \u001b[36m0.6414\u001b[0m  0.0754\n",
            "     50        \u001b[36m0.6412\u001b[0m  0.0730\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.6608\u001b[0m  0.0682\n",
            "      2        \u001b[36m2.4130\u001b[0m  0.0739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m2.1528\u001b[0m  0.0886\n",
            "      4        \u001b[36m1.8790\u001b[0m  0.0737\n",
            "      5        \u001b[36m1.3200\u001b[0m  0.0737\n",
            "      6        \u001b[36m0.7208\u001b[0m  0.0863\n",
            "      7        \u001b[36m0.6876\u001b[0m  0.0848\n",
            "      8        \u001b[36m0.6778\u001b[0m  0.0748\n",
            "      9        \u001b[36m0.6755\u001b[0m  0.0781\n",
            "     10        \u001b[36m0.6741\u001b[0m  0.0735\n",
            "     11        \u001b[36m0.6731\u001b[0m  0.0766\n",
            "     12        \u001b[36m0.6724\u001b[0m  0.0783\n",
            "     13        \u001b[36m0.6718\u001b[0m  0.0758\n",
            "     14        \u001b[36m0.6714\u001b[0m  0.0749\n",
            "     15        \u001b[36m0.6710\u001b[0m  0.0750\n",
            "     16        \u001b[36m0.6706\u001b[0m  0.0752\n",
            "     17        \u001b[36m0.6703\u001b[0m  0.0745\n",
            "     18        \u001b[36m0.6701\u001b[0m  0.0808\n",
            "     19        \u001b[36m0.6698\u001b[0m  0.0742\n",
            "     20        \u001b[36m0.6696\u001b[0m  0.0814\n",
            "     21        \u001b[36m0.6694\u001b[0m  0.0753\n",
            "     22        0.6696  0.0734\n",
            "     23        \u001b[36m0.6691\u001b[0m  0.0762\n",
            "     24        \u001b[36m0.6689\u001b[0m  0.0757\n",
            "     25        \u001b[36m0.6688\u001b[0m  0.0813\n",
            "     26        \u001b[36m0.6687\u001b[0m  0.0733\n",
            "     27        \u001b[36m0.6685\u001b[0m  0.0737\n",
            "     28        \u001b[36m0.6685\u001b[0m  0.0738\n",
            "     29        0.6868  0.0734\n",
            "     30        0.6983  0.0762\n",
            "     31        0.6864  0.0730\n",
            "     32        0.6800  0.0770\n",
            "     33        0.6760  0.0896\n",
            "     34        0.7041  0.0759\n",
            "     35        0.6819  0.0796\n",
            "     36        \u001b[36m0.6471\u001b[0m  0.0767\n",
            "     37        0.6664  0.0749\n",
            "     38        0.6612  0.0741\n",
            "     39        0.6614  0.0734\n",
            "     40        0.6656  0.0733\n",
            "     41        0.6623  0.0748\n",
            "     42        0.6576  0.0753\n",
            "     43        0.6557  0.0826\n",
            "     44        0.6542  0.0842\n",
            "     45        0.6528  0.0829\n",
            "     46        0.6516  0.0811\n",
            "     47        0.6506  0.0780\n",
            "     48        0.6496  0.0742\n",
            "     49        0.6487  0.0736\n",
            "     50        0.6479  0.0703\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.2203\u001b[0m  0.0665\n",
            "      2        \u001b[36m2.9839\u001b[0m  0.0723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m2.7332\u001b[0m  0.0799\n",
            "      4        \u001b[36m2.4257\u001b[0m  0.0715\n",
            "      5        \u001b[36m1.6413\u001b[0m  0.0719\n",
            "      6        \u001b[36m0.8783\u001b[0m  0.0790\n",
            "      7        \u001b[36m0.6912\u001b[0m  0.0711\n",
            "      8        \u001b[36m0.6766\u001b[0m  0.0732\n",
            "      9        \u001b[36m0.6737\u001b[0m  0.0828\n",
            "     10        \u001b[36m0.6723\u001b[0m  0.0770\n",
            "     11        \u001b[36m0.6715\u001b[0m  0.0772\n",
            "     12        \u001b[36m0.6711\u001b[0m  0.0761\n",
            "     13        \u001b[36m0.6707\u001b[0m  0.0753\n",
            "     14        \u001b[36m0.6705\u001b[0m  0.0719\n",
            "     15        \u001b[36m0.6703\u001b[0m  0.0744\n",
            "     16        \u001b[36m0.6694\u001b[0m  0.0727\n",
            "     17        \u001b[36m0.6675\u001b[0m  0.0722\n",
            "     18        \u001b[36m0.6658\u001b[0m  0.0776\n",
            "     19        \u001b[36m0.6650\u001b[0m  0.0728\n",
            "     20        \u001b[36m0.6647\u001b[0m  0.0717\n",
            "     21        \u001b[36m0.6644\u001b[0m  0.0758\n",
            "     22        \u001b[36m0.6642\u001b[0m  0.0890\n",
            "     23        \u001b[36m0.6640\u001b[0m  0.0743\n",
            "     24        \u001b[36m0.6632\u001b[0m  0.0749\n",
            "     25        0.6683  0.0762\n",
            "     26        0.6632  0.0739\n",
            "     27        \u001b[36m0.6581\u001b[0m  0.0762\n",
            "     28        0.6868  0.0745\n",
            "     29        \u001b[36m0.6556\u001b[0m  0.0744\n",
            "     30        0.6917  0.0767\n",
            "     31        0.6760  0.0729\n",
            "     32        0.6669  0.0809\n",
            "     33        \u001b[36m0.6365\u001b[0m  0.0787\n",
            "     34        0.6840  0.0779\n",
            "     35        0.6939  0.0831\n",
            "     36        0.6768  0.0755\n",
            "     37        0.6660  0.0770\n",
            "     38        0.6814  0.0732\n",
            "     39        0.6773  0.0741\n",
            "     40        0.6711  0.0775\n",
            "     41        0.6681  0.0793\n",
            "     42        0.6661  0.0762\n",
            "     43        0.6645  0.0788\n",
            "     44        0.6633  0.0761\n",
            "     45        0.6624  0.0760\n",
            "     46        0.6615  0.0768\n",
            "     47        0.6608  0.0731\n",
            "     48        0.6602  0.0870\n",
            "     49        0.6596  0.0740\n",
            "     50        0.6591  0.0747\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.1720\u001b[0m  0.0702\n",
            "      2        \u001b[36m2.9340\u001b[0m  0.0739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m2.6837\u001b[0m  0.0796\n",
            "      4        \u001b[36m2.3987\u001b[0m  0.0712\n",
            "      5        \u001b[36m1.7202\u001b[0m  0.0717\n",
            "      6        \u001b[36m0.8179\u001b[0m  0.0727\n",
            "      7        \u001b[36m0.6780\u001b[0m  0.0720\n",
            "      8        \u001b[36m0.6748\u001b[0m  0.0763\n",
            "      9        \u001b[36m0.6733\u001b[0m  0.0751\n",
            "     10        \u001b[36m0.6724\u001b[0m  0.0856\n",
            "     11        \u001b[36m0.6719\u001b[0m  0.0831\n",
            "     12        \u001b[36m0.6715\u001b[0m  0.0743\n",
            "     13        \u001b[36m0.6712\u001b[0m  0.0760\n",
            "     14        \u001b[36m0.6709\u001b[0m  0.0787\n",
            "     15        \u001b[36m0.6707\u001b[0m  0.0743\n",
            "     16        \u001b[36m0.6706\u001b[0m  0.0737\n",
            "     17        \u001b[36m0.6704\u001b[0m  0.0719\n",
            "     18        \u001b[36m0.6703\u001b[0m  0.0741\n",
            "     19        \u001b[36m0.6702\u001b[0m  0.0793\n",
            "     20        \u001b[36m0.6695\u001b[0m  0.0742\n",
            "     21        \u001b[36m0.6688\u001b[0m  0.0815\n",
            "     22        \u001b[36m0.6671\u001b[0m  0.0776\n",
            "     23        \u001b[36m0.6662\u001b[0m  0.0738\n",
            "     24        \u001b[36m0.6653\u001b[0m  0.0887\n",
            "     25        \u001b[36m0.6577\u001b[0m  0.0756\n",
            "     26        \u001b[36m0.6506\u001b[0m  0.0877\n",
            "     27        \u001b[36m0.6494\u001b[0m  0.0749\n",
            "     28        0.6532  0.0790\n",
            "     29        0.6764  0.0746\n",
            "     30        0.6580  0.0767\n",
            "     31        \u001b[36m0.6371\u001b[0m  0.0741\n",
            "     32        0.6541  0.0725\n",
            "     33        0.6412  0.0794\n",
            "     34        0.6525  0.0739\n",
            "     35        \u001b[36m0.6324\u001b[0m  0.0779\n",
            "     36        \u001b[36m0.6315\u001b[0m  0.0743\n",
            "     37        0.6475  0.0825\n",
            "     38        \u001b[36m0.6238\u001b[0m  0.0820\n",
            "     39        0.6309  0.0747\n",
            "     40        0.6396  0.0770\n",
            "     41        0.6400  0.0729\n",
            "     42        0.6564  0.0726\n",
            "     43        0.6492  0.0756\n",
            "     44        0.6459  0.0739\n",
            "     45        0.6442  0.0736\n",
            "     46        0.6441  0.0746\n",
            "     47        0.6440  0.0742\n",
            "     48        0.6439  0.0830\n",
            "     49        0.6438  0.0764\n",
            "     50        0.6438  0.0871\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.4492\u001b[0m  0.0737\n",
            "      2        \u001b[36m2.1995\u001b[0m  0.0743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.9390\u001b[0m  0.0804\n",
            "      4        \u001b[36m1.6786\u001b[0m  0.0782\n",
            "      5        \u001b[36m1.3814\u001b[0m  0.0734\n",
            "      6        \u001b[36m0.7996\u001b[0m  0.0788\n",
            "      7        \u001b[36m0.6820\u001b[0m  0.0731\n",
            "      8        \u001b[36m0.6779\u001b[0m  0.0771\n",
            "      9        \u001b[36m0.6754\u001b[0m  0.0835\n",
            "     10        \u001b[36m0.6741\u001b[0m  0.0721\n",
            "     11        \u001b[36m0.6733\u001b[0m  0.0740\n",
            "     12        \u001b[36m0.6727\u001b[0m  0.0748\n",
            "     13        \u001b[36m0.6722\u001b[0m  0.0847\n",
            "     14        \u001b[36m0.6719\u001b[0m  0.0777\n",
            "     15        \u001b[36m0.6716\u001b[0m  0.0721\n",
            "     16        \u001b[36m0.6713\u001b[0m  0.0751\n",
            "     17        \u001b[36m0.6711\u001b[0m  0.0706\n",
            "     18        \u001b[36m0.6709\u001b[0m  0.0724\n",
            "     19        0.6714  0.0700\n",
            "     20        0.6806  0.0731\n",
            "     21        \u001b[36m0.6703\u001b[0m  0.0762\n",
            "     22        \u001b[36m0.6701\u001b[0m  0.0715\n",
            "     23        \u001b[36m0.6635\u001b[0m  0.0715\n",
            "     24        0.6888  0.0780\n",
            "     25        0.6756  0.0765\n",
            "     26        0.6750  0.0808\n",
            "     27        0.6744  0.0761\n",
            "     28        0.6738  0.0748\n",
            "     29        0.6731  0.0700\n",
            "     30        0.6702  0.0743\n",
            "     31        \u001b[36m0.6628\u001b[0m  0.0734\n",
            "     32        0.6765  0.0722\n",
            "     33        0.6737  0.0787\n",
            "     34        0.6669  0.0756\n",
            "     35        \u001b[36m0.6458\u001b[0m  0.0756\n",
            "     36        \u001b[36m0.6360\u001b[0m  0.0754\n",
            "     37        0.6728  0.0815\n",
            "     38        0.7091  0.0772\n",
            "     39        0.6673  0.0824\n",
            "     40        0.6571  0.0721\n",
            "     41        0.6615  0.0712\n",
            "     42        0.6578  0.0730\n",
            "     43        0.6559  0.0706\n",
            "     44        0.6545  0.0705\n",
            "     45        0.6533  0.0742\n",
            "     46        0.6522  0.0763\n",
            "     47        0.6512  0.0692\n",
            "     48        0.6504  0.0759\n",
            "     49        0.6495  0.0766\n",
            "     50        0.6486  0.0708\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2114\u001b[0m  0.0688\n",
            "      2        \u001b[36m1.9662\u001b[0m  0.0849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.7130\u001b[0m  0.0822\n",
            "      4        \u001b[36m1.4536\u001b[0m  0.0709\n",
            "      5        \u001b[36m1.0896\u001b[0m  0.0741\n",
            "      6        \u001b[36m0.7550\u001b[0m  0.0731\n",
            "      7        \u001b[36m0.6738\u001b[0m  0.0793\n",
            "      8        \u001b[36m0.6686\u001b[0m  0.0722\n",
            "      9        \u001b[36m0.6675\u001b[0m  0.0759\n",
            "     10        \u001b[36m0.6669\u001b[0m  0.0796\n",
            "     11        \u001b[36m0.6666\u001b[0m  0.0773\n",
            "     12        \u001b[36m0.6664\u001b[0m  0.0721\n",
            "     13        \u001b[36m0.6663\u001b[0m  0.0739\n",
            "     14        \u001b[36m0.6662\u001b[0m  0.0746\n",
            "     15        \u001b[36m0.6661\u001b[0m  0.0837\n",
            "     16        \u001b[36m0.6660\u001b[0m  0.0712\n",
            "     17        \u001b[36m0.6659\u001b[0m  0.0725\n",
            "     18        \u001b[36m0.6659\u001b[0m  0.0744\n",
            "     19        \u001b[36m0.6642\u001b[0m  0.0780\n",
            "     20        0.6811  0.0734\n",
            "     21        0.6709  0.0736\n",
            "     22        0.6686  0.0802\n",
            "     23        0.6672  0.0717\n",
            "     24        0.6671  0.0749\n",
            "     25        0.6668  0.0726\n",
            "     26        0.6667  0.0728\n",
            "     27        0.6665  0.0726\n",
            "     28        \u001b[36m0.6571\u001b[0m  0.0785\n",
            "     29        0.6806  0.0720\n",
            "     30        0.6657  0.0794\n",
            "     31        0.6796  0.0739\n",
            "     32        0.6717  0.0735\n",
            "     33        0.6672  0.0731\n",
            "     34        0.6627  0.0775\n",
            "     35        \u001b[36m0.6442\u001b[0m  0.0722\n",
            "     36        0.6624  0.0728\n",
            "     37        \u001b[36m0.6302\u001b[0m  0.0847\n",
            "     38        0.6495  0.0775\n",
            "     39        0.6453  0.0741\n",
            "     40        0.6366  0.0752\n",
            "     41        0.6427  0.0804\n",
            "     42        0.6413  0.0738\n",
            "     43        0.6423  0.0707\n",
            "     44        0.6394  0.0708\n",
            "     45        0.6352  0.0713\n",
            "     46        \u001b[36m0.6183\u001b[0m  0.0722\n",
            "     47        \u001b[36m0.6107\u001b[0m  0.0742\n",
            "     48        0.6409  0.0693\n",
            "     49        0.6400  0.0761\n",
            "     50        0.6374  0.0714\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.8519\u001b[0m  0.0736\n",
            "      2        \u001b[36m2.6036\u001b[0m  0.0732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m2.3422\u001b[0m  0.0869\n",
            "      4        \u001b[36m2.0208\u001b[0m  0.0725\n",
            "      5        \u001b[36m1.2155\u001b[0m  0.0776\n",
            "      6        \u001b[36m0.7191\u001b[0m  0.0730\n",
            "      7        \u001b[36m0.6722\u001b[0m  0.0703\n",
            "      8        \u001b[36m0.6691\u001b[0m  0.0717\n",
            "      9        \u001b[36m0.6683\u001b[0m  0.0701\n",
            "     10        \u001b[36m0.6679\u001b[0m  0.0706\n",
            "     11        \u001b[36m0.6677\u001b[0m  0.0845\n",
            "     12        \u001b[36m0.6676\u001b[0m  0.0720\n",
            "     13        \u001b[36m0.6675\u001b[0m  0.0938\n",
            "     14        \u001b[36m0.6674\u001b[0m  0.0728\n",
            "     15        \u001b[36m0.6673\u001b[0m  0.0712\n",
            "     16        \u001b[36m0.6673\u001b[0m  0.0794\n",
            "     17        \u001b[36m0.6673\u001b[0m  0.0734\n",
            "     18        \u001b[36m0.6672\u001b[0m  0.0815\n",
            "     19        \u001b[36m0.6672\u001b[0m  0.0737\n",
            "     20        0.6672  0.0737\n",
            "     21        0.6676  0.0734\n",
            "     22        \u001b[36m0.6607\u001b[0m  0.0719\n",
            "     23        0.6844  0.0707\n",
            "     24        0.6718  0.0746\n",
            "     25        0.6707  0.0726\n",
            "     26        0.6667  0.0807\n",
            "     27        0.6876  0.0853\n",
            "     28        \u001b[36m0.6567\u001b[0m  0.0726\n",
            "     29        \u001b[36m0.6513\u001b[0m  0.0782\n",
            "     30        0.7379  0.0743\n",
            "     31        0.6876  0.0785\n",
            "     32        0.6794  0.0749\n",
            "     33        0.6909  0.0762\n",
            "     34        0.6941  0.0749\n",
            "     35        0.6810  0.0726\n",
            "     36        0.6812  0.0746\n",
            "     37        0.6792  0.0723\n",
            "     38        0.6766  0.0820\n",
            "     39        0.6745  0.0760\n",
            "     40        0.6709  0.0755\n",
            "     41        0.6619  0.0735\n",
            "     42        0.6591  0.0765\n",
            "     43        \u001b[36m0.6388\u001b[0m  0.0717\n",
            "     44        0.6453  0.0861\n",
            "     45        \u001b[36m0.6219\u001b[0m  0.0753\n",
            "     46        0.6504  0.0746\n",
            "     47        0.6391  0.0734\n",
            "     48        0.6335  0.0743\n",
            "     49        \u001b[36m0.6131\u001b[0m  0.0771\n",
            "     50        0.6211  0.0745\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.2053\u001b[0m  0.0673\n",
            "      2        \u001b[36m2.9614\u001b[0m  0.0729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m2.7048\u001b[0m  0.0895\n",
            "      4        \u001b[36m2.4060\u001b[0m  0.0721\n",
            "      5        \u001b[36m1.6305\u001b[0m  0.0728\n",
            "      6        \u001b[36m0.7869\u001b[0m  0.0757\n",
            "      7        \u001b[36m0.6802\u001b[0m  0.0795\n",
            "      8        \u001b[36m0.6772\u001b[0m  0.0718\n",
            "      9        \u001b[36m0.6755\u001b[0m  0.0704\n",
            "     10        \u001b[36m0.6745\u001b[0m  0.0720\n",
            "     11        \u001b[36m0.6739\u001b[0m  0.0723\n",
            "     12        \u001b[36m0.6734\u001b[0m  0.0775\n",
            "     13        \u001b[36m0.6730\u001b[0m  0.0712\n",
            "     14        \u001b[36m0.6727\u001b[0m  0.0714\n",
            "     15        0.6728  0.0795\n",
            "     16        0.6806  0.0733\n",
            "     17        \u001b[36m0.6712\u001b[0m  0.0781\n",
            "     18        0.6712  0.0752\n",
            "     19        \u001b[36m0.6711\u001b[0m  0.0719\n",
            "     20        \u001b[36m0.6709\u001b[0m  0.0805\n",
            "     21        \u001b[36m0.6708\u001b[0m  0.0735\n",
            "     22        \u001b[36m0.6707\u001b[0m  0.0815\n",
            "     23        \u001b[36m0.6668\u001b[0m  0.0784\n",
            "     24        \u001b[36m0.6632\u001b[0m  0.0738\n",
            "     25        \u001b[36m0.6563\u001b[0m  0.0724\n",
            "     26        0.6930  0.0733\n",
            "     27        0.6599  0.0838\n",
            "     28        0.6911  0.0749\n",
            "     29        0.6710  0.0728\n",
            "     30        0.6590  0.0830\n",
            "     31        \u001b[36m0.6556\u001b[0m  0.0738\n",
            "     32        \u001b[36m0.6529\u001b[0m  0.0780\n",
            "     33        \u001b[36m0.6514\u001b[0m  0.0799\n",
            "     34        \u001b[36m0.6492\u001b[0m  0.0772\n",
            "     35        0.6535  0.0742\n",
            "     36        0.6498  0.0784\n",
            "     37        \u001b[36m0.6474\u001b[0m  0.0745\n",
            "     38        0.6511  0.0795\n",
            "     39        0.6780  0.0740\n",
            "     40        0.6651  0.0723\n",
            "     41        0.6535  0.0737\n",
            "     42        0.6856  0.0731\n",
            "     43        0.6655  0.0798\n",
            "     44        0.6791  0.0733\n",
            "     45        0.6669  0.0730\n",
            "     46        0.6625  0.0830\n",
            "     47        0.6593  0.0718\n",
            "     48        0.6569  0.0728\n",
            "     49        0.6549  0.0743\n",
            "     50        0.6532  0.0785\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.3403\u001b[0m  0.0699\n",
            "      2        \u001b[36m3.0972\u001b[0m  0.0728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m2.8425\u001b[0m  0.0808\n",
            "      4        \u001b[36m2.5732\u001b[0m  0.0745\n",
            "      5        \u001b[36m2.0589\u001b[0m  0.0741\n",
            "      6        \u001b[36m1.1019\u001b[0m  0.0748\n",
            "      7        \u001b[36m0.6897\u001b[0m  0.0801\n",
            "      8        \u001b[36m0.6776\u001b[0m  0.0742\n",
            "      9        \u001b[36m0.6755\u001b[0m  0.0822\n",
            "     10        \u001b[36m0.6742\u001b[0m  0.0776\n",
            "     11        \u001b[36m0.6735\u001b[0m  0.0742\n",
            "     12        \u001b[36m0.6730\u001b[0m  0.0731\n",
            "     13        \u001b[36m0.6726\u001b[0m  0.0714\n",
            "     14        \u001b[36m0.6723\u001b[0m  0.0736\n",
            "     15        \u001b[36m0.6720\u001b[0m  0.0832\n",
            "     16        \u001b[36m0.6718\u001b[0m  0.0722\n",
            "     17        \u001b[36m0.6716\u001b[0m  0.0737\n",
            "     18        \u001b[36m0.6715\u001b[0m  0.0730\n",
            "     19        \u001b[36m0.6713\u001b[0m  0.0838\n",
            "     20        \u001b[36m0.6712\u001b[0m  0.0726\n",
            "     21        \u001b[36m0.6711\u001b[0m  0.0741\n",
            "     22        \u001b[36m0.6709\u001b[0m  0.0801\n",
            "     23        \u001b[36m0.6708\u001b[0m  0.0713\n",
            "     24        \u001b[36m0.6707\u001b[0m  0.0710\n",
            "     25        0.6707  0.0744\n",
            "     26        \u001b[36m0.6622\u001b[0m  0.0719\n",
            "     27        0.7015  0.0818\n",
            "     28        0.6669  0.0732\n",
            "     29        \u001b[36m0.6544\u001b[0m  0.0711\n",
            "     30        0.6947  0.0738\n",
            "     31        0.6721  0.0759\n",
            "     32        0.6559  0.0801\n",
            "     33        \u001b[36m0.6163\u001b[0m  0.0744\n",
            "     34        0.6386  0.0744\n",
            "     35        0.6175  0.0788\n",
            "     36        0.6329  0.0752\n",
            "     37        0.6338  0.0722\n",
            "     38        \u001b[36m0.6112\u001b[0m  0.0723\n",
            "     39        0.6414  0.0784\n",
            "     40        0.6302  0.0760\n",
            "     41        \u001b[36m0.5878\u001b[0m  0.0712\n",
            "     42        0.6095  0.0722\n",
            "     43        0.5982  0.0719\n",
            "     44        0.6031  0.0771\n",
            "     45        0.5954  0.0738\n",
            "     46        \u001b[36m0.5772\u001b[0m  0.0747\n",
            "     47        0.5777  0.0736\n",
            "     48        \u001b[36m0.5757\u001b[0m  0.0750\n",
            "     49        0.5833  0.0709\n",
            "     50        \u001b[36m0.5750\u001b[0m  0.0731\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.6889\u001b[0m  0.0659\n",
            "      2        \u001b[36m2.4462\u001b[0m  0.0945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m2.1929\u001b[0m  0.0832\n",
            "      4        \u001b[36m1.9359\u001b[0m  0.0777\n",
            "      5        \u001b[36m1.6372\u001b[0m  0.0798\n",
            "      6        \u001b[36m1.0971\u001b[0m  0.0783\n",
            "      7        \u001b[36m0.6879\u001b[0m  0.0772\n",
            "      8        \u001b[36m0.6832\u001b[0m  0.0752\n",
            "      9        \u001b[36m0.6758\u001b[0m  0.0759\n",
            "     10        \u001b[36m0.6739\u001b[0m  0.0779\n",
            "     11        \u001b[36m0.6728\u001b[0m  0.0817\n",
            "     12        \u001b[36m0.6720\u001b[0m  0.0764\n",
            "     13        \u001b[36m0.6715\u001b[0m  0.0746\n",
            "     14        \u001b[36m0.6711\u001b[0m  0.0756\n",
            "     15        \u001b[36m0.6708\u001b[0m  0.0817\n",
            "     16        \u001b[36m0.6706\u001b[0m  0.0758\n",
            "     17        \u001b[36m0.6703\u001b[0m  0.0771\n",
            "     18        \u001b[36m0.6701\u001b[0m  0.0732\n",
            "     19        \u001b[36m0.6674\u001b[0m  0.0733\n",
            "     20        0.6687  0.0774\n",
            "     21        0.6693  0.0759\n",
            "     22        0.6694  0.0755\n",
            "     23        0.6693  0.0805\n",
            "     24        0.6692  0.0824\n",
            "     25        0.6681  0.0752\n",
            "     26        0.6675  0.0760\n",
            "     27        \u001b[36m0.6663\u001b[0m  0.0833\n",
            "     28        0.6678  0.0817\n",
            "     29        0.6729  0.0742\n",
            "     30        0.6666  0.0764\n",
            "     31        \u001b[36m0.6646\u001b[0m  0.0753\n",
            "     32        \u001b[36m0.6619\u001b[0m  0.0869\n",
            "     33        \u001b[36m0.6603\u001b[0m  0.0755\n",
            "     34        \u001b[36m0.6590\u001b[0m  0.0748\n",
            "     35        \u001b[36m0.6325\u001b[0m  0.0780\n",
            "     36        0.6914  0.0746\n",
            "     37        0.6600  0.0836\n",
            "     38        0.6577  0.0765\n",
            "     39        0.6606  0.0746\n",
            "     40        0.6574  0.0717\n",
            "     41        0.6558  0.0726\n",
            "     42        0.6546  0.0789\n",
            "     43        0.6537  0.0739\n",
            "     44        0.6529  0.0829\n",
            "     45        0.6522  0.0795\n",
            "     46        0.6515  0.0767\n",
            "     47        0.6510  0.0761\n",
            "     48        0.6505  0.0811\n",
            "     49        0.6500  0.0750\n",
            "     50        0.6496  0.0782\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.9022\u001b[0m  0.0565\n",
            "      2        \u001b[36m2.7802\u001b[0m  0.0591\n",
            "      3        \u001b[36m2.6582\u001b[0m  0.0587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m2.5364\u001b[0m  0.0747\n",
            "      5        \u001b[36m2.4149\u001b[0m  0.0655\n",
            "      6        \u001b[36m2.2937\u001b[0m  0.0618\n",
            "      7        \u001b[36m2.1729\u001b[0m  0.0604\n",
            "      8        \u001b[36m2.0528\u001b[0m  0.0634\n",
            "      9        \u001b[36m1.9336\u001b[0m  0.0610\n",
            "     10        \u001b[36m1.8155\u001b[0m  0.0582\n",
            "     11        \u001b[36m1.6990\u001b[0m  0.0622\n",
            "     12        \u001b[36m1.5848\u001b[0m  0.0597\n",
            "     13        \u001b[36m1.4734\u001b[0m  0.0598\n",
            "     14        \u001b[36m1.3658\u001b[0m  0.0582\n",
            "     15        \u001b[36m1.2632\u001b[0m  0.0701\n",
            "     16        \u001b[36m1.1667\u001b[0m  0.0616\n",
            "     17        \u001b[36m1.0776\u001b[0m  0.0617\n",
            "     18        \u001b[36m0.9973\u001b[0m  0.0549\n",
            "     19        \u001b[36m0.9267\u001b[0m  0.0619\n",
            "     20        \u001b[36m0.8664\u001b[0m  0.0599\n",
            "     21        \u001b[36m0.8165\u001b[0m  0.0613\n",
            "     22        \u001b[36m0.7764\u001b[0m  0.0603\n",
            "     23        \u001b[36m0.7451\u001b[0m  0.0576\n",
            "     24        \u001b[36m0.7214\u001b[0m  0.0583\n",
            "     25        \u001b[36m0.7038\u001b[0m  0.0582\n",
            "     26        \u001b[36m0.6909\u001b[0m  0.0598\n",
            "     27        \u001b[36m0.6817\u001b[0m  0.0637\n",
            "     28        \u001b[36m0.6752\u001b[0m  0.0600\n",
            "     29        \u001b[36m0.6706\u001b[0m  0.0610\n",
            "     30        \u001b[36m0.6675\u001b[0m  0.0590\n",
            "     31        \u001b[36m0.6652\u001b[0m  0.0679\n",
            "     32        \u001b[36m0.6637\u001b[0m  0.0599\n",
            "     33        \u001b[36m0.6626\u001b[0m  0.0589\n",
            "     34        \u001b[36m0.6619\u001b[0m  0.0586\n",
            "     35        \u001b[36m0.6614\u001b[0m  0.0627\n",
            "     36        \u001b[36m0.6610\u001b[0m  0.0598\n",
            "     37        \u001b[36m0.6607\u001b[0m  0.0660\n",
            "     38        \u001b[36m0.6605\u001b[0m  0.0665\n",
            "     39        \u001b[36m0.6604\u001b[0m  0.0585\n",
            "     40        \u001b[36m0.6603\u001b[0m  0.0625\n",
            "     41        \u001b[36m0.6602\u001b[0m  0.0587\n",
            "     42        \u001b[36m0.6602\u001b[0m  0.0617\n",
            "     43        \u001b[36m0.6602\u001b[0m  0.0600\n",
            "     44        \u001b[36m0.6601\u001b[0m  0.0606\n",
            "     45        \u001b[36m0.6601\u001b[0m  0.0576\n",
            "     46        \u001b[36m0.6601\u001b[0m  0.0596\n",
            "     47        \u001b[36m0.6601\u001b[0m  0.0678\n",
            "     48        \u001b[36m0.6601\u001b[0m  0.0578\n",
            "     49        \u001b[36m0.6601\u001b[0m  0.0572\n",
            "     50        \u001b[36m0.6600\u001b[0m  0.0600\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.3973\u001b[0m  0.0570\n",
            "      2        \u001b[36m3.2750\u001b[0m  0.0672\n",
            "      3        \u001b[36m3.1528\u001b[0m  0.0585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m3.0305\u001b[0m  0.0660\n",
            "      5        \u001b[36m2.9083\u001b[0m  0.0580\n",
            "      6        \u001b[36m2.7862\u001b[0m  0.0634\n",
            "      7        \u001b[36m2.6643\u001b[0m  0.0586\n",
            "      8        \u001b[36m2.5425\u001b[0m  0.0559\n",
            "      9        \u001b[36m2.4209\u001b[0m  0.0568\n",
            "     10        \u001b[36m2.2997\u001b[0m  0.0605\n",
            "     11        \u001b[36m2.1789\u001b[0m  0.0586\n",
            "     12        \u001b[36m2.0588\u001b[0m  0.0570\n",
            "     13        \u001b[36m1.9394\u001b[0m  0.0658\n",
            "     14        \u001b[36m1.8213\u001b[0m  0.0584\n",
            "     15        \u001b[36m1.7048\u001b[0m  0.0661\n",
            "     16        \u001b[36m1.5904\u001b[0m  0.0581\n",
            "     17        \u001b[36m1.4788\u001b[0m  0.0571\n",
            "     18        \u001b[36m1.3710\u001b[0m  0.0577\n",
            "     19        \u001b[36m1.2681\u001b[0m  0.0687\n",
            "     20        \u001b[36m1.1712\u001b[0m  0.0612\n",
            "     21        \u001b[36m1.0817\u001b[0m  0.0614\n",
            "     22        \u001b[36m1.0009\u001b[0m  0.0607\n",
            "     23        \u001b[36m0.9297\u001b[0m  0.0563\n",
            "     24        \u001b[36m0.8689\u001b[0m  0.0574\n",
            "     25        \u001b[36m0.8185\u001b[0m  0.0578\n",
            "     26        \u001b[36m0.7779\u001b[0m  0.0555\n",
            "     27        \u001b[36m0.7462\u001b[0m  0.0569\n",
            "     28        \u001b[36m0.7221\u001b[0m  0.0603\n",
            "     29        \u001b[36m0.7042\u001b[0m  0.0593\n",
            "     30        \u001b[36m0.6912\u001b[0m  0.0721\n",
            "     31        \u001b[36m0.6818\u001b[0m  0.0578\n",
            "     32        \u001b[36m0.6752\u001b[0m  0.0583\n",
            "     33        \u001b[36m0.6706\u001b[0m  0.0577\n",
            "     34        \u001b[36m0.6674\u001b[0m  0.0566\n",
            "     35        \u001b[36m0.6651\u001b[0m  0.0650\n",
            "     36        \u001b[36m0.6636\u001b[0m  0.0584\n",
            "     37        \u001b[36m0.6625\u001b[0m  0.0609\n",
            "     38        \u001b[36m0.6618\u001b[0m  0.0632\n",
            "     39        \u001b[36m0.6612\u001b[0m  0.0616\n",
            "     40        \u001b[36m0.6609\u001b[0m  0.0625\n",
            "     41        \u001b[36m0.6606\u001b[0m  0.0597\n",
            "     42        \u001b[36m0.6604\u001b[0m  0.0579\n",
            "     43        \u001b[36m0.6603\u001b[0m  0.0614\n",
            "     44        \u001b[36m0.6602\u001b[0m  0.0598\n",
            "     45        \u001b[36m0.6601\u001b[0m  0.0593\n",
            "     46        \u001b[36m0.6601\u001b[0m  0.0653\n",
            "     47        \u001b[36m0.6601\u001b[0m  0.0589\n",
            "     48        \u001b[36m0.6600\u001b[0m  0.0641\n",
            "     49        \u001b[36m0.6600\u001b[0m  0.0645\n",
            "     50        \u001b[36m0.6600\u001b[0m  0.0561\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.4672\u001b[0m  0.0573\n",
            "      2        \u001b[36m2.3446\u001b[0m  0.0617\n",
            "      3        \u001b[36m2.2224\u001b[0m  0.0610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m2.1008\u001b[0m  0.0682\n",
            "      5        \u001b[36m1.9800\u001b[0m  0.0609\n",
            "      6        \u001b[36m1.8602\u001b[0m  0.0574\n",
            "      7        \u001b[36m1.7420\u001b[0m  0.0598\n",
            "      8        \u001b[36m1.6258\u001b[0m  0.0567\n",
            "      9        \u001b[36m1.5123\u001b[0m  0.0599\n",
            "     10        \u001b[36m1.4023\u001b[0m  0.0620\n",
            "     11        \u001b[36m1.2970\u001b[0m  0.0581\n",
            "     12        \u001b[36m1.1976\u001b[0m  0.0666\n",
            "     13        \u001b[36m1.1053\u001b[0m  0.0684\n",
            "     14        \u001b[36m1.0215\u001b[0m  0.0548\n",
            "     15        \u001b[36m0.9474\u001b[0m  0.0575\n",
            "     16        \u001b[36m0.8837\u001b[0m  0.0671\n",
            "     17        \u001b[36m0.8305\u001b[0m  0.0661\n",
            "     18        \u001b[36m0.7875\u001b[0m  0.0608\n",
            "     19        \u001b[36m0.7537\u001b[0m  0.0650\n",
            "     20        \u001b[36m0.7280\u001b[0m  0.0597\n",
            "     21        \u001b[36m0.7088\u001b[0m  0.0606\n",
            "     22        \u001b[36m0.6948\u001b[0m  0.0592\n",
            "     23        \u001b[36m0.6847\u001b[0m  0.0610\n",
            "     24        \u001b[36m0.6776\u001b[0m  0.0578\n",
            "     25        \u001b[36m0.6726\u001b[0m  0.0592\n",
            "     26        \u001b[36m0.6691\u001b[0m  0.0591\n",
            "     27        \u001b[36m0.6667\u001b[0m  0.0722\n",
            "     28        \u001b[36m0.6650\u001b[0m  0.0657\n",
            "     29        \u001b[36m0.6639\u001b[0m  0.0618\n",
            "     30        \u001b[36m0.6631\u001b[0m  0.0578\n",
            "     31        \u001b[36m0.6625\u001b[0m  0.0593\n",
            "     32        \u001b[36m0.6621\u001b[0m  0.0598\n",
            "     33        \u001b[36m0.6619\u001b[0m  0.0570\n",
            "     34        \u001b[36m0.6617\u001b[0m  0.0612\n",
            "     35        \u001b[36m0.6615\u001b[0m  0.0690\n",
            "     36        \u001b[36m0.6614\u001b[0m  0.0609\n",
            "     37        \u001b[36m0.6614\u001b[0m  0.0599\n",
            "     38        \u001b[36m0.6613\u001b[0m  0.0614\n",
            "     39        \u001b[36m0.6613\u001b[0m  0.0573\n",
            "     40        \u001b[36m0.6612\u001b[0m  0.0589\n",
            "     41        \u001b[36m0.6612\u001b[0m  0.0591\n",
            "     42        \u001b[36m0.6612\u001b[0m  0.0590\n",
            "     43        \u001b[36m0.6612\u001b[0m  0.0578\n",
            "     44        \u001b[36m0.6612\u001b[0m  0.0684\n",
            "     45        \u001b[36m0.6612\u001b[0m  0.0596\n",
            "     46        \u001b[36m0.6612\u001b[0m  0.0695\n",
            "     47        \u001b[36m0.6612\u001b[0m  0.0605\n",
            "     48        \u001b[36m0.6612\u001b[0m  0.0596\n",
            "     49        \u001b[36m0.6612\u001b[0m  0.0576\n",
            "     50        \u001b[36m0.6612\u001b[0m  0.0599\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.4971\u001b[0m  0.0584\n",
            "      2        \u001b[36m2.3744\u001b[0m  0.0591\n",
            "      3        \u001b[36m2.2521\u001b[0m  0.0574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m2.1304\u001b[0m  0.0711\n",
            "      5        \u001b[36m2.0093\u001b[0m  0.0598\n",
            "      6        \u001b[36m1.8893\u001b[0m  0.0630\n",
            "      7        \u001b[36m1.7707\u001b[0m  0.0601\n",
            "      8        \u001b[36m1.6539\u001b[0m  0.0597\n",
            "      9        \u001b[36m1.5396\u001b[0m  0.0595\n",
            "     10        \u001b[36m1.4287\u001b[0m  0.0745\n",
            "     11        \u001b[36m1.3222\u001b[0m  0.0621\n",
            "     12        \u001b[36m1.2211\u001b[0m  0.0577\n",
            "     13        \u001b[36m1.1270\u001b[0m  0.0600\n",
            "     14        \u001b[36m1.0410\u001b[0m  0.0622\n",
            "     15        \u001b[36m0.9644\u001b[0m  0.0633\n",
            "     16        \u001b[36m0.8981\u001b[0m  0.0634\n",
            "     17        \u001b[36m0.8424\u001b[0m  0.0608\n",
            "     18        \u001b[36m0.7969\u001b[0m  0.0609\n",
            "     19        \u001b[36m0.7610\u001b[0m  0.0628\n",
            "     20        \u001b[36m0.7335\u001b[0m  0.0618\n",
            "     21        \u001b[36m0.7128\u001b[0m  0.0643\n",
            "     22        \u001b[36m0.6977\u001b[0m  0.0589\n",
            "     23        \u001b[36m0.6868\u001b[0m  0.0631\n",
            "     24        \u001b[36m0.6790\u001b[0m  0.0629\n",
            "     25        \u001b[36m0.6736\u001b[0m  0.0666\n",
            "     26        \u001b[36m0.6698\u001b[0m  0.0688\n",
            "     27        \u001b[36m0.6672\u001b[0m  0.0602\n",
            "     28        \u001b[36m0.6654\u001b[0m  0.0589\n",
            "     29        \u001b[36m0.6641\u001b[0m  0.0605\n",
            "     30        \u001b[36m0.6632\u001b[0m  0.0592\n",
            "     31        \u001b[36m0.6626\u001b[0m  0.0601\n",
            "     32        \u001b[36m0.6622\u001b[0m  0.0635\n",
            "     33        \u001b[36m0.6619\u001b[0m  0.0576\n",
            "     34        \u001b[36m0.6617\u001b[0m  0.0643\n",
            "     35        \u001b[36m0.6616\u001b[0m  0.0603\n",
            "     36        \u001b[36m0.6615\u001b[0m  0.0607\n",
            "     37        \u001b[36m0.6614\u001b[0m  0.0600\n",
            "     38        \u001b[36m0.6613\u001b[0m  0.0601\n",
            "     39        \u001b[36m0.6613\u001b[0m  0.0652\n",
            "     40        \u001b[36m0.6613\u001b[0m  0.0610\n",
            "     41        \u001b[36m0.6613\u001b[0m  0.0687\n",
            "     42        \u001b[36m0.6612\u001b[0m  0.0590\n",
            "     43        \u001b[36m0.6612\u001b[0m  0.0693\n",
            "     44        \u001b[36m0.6612\u001b[0m  0.0619\n",
            "     45        \u001b[36m0.6612\u001b[0m  0.0632\n",
            "     46        \u001b[36m0.6612\u001b[0m  0.0605\n",
            "     47        \u001b[36m0.6612\u001b[0m  0.0643\n",
            "     48        \u001b[36m0.6612\u001b[0m  0.0594\n",
            "     49        \u001b[36m0.6612\u001b[0m  0.0583\n",
            "     50        \u001b[36m0.6612\u001b[0m  0.0613\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.9800\u001b[0m  0.0564\n",
            "      2        \u001b[36m2.8566\u001b[0m  0.0617\n",
            "      3        \u001b[36m2.7332\u001b[0m  0.0598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m2.6101\u001b[0m  0.0656\n",
            "      5        \u001b[36m2.4871\u001b[0m  0.0618\n",
            "      6        \u001b[36m2.3645\u001b[0m  0.0601\n",
            "      7        \u001b[36m2.2422\u001b[0m  0.0767\n",
            "      8        \u001b[36m2.1205\u001b[0m  0.0601\n",
            "      9        \u001b[36m1.9995\u001b[0m  0.0610\n",
            "     10        \u001b[36m1.8796\u001b[0m  0.0588\n",
            "     11        \u001b[36m1.7611\u001b[0m  0.0599\n",
            "     12        \u001b[36m1.6445\u001b[0m  0.0639\n",
            "     13        \u001b[36m1.5305\u001b[0m  0.0615\n",
            "     14        \u001b[36m1.4199\u001b[0m  0.0600\n",
            "     15        \u001b[36m1.3137\u001b[0m  0.0569\n",
            "     16        \u001b[36m1.2132\u001b[0m  0.0569\n",
            "     17        \u001b[36m1.1196\u001b[0m  0.0612\n",
            "     18        \u001b[36m1.0344\u001b[0m  0.0583\n",
            "     19        \u001b[36m0.9586\u001b[0m  0.0589\n",
            "     20        \u001b[36m0.8931\u001b[0m  0.0562\n",
            "     21        \u001b[36m0.8382\u001b[0m  0.0573\n",
            "     22        \u001b[36m0.7936\u001b[0m  0.0636\n",
            "     23        \u001b[36m0.7584\u001b[0m  0.0678\n",
            "     24        \u001b[36m0.7314\u001b[0m  0.0590\n",
            "     25        \u001b[36m0.7112\u001b[0m  0.0571\n",
            "     26        \u001b[36m0.6965\u001b[0m  0.0582\n",
            "     27        \u001b[36m0.6859\u001b[0m  0.0580\n",
            "     28        \u001b[36m0.6783\u001b[0m  0.0624\n",
            "     29        \u001b[36m0.6731\u001b[0m  0.0623\n",
            "     30        \u001b[36m0.6694\u001b[0m  0.0584\n",
            "     31        \u001b[36m0.6668\u001b[0m  0.0588\n",
            "     32        \u001b[36m0.6651\u001b[0m  0.0599\n",
            "     33        \u001b[36m0.6638\u001b[0m  0.0617\n",
            "     34        \u001b[36m0.6630\u001b[0m  0.0594\n",
            "     35        \u001b[36m0.6624\u001b[0m  0.0625\n",
            "     36        \u001b[36m0.6620\u001b[0m  0.0639\n",
            "     37        \u001b[36m0.6617\u001b[0m  0.0638\n",
            "     38        \u001b[36m0.6615\u001b[0m  0.0607\n",
            "     39        \u001b[36m0.6614\u001b[0m  0.0679\n",
            "     40        \u001b[36m0.6613\u001b[0m  0.0632\n",
            "     41        \u001b[36m0.6612\u001b[0m  0.0641\n",
            "     42        \u001b[36m0.6611\u001b[0m  0.0583\n",
            "     43        \u001b[36m0.6611\u001b[0m  0.0621\n",
            "     44        \u001b[36m0.6611\u001b[0m  0.0602\n",
            "     45        \u001b[36m0.6610\u001b[0m  0.0598\n",
            "     46        \u001b[36m0.6610\u001b[0m  0.0592\n",
            "     47        \u001b[36m0.6610\u001b[0m  0.0629\n",
            "     48        \u001b[36m0.6610\u001b[0m  0.0573\n",
            "     49        \u001b[36m0.6610\u001b[0m  0.0574\n",
            "     50        \u001b[36m0.6610\u001b[0m  0.0588\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.9068\u001b[0m  0.0531\n",
            "      2        \u001b[36m3.7832\u001b[0m  0.0582\n",
            "      3        \u001b[36m3.6596\u001b[0m  0.0610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m3.5359\u001b[0m  0.0639\n",
            "      5        \u001b[36m3.4122\u001b[0m  0.0743\n",
            "      6        \u001b[36m3.2886\u001b[0m  0.0617\n",
            "      7        \u001b[36m3.1652\u001b[0m  0.0633\n",
            "      8        \u001b[36m3.0416\u001b[0m  0.0592\n",
            "      9        \u001b[36m2.9181\u001b[0m  0.0656\n",
            "     10        \u001b[36m2.7948\u001b[0m  0.0632\n",
            "     11        \u001b[36m2.6716\u001b[0m  0.0593\n",
            "     12        \u001b[36m2.5485\u001b[0m  0.0587\n",
            "     13        \u001b[36m2.4257\u001b[0m  0.0584\n",
            "     14        \u001b[36m2.3032\u001b[0m  0.0604\n",
            "     15        \u001b[36m2.1812\u001b[0m  0.0584\n",
            "     16        \u001b[36m2.0598\u001b[0m  0.0585\n",
            "     17        \u001b[36m1.9393\u001b[0m  0.0621\n",
            "     18        \u001b[36m1.8201\u001b[0m  0.0587\n",
            "     19        \u001b[36m1.7024\u001b[0m  0.0674\n",
            "     20        \u001b[36m1.5870\u001b[0m  0.0591\n",
            "     21        \u001b[36m1.4746\u001b[0m  0.0695\n",
            "     22        \u001b[36m1.3661\u001b[0m  0.0642\n",
            "     23        \u001b[36m1.2626\u001b[0m  0.0591\n",
            "     24        \u001b[36m1.1654\u001b[0m  0.0597\n",
            "     25        \u001b[36m1.0758\u001b[0m  0.0630\n",
            "     26        \u001b[36m0.9952\u001b[0m  0.0604\n",
            "     27        \u001b[36m0.9245\u001b[0m  0.0605\n",
            "     28        \u001b[36m0.8643\u001b[0m  0.0615\n",
            "     29        \u001b[36m0.8146\u001b[0m  0.0601\n",
            "     30        \u001b[36m0.7749\u001b[0m  0.0601\n",
            "     31        \u001b[36m0.7440\u001b[0m  0.0591\n",
            "     32        \u001b[36m0.7206\u001b[0m  0.0611\n",
            "     33        \u001b[36m0.7033\u001b[0m  0.0596\n",
            "     34        \u001b[36m0.6908\u001b[0m  0.0691\n",
            "     35        \u001b[36m0.6818\u001b[0m  0.0696\n",
            "     36        \u001b[36m0.6755\u001b[0m  0.0676\n",
            "     37        \u001b[36m0.6711\u001b[0m  0.0767\n",
            "     38        \u001b[36m0.6680\u001b[0m  0.0620\n",
            "     39        \u001b[36m0.6659\u001b[0m  0.0593\n",
            "     40        \u001b[36m0.6644\u001b[0m  0.0585\n",
            "     41        \u001b[36m0.6634\u001b[0m  0.0629\n",
            "     42        \u001b[36m0.6627\u001b[0m  0.0606\n",
            "     43        \u001b[36m0.6622\u001b[0m  0.0578\n",
            "     44        \u001b[36m0.6619\u001b[0m  0.0590\n",
            "     45        \u001b[36m0.6617\u001b[0m  0.0577\n",
            "     46        \u001b[36m0.6615\u001b[0m  0.0607\n",
            "     47        \u001b[36m0.6614\u001b[0m  0.0595\n",
            "     48        \u001b[36m0.6613\u001b[0m  0.0596\n",
            "     49        \u001b[36m0.6612\u001b[0m  0.0620\n",
            "     50        \u001b[36m0.6612\u001b[0m  0.0584\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.5113\u001b[0m  0.0537\n",
            "      2        \u001b[36m2.3886\u001b[0m  0.0678\n",
            "      3        \u001b[36m2.2662\u001b[0m  0.0673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m2.1444\u001b[0m  0.0690\n",
            "      5        \u001b[36m2.0233\u001b[0m  0.0600\n",
            "      6        \u001b[36m1.9031\u001b[0m  0.0611\n",
            "      7        \u001b[36m1.7843\u001b[0m  0.0595\n",
            "      8        \u001b[36m1.6673\u001b[0m  0.0583\n",
            "      9        \u001b[36m1.5527\u001b[0m  0.0563\n",
            "     10        \u001b[36m1.4413\u001b[0m  0.0572\n",
            "     11        \u001b[36m1.3342\u001b[0m  0.0606\n",
            "     12        \u001b[36m1.2325\u001b[0m  0.0593\n",
            "     13        \u001b[36m1.1374\u001b[0m  0.0622\n",
            "     14        \u001b[36m1.0505\u001b[0m  0.0583\n",
            "     15        \u001b[36m0.9727\u001b[0m  0.0584\n",
            "     16        \u001b[36m0.9052\u001b[0m  0.0634\n",
            "     17        \u001b[36m0.8482\u001b[0m  0.0582\n",
            "     18        \u001b[36m0.8016\u001b[0m  0.0625\n",
            "     19        \u001b[36m0.7647\u001b[0m  0.0665\n",
            "     20        \u001b[36m0.7362\u001b[0m  0.0619\n",
            "     21        \u001b[36m0.7148\u001b[0m  0.0693\n",
            "     22        \u001b[36m0.6991\u001b[0m  0.0593\n",
            "     23        \u001b[36m0.6877\u001b[0m  0.0572\n",
            "     24        \u001b[36m0.6797\u001b[0m  0.0616\n",
            "     25        \u001b[36m0.6740\u001b[0m  0.0573\n",
            "     26        \u001b[36m0.6700\u001b[0m  0.0585\n",
            "     27        \u001b[36m0.6673\u001b[0m  0.0570\n",
            "     28        \u001b[36m0.6654\u001b[0m  0.0569\n",
            "     29        \u001b[36m0.6641\u001b[0m  0.0595\n",
            "     30        \u001b[36m0.6632\u001b[0m  0.0647\n",
            "     31        \u001b[36m0.6626\u001b[0m  0.0611\n",
            "     32        \u001b[36m0.6621\u001b[0m  0.0620\n",
            "     33        \u001b[36m0.6618\u001b[0m  0.0596\n",
            "     34        \u001b[36m0.6616\u001b[0m  0.0584\n",
            "     35        \u001b[36m0.6614\u001b[0m  0.0688\n",
            "     36        \u001b[36m0.6613\u001b[0m  0.0565\n",
            "     37        \u001b[36m0.6613\u001b[0m  0.0600\n",
            "     38        \u001b[36m0.6612\u001b[0m  0.0623\n",
            "     39        \u001b[36m0.6612\u001b[0m  0.0631\n",
            "     40        \u001b[36m0.6611\u001b[0m  0.0610\n",
            "     41        \u001b[36m0.6611\u001b[0m  0.0585\n",
            "     42        \u001b[36m0.6611\u001b[0m  0.0624\n",
            "     43        \u001b[36m0.6611\u001b[0m  0.0647\n",
            "     44        \u001b[36m0.6611\u001b[0m  0.0619\n",
            "     45        \u001b[36m0.6610\u001b[0m  0.0646\n",
            "     46        \u001b[36m0.6610\u001b[0m  0.0589\n",
            "     47        \u001b[36m0.6610\u001b[0m  0.0601\n",
            "     48        \u001b[36m0.6610\u001b[0m  0.0588\n",
            "     49        \u001b[36m0.6610\u001b[0m  0.0657\n",
            "     50        \u001b[36m0.6610\u001b[0m  0.0635\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.5386\u001b[0m  0.0611\n",
            "      2        \u001b[36m3.4150\u001b[0m  0.0595\n",
            "      3        \u001b[36m3.2913\u001b[0m  0.0690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m3.1679\u001b[0m  0.0663\n",
            "      5        \u001b[36m3.0443\u001b[0m  0.0580\n",
            "      6        \u001b[36m2.9209\u001b[0m  0.0599\n",
            "      7        \u001b[36m2.7975\u001b[0m  0.0585\n",
            "      8        \u001b[36m2.6743\u001b[0m  0.0589\n",
            "      9        \u001b[36m2.5512\u001b[0m  0.0584\n",
            "     10        \u001b[36m2.4284\u001b[0m  0.0602\n",
            "     11        \u001b[36m2.3059\u001b[0m  0.0595\n",
            "     12        \u001b[36m2.1839\u001b[0m  0.0577\n",
            "     13        \u001b[36m2.0625\u001b[0m  0.0697\n",
            "     14        \u001b[36m1.9420\u001b[0m  0.0616\n",
            "     15        \u001b[36m1.8227\u001b[0m  0.0592\n",
            "     16        \u001b[36m1.7051\u001b[0m  0.0627\n",
            "     17        \u001b[36m1.5896\u001b[0m  0.0658\n",
            "     18        \u001b[36m1.4771\u001b[0m  0.0591\n",
            "     19        \u001b[36m1.3685\u001b[0m  0.0656\n",
            "     20        \u001b[36m1.2649\u001b[0m  0.0593\n",
            "     21        \u001b[36m1.1676\u001b[0m  0.0578\n",
            "     22        \u001b[36m1.0779\u001b[0m  0.0582\n",
            "     23        \u001b[36m0.9971\u001b[0m  0.0687\n",
            "     24        \u001b[36m0.9262\u001b[0m  0.0581\n",
            "     25        \u001b[36m0.8658\u001b[0m  0.0607\n",
            "     26        \u001b[36m0.8159\u001b[0m  0.0596\n",
            "     27        \u001b[36m0.7760\u001b[0m  0.0609\n",
            "     28        \u001b[36m0.7449\u001b[0m  0.0639\n",
            "     29        \u001b[36m0.7213\u001b[0m  0.0590\n",
            "     30        \u001b[36m0.7039\u001b[0m  0.0614\n",
            "     31        \u001b[36m0.6913\u001b[0m  0.0594\n",
            "     32        \u001b[36m0.6822\u001b[0m  0.0637\n",
            "     33        \u001b[36m0.6758\u001b[0m  0.0653\n",
            "     34        \u001b[36m0.6714\u001b[0m  0.0595\n",
            "     35        \u001b[36m0.6683\u001b[0m  0.0610\n",
            "     36        \u001b[36m0.6661\u001b[0m  0.0608\n",
            "     37        \u001b[36m0.6646\u001b[0m  0.0611\n",
            "     38        \u001b[36m0.6636\u001b[0m  0.0590\n",
            "     39        \u001b[36m0.6628\u001b[0m  0.0628\n",
            "     40        \u001b[36m0.6623\u001b[0m  0.0598\n",
            "     41        \u001b[36m0.6620\u001b[0m  0.0666\n",
            "     42        \u001b[36m0.6617\u001b[0m  0.0594\n",
            "     43        \u001b[36m0.6616\u001b[0m  0.0579\n",
            "     44        \u001b[36m0.6614\u001b[0m  0.0629\n",
            "     45        \u001b[36m0.6613\u001b[0m  0.0596\n",
            "     46        \u001b[36m0.6613\u001b[0m  0.0583\n",
            "     47        \u001b[36m0.6612\u001b[0m  0.0657\n",
            "     48        \u001b[36m0.6612\u001b[0m  0.0574\n",
            "     49        \u001b[36m0.6612\u001b[0m  0.0629\n",
            "     50        \u001b[36m0.6611\u001b[0m  0.0623\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.7128\u001b[0m  0.0581\n",
            "      2        \u001b[36m3.5892\u001b[0m  0.0579\n",
            "      3        \u001b[36m3.4655\u001b[0m  0.0540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m3.3419\u001b[0m  0.0666\n",
            "      5        \u001b[36m3.2184\u001b[0m  0.0571\n",
            "      6        \u001b[36m3.0948\u001b[0m  0.0591\n",
            "      7        \u001b[36m2.9714\u001b[0m  0.0592\n",
            "      8        \u001b[36m2.8480\u001b[0m  0.0593\n",
            "      9        \u001b[36m2.7247\u001b[0m  0.0554\n",
            "     10        \u001b[36m2.6015\u001b[0m  0.0615\n",
            "     11        \u001b[36m2.4786\u001b[0m  0.0655\n",
            "     12        \u001b[36m2.3560\u001b[0m  0.0582\n",
            "     13        \u001b[36m2.2338\u001b[0m  0.0595\n",
            "     14        \u001b[36m2.1121\u001b[0m  0.0614\n",
            "     15        \u001b[36m1.9912\u001b[0m  0.0647\n",
            "     16        \u001b[36m1.8714\u001b[0m  0.0616\n",
            "     17        \u001b[36m1.7530\u001b[0m  0.0592\n",
            "     18        \u001b[36m1.6366\u001b[0m  0.0602\n",
            "     19        \u001b[36m1.5228\u001b[0m  0.0594\n",
            "     20        \u001b[36m1.4125\u001b[0m  0.0625\n",
            "     21        \u001b[36m1.3067\u001b[0m  0.0634\n",
            "     22        \u001b[36m1.2067\u001b[0m  0.0577\n",
            "     23        \u001b[36m1.1137\u001b[0m  0.0598\n",
            "     24        \u001b[36m1.0292\u001b[0m  0.0571\n",
            "     25        \u001b[36m0.9542\u001b[0m  0.0718\n",
            "     26        \u001b[36m0.8895\u001b[0m  0.0572\n",
            "     27        \u001b[36m0.8354\u001b[0m  0.0570\n",
            "     28        \u001b[36m0.7915\u001b[0m  0.0580\n",
            "     29        \u001b[36m0.7569\u001b[0m  0.0584\n",
            "     30        \u001b[36m0.7304\u001b[0m  0.0564\n",
            "     31        \u001b[36m0.7107\u001b[0m  0.0707\n",
            "     32        \u001b[36m0.6962\u001b[0m  0.0614\n",
            "     33        \u001b[36m0.6858\u001b[0m  0.0606\n",
            "     34        \u001b[36m0.6784\u001b[0m  0.0588\n",
            "     35        \u001b[36m0.6732\u001b[0m  0.0583\n",
            "     36        \u001b[36m0.6696\u001b[0m  0.0629\n",
            "     37        \u001b[36m0.6670\u001b[0m  0.0599\n",
            "     38        \u001b[36m0.6653\u001b[0m  0.0578\n",
            "     39        \u001b[36m0.6640\u001b[0m  0.0604\n",
            "     40        \u001b[36m0.6632\u001b[0m  0.0582\n",
            "     41        \u001b[36m0.6626\u001b[0m  0.0656\n",
            "     42        \u001b[36m0.6622\u001b[0m  0.0597\n",
            "     43        \u001b[36m0.6619\u001b[0m  0.0588\n",
            "     44        \u001b[36m0.6617\u001b[0m  0.0726\n",
            "     45        \u001b[36m0.6615\u001b[0m  0.0653\n",
            "     46        \u001b[36m0.6614\u001b[0m  0.0598\n",
            "     47        \u001b[36m0.6613\u001b[0m  0.0676\n",
            "     48        \u001b[36m0.6613\u001b[0m  0.0621\n",
            "     49        \u001b[36m0.6612\u001b[0m  0.0618\n",
            "     50        \u001b[36m0.6612\u001b[0m  0.0592\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2343\u001b[0m  0.0585\n",
            "      2        \u001b[36m2.1153\u001b[0m  0.0618\n",
            "      3        \u001b[36m1.9971\u001b[0m  0.0632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.8799\u001b[0m  0.0784\n",
            "      5        \u001b[36m1.7641\u001b[0m  0.0590\n",
            "      6        \u001b[36m1.6501\u001b[0m  0.0584\n",
            "      7        \u001b[36m1.5385\u001b[0m  0.0593\n",
            "      8        \u001b[36m1.4302\u001b[0m  0.0674\n",
            "      9        \u001b[36m1.3260\u001b[0m  0.0627\n",
            "     10        \u001b[36m1.2271\u001b[0m  0.0616\n",
            "     11        \u001b[36m1.1348\u001b[0m  0.0596\n",
            "     12        \u001b[36m1.0502\u001b[0m  0.0642\n",
            "     13        \u001b[36m0.9745\u001b[0m  0.0627\n",
            "     14        \u001b[36m0.9086\u001b[0m  0.0612\n",
            "     15        \u001b[36m0.8527\u001b[0m  0.0611\n",
            "     16        \u001b[36m0.8067\u001b[0m  0.0578\n",
            "     17        \u001b[36m0.7699\u001b[0m  0.0593\n",
            "     18        \u001b[36m0.7413\u001b[0m  0.0590\n",
            "     19        \u001b[36m0.7196\u001b[0m  0.0611\n",
            "     20        \u001b[36m0.7034\u001b[0m  0.0625\n",
            "     21        \u001b[36m0.6915\u001b[0m  0.0621\n",
            "     22        \u001b[36m0.6829\u001b[0m  0.0668\n",
            "     23        \u001b[36m0.6767\u001b[0m  0.0604\n",
            "     24        \u001b[36m0.6723\u001b[0m  0.0621\n",
            "     25        \u001b[36m0.6692\u001b[0m  0.0593\n",
            "     26        \u001b[36m0.6669\u001b[0m  0.0616\n",
            "     27        \u001b[36m0.6653\u001b[0m  0.0593\n",
            "     28        \u001b[36m0.6642\u001b[0m  0.0619\n",
            "     29        \u001b[36m0.6634\u001b[0m  0.0724\n",
            "     30        \u001b[36m0.6628\u001b[0m  0.0630\n",
            "     31        \u001b[36m0.6623\u001b[0m  0.0618\n",
            "     32        \u001b[36m0.6620\u001b[0m  0.0585\n",
            "     33        \u001b[36m0.6618\u001b[0m  0.0598\n",
            "     34        \u001b[36m0.6616\u001b[0m  0.0604\n",
            "     35        \u001b[36m0.6614\u001b[0m  0.0599\n",
            "     36        \u001b[36m0.6613\u001b[0m  0.0599\n",
            "     37        \u001b[36m0.6613\u001b[0m  0.0642\n",
            "     38        \u001b[36m0.6612\u001b[0m  0.0603\n",
            "     39        \u001b[36m0.6611\u001b[0m  0.0598\n",
            "     40        \u001b[36m0.6611\u001b[0m  0.0634\n",
            "     41        \u001b[36m0.6611\u001b[0m  0.0677\n",
            "     42        \u001b[36m0.6610\u001b[0m  0.0614\n",
            "     43        \u001b[36m0.6610\u001b[0m  0.0579\n",
            "     44        \u001b[36m0.6610\u001b[0m  0.0621\n",
            "     45        \u001b[36m0.6610\u001b[0m  0.0671\n",
            "     46        \u001b[36m0.6610\u001b[0m  0.0609\n",
            "     47        \u001b[36m0.6610\u001b[0m  0.0594\n",
            "     48        \u001b[36m0.6610\u001b[0m  0.0651\n",
            "     49        \u001b[36m0.6610\u001b[0m  0.0622\n",
            "     50        \u001b[36m0.6610\u001b[0m  0.0586\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9067\u001b[0m  0.0681\n",
            "      2        \u001b[36m0.8380\u001b[0m  0.0790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.7795\u001b[0m  0.0815\n",
            "      4        \u001b[36m0.7467\u001b[0m  0.0784\n",
            "      5        \u001b[36m0.7239\u001b[0m  0.0738\n",
            "      6        \u001b[36m0.7071\u001b[0m  0.0812\n",
            "      7        \u001b[36m0.6948\u001b[0m  0.0717\n",
            "      8        \u001b[36m0.6879\u001b[0m  0.0759\n",
            "      9        \u001b[36m0.6795\u001b[0m  0.0785\n",
            "     10        \u001b[36m0.6755\u001b[0m  0.0860\n",
            "     11        \u001b[36m0.6716\u001b[0m  0.0733\n",
            "     12        \u001b[36m0.6653\u001b[0m  0.0763\n",
            "     13        \u001b[36m0.6631\u001b[0m  0.0819\n",
            "     14        \u001b[36m0.6612\u001b[0m  0.0733\n",
            "     15        \u001b[36m0.6594\u001b[0m  0.0781\n",
            "     16        \u001b[36m0.6576\u001b[0m  0.0765\n",
            "     17        \u001b[36m0.6560\u001b[0m  0.0759\n",
            "     18        \u001b[36m0.6545\u001b[0m  0.0756\n",
            "     19        \u001b[36m0.6531\u001b[0m  0.0743\n",
            "     20        \u001b[36m0.6512\u001b[0m  0.0740\n",
            "     21        \u001b[36m0.6498\u001b[0m  0.0809\n",
            "     22        \u001b[36m0.6485\u001b[0m  0.0780\n",
            "     23        \u001b[36m0.6474\u001b[0m  0.0766\n",
            "     24        \u001b[36m0.6458\u001b[0m  0.0729\n",
            "     25        \u001b[36m0.6448\u001b[0m  0.0743\n",
            "     26        \u001b[36m0.6431\u001b[0m  0.0785\n",
            "     27        \u001b[36m0.6424\u001b[0m  0.0733\n",
            "     28        \u001b[36m0.6420\u001b[0m  0.0757\n",
            "     29        \u001b[36m0.6401\u001b[0m  0.0725\n",
            "     30        0.6405  0.0789\n",
            "     31        \u001b[36m0.6392\u001b[0m  0.0807\n",
            "     32        \u001b[36m0.6352\u001b[0m  0.0745\n",
            "     33        0.6375  0.0769\n",
            "     34        0.6360  0.0775\n",
            "     35        0.6399  0.0819\n",
            "     36        0.6390  0.0788\n",
            "     37        0.6379  0.0727\n",
            "     38        \u001b[36m0.6215\u001b[0m  0.0759\n",
            "     39        \u001b[36m0.6213\u001b[0m  0.0776\n",
            "     40        0.6239  0.0769\n",
            "     41        0.6283  0.0742\n",
            "     42        0.6262  0.0805\n",
            "     43        0.6246  0.0734\n",
            "     44        0.6234  0.0752\n",
            "     45        0.6223  0.0729\n",
            "     46        \u001b[36m0.6213\u001b[0m  0.0766\n",
            "     47        \u001b[36m0.6204\u001b[0m  0.0813\n",
            "     48        \u001b[36m0.6196\u001b[0m  0.0799\n",
            "     49        \u001b[36m0.6189\u001b[0m  0.0752\n",
            "     50        \u001b[36m0.6179\u001b[0m  0.0738\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6871\u001b[0m  0.0697\n",
            "      2        \u001b[36m0.6495\u001b[0m  0.0726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.6366\u001b[0m  0.0852\n",
            "      4        \u001b[36m0.6256\u001b[0m  0.0761\n",
            "      5        \u001b[36m0.6220\u001b[0m  0.0834\n",
            "      6        \u001b[36m0.6207\u001b[0m  0.0733\n",
            "      7        \u001b[36m0.6197\u001b[0m  0.0735\n",
            "      8        \u001b[36m0.6116\u001b[0m  0.0764\n",
            "      9        \u001b[36m0.6030\u001b[0m  0.0762\n",
            "     10        \u001b[36m0.6007\u001b[0m  0.0783\n",
            "     11        \u001b[36m0.5981\u001b[0m  0.0773\n",
            "     12        \u001b[36m0.5955\u001b[0m  0.0714\n",
            "     13        \u001b[36m0.5922\u001b[0m  0.0737\n",
            "     14        0.5924  0.0751\n",
            "     15        \u001b[36m0.5910\u001b[0m  0.0800\n",
            "     16        \u001b[36m0.5898\u001b[0m  0.0766\n",
            "     17        \u001b[36m0.5884\u001b[0m  0.0752\n",
            "     18        \u001b[36m0.5871\u001b[0m  0.0729\n",
            "     19        \u001b[36m0.5812\u001b[0m  0.0776\n",
            "     20        0.6410  0.0742\n",
            "     21        0.5909  0.0768\n",
            "     22        0.5907  0.0755\n",
            "     23        \u001b[36m0.5805\u001b[0m  0.0795\n",
            "     24        0.5811  0.0739\n",
            "     25        \u001b[36m0.5775\u001b[0m  0.0750\n",
            "     26        0.5782  0.0728\n",
            "     27        \u001b[36m0.5753\u001b[0m  0.0729\n",
            "     28        0.5956  0.0724\n",
            "     29        0.6101  0.0797\n",
            "     30        0.6094  0.0729\n",
            "     31        0.5898  0.0782\n",
            "     32        0.5892  0.0744\n",
            "     33        0.5871  0.0765\n",
            "     34        0.5848  0.0743\n",
            "     35        0.5829  0.0738\n",
            "     36        0.5820  0.0715\n",
            "     37        0.5818  0.0845\n",
            "     38        0.5803  0.0723\n",
            "     39        0.5781  0.0728\n",
            "     40        0.5775  0.0778\n",
            "     41        0.5769  0.0731\n",
            "     42        0.5764  0.0795\n",
            "     43        0.5759  0.0766\n",
            "     44        0.5754  0.0717\n",
            "     45        \u001b[36m0.5749\u001b[0m  0.0756\n",
            "     46        \u001b[36m0.5745\u001b[0m  0.0879\n",
            "     47        \u001b[36m0.5741\u001b[0m  0.0775\n",
            "     48        \u001b[36m0.5737\u001b[0m  0.0731\n",
            "     49        \u001b[36m0.5733\u001b[0m  0.0769\n",
            "     50        \u001b[36m0.5729\u001b[0m  0.0802\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.1251\u001b[0m  0.0698\n",
            "      2        \u001b[36m0.9461\u001b[0m  0.0721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.8118\u001b[0m  0.0855\n",
            "      4        \u001b[36m0.7190\u001b[0m  0.0716\n",
            "      5        \u001b[36m0.6569\u001b[0m  0.0728\n",
            "      6        \u001b[36m0.6201\u001b[0m  0.0725\n",
            "      7        \u001b[36m0.6045\u001b[0m  0.0755\n",
            "      8        \u001b[36m0.5885\u001b[0m  0.0782\n",
            "      9        \u001b[36m0.5806\u001b[0m  0.0759\n",
            "     10        \u001b[36m0.5745\u001b[0m  0.0773\n",
            "     11        \u001b[36m0.5666\u001b[0m  0.0728\n",
            "     12        \u001b[36m0.5614\u001b[0m  0.0716\n",
            "     13        \u001b[36m0.5568\u001b[0m  0.0849\n",
            "     14        \u001b[36m0.5543\u001b[0m  0.0708\n",
            "     15        \u001b[36m0.5527\u001b[0m  0.0772\n",
            "     16        \u001b[36m0.5504\u001b[0m  0.0743\n",
            "     17        0.5504  0.0723\n",
            "     18        \u001b[36m0.5492\u001b[0m  0.0725\n",
            "     19        \u001b[36m0.5481\u001b[0m  0.0819\n",
            "     20        0.5503  0.0825\n",
            "     21        0.5499  0.0737\n",
            "     22        0.5500  0.0770\n",
            "     23        0.5489  0.0777\n",
            "     24        \u001b[36m0.5479\u001b[0m  0.0736\n",
            "     25        \u001b[36m0.5471\u001b[0m  0.0732\n",
            "     26        \u001b[36m0.5414\u001b[0m  0.0794\n",
            "     27        0.5458  0.0740\n",
            "     28        \u001b[36m0.5402\u001b[0m  0.0765\n",
            "     29        \u001b[36m0.5395\u001b[0m  0.0721\n",
            "     30        \u001b[36m0.5394\u001b[0m  0.0756\n",
            "     31        \u001b[36m0.5393\u001b[0m  0.0776\n",
            "     32        \u001b[36m0.5388\u001b[0m  0.0736\n",
            "     33        \u001b[36m0.5383\u001b[0m  0.0749\n",
            "     34        \u001b[36m0.5378\u001b[0m  0.0721\n",
            "     35        \u001b[36m0.5374\u001b[0m  0.0741\n",
            "     36        \u001b[36m0.5370\u001b[0m  0.0713\n",
            "     37        \u001b[36m0.5366\u001b[0m  0.0728\n",
            "     38        \u001b[36m0.5363\u001b[0m  0.0752\n",
            "     39        \u001b[36m0.5359\u001b[0m  0.0776\n",
            "     40        \u001b[36m0.5356\u001b[0m  0.0717\n",
            "     41        \u001b[36m0.5352\u001b[0m  0.0747\n",
            "     42        \u001b[36m0.5350\u001b[0m  0.0776\n",
            "     43        \u001b[36m0.5346\u001b[0m  0.0775\n",
            "     44        0.5348  0.0712\n",
            "     45        0.5347  0.0736\n",
            "     46        \u001b[36m0.5344\u001b[0m  0.0737\n",
            "     47        \u001b[36m0.5340\u001b[0m  0.0786\n",
            "     48        \u001b[36m0.5337\u001b[0m  0.0802\n",
            "     49        \u001b[36m0.5334\u001b[0m  0.0773\n",
            "     50        \u001b[36m0.5331\u001b[0m  0.0740\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4760\u001b[0m  0.0678\n",
            "      2        \u001b[36m1.3261\u001b[0m  0.0829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.2581\u001b[0m  0.0835\n",
            "      4        \u001b[36m1.1977\u001b[0m  0.0771\n",
            "      5        \u001b[36m1.1361\u001b[0m  0.0778\n",
            "      6        \u001b[36m1.0902\u001b[0m  0.0737\n",
            "      7        \u001b[36m1.0541\u001b[0m  0.0780\n",
            "      8        \u001b[36m1.0304\u001b[0m  0.0755\n",
            "      9        \u001b[36m1.0029\u001b[0m  0.0738\n",
            "     10        \u001b[36m0.9769\u001b[0m  0.0773\n",
            "     11        \u001b[36m0.9546\u001b[0m  0.0742\n",
            "     12        \u001b[36m0.9375\u001b[0m  0.0753\n",
            "     13        \u001b[36m0.9217\u001b[0m  0.0730\n",
            "     14        \u001b[36m0.9069\u001b[0m  0.0751\n",
            "     15        \u001b[36m0.8932\u001b[0m  0.0855\n",
            "     16        \u001b[36m0.8815\u001b[0m  0.0757\n",
            "     17        \u001b[36m0.8655\u001b[0m  0.0722\n",
            "     18        \u001b[36m0.8543\u001b[0m  0.0746\n",
            "     19        \u001b[36m0.8451\u001b[0m  0.0802\n",
            "     20        \u001b[36m0.8363\u001b[0m  0.0731\n",
            "     21        \u001b[36m0.8280\u001b[0m  0.0781\n",
            "     22        \u001b[36m0.8201\u001b[0m  0.0749\n",
            "     23        \u001b[36m0.8125\u001b[0m  0.0836\n",
            "     24        \u001b[36m0.7961\u001b[0m  0.0716\n",
            "     25        \u001b[36m0.7896\u001b[0m  0.0739\n",
            "     26        \u001b[36m0.7832\u001b[0m  0.0732\n",
            "     27        \u001b[36m0.7769\u001b[0m  0.0749\n",
            "     28        \u001b[36m0.7707\u001b[0m  0.0792\n",
            "     29        \u001b[36m0.7647\u001b[0m  0.0727\n",
            "     30        \u001b[36m0.7586\u001b[0m  0.0764\n",
            "     31        \u001b[36m0.7527\u001b[0m  0.0840\n",
            "     32        \u001b[36m0.7467\u001b[0m  0.0739\n",
            "     33        \u001b[36m0.7211\u001b[0m  0.0787\n",
            "     34        \u001b[36m0.7157\u001b[0m  0.0728\n",
            "     35        \u001b[36m0.7111\u001b[0m  0.0782\n",
            "     36        \u001b[36m0.7065\u001b[0m  0.0761\n",
            "     37        \u001b[36m0.7019\u001b[0m  0.0723\n",
            "     38        \u001b[36m0.6973\u001b[0m  0.0715\n",
            "     39        \u001b[36m0.6927\u001b[0m  0.0775\n",
            "     40        \u001b[36m0.6877\u001b[0m  0.0744\n",
            "     41        \u001b[36m0.6832\u001b[0m  0.0838\n",
            "     42        \u001b[36m0.6787\u001b[0m  0.0748\n",
            "     43        \u001b[36m0.6744\u001b[0m  0.0743\n",
            "     44        \u001b[36m0.6703\u001b[0m  0.0735\n",
            "     45        \u001b[36m0.6666\u001b[0m  0.0802\n",
            "     46        \u001b[36m0.6630\u001b[0m  0.0791\n",
            "     47        \u001b[36m0.6597\u001b[0m  0.0748\n",
            "     48        \u001b[36m0.6567\u001b[0m  0.0759\n",
            "     49        \u001b[36m0.6539\u001b[0m  0.0850\n",
            "     50        \u001b[36m0.6513\u001b[0m  0.0750\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8995\u001b[0m  0.0713\n",
            "      2        \u001b[36m0.8122\u001b[0m  0.0778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.7557\u001b[0m  0.0844\n",
            "      4        \u001b[36m0.7360\u001b[0m  0.0764\n",
            "      5        \u001b[36m0.7181\u001b[0m  0.0757\n",
            "      6        \u001b[36m0.7005\u001b[0m  0.0721\n",
            "      7        \u001b[36m0.6887\u001b[0m  0.0788\n",
            "      8        \u001b[36m0.6813\u001b[0m  0.0773\n",
            "      9        \u001b[36m0.6726\u001b[0m  0.0779\n",
            "     10        \u001b[36m0.6681\u001b[0m  0.0732\n",
            "     11        \u001b[36m0.6620\u001b[0m  0.0754\n",
            "     12        0.6623  0.0717\n",
            "     13        \u001b[36m0.6568\u001b[0m  0.0751\n",
            "     14        \u001b[36m0.6512\u001b[0m  0.0769\n",
            "     15        \u001b[36m0.6466\u001b[0m  0.0795\n",
            "     16        \u001b[36m0.6410\u001b[0m  0.0813\n",
            "     17        \u001b[36m0.6369\u001b[0m  0.0741\n",
            "     18        \u001b[36m0.6339\u001b[0m  0.0719\n",
            "     19        \u001b[36m0.6326\u001b[0m  0.0872\n",
            "     20        \u001b[36m0.6303\u001b[0m  0.0731\n",
            "     21        \u001b[36m0.6285\u001b[0m  0.0775\n",
            "     22        \u001b[36m0.6269\u001b[0m  0.0738\n",
            "     23        \u001b[36m0.6253\u001b[0m  0.0784\n",
            "     24        \u001b[36m0.6234\u001b[0m  0.0780\n",
            "     25        \u001b[36m0.6221\u001b[0m  0.0745\n",
            "     26        \u001b[36m0.6210\u001b[0m  0.0718\n",
            "     27        \u001b[36m0.6200\u001b[0m  0.0740\n",
            "     28        \u001b[36m0.6190\u001b[0m  0.0717\n",
            "     29        \u001b[36m0.6181\u001b[0m  0.0809\n",
            "     30        \u001b[36m0.6173\u001b[0m  0.0740\n",
            "     31        \u001b[36m0.6165\u001b[0m  0.0777\n",
            "     32        \u001b[36m0.6158\u001b[0m  0.0839\n",
            "     33        \u001b[36m0.6148\u001b[0m  0.0841\n",
            "     34        \u001b[36m0.6137\u001b[0m  0.0817\n",
            "     35        \u001b[36m0.6132\u001b[0m  0.0769\n",
            "     36        0.6132  0.0781\n",
            "     37        \u001b[36m0.6127\u001b[0m  0.0769\n",
            "     38        0.6143  0.0827\n",
            "     39        0.6209  0.0756\n",
            "     40        0.6240  0.0779\n",
            "     41        0.6279  0.0784\n",
            "     42        0.6269  0.0823\n",
            "     43        0.6254  0.0738\n",
            "     44        0.6252  0.0734\n",
            "     45        0.6249  0.0858\n",
            "     46        0.6246  0.0739\n",
            "     47        0.6243  0.0779\n",
            "     48        0.6249  0.0766\n",
            "     49        0.6248  0.0781\n",
            "     50        0.6247  0.0744\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9162\u001b[0m  0.0730\n",
            "      2        \u001b[36m0.7997\u001b[0m  0.0743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.7430\u001b[0m  0.0826\n",
            "      4        \u001b[36m0.7159\u001b[0m  0.0802\n",
            "      5        \u001b[36m0.7016\u001b[0m  0.0754\n",
            "      6        \u001b[36m0.6850\u001b[0m  0.0778\n",
            "      7        \u001b[36m0.6721\u001b[0m  0.0775\n",
            "      8        \u001b[36m0.6674\u001b[0m  0.0702\n",
            "      9        \u001b[36m0.6616\u001b[0m  0.0730\n",
            "     10        \u001b[36m0.6552\u001b[0m  0.0806\n",
            "     11        \u001b[36m0.6480\u001b[0m  0.0763\n",
            "     12        \u001b[36m0.6418\u001b[0m  0.0737\n",
            "     13        \u001b[36m0.6395\u001b[0m  0.0733\n",
            "     14        \u001b[36m0.6332\u001b[0m  0.0735\n",
            "     15        \u001b[36m0.6274\u001b[0m  0.0718\n",
            "     16        \u001b[36m0.6220\u001b[0m  0.0751\n",
            "     17        \u001b[36m0.6194\u001b[0m  0.0726\n",
            "     18        \u001b[36m0.6164\u001b[0m  0.0907\n",
            "     19        \u001b[36m0.6142\u001b[0m  0.0730\n",
            "     20        \u001b[36m0.6122\u001b[0m  0.0750\n",
            "     21        0.6133  0.0730\n",
            "     22        \u001b[36m0.6121\u001b[0m  0.0765\n",
            "     23        \u001b[36m0.6058\u001b[0m  0.0727\n",
            "     24        \u001b[36m0.5985\u001b[0m  0.0773\n",
            "     25        \u001b[36m0.5964\u001b[0m  0.0723\n",
            "     26        \u001b[36m0.5947\u001b[0m  0.0790\n",
            "     27        \u001b[36m0.5931\u001b[0m  0.0739\n",
            "     28        \u001b[36m0.5917\u001b[0m  0.0766\n",
            "     29        \u001b[36m0.5904\u001b[0m  0.0738\n",
            "     30        \u001b[36m0.5891\u001b[0m  0.0732\n",
            "     31        \u001b[36m0.5879\u001b[0m  0.0841\n",
            "     32        \u001b[36m0.5868\u001b[0m  0.0732\n",
            "     33        \u001b[36m0.5856\u001b[0m  0.0724\n",
            "     34        \u001b[36m0.5822\u001b[0m  0.0801\n",
            "     35        0.5867  0.0748\n",
            "     36        0.5891  0.0723\n",
            "     37        \u001b[36m0.5791\u001b[0m  0.0846\n",
            "     38        0.5805  0.0724\n",
            "     39        \u001b[36m0.5721\u001b[0m  0.0732\n",
            "     40        0.5778  0.0769\n",
            "     41        0.5799  0.0739\n",
            "     42        0.5790  0.0725\n",
            "     43        0.5812  0.0723\n",
            "     44        0.5834  0.0812\n",
            "     45        0.5839  0.0854\n",
            "     46        0.5829  0.0723\n",
            "     47        0.5823  0.0744\n",
            "     48        0.5814  0.0745\n",
            "     49        0.5803  0.0768\n",
            "     50        0.5798  0.0751\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7323\u001b[0m  0.0708\n",
            "      2        \u001b[36m0.7076\u001b[0m  0.0757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.6852\u001b[0m  0.0812\n",
            "      4        \u001b[36m0.6749\u001b[0m  0.0729\n",
            "      5        \u001b[36m0.6727\u001b[0m  0.0815\n",
            "      6        \u001b[36m0.6644\u001b[0m  0.0743\n",
            "      7        \u001b[36m0.6563\u001b[0m  0.0828\n",
            "      8        \u001b[36m0.6529\u001b[0m  0.0735\n",
            "      9        \u001b[36m0.6490\u001b[0m  0.0725\n",
            "     10        \u001b[36m0.6482\u001b[0m  0.0813\n",
            "     11        \u001b[36m0.6367\u001b[0m  0.0736\n",
            "     12        \u001b[36m0.6261\u001b[0m  0.0742\n",
            "     13        0.6266  0.0730\n",
            "     14        \u001b[36m0.6233\u001b[0m  0.0764\n",
            "     15        \u001b[36m0.6201\u001b[0m  0.0778\n",
            "     16        0.6207  0.0758\n",
            "     17        \u001b[36m0.6172\u001b[0m  0.0742\n",
            "     18        \u001b[36m0.6163\u001b[0m  0.0759\n",
            "     19        \u001b[36m0.6120\u001b[0m  0.0737\n",
            "     20        \u001b[36m0.6099\u001b[0m  0.0791\n",
            "     21        \u001b[36m0.6080\u001b[0m  0.0716\n",
            "     22        \u001b[36m0.6060\u001b[0m  0.0842\n",
            "     23        \u001b[36m0.6012\u001b[0m  0.0761\n",
            "     24        \u001b[36m0.5998\u001b[0m  0.0767\n",
            "     25        \u001b[36m0.5984\u001b[0m  0.0765\n",
            "     26        \u001b[36m0.5967\u001b[0m  0.0796\n",
            "     27        \u001b[36m0.5954\u001b[0m  0.0721\n",
            "     28        \u001b[36m0.5942\u001b[0m  0.0727\n",
            "     29        \u001b[36m0.5930\u001b[0m  0.0788\n",
            "     30        \u001b[36m0.5918\u001b[0m  0.0741\n",
            "     31        \u001b[36m0.5892\u001b[0m  0.0732\n",
            "     32        \u001b[36m0.5868\u001b[0m  0.0742\n",
            "     33        \u001b[36m0.5858\u001b[0m  0.0812\n",
            "     34        \u001b[36m0.5847\u001b[0m  0.0724\n",
            "     35        \u001b[36m0.5837\u001b[0m  0.0741\n",
            "     36        \u001b[36m0.5816\u001b[0m  0.0743\n",
            "     37        \u001b[36m0.5812\u001b[0m  0.0885\n",
            "     38        \u001b[36m0.5802\u001b[0m  0.0774\n",
            "     39        \u001b[36m0.5789\u001b[0m  0.0734\n",
            "     40        \u001b[36m0.5780\u001b[0m  0.0724\n",
            "     41        0.5785  0.0716\n",
            "     42        \u001b[36m0.5762\u001b[0m  0.0764\n",
            "     43        \u001b[36m0.5754\u001b[0m  0.0724\n",
            "     44        \u001b[36m0.5747\u001b[0m  0.0719\n",
            "     45        \u001b[36m0.5739\u001b[0m  0.0794\n",
            "     46        \u001b[36m0.5732\u001b[0m  0.0811\n",
            "     47        \u001b[36m0.5725\u001b[0m  0.0734\n",
            "     48        \u001b[36m0.5718\u001b[0m  0.0720\n",
            "     49        0.5747  0.0744\n",
            "     50        0.5740  0.0715\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7775\u001b[0m  0.0701\n",
            "      2        \u001b[36m0.7040\u001b[0m  0.0729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.6710\u001b[0m  0.0806\n",
            "      4        \u001b[36m0.6542\u001b[0m  0.0794\n",
            "      5        \u001b[36m0.6391\u001b[0m  0.0721\n",
            "      6        \u001b[36m0.6347\u001b[0m  0.0727\n",
            "      7        \u001b[36m0.6280\u001b[0m  0.0729\n",
            "      8        \u001b[36m0.6212\u001b[0m  0.0698\n",
            "      9        \u001b[36m0.6181\u001b[0m  0.0821\n",
            "     10        \u001b[36m0.6180\u001b[0m  0.0746\n",
            "     11        \u001b[36m0.6170\u001b[0m  0.0845\n",
            "     12        \u001b[36m0.6124\u001b[0m  0.0790\n",
            "     13        \u001b[36m0.6038\u001b[0m  0.0731\n",
            "     14        \u001b[36m0.6003\u001b[0m  0.0734\n",
            "     15        \u001b[36m0.5973\u001b[0m  0.0743\n",
            "     16        0.6060  0.0705\n",
            "     17        0.6035  0.0746\n",
            "     18        0.6017  0.0717\n",
            "     19        0.5995  0.0712\n",
            "     20        0.5979  0.0731\n",
            "     21        \u001b[36m0.5964\u001b[0m  0.0863\n",
            "     22        \u001b[36m0.5950\u001b[0m  0.0946\n",
            "     23        \u001b[36m0.5937\u001b[0m  0.0751\n",
            "     24        \u001b[36m0.5925\u001b[0m  0.0738\n",
            "     25        0.5932  0.0718\n",
            "     26        \u001b[36m0.5917\u001b[0m  0.0768\n",
            "     27        \u001b[36m0.5907\u001b[0m  0.0719\n",
            "     28        \u001b[36m0.5898\u001b[0m  0.0769\n",
            "     29        \u001b[36m0.5888\u001b[0m  0.0741\n",
            "     30        \u001b[36m0.5879\u001b[0m  0.0743\n",
            "     31        \u001b[36m0.5871\u001b[0m  0.0750\n",
            "     32        \u001b[36m0.5863\u001b[0m  0.0728\n",
            "     33        \u001b[36m0.5855\u001b[0m  0.0724\n",
            "     34        \u001b[36m0.5847\u001b[0m  0.0787\n",
            "     35        \u001b[36m0.5840\u001b[0m  0.0810\n",
            "     36        \u001b[36m0.5833\u001b[0m  0.0766\n",
            "     37        \u001b[36m0.5826\u001b[0m  0.0739\n",
            "     38        \u001b[36m0.5820\u001b[0m  0.0737\n",
            "     39        \u001b[36m0.5816\u001b[0m  0.0728\n",
            "     40        \u001b[36m0.5810\u001b[0m  0.0770\n",
            "     41        \u001b[36m0.5804\u001b[0m  0.0750\n",
            "     42        \u001b[36m0.5799\u001b[0m  0.0742\n",
            "     43        \u001b[36m0.5795\u001b[0m  0.0747\n",
            "     44        \u001b[36m0.5790\u001b[0m  0.0803\n",
            "     45        \u001b[36m0.5785\u001b[0m  0.0737\n",
            "     46        \u001b[36m0.5781\u001b[0m  0.0726\n",
            "     47        \u001b[36m0.5777\u001b[0m  0.0717\n",
            "     48        \u001b[36m0.5776\u001b[0m  0.0812\n",
            "     49        \u001b[36m0.5772\u001b[0m  0.0789\n",
            "     50        \u001b[36m0.5768\u001b[0m  0.0785\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.2495\u001b[0m  0.0753\n",
            "      2        \u001b[36m1.1056\u001b[0m  0.0778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.9625\u001b[0m  0.0843\n",
            "      4        \u001b[36m0.8354\u001b[0m  0.0741\n",
            "      5        \u001b[36m0.7572\u001b[0m  0.0769\n",
            "      6        \u001b[36m0.7123\u001b[0m  0.0740\n",
            "      7        \u001b[36m0.6835\u001b[0m  0.0727\n",
            "      8        \u001b[36m0.6599\u001b[0m  0.0750\n",
            "      9        \u001b[36m0.6431\u001b[0m  0.0715\n",
            "     10        \u001b[36m0.6256\u001b[0m  0.0750\n",
            "     11        \u001b[36m0.6239\u001b[0m  0.0832\n",
            "     12        \u001b[36m0.6113\u001b[0m  0.0722\n",
            "     13        \u001b[36m0.6039\u001b[0m  0.0754\n",
            "     14        \u001b[36m0.5956\u001b[0m  0.0743\n",
            "     15        \u001b[36m0.5910\u001b[0m  0.0739\n",
            "     16        \u001b[36m0.5824\u001b[0m  0.0728\n",
            "     17        \u001b[36m0.5691\u001b[0m  0.0731\n",
            "     18        \u001b[36m0.5624\u001b[0m  0.0811\n",
            "     19        \u001b[36m0.5575\u001b[0m  0.0737\n",
            "     20        \u001b[36m0.5549\u001b[0m  0.0757\n",
            "     21        \u001b[36m0.5519\u001b[0m  0.0729\n",
            "     22        \u001b[36m0.5489\u001b[0m  0.0803\n",
            "     23        \u001b[36m0.5448\u001b[0m  0.0760\n",
            "     24        \u001b[36m0.5426\u001b[0m  0.0819\n",
            "     25        \u001b[36m0.5367\u001b[0m  0.0724\n",
            "     26        \u001b[36m0.5329\u001b[0m  0.0736\n",
            "     27        0.5406  0.0840\n",
            "     28        0.5552  0.0732\n",
            "     29        0.5420  0.0752\n",
            "     30        0.5362  0.0736\n",
            "     31        0.5341  0.0786\n",
            "     32        \u001b[36m0.5216\u001b[0m  0.0742\n",
            "     33        \u001b[36m0.5198\u001b[0m  0.0744\n",
            "     34        \u001b[36m0.5180\u001b[0m  0.0801\n",
            "     35        \u001b[36m0.5168\u001b[0m  0.0771\n",
            "     36        \u001b[36m0.5157\u001b[0m  0.0784\n",
            "     37        0.5198  0.0832\n",
            "     38        0.5194  0.0782\n",
            "     39        0.5184  0.0767\n",
            "     40        0.5175  0.0781\n",
            "     41        0.5166  0.0733\n",
            "     42        0.5157  0.0758\n",
            "     43        \u001b[36m0.5140\u001b[0m  0.0729\n",
            "     44        \u001b[36m0.5112\u001b[0m  0.0796\n",
            "     45        \u001b[36m0.5082\u001b[0m  0.0758\n",
            "     46        0.5091  0.0756\n",
            "     47        \u001b[36m0.5061\u001b[0m  0.0740\n",
            "     48        0.5071  0.0752\n",
            "     49        0.5063  0.0807\n",
            "     50        \u001b[36m0.5055\u001b[0m  0.0834\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.1081\u001b[0m  0.0708\n",
            "      2        \u001b[36m0.9643\u001b[0m  0.0792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.8512\u001b[0m  0.0866\n",
            "      4        \u001b[36m0.7661\u001b[0m  0.0756\n",
            "      5        \u001b[36m0.7022\u001b[0m  0.0770\n",
            "      6        \u001b[36m0.6564\u001b[0m  0.0753\n",
            "      7        \u001b[36m0.6183\u001b[0m  0.0761\n",
            "      8        \u001b[36m0.5993\u001b[0m  0.0765\n",
            "      9        \u001b[36m0.5452\u001b[0m  0.0734\n",
            "     10        \u001b[36m0.5225\u001b[0m  0.0791\n",
            "     11        \u001b[36m0.5075\u001b[0m  0.0785\n",
            "     12        \u001b[36m0.5040\u001b[0m  0.0881\n",
            "     13        \u001b[36m0.4887\u001b[0m  0.0750\n",
            "     14        \u001b[36m0.4867\u001b[0m  0.0754\n",
            "     15        0.5057  0.0763\n",
            "     16        0.4996  0.0766\n",
            "     17        0.4952  0.0741\n",
            "     18        0.4928  0.0788\n",
            "     19        0.4908  0.0747\n",
            "     20        0.4890  0.0727\n",
            "     21        0.4873  0.0801\n",
            "     22        0.5025  0.0768\n",
            "     23        0.5002  0.0734\n",
            "     24        0.5065  0.0727\n",
            "     25        0.5049  0.0795\n",
            "     26        0.5022  0.0765\n",
            "     27        0.4949  0.0752\n",
            "     28        0.4892  0.0786\n",
            "     29        0.4982  0.0754\n",
            "     30        0.4980  0.0725\n",
            "     31        0.4985  0.0726\n",
            "     32        0.4982  0.0775\n",
            "     33        0.4975  0.0743\n",
            "     34        0.5000  0.0733\n",
            "     35        0.4996  0.0765\n",
            "     36        0.4990  0.0745\n",
            "     37        0.4983  0.0809\n",
            "     38        0.4976  0.0812\n",
            "     39        0.4976  0.0723\n",
            "     40        0.4962  0.0735\n",
            "     41        0.4956  0.0756\n",
            "     42        0.4935  0.0706\n",
            "     43        0.5145  0.0734\n",
            "     44        0.5068  0.0806\n",
            "     45        0.5103  0.0733\n",
            "     46        0.5094  0.0727\n",
            "     47        0.5084  0.0740\n",
            "     48        0.5068  0.0712\n",
            "     49        0.5062  0.0821\n",
            "     50        0.5056  0.0714\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3158\u001b[0m  0.0515\n",
            "      2        \u001b[36m1.8144\u001b[0m  0.0693\n",
            "      3        \u001b[36m1.5480\u001b[0m  0.0604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.4725\u001b[0m  0.0723\n",
            "      5        \u001b[36m1.3925\u001b[0m  0.0610\n",
            "      6        \u001b[36m1.3113\u001b[0m  0.0743\n",
            "      7        \u001b[36m1.2381\u001b[0m  0.0577\n",
            "      8        \u001b[36m1.1818\u001b[0m  0.0607\n",
            "      9        \u001b[36m1.1424\u001b[0m  0.0582\n",
            "     10        \u001b[36m1.1147\u001b[0m  0.0600\n",
            "     11        \u001b[36m1.0935\u001b[0m  0.0630\n",
            "     12        \u001b[36m1.0757\u001b[0m  0.0662\n",
            "     13        \u001b[36m1.0598\u001b[0m  0.0590\n",
            "     14        \u001b[36m1.0449\u001b[0m  0.0607\n",
            "     15        \u001b[36m1.0309\u001b[0m  0.0628\n",
            "     16        \u001b[36m1.0174\u001b[0m  0.0626\n",
            "     17        \u001b[36m1.0045\u001b[0m  0.0590\n",
            "     18        \u001b[36m0.9921\u001b[0m  0.0676\n",
            "     19        \u001b[36m0.9802\u001b[0m  0.0650\n",
            "     20        \u001b[36m0.9688\u001b[0m  0.0602\n",
            "     21        \u001b[36m0.9579\u001b[0m  0.0588\n",
            "     22        \u001b[36m0.9476\u001b[0m  0.0625\n",
            "     23        \u001b[36m0.9377\u001b[0m  0.0602\n",
            "     24        \u001b[36m0.9283\u001b[0m  0.0599\n",
            "     25        \u001b[36m0.9194\u001b[0m  0.0615\n",
            "     26        \u001b[36m0.9111\u001b[0m  0.0625\n",
            "     27        \u001b[36m0.9032\u001b[0m  0.0597\n",
            "     28        \u001b[36m0.8957\u001b[0m  0.0644\n",
            "     29        \u001b[36m0.8887\u001b[0m  0.0578\n",
            "     30        \u001b[36m0.8821\u001b[0m  0.0599\n",
            "     31        \u001b[36m0.8759\u001b[0m  0.0694\n",
            "     32        \u001b[36m0.8701\u001b[0m  0.0596\n",
            "     33        \u001b[36m0.8647\u001b[0m  0.0590\n",
            "     34        \u001b[36m0.8595\u001b[0m  0.0683\n",
            "     35        \u001b[36m0.8547\u001b[0m  0.0629\n",
            "     36        \u001b[36m0.8502\u001b[0m  0.0667\n",
            "     37        \u001b[36m0.8459\u001b[0m  0.0623\n",
            "     38        \u001b[36m0.8419\u001b[0m  0.0586\n",
            "     39        \u001b[36m0.8380\u001b[0m  0.0621\n",
            "     40        \u001b[36m0.8344\u001b[0m  0.0579\n",
            "     41        \u001b[36m0.8310\u001b[0m  0.0578\n",
            "     42        \u001b[36m0.8277\u001b[0m  0.0596\n",
            "     43        \u001b[36m0.8246\u001b[0m  0.0601\n",
            "     44        \u001b[36m0.8217\u001b[0m  0.0640\n",
            "     45        \u001b[36m0.8189\u001b[0m  0.0634\n",
            "     46        \u001b[36m0.8161\u001b[0m  0.0605\n",
            "     47        \u001b[36m0.8135\u001b[0m  0.0612\n",
            "     48        \u001b[36m0.8110\u001b[0m  0.0605\n",
            "     49        \u001b[36m0.8086\u001b[0m  0.0637\n",
            "     50        \u001b[36m0.8062\u001b[0m  0.0708\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7239\u001b[0m  0.0563\n",
            "      2        \u001b[36m0.7162\u001b[0m  0.0634\n",
            "      3        \u001b[36m0.7100\u001b[0m  0.0603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.7050\u001b[0m  0.0653\n",
            "      5        \u001b[36m0.7006\u001b[0m  0.0607\n",
            "      6        \u001b[36m0.6970\u001b[0m  0.0576\n",
            "      7        \u001b[36m0.6939\u001b[0m  0.0592\n",
            "      8        \u001b[36m0.6913\u001b[0m  0.0566\n",
            "      9        \u001b[36m0.6890\u001b[0m  0.0565\n",
            "     10        \u001b[36m0.6870\u001b[0m  0.0597\n",
            "     11        \u001b[36m0.6853\u001b[0m  0.0645\n",
            "     12        \u001b[36m0.6837\u001b[0m  0.0580\n",
            "     13        \u001b[36m0.6823\u001b[0m  0.0582\n",
            "     14        \u001b[36m0.6811\u001b[0m  0.0591\n",
            "     15        \u001b[36m0.6799\u001b[0m  0.0576\n",
            "     16        \u001b[36m0.6789\u001b[0m  0.0664\n",
            "     17        \u001b[36m0.6779\u001b[0m  0.0607\n",
            "     18        \u001b[36m0.6770\u001b[0m  0.0596\n",
            "     19        \u001b[36m0.6762\u001b[0m  0.0578\n",
            "     20        \u001b[36m0.6754\u001b[0m  0.0565\n",
            "     21        \u001b[36m0.6746\u001b[0m  0.0624\n",
            "     22        \u001b[36m0.6740\u001b[0m  0.0618\n",
            "     23        \u001b[36m0.6733\u001b[0m  0.0587\n",
            "     24        \u001b[36m0.6727\u001b[0m  0.0583\n",
            "     25        \u001b[36m0.6721\u001b[0m  0.0564\n",
            "     26        \u001b[36m0.6715\u001b[0m  0.0601\n",
            "     27        \u001b[36m0.6709\u001b[0m  0.0620\n",
            "     28        \u001b[36m0.6704\u001b[0m  0.0596\n",
            "     29        \u001b[36m0.6699\u001b[0m  0.0666\n",
            "     30        \u001b[36m0.6694\u001b[0m  0.0613\n",
            "     31        \u001b[36m0.6689\u001b[0m  0.0604\n",
            "     32        \u001b[36m0.6684\u001b[0m  0.0743\n",
            "     33        \u001b[36m0.6680\u001b[0m  0.0671\n",
            "     34        \u001b[36m0.6675\u001b[0m  0.0589\n",
            "     35        \u001b[36m0.6671\u001b[0m  0.0608\n",
            "     36        \u001b[36m0.6667\u001b[0m  0.0599\n",
            "     37        \u001b[36m0.6662\u001b[0m  0.0678\n",
            "     38        \u001b[36m0.6658\u001b[0m  0.0604\n",
            "     39        \u001b[36m0.6654\u001b[0m  0.0615\n",
            "     40        \u001b[36m0.6650\u001b[0m  0.0598\n",
            "     41        \u001b[36m0.6647\u001b[0m  0.0641\n",
            "     42        \u001b[36m0.6643\u001b[0m  0.0613\n",
            "     43        \u001b[36m0.6639\u001b[0m  0.0679\n",
            "     44        \u001b[36m0.6635\u001b[0m  0.0589\n",
            "     45        \u001b[36m0.6632\u001b[0m  0.0601\n",
            "     46        \u001b[36m0.6628\u001b[0m  0.0654\n",
            "     47        \u001b[36m0.6625\u001b[0m  0.0635\n",
            "     48        \u001b[36m0.6621\u001b[0m  0.0687\n",
            "     49        \u001b[36m0.6618\u001b[0m  0.0577\n",
            "     50        \u001b[36m0.6614\u001b[0m  0.0595\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9007\u001b[0m  0.0617\n",
            "      2        0.9081  0.0609\n",
            "      3        0.9380  0.0604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        0.9126  0.0692\n",
            "      5        0.9052  0.0595\n",
            "      6        \u001b[36m0.8632\u001b[0m  0.0629\n",
            "      7        0.8686  0.0659\n",
            "      8        0.8640  0.0608\n",
            "      9        \u001b[36m0.8565\u001b[0m  0.0602\n",
            "     10        \u001b[36m0.8495\u001b[0m  0.0618\n",
            "     11        \u001b[36m0.8431\u001b[0m  0.0602\n",
            "     12        \u001b[36m0.8371\u001b[0m  0.0655\n",
            "     13        \u001b[36m0.8315\u001b[0m  0.0725\n",
            "     14        \u001b[36m0.8263\u001b[0m  0.0615\n",
            "     15        \u001b[36m0.8213\u001b[0m  0.0588\n",
            "     16        \u001b[36m0.8166\u001b[0m  0.0598\n",
            "     17        \u001b[36m0.8121\u001b[0m  0.0587\n",
            "     18        \u001b[36m0.8079\u001b[0m  0.0613\n",
            "     19        0.8085  0.0595\n",
            "     20        \u001b[36m0.8012\u001b[0m  0.0623\n",
            "     21        \u001b[36m0.7971\u001b[0m  0.0604\n",
            "     22        \u001b[36m0.7935\u001b[0m  0.0618\n",
            "     23        \u001b[36m0.7899\u001b[0m  0.0594\n",
            "     24        \u001b[36m0.7864\u001b[0m  0.0584\n",
            "     25        \u001b[36m0.7831\u001b[0m  0.0666\n",
            "     26        \u001b[36m0.7798\u001b[0m  0.0588\n",
            "     27        \u001b[36m0.7767\u001b[0m  0.0651\n",
            "     28        \u001b[36m0.7736\u001b[0m  0.0593\n",
            "     29        \u001b[36m0.7706\u001b[0m  0.0670\n",
            "     30        \u001b[36m0.7677\u001b[0m  0.0594\n",
            "     31        \u001b[36m0.7649\u001b[0m  0.0631\n",
            "     32        \u001b[36m0.7622\u001b[0m  0.0652\n",
            "     33        \u001b[36m0.7595\u001b[0m  0.0604\n",
            "     34        \u001b[36m0.7569\u001b[0m  0.0600\n",
            "     35        \u001b[36m0.7452\u001b[0m  0.0593\n",
            "     36        0.7484  0.0611\n",
            "     37        0.7531  0.0596\n",
            "     38        0.7499  0.0571\n",
            "     39        0.7470  0.0656\n",
            "     40        \u001b[36m0.7445\u001b[0m  0.0633\n",
            "     41        \u001b[36m0.7421\u001b[0m  0.0626\n",
            "     42        \u001b[36m0.7386\u001b[0m  0.0615\n",
            "     43        \u001b[36m0.7345\u001b[0m  0.0608\n",
            "     44        \u001b[36m0.7325\u001b[0m  0.0615\n",
            "     45        \u001b[36m0.7307\u001b[0m  0.0679\n",
            "     46        \u001b[36m0.7289\u001b[0m  0.0587\n",
            "     47        \u001b[36m0.7272\u001b[0m  0.0583\n",
            "     48        \u001b[36m0.7255\u001b[0m  0.0621\n",
            "     49        \u001b[36m0.7239\u001b[0m  0.0631\n",
            "     50        \u001b[36m0.7224\u001b[0m  0.0591\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.8935\u001b[0m  0.0562\n",
            "      2        \u001b[36m1.7928\u001b[0m  0.0645\n",
            "      3        \u001b[36m1.6986\u001b[0m  0.0598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.6103\u001b[0m  0.0767\n",
            "      5        \u001b[36m1.5276\u001b[0m  0.0595\n",
            "      6        \u001b[36m1.4501\u001b[0m  0.0592\n",
            "      7        \u001b[36m1.3778\u001b[0m  0.0643\n",
            "      8        \u001b[36m1.3105\u001b[0m  0.0632\n",
            "      9        \u001b[36m1.2482\u001b[0m  0.0584\n",
            "     10        \u001b[36m1.1906\u001b[0m  0.0614\n",
            "     11        \u001b[36m1.1378\u001b[0m  0.0682\n",
            "     12        \u001b[36m1.0899\u001b[0m  0.0598\n",
            "     13        \u001b[36m1.0465\u001b[0m  0.0589\n",
            "     14        \u001b[36m1.0074\u001b[0m  0.0639\n",
            "     15        \u001b[36m0.9724\u001b[0m  0.0588\n",
            "     16        \u001b[36m0.9410\u001b[0m  0.0595\n",
            "     17        \u001b[36m0.9131\u001b[0m  0.0591\n",
            "     18        \u001b[36m0.8883\u001b[0m  0.0743\n",
            "     19        \u001b[36m0.8663\u001b[0m  0.0606\n",
            "     20        \u001b[36m0.8467\u001b[0m  0.0592\n",
            "     21        \u001b[36m0.8294\u001b[0m  0.0585\n",
            "     22        \u001b[36m0.8140\u001b[0m  0.0626\n",
            "     23        \u001b[36m0.8004\u001b[0m  0.0592\n",
            "     24        \u001b[36m0.7882\u001b[0m  0.0587\n",
            "     25        \u001b[36m0.7773\u001b[0m  0.0642\n",
            "     26        \u001b[36m0.7676\u001b[0m  0.0578\n",
            "     27        \u001b[36m0.7588\u001b[0m  0.0651\n",
            "     28        \u001b[36m0.7509\u001b[0m  0.0749\n",
            "     29        \u001b[36m0.7437\u001b[0m  0.0588\n",
            "     30        \u001b[36m0.7372\u001b[0m  0.0687\n",
            "     31        \u001b[36m0.7313\u001b[0m  0.0599\n",
            "     32        \u001b[36m0.7258\u001b[0m  0.0614\n",
            "     33        \u001b[36m0.7207\u001b[0m  0.0583\n",
            "     34        \u001b[36m0.7161\u001b[0m  0.0581\n",
            "     35        \u001b[36m0.7117\u001b[0m  0.0577\n",
            "     36        \u001b[36m0.7076\u001b[0m  0.0590\n",
            "     37        \u001b[36m0.7038\u001b[0m  0.0659\n",
            "     38        \u001b[36m0.7002\u001b[0m  0.0622\n",
            "     39        \u001b[36m0.6968\u001b[0m  0.0624\n",
            "     40        \u001b[36m0.6936\u001b[0m  0.0588\n",
            "     41        \u001b[36m0.6906\u001b[0m  0.0630\n",
            "     42        \u001b[36m0.6876\u001b[0m  0.0624\n",
            "     43        \u001b[36m0.6848\u001b[0m  0.0657\n",
            "     44        \u001b[36m0.6822\u001b[0m  0.0611\n",
            "     45        \u001b[36m0.6796\u001b[0m  0.0603\n",
            "     46        \u001b[36m0.6771\u001b[0m  0.0601\n",
            "     47        \u001b[36m0.6747\u001b[0m  0.0635\n",
            "     48        \u001b[36m0.6724\u001b[0m  0.0586\n",
            "     49        \u001b[36m0.6702\u001b[0m  0.0602\n",
            "     50        \u001b[36m0.6681\u001b[0m  0.0623\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9191\u001b[0m  0.0567\n",
            "      2        \u001b[36m0.8757\u001b[0m  0.0699\n",
            "      3        \u001b[36m0.8469\u001b[0m  0.0591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.8284\u001b[0m  0.0666\n",
            "      5        \u001b[36m0.8161\u001b[0m  0.0603\n",
            "      6        \u001b[36m0.8076\u001b[0m  0.0618\n",
            "      7        \u001b[36m0.8017\u001b[0m  0.0585\n",
            "      8        \u001b[36m0.7974\u001b[0m  0.0643\n",
            "      9        \u001b[36m0.7941\u001b[0m  0.0606\n",
            "     10        \u001b[36m0.7916\u001b[0m  0.0630\n",
            "     11        \u001b[36m0.7895\u001b[0m  0.0583\n",
            "     12        \u001b[36m0.7877\u001b[0m  0.0629\n",
            "     13        \u001b[36m0.7862\u001b[0m  0.0598\n",
            "     14        \u001b[36m0.7848\u001b[0m  0.0592\n",
            "     15        \u001b[36m0.7835\u001b[0m  0.0731\n",
            "     16        \u001b[36m0.7821\u001b[0m  0.0659\n",
            "     17        \u001b[36m0.7802\u001b[0m  0.0593\n",
            "     18        \u001b[36m0.7789\u001b[0m  0.0599\n",
            "     19        \u001b[36m0.7779\u001b[0m  0.0573\n",
            "     20        \u001b[36m0.7768\u001b[0m  0.0600\n",
            "     21        \u001b[36m0.7757\u001b[0m  0.0625\n",
            "     22        \u001b[36m0.7747\u001b[0m  0.0633\n",
            "     23        \u001b[36m0.7737\u001b[0m  0.0581\n",
            "     24        \u001b[36m0.7726\u001b[0m  0.0658\n",
            "     25        \u001b[36m0.7717\u001b[0m  0.0636\n",
            "     26        \u001b[36m0.7707\u001b[0m  0.0605\n",
            "     27        \u001b[36m0.7697\u001b[0m  0.0627\n",
            "     28        \u001b[36m0.7687\u001b[0m  0.0607\n",
            "     29        \u001b[36m0.7678\u001b[0m  0.0604\n",
            "     30        \u001b[36m0.7668\u001b[0m  0.0577\n",
            "     31        \u001b[36m0.7659\u001b[0m  0.0605\n",
            "     32        \u001b[36m0.7650\u001b[0m  0.0593\n",
            "     33        \u001b[36m0.7640\u001b[0m  0.0617\n",
            "     34        \u001b[36m0.7631\u001b[0m  0.0645\n",
            "     35        \u001b[36m0.7622\u001b[0m  0.0603\n",
            "     36        \u001b[36m0.7613\u001b[0m  0.0604\n",
            "     37        \u001b[36m0.7605\u001b[0m  0.0696\n",
            "     38        \u001b[36m0.7596\u001b[0m  0.0603\n",
            "     39        \u001b[36m0.7587\u001b[0m  0.0590\n",
            "     40        \u001b[36m0.7579\u001b[0m  0.0570\n",
            "     41        \u001b[36m0.7570\u001b[0m  0.0694\n",
            "     42        \u001b[36m0.7562\u001b[0m  0.0599\n",
            "     43        \u001b[36m0.7553\u001b[0m  0.0596\n",
            "     44        \u001b[36m0.7545\u001b[0m  0.0589\n",
            "     45        \u001b[36m0.7537\u001b[0m  0.0617\n",
            "     46        \u001b[36m0.7529\u001b[0m  0.0600\n",
            "     47        \u001b[36m0.7521\u001b[0m  0.0615\n",
            "     48        \u001b[36m0.7513\u001b[0m  0.0717\n",
            "     49        \u001b[36m0.7505\u001b[0m  0.0674\n",
            "     50        \u001b[36m0.7497\u001b[0m  0.0595\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7898\u001b[0m  0.0575\n",
            "      2        \u001b[36m0.7731\u001b[0m  0.0603\n",
            "      3        \u001b[36m0.7634\u001b[0m  0.0625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.7550\u001b[0m  0.0683\n",
            "      5        \u001b[36m0.7478\u001b[0m  0.0553\n",
            "      6        \u001b[36m0.7416\u001b[0m  0.0634\n",
            "      7        \u001b[36m0.7363\u001b[0m  0.0588\n",
            "      8        \u001b[36m0.7317\u001b[0m  0.0639\n",
            "      9        \u001b[36m0.7277\u001b[0m  0.0615\n",
            "     10        \u001b[36m0.7242\u001b[0m  0.0606\n",
            "     11        \u001b[36m0.7212\u001b[0m  0.0591\n",
            "     12        \u001b[36m0.7184\u001b[0m  0.0637\n",
            "     13        \u001b[36m0.7159\u001b[0m  0.0622\n",
            "     14        \u001b[36m0.7137\u001b[0m  0.0584\n",
            "     15        \u001b[36m0.7116\u001b[0m  0.0602\n",
            "     16        \u001b[36m0.7097\u001b[0m  0.0607\n",
            "     17        \u001b[36m0.7080\u001b[0m  0.0620\n",
            "     18        \u001b[36m0.7063\u001b[0m  0.0585\n",
            "     19        \u001b[36m0.7047\u001b[0m  0.0577\n",
            "     20        \u001b[36m0.7032\u001b[0m  0.0705\n",
            "     21        \u001b[36m0.7018\u001b[0m  0.0585\n",
            "     22        \u001b[36m0.7004\u001b[0m  0.0602\n",
            "     23        \u001b[36m0.6991\u001b[0m  0.0647\n",
            "     24        \u001b[36m0.6979\u001b[0m  0.0585\n",
            "     25        \u001b[36m0.6966\u001b[0m  0.0584\n",
            "     26        \u001b[36m0.6954\u001b[0m  0.0590\n",
            "     27        \u001b[36m0.6943\u001b[0m  0.0586\n",
            "     28        \u001b[36m0.6932\u001b[0m  0.0580\n",
            "     29        \u001b[36m0.6921\u001b[0m  0.0597\n",
            "     30        \u001b[36m0.6911\u001b[0m  0.0575\n",
            "     31        \u001b[36m0.6900\u001b[0m  0.0631\n",
            "     32        \u001b[36m0.6890\u001b[0m  0.0618\n",
            "     33        \u001b[36m0.6881\u001b[0m  0.0628\n",
            "     34        \u001b[36m0.6871\u001b[0m  0.0634\n",
            "     35        \u001b[36m0.6862\u001b[0m  0.0594\n",
            "     36        \u001b[36m0.6853\u001b[0m  0.0575\n",
            "     37        \u001b[36m0.6844\u001b[0m  0.0608\n",
            "     38        \u001b[36m0.6835\u001b[0m  0.0585\n",
            "     39        \u001b[36m0.6827\u001b[0m  0.0647\n",
            "     40        \u001b[36m0.6818\u001b[0m  0.0587\n",
            "     41        \u001b[36m0.6810\u001b[0m  0.0594\n",
            "     42        \u001b[36m0.6802\u001b[0m  0.0602\n",
            "     43        \u001b[36m0.6794\u001b[0m  0.0599\n",
            "     44        \u001b[36m0.6787\u001b[0m  0.0613\n",
            "     45        \u001b[36m0.6779\u001b[0m  0.0643\n",
            "     46        \u001b[36m0.6772\u001b[0m  0.0642\n",
            "     47        \u001b[36m0.6765\u001b[0m  0.0591\n",
            "     48        \u001b[36m0.6758\u001b[0m  0.0586\n",
            "     49        \u001b[36m0.6751\u001b[0m  0.0605\n",
            "     50        \u001b[36m0.6744\u001b[0m  0.0663\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8925\u001b[0m  0.0539\n",
            "      2        \u001b[36m0.8870\u001b[0m  0.0589\n",
            "      3        \u001b[36m0.8858\u001b[0m  0.0635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        0.8904  0.0705\n",
            "      5        \u001b[36m0.8644\u001b[0m  0.0653\n",
            "      6        \u001b[36m0.8592\u001b[0m  0.0622\n",
            "      7        \u001b[36m0.8544\u001b[0m  0.0602\n",
            "      8        \u001b[36m0.8500\u001b[0m  0.0592\n",
            "      9        \u001b[36m0.8458\u001b[0m  0.0676\n",
            "     10        \u001b[36m0.8420\u001b[0m  0.0585\n",
            "     11        \u001b[36m0.8384\u001b[0m  0.0585\n",
            "     12        \u001b[36m0.8350\u001b[0m  0.0609\n",
            "     13        \u001b[36m0.8319\u001b[0m  0.0594\n",
            "     14        \u001b[36m0.8289\u001b[0m  0.0641\n",
            "     15        \u001b[36m0.8261\u001b[0m  0.0570\n",
            "     16        \u001b[36m0.8234\u001b[0m  0.0602\n",
            "     17        \u001b[36m0.8208\u001b[0m  0.0580\n",
            "     18        \u001b[36m0.8184\u001b[0m  0.0588\n",
            "     19        \u001b[36m0.8161\u001b[0m  0.0602\n",
            "     20        \u001b[36m0.8138\u001b[0m  0.0585\n",
            "     21        \u001b[36m0.8137\u001b[0m  0.0651\n",
            "     22        \u001b[36m0.8109\u001b[0m  0.0569\n",
            "     23        \u001b[36m0.8089\u001b[0m  0.0599\n",
            "     24        \u001b[36m0.8069\u001b[0m  0.0600\n",
            "     25        \u001b[36m0.8051\u001b[0m  0.0597\n",
            "     26        \u001b[36m0.8032\u001b[0m  0.0581\n",
            "     27        \u001b[36m0.8015\u001b[0m  0.0582\n",
            "     28        \u001b[36m0.7998\u001b[0m  0.0620\n",
            "     29        \u001b[36m0.7981\u001b[0m  0.0702\n",
            "     30        \u001b[36m0.7965\u001b[0m  0.0601\n",
            "     31        \u001b[36m0.7949\u001b[0m  0.0608\n",
            "     32        \u001b[36m0.7934\u001b[0m  0.0640\n",
            "     33        \u001b[36m0.7919\u001b[0m  0.0604\n",
            "     34        \u001b[36m0.7905\u001b[0m  0.0592\n",
            "     35        \u001b[36m0.7891\u001b[0m  0.0603\n",
            "     36        \u001b[36m0.7877\u001b[0m  0.0588\n",
            "     37        \u001b[36m0.7864\u001b[0m  0.0681\n",
            "     38        \u001b[36m0.7851\u001b[0m  0.0612\n",
            "     39        \u001b[36m0.7838\u001b[0m  0.0616\n",
            "     40        \u001b[36m0.7826\u001b[0m  0.0598\n",
            "     41        \u001b[36m0.7814\u001b[0m  0.0660\n",
            "     42        \u001b[36m0.7802\u001b[0m  0.0604\n",
            "     43        \u001b[36m0.7791\u001b[0m  0.0673\n",
            "     44        \u001b[36m0.7779\u001b[0m  0.0695\n",
            "     45        \u001b[36m0.7768\u001b[0m  0.0579\n",
            "     46        \u001b[36m0.7758\u001b[0m  0.0656\n",
            "     47        \u001b[36m0.7747\u001b[0m  0.0618\n",
            "     48        \u001b[36m0.7737\u001b[0m  0.0631\n",
            "     49        \u001b[36m0.7727\u001b[0m  0.0591\n",
            "     50        \u001b[36m0.7717\u001b[0m  0.0634\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0881\u001b[0m  0.0547\n",
            "      2        \u001b[36m1.0537\u001b[0m  0.0709\n",
            "      3        \u001b[36m1.0269\u001b[0m  0.0633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.0020\u001b[0m  0.0683\n",
            "      5        \u001b[36m0.9810\u001b[0m  0.0635\n",
            "      6        \u001b[36m0.9636\u001b[0m  0.0691\n",
            "      7        \u001b[36m0.9490\u001b[0m  0.0611\n",
            "      8        \u001b[36m0.9368\u001b[0m  0.0599\n",
            "      9        \u001b[36m0.9264\u001b[0m  0.0594\n",
            "     10        \u001b[36m0.9173\u001b[0m  0.0587\n",
            "     11        \u001b[36m0.9092\u001b[0m  0.0603\n",
            "     12        \u001b[36m0.9019\u001b[0m  0.0619\n",
            "     13        \u001b[36m0.8952\u001b[0m  0.0616\n",
            "     14        \u001b[36m0.8891\u001b[0m  0.0585\n",
            "     15        \u001b[36m0.8833\u001b[0m  0.0589\n",
            "     16        \u001b[36m0.8778\u001b[0m  0.0596\n",
            "     17        \u001b[36m0.8726\u001b[0m  0.0644\n",
            "     18        \u001b[36m0.8677\u001b[0m  0.0599\n",
            "     19        \u001b[36m0.8630\u001b[0m  0.0660\n",
            "     20        \u001b[36m0.8585\u001b[0m  0.0675\n",
            "     21        \u001b[36m0.8543\u001b[0m  0.0628\n",
            "     22        \u001b[36m0.8502\u001b[0m  0.0609\n",
            "     23        \u001b[36m0.8463\u001b[0m  0.0610\n",
            "     24        \u001b[36m0.8426\u001b[0m  0.0602\n",
            "     25        \u001b[36m0.8390\u001b[0m  0.0675\n",
            "     26        \u001b[36m0.8356\u001b[0m  0.0584\n",
            "     27        \u001b[36m0.8323\u001b[0m  0.0595\n",
            "     28        \u001b[36m0.8292\u001b[0m  0.0608\n",
            "     29        \u001b[36m0.8262\u001b[0m  0.0592\n",
            "     30        \u001b[36m0.8233\u001b[0m  0.0607\n",
            "     31        \u001b[36m0.8205\u001b[0m  0.0586\n",
            "     32        \u001b[36m0.8179\u001b[0m  0.0599\n",
            "     33        \u001b[36m0.8153\u001b[0m  0.0607\n",
            "     34        \u001b[36m0.8129\u001b[0m  0.0624\n",
            "     35        \u001b[36m0.8105\u001b[0m  0.0680\n",
            "     36        \u001b[36m0.8083\u001b[0m  0.0589\n",
            "     37        \u001b[36m0.8061\u001b[0m  0.0596\n",
            "     38        \u001b[36m0.8040\u001b[0m  0.0660\n",
            "     39        \u001b[36m0.8020\u001b[0m  0.0702\n",
            "     40        \u001b[36m0.8000\u001b[0m  0.0597\n",
            "     41        \u001b[36m0.7982\u001b[0m  0.0614\n",
            "     42        \u001b[36m0.7964\u001b[0m  0.0603\n",
            "     43        \u001b[36m0.7946\u001b[0m  0.0666\n",
            "     44        \u001b[36m0.7929\u001b[0m  0.0605\n",
            "     45        \u001b[36m0.7913\u001b[0m  0.0619\n",
            "     46        \u001b[36m0.7897\u001b[0m  0.0562\n",
            "     47        \u001b[36m0.7882\u001b[0m  0.0604\n",
            "     48        \u001b[36m0.7867\u001b[0m  0.0594\n",
            "     49        \u001b[36m0.7853\u001b[0m  0.0589\n",
            "     50        \u001b[36m0.7839\u001b[0m  0.0648\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.2510\u001b[0m  0.0639\n",
            "      2        \u001b[36m1.1736\u001b[0m  0.0622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.1045\u001b[0m  0.0746\n",
            "      4        \u001b[36m1.0439\u001b[0m  0.0636\n",
            "      5        \u001b[36m0.9917\u001b[0m  0.0625\n",
            "      6        \u001b[36m0.9471\u001b[0m  0.0600\n",
            "      7        \u001b[36m0.9093\u001b[0m  0.0580\n",
            "      8        \u001b[36m0.8773\u001b[0m  0.0598\n",
            "      9        \u001b[36m0.8503\u001b[0m  0.0644\n",
            "     10        \u001b[36m0.8274\u001b[0m  0.0589\n",
            "     11        \u001b[36m0.8080\u001b[0m  0.0586\n",
            "     12        \u001b[36m0.7913\u001b[0m  0.0579\n",
            "     13        \u001b[36m0.7770\u001b[0m  0.0614\n",
            "     14        \u001b[36m0.7646\u001b[0m  0.0593\n",
            "     15        \u001b[36m0.7538\u001b[0m  0.0585\n",
            "     16        \u001b[36m0.7443\u001b[0m  0.0577\n",
            "     17        \u001b[36m0.7359\u001b[0m  0.0707\n",
            "     18        \u001b[36m0.7284\u001b[0m  0.0545\n",
            "     19        \u001b[36m0.7217\u001b[0m  0.0590\n",
            "     20        \u001b[36m0.7156\u001b[0m  0.0590\n",
            "     21        \u001b[36m0.7101\u001b[0m  0.0593\n",
            "     22        \u001b[36m0.7050\u001b[0m  0.0582\n",
            "     23        \u001b[36m0.7003\u001b[0m  0.0569\n",
            "     24        \u001b[36m0.6959\u001b[0m  0.0658\n",
            "     25        \u001b[36m0.6918\u001b[0m  0.0601\n",
            "     26        \u001b[36m0.6879\u001b[0m  0.0594\n",
            "     27        \u001b[36m0.6842\u001b[0m  0.0587\n",
            "     28        \u001b[36m0.6807\u001b[0m  0.0603\n",
            "     29        \u001b[36m0.6774\u001b[0m  0.0593\n",
            "     30        \u001b[36m0.6743\u001b[0m  0.0588\n",
            "     31        \u001b[36m0.6712\u001b[0m  0.0602\n",
            "     32        \u001b[36m0.6683\u001b[0m  0.0586\n",
            "     33        \u001b[36m0.6655\u001b[0m  0.0647\n",
            "     34        \u001b[36m0.6628\u001b[0m  0.0588\n",
            "     35        \u001b[36m0.6602\u001b[0m  0.0647\n",
            "     36        \u001b[36m0.6577\u001b[0m  0.0578\n",
            "     37        \u001b[36m0.6552\u001b[0m  0.0681\n",
            "     38        \u001b[36m0.6529\u001b[0m  0.0592\n",
            "     39        \u001b[36m0.6506\u001b[0m  0.0601\n",
            "     40        \u001b[36m0.6484\u001b[0m  0.0612\n",
            "     41        \u001b[36m0.6463\u001b[0m  0.0626\n",
            "     42        \u001b[36m0.6443\u001b[0m  0.0601\n",
            "     43        \u001b[36m0.6423\u001b[0m  0.0597\n",
            "     44        \u001b[36m0.6405\u001b[0m  0.0608\n",
            "     45        \u001b[36m0.6386\u001b[0m  0.0619\n",
            "     46        \u001b[36m0.6369\u001b[0m  0.0604\n",
            "     47        \u001b[36m0.6352\u001b[0m  0.0677\n",
            "     48        \u001b[36m0.6335\u001b[0m  0.0598\n",
            "     49        \u001b[36m0.6319\u001b[0m  0.0657\n",
            "     50        \u001b[36m0.6304\u001b[0m  0.0621\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9926\u001b[0m  0.0620\n",
            "      2        \u001b[36m0.9666\u001b[0m  0.0606\n",
            "      3        \u001b[36m0.9422\u001b[0m  0.0642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.9199\u001b[0m  0.0644\n",
            "      5        \u001b[36m0.9036\u001b[0m  0.0591\n",
            "      6        \u001b[36m0.8891\u001b[0m  0.0649\n",
            "      7        \u001b[36m0.8765\u001b[0m  0.0593\n",
            "      8        \u001b[36m0.8652\u001b[0m  0.0592\n",
            "      9        \u001b[36m0.8551\u001b[0m  0.0615\n",
            "     10        \u001b[36m0.8460\u001b[0m  0.0658\n",
            "     11        \u001b[36m0.8377\u001b[0m  0.0622\n",
            "     12        \u001b[36m0.8302\u001b[0m  0.0604\n",
            "     13        \u001b[36m0.8232\u001b[0m  0.0595\n",
            "     14        \u001b[36m0.8168\u001b[0m  0.0603\n",
            "     15        \u001b[36m0.8109\u001b[0m  0.0685\n",
            "     16        \u001b[36m0.8054\u001b[0m  0.0614\n",
            "     17        \u001b[36m0.8003\u001b[0m  0.0594\n",
            "     18        \u001b[36m0.7955\u001b[0m  0.0588\n",
            "     19        \u001b[36m0.7910\u001b[0m  0.0625\n",
            "     20        \u001b[36m0.7865\u001b[0m  0.0598\n",
            "     21        \u001b[36m0.7825\u001b[0m  0.0603\n",
            "     22        \u001b[36m0.7787\u001b[0m  0.0654\n",
            "     23        \u001b[36m0.7751\u001b[0m  0.0583\n",
            "     24        \u001b[36m0.7717\u001b[0m  0.0664\n",
            "     25        \u001b[36m0.7685\u001b[0m  0.0622\n",
            "     26        \u001b[36m0.7654\u001b[0m  0.0626\n",
            "     27        \u001b[36m0.7624\u001b[0m  0.0628\n",
            "     28        \u001b[36m0.7596\u001b[0m  0.0598\n",
            "     29        \u001b[36m0.7569\u001b[0m  0.0643\n",
            "     30        \u001b[36m0.7543\u001b[0m  0.0606\n",
            "     31        \u001b[36m0.7518\u001b[0m  0.0660\n",
            "     32        \u001b[36m0.7493\u001b[0m  0.0599\n",
            "     33        \u001b[36m0.7470\u001b[0m  0.0643\n",
            "     34        \u001b[36m0.7448\u001b[0m  0.0629\n",
            "     35        \u001b[36m0.7426\u001b[0m  0.0597\n",
            "     36        \u001b[36m0.7405\u001b[0m  0.0584\n",
            "     37        \u001b[36m0.7385\u001b[0m  0.0622\n",
            "     38        \u001b[36m0.7365\u001b[0m  0.0602\n",
            "     39        \u001b[36m0.7346\u001b[0m  0.0580\n",
            "     40        \u001b[36m0.7328\u001b[0m  0.0599\n",
            "     41        \u001b[36m0.7310\u001b[0m  0.0598\n",
            "     42        \u001b[36m0.7292\u001b[0m  0.0595\n",
            "     43        \u001b[36m0.7275\u001b[0m  0.0595\n",
            "     44        \u001b[36m0.7258\u001b[0m  0.0577\n",
            "     45        \u001b[36m0.7242\u001b[0m  0.0618\n",
            "     46        \u001b[36m0.7226\u001b[0m  0.0607\n",
            "     47        \u001b[36m0.7211\u001b[0m  0.0685\n",
            "     48        \u001b[36m0.7196\u001b[0m  0.0667\n",
            "     49        \u001b[36m0.7181\u001b[0m  0.0610\n",
            "     50        \u001b[36m0.7167\u001b[0m  0.0606\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4011\u001b[0m  0.0766\n",
            "      2        \u001b[36m1.1333\u001b[0m  0.0788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.9529\u001b[0m  0.0847\n",
            "      4        \u001b[36m0.8209\u001b[0m  0.0821\n",
            "      5        \u001b[36m0.7607\u001b[0m  0.0782\n",
            "      6        \u001b[36m0.7178\u001b[0m  0.0757\n",
            "      7        \u001b[36m0.6921\u001b[0m  0.0756\n",
            "      8        \u001b[36m0.6655\u001b[0m  0.0904\n",
            "      9        \u001b[36m0.6531\u001b[0m  0.0842\n",
            "     10        \u001b[36m0.6453\u001b[0m  0.0832\n",
            "     11        \u001b[36m0.6337\u001b[0m  0.0750\n",
            "     12        \u001b[36m0.6240\u001b[0m  0.0799\n",
            "     13        \u001b[36m0.6207\u001b[0m  0.0769\n",
            "     14        \u001b[36m0.6165\u001b[0m  0.0753\n",
            "     15        \u001b[36m0.6077\u001b[0m  0.0710\n",
            "     16        0.6095  0.0737\n",
            "     17        \u001b[36m0.6066\u001b[0m  0.0728\n",
            "     18        \u001b[36m0.6026\u001b[0m  0.0709\n",
            "     19        0.6035  0.0740\n",
            "     20        \u001b[36m0.6018\u001b[0m  0.0765\n",
            "     21        \u001b[36m0.6003\u001b[0m  0.0749\n",
            "     22        \u001b[36m0.5988\u001b[0m  0.0706\n",
            "     23        \u001b[36m0.5975\u001b[0m  0.0834\n",
            "     24        0.5979  0.0732\n",
            "     25        \u001b[36m0.5937\u001b[0m  0.0792\n",
            "     26        \u001b[36m0.5930\u001b[0m  0.0780\n",
            "     27        \u001b[36m0.5916\u001b[0m  0.0844\n",
            "     28        0.5917  0.0745\n",
            "     29        \u001b[36m0.5895\u001b[0m  0.0766\n",
            "     30        \u001b[36m0.5856\u001b[0m  0.0769\n",
            "     31        0.5866  0.0747\n",
            "     32        \u001b[36m0.5681\u001b[0m  0.0740\n",
            "     33        0.6415  0.0753\n",
            "     34        0.6195  0.0807\n",
            "     35        0.5988  0.0742\n",
            "     36        0.5905  0.0888\n",
            "     37        0.5856  0.0783\n",
            "     38        0.5822  0.0733\n",
            "     39        0.5777  0.0759\n",
            "     40        0.5751  0.0839\n",
            "     41        0.5726  0.0727\n",
            "     42        0.5727  0.0739\n",
            "     43        0.5709  0.0767\n",
            "     44        0.5698  0.0745\n",
            "     45        0.5688  0.0755\n",
            "     46        \u001b[36m0.5678\u001b[0m  0.0754\n",
            "     47        \u001b[36m0.5666\u001b[0m  0.0760\n",
            "     48        \u001b[36m0.5655\u001b[0m  0.0782\n",
            "     49        0.5674  0.0885\n",
            "     50        0.5688  0.0762\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2813\u001b[0m  0.0705\n",
            "      2        \u001b[36m1.2148\u001b[0m  0.0812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.0332\u001b[0m  0.0849\n",
            "      4        \u001b[36m1.0059\u001b[0m  0.0755\n",
            "      5        \u001b[36m0.9738\u001b[0m  0.0774\n",
            "      6        \u001b[36m0.9318\u001b[0m  0.0749\n",
            "      7        \u001b[36m0.8917\u001b[0m  0.0825\n",
            "      8        \u001b[36m0.8474\u001b[0m  0.0741\n",
            "      9        \u001b[36m0.8068\u001b[0m  0.0799\n",
            "     10        \u001b[36m0.7675\u001b[0m  0.0733\n",
            "     11        \u001b[36m0.7428\u001b[0m  0.0841\n",
            "     12        \u001b[36m0.7361\u001b[0m  0.0758\n",
            "     13        \u001b[36m0.7157\u001b[0m  0.0757\n",
            "     14        \u001b[36m0.7042\u001b[0m  0.0731\n",
            "     15        \u001b[36m0.6965\u001b[0m  0.0786\n",
            "     16        \u001b[36m0.6860\u001b[0m  0.0833\n",
            "     17        \u001b[36m0.6694\u001b[0m  0.0707\n",
            "     18        \u001b[36m0.6605\u001b[0m  0.0780\n",
            "     19        \u001b[36m0.6518\u001b[0m  0.0729\n",
            "     20        \u001b[36m0.6421\u001b[0m  0.0762\n",
            "     21        \u001b[36m0.6355\u001b[0m  0.0732\n",
            "     22        \u001b[36m0.6327\u001b[0m  0.0732\n",
            "     23        \u001b[36m0.6231\u001b[0m  0.0724\n",
            "     24        \u001b[36m0.6199\u001b[0m  0.0859\n",
            "     25        \u001b[36m0.6169\u001b[0m  0.0760\n",
            "     26        \u001b[36m0.6106\u001b[0m  0.0774\n",
            "     27        \u001b[36m0.6077\u001b[0m  0.0813\n",
            "     28        \u001b[36m0.6047\u001b[0m  0.0731\n",
            "     29        \u001b[36m0.6022\u001b[0m  0.0761\n",
            "     30        \u001b[36m0.6002\u001b[0m  0.0732\n",
            "     31        0.6041  0.0738\n",
            "     32        \u001b[36m0.5987\u001b[0m  0.0772\n",
            "     33        \u001b[36m0.5972\u001b[0m  0.0742\n",
            "     34        \u001b[36m0.5960\u001b[0m  0.0772\n",
            "     35        \u001b[36m0.5953\u001b[0m  0.0812\n",
            "     36        \u001b[36m0.5944\u001b[0m  0.0841\n",
            "     37        \u001b[36m0.5933\u001b[0m  0.0869\n",
            "     38        \u001b[36m0.5909\u001b[0m  0.0786\n",
            "     39        \u001b[36m0.5906\u001b[0m  0.0759\n",
            "     40        0.5910  0.0768\n",
            "     41        0.5920  0.0740\n",
            "     42        0.5916  0.0751\n",
            "     43        0.5926  0.0763\n",
            "     44        \u001b[36m0.5895\u001b[0m  0.0791\n",
            "     45        \u001b[36m0.5869\u001b[0m  0.0776\n",
            "     46        \u001b[36m0.5862\u001b[0m  0.0744\n",
            "     47        0.5943  0.0817\n",
            "     48        0.5933  0.0766\n",
            "     49        0.5924  0.0725\n",
            "     50        0.5931  0.0845\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7828\u001b[0m  0.0686\n",
            "      2        \u001b[36m0.6703\u001b[0m  0.0795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.6202\u001b[0m  0.0870\n",
            "      4        \u001b[36m0.5767\u001b[0m  0.0765\n",
            "      5        \u001b[36m0.5485\u001b[0m  0.0752\n",
            "      6        \u001b[36m0.5328\u001b[0m  0.0764\n",
            "      7        \u001b[36m0.5159\u001b[0m  0.0754\n",
            "      8        0.5219  0.0781\n",
            "      9        \u001b[36m0.5032\u001b[0m  0.0755\n",
            "     10        \u001b[36m0.4960\u001b[0m  0.0751\n",
            "     11        0.4963  0.0802\n",
            "     12        \u001b[36m0.4906\u001b[0m  0.0894\n",
            "     13        \u001b[36m0.4867\u001b[0m  0.0848\n",
            "     14        \u001b[36m0.4838\u001b[0m  0.0774\n",
            "     15        0.4909  0.0798\n",
            "     16        0.4861  0.0736\n",
            "     17        0.4858  0.0745\n",
            "     18        \u001b[36m0.4815\u001b[0m  0.0781\n",
            "     19        0.4824  0.0753\n",
            "     20        0.4817  0.0790\n",
            "     21        \u001b[36m0.4804\u001b[0m  0.0802\n",
            "     22        \u001b[36m0.4787\u001b[0m  0.0752\n",
            "     23        \u001b[36m0.4768\u001b[0m  0.0816\n",
            "     24        \u001b[36m0.4767\u001b[0m  0.0765\n",
            "     25        0.4801  0.0841\n",
            "     26        0.5013  0.0747\n",
            "     27        0.5020  0.0759\n",
            "     28        0.5013  0.0749\n",
            "     29        0.4832  0.0736\n",
            "     30        0.4872  0.0807\n",
            "     31        0.4867  0.0732\n",
            "     32        0.4783  0.0718\n",
            "     33        0.4791  0.0725\n",
            "     34        0.4969  0.0774\n",
            "     35        0.4874  0.0754\n",
            "     36        0.4877  0.0721\n",
            "     37        0.4907  0.0738\n",
            "     38        0.4854  0.0848\n",
            "     39        \u001b[36m0.4706\u001b[0m  0.0821\n",
            "     40        0.4841  0.0762\n",
            "     41        0.4737  0.0726\n",
            "     42        0.4825  0.0765\n",
            "     43        0.4777  0.0774\n",
            "     44        0.4822  0.0868\n",
            "     45        0.4834  0.0742\n",
            "     46        0.4860  0.0724\n",
            "     47        0.4817  0.0723\n",
            "     48        0.4812  0.0792\n",
            "     49        0.4815  0.0762\n",
            "     50        0.4876  0.0815\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.3094\u001b[0m  0.0717\n",
            "      2        \u001b[36m1.1673\u001b[0m  0.0787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.0680\u001b[0m  0.0830\n",
            "      4        \u001b[36m1.0080\u001b[0m  0.0722\n",
            "      5        \u001b[36m0.9056\u001b[0m  0.0749\n",
            "      6        \u001b[36m0.8568\u001b[0m  0.0780\n",
            "      7        \u001b[36m0.8251\u001b[0m  0.0726\n",
            "      8        \u001b[36m0.7953\u001b[0m  0.0781\n",
            "      9        \u001b[36m0.7738\u001b[0m  0.0736\n",
            "     10        \u001b[36m0.7333\u001b[0m  0.0767\n",
            "     11        \u001b[36m0.7187\u001b[0m  0.0835\n",
            "     12        0.7237  0.0745\n",
            "     13        \u001b[36m0.7094\u001b[0m  0.0793\n",
            "     14        \u001b[36m0.7053\u001b[0m  0.0770\n",
            "     15        \u001b[36m0.7027\u001b[0m  0.0761\n",
            "     16        \u001b[36m0.6963\u001b[0m  0.0709\n",
            "     17        \u001b[36m0.6819\u001b[0m  0.0788\n",
            "     18        \u001b[36m0.6702\u001b[0m  0.0779\n",
            "     19        \u001b[36m0.6653\u001b[0m  0.0763\n",
            "     20        \u001b[36m0.6463\u001b[0m  0.0763\n",
            "     21        \u001b[36m0.6405\u001b[0m  0.0774\n",
            "     22        \u001b[36m0.6361\u001b[0m  0.0882\n",
            "     23        \u001b[36m0.6283\u001b[0m  0.0772\n",
            "     24        0.6378  0.0804\n",
            "     25        0.6413  0.0769\n",
            "     26        0.6353  0.0849\n",
            "     27        \u001b[36m0.6277\u001b[0m  0.0787\n",
            "     28        \u001b[36m0.6213\u001b[0m  0.0810\n",
            "     29        \u001b[36m0.6089\u001b[0m  0.0790\n",
            "     30        \u001b[36m0.6053\u001b[0m  0.0804\n",
            "     31        \u001b[36m0.6007\u001b[0m  0.0772\n",
            "     32        \u001b[36m0.5973\u001b[0m  0.0812\n",
            "     33        \u001b[36m0.5936\u001b[0m  0.0773\n",
            "     34        \u001b[36m0.5792\u001b[0m  0.0764\n",
            "     35        \u001b[36m0.5771\u001b[0m  0.0774\n",
            "     36        \u001b[36m0.5749\u001b[0m  0.0750\n",
            "     37        \u001b[36m0.5739\u001b[0m  0.0811\n",
            "     38        \u001b[36m0.5701\u001b[0m  0.0793\n",
            "     39        \u001b[36m0.5670\u001b[0m  0.0845\n",
            "     40        \u001b[36m0.5628\u001b[0m  0.0773\n",
            "     41        0.5663  0.0738\n",
            "     42        0.5636  0.0923\n",
            "     43        \u001b[36m0.5614\u001b[0m  0.0802\n",
            "     44        0.5634  0.0771\n",
            "     45        \u001b[36m0.5586\u001b[0m  0.0744\n",
            "     46        \u001b[36m0.5547\u001b[0m  0.0757\n",
            "     47        \u001b[36m0.5534\u001b[0m  0.0779\n",
            "     48        \u001b[36m0.5521\u001b[0m  0.0815\n",
            "     49        \u001b[36m0.5511\u001b[0m  0.0781\n",
            "     50        \u001b[36m0.5501\u001b[0m  0.0756\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9764\u001b[0m  0.0790\n",
            "      2        \u001b[36m0.7851\u001b[0m  0.0824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.7046\u001b[0m  0.0819\n",
            "      4        \u001b[36m0.6649\u001b[0m  0.0773\n",
            "      5        \u001b[36m0.6367\u001b[0m  0.0764\n",
            "      6        \u001b[36m0.6171\u001b[0m  0.0790\n",
            "      7        \u001b[36m0.6038\u001b[0m  0.0725\n",
            "      8        \u001b[36m0.5917\u001b[0m  0.0749\n",
            "      9        \u001b[36m0.5828\u001b[0m  0.0837\n",
            "     10        \u001b[36m0.5756\u001b[0m  0.0784\n",
            "     11        \u001b[36m0.5695\u001b[0m  0.0800\n",
            "     12        \u001b[36m0.5650\u001b[0m  0.0761\n",
            "     13        \u001b[36m0.5619\u001b[0m  0.0738\n",
            "     14        0.5636  0.0894\n",
            "     15        0.5686  0.0751\n",
            "     16        \u001b[36m0.5588\u001b[0m  0.0741\n",
            "     17        \u001b[36m0.5551\u001b[0m  0.0761\n",
            "     18        0.5668  0.0751\n",
            "     19        0.5594  0.0725\n",
            "     20        \u001b[36m0.5469\u001b[0m  0.0719\n",
            "     21        0.5477  0.0757\n",
            "     22        0.5515  0.0751\n",
            "     23        0.5518  0.0741\n",
            "     24        0.5501  0.0720\n",
            "     25        0.5499  0.0738\n",
            "     26        0.5482  0.0789\n",
            "     27        0.5469  0.0838\n",
            "     28        0.5486  0.0840\n",
            "     29        \u001b[36m0.5454\u001b[0m  0.0792\n",
            "     30        \u001b[36m0.5427\u001b[0m  0.0755\n",
            "     31        \u001b[36m0.5400\u001b[0m  0.0740\n",
            "     32        \u001b[36m0.5390\u001b[0m  0.0760\n",
            "     33        0.5403  0.0759\n",
            "     34        0.5393  0.0775\n",
            "     35        \u001b[36m0.5384\u001b[0m  0.0824\n",
            "     36        \u001b[36m0.5380\u001b[0m  0.0823\n",
            "     37        \u001b[36m0.5371\u001b[0m  0.0764\n",
            "     38        \u001b[36m0.5359\u001b[0m  0.0791\n",
            "     39        0.5402  0.0827\n",
            "     40        0.5378  0.0824\n",
            "     41        0.5368  0.0734\n",
            "     42        \u001b[36m0.5321\u001b[0m  0.0742\n",
            "     43        \u001b[36m0.5310\u001b[0m  0.0755\n",
            "     44        0.5311  0.0734\n",
            "     45        \u001b[36m0.5305\u001b[0m  0.0748\n",
            "     46        \u001b[36m0.5299\u001b[0m  0.0708\n",
            "     47        \u001b[36m0.5288\u001b[0m  0.0789\n",
            "     48        \u001b[36m0.5274\u001b[0m  0.0732\n",
            "     49        \u001b[36m0.5264\u001b[0m  0.0802\n",
            "     50        \u001b[36m0.5255\u001b[0m  0.0725\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.3653\u001b[0m  0.0698\n",
            "      2        \u001b[36m2.3505\u001b[0m  0.0799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.2597\u001b[0m  0.0866\n",
            "      4        \u001b[36m0.9123\u001b[0m  0.0769\n",
            "      5        \u001b[36m0.8627\u001b[0m  0.0767\n",
            "      6        \u001b[36m0.8104\u001b[0m  0.0829\n",
            "      7        \u001b[36m0.7821\u001b[0m  0.0764\n",
            "      8        \u001b[36m0.7668\u001b[0m  0.0817\n",
            "      9        \u001b[36m0.7446\u001b[0m  0.0810\n",
            "     10        \u001b[36m0.7285\u001b[0m  0.0762\n",
            "     11        \u001b[36m0.7270\u001b[0m  0.0747\n",
            "     12        \u001b[36m0.7113\u001b[0m  0.0787\n",
            "     13        \u001b[36m0.6879\u001b[0m  0.0765\n",
            "     14        \u001b[36m0.6788\u001b[0m  0.0831\n",
            "     15        \u001b[36m0.6672\u001b[0m  0.0861\n",
            "     16        \u001b[36m0.6585\u001b[0m  0.0739\n",
            "     17        \u001b[36m0.6421\u001b[0m  0.0750\n",
            "     18        \u001b[36m0.6376\u001b[0m  0.0763\n",
            "     19        \u001b[36m0.6302\u001b[0m  0.0770\n",
            "     20        \u001b[36m0.6247\u001b[0m  0.0783\n",
            "     21        \u001b[36m0.6108\u001b[0m  0.0759\n",
            "     22        \u001b[36m0.5939\u001b[0m  0.0774\n",
            "     23        \u001b[36m0.5874\u001b[0m  0.0731\n",
            "     24        \u001b[36m0.5814\u001b[0m  0.0838\n",
            "     25        \u001b[36m0.5748\u001b[0m  0.0726\n",
            "     26        \u001b[36m0.5694\u001b[0m  0.0770\n",
            "     27        \u001b[36m0.5635\u001b[0m  0.0918\n",
            "     28        \u001b[36m0.5594\u001b[0m  0.0827\n",
            "     29        \u001b[36m0.5552\u001b[0m  0.0748\n",
            "     30        \u001b[36m0.5508\u001b[0m  0.0809\n",
            "     31        \u001b[36m0.5470\u001b[0m  0.0776\n",
            "     32        \u001b[36m0.5416\u001b[0m  0.0737\n",
            "     33        \u001b[36m0.5392\u001b[0m  0.0734\n",
            "     34        \u001b[36m0.5371\u001b[0m  0.0767\n",
            "     35        \u001b[36m0.5352\u001b[0m  0.0782\n",
            "     36        \u001b[36m0.5334\u001b[0m  0.0734\n",
            "     37        \u001b[36m0.5332\u001b[0m  0.0783\n",
            "     38        \u001b[36m0.5318\u001b[0m  0.0754\n",
            "     39        \u001b[36m0.5305\u001b[0m  0.0773\n",
            "     40        0.5310  0.0739\n",
            "     41        0.5360  0.0832\n",
            "     42        0.5337  0.0764\n",
            "     43        0.5317  0.0731\n",
            "     44        0.5305  0.0740\n",
            "     45        \u001b[36m0.5289\u001b[0m  0.0722\n",
            "     46        \u001b[36m0.5277\u001b[0m  0.0809\n",
            "     47        \u001b[36m0.5262\u001b[0m  0.0731\n",
            "     48        \u001b[36m0.5249\u001b[0m  0.0794\n",
            "     49        \u001b[36m0.5241\u001b[0m  0.0767\n",
            "     50        \u001b[36m0.5228\u001b[0m  0.0763\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.7325\u001b[0m  0.0692\n",
            "      2        \u001b[36m1.3317\u001b[0m  0.0767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.0645\u001b[0m  0.0847\n",
            "      4        \u001b[36m0.8934\u001b[0m  0.0803\n",
            "      5        \u001b[36m0.8203\u001b[0m  0.0809\n",
            "      6        \u001b[36m0.7793\u001b[0m  0.0787\n",
            "      7        \u001b[36m0.7393\u001b[0m  0.0737\n",
            "      8        \u001b[36m0.7056\u001b[0m  0.0749\n",
            "      9        \u001b[36m0.6733\u001b[0m  0.0745\n",
            "     10        \u001b[36m0.6435\u001b[0m  0.0739\n",
            "     11        \u001b[36m0.6178\u001b[0m  0.0811\n",
            "     12        \u001b[36m0.5913\u001b[0m  0.0752\n",
            "     13        \u001b[36m0.5681\u001b[0m  0.0771\n",
            "     14        \u001b[36m0.5501\u001b[0m  0.0787\n",
            "     15        \u001b[36m0.5334\u001b[0m  0.0780\n",
            "     16        \u001b[36m0.5162\u001b[0m  0.0840\n",
            "     17        \u001b[36m0.5054\u001b[0m  0.0752\n",
            "     18        \u001b[36m0.5050\u001b[0m  0.0779\n",
            "     19        \u001b[36m0.4981\u001b[0m  0.0766\n",
            "     20        \u001b[36m0.4964\u001b[0m  0.0748\n",
            "     21        \u001b[36m0.4886\u001b[0m  0.0763\n",
            "     22        \u001b[36m0.4828\u001b[0m  0.0756\n",
            "     23        \u001b[36m0.4784\u001b[0m  0.0892\n",
            "     24        \u001b[36m0.4773\u001b[0m  0.0788\n",
            "     25        \u001b[36m0.4733\u001b[0m  0.0734\n",
            "     26        \u001b[36m0.4694\u001b[0m  0.0752\n",
            "     27        \u001b[36m0.4693\u001b[0m  0.0755\n",
            "     28        \u001b[36m0.4603\u001b[0m  0.0807\n",
            "     29        \u001b[36m0.4587\u001b[0m  0.0849\n",
            "     30        \u001b[36m0.4556\u001b[0m  0.0761\n",
            "     31        \u001b[36m0.4530\u001b[0m  0.0763\n",
            "     32        \u001b[36m0.4505\u001b[0m  0.0771\n",
            "     33        \u001b[36m0.4491\u001b[0m  0.0752\n",
            "     34        \u001b[36m0.4458\u001b[0m  0.0856\n",
            "     35        \u001b[36m0.4414\u001b[0m  0.0762\n",
            "     36        \u001b[36m0.4395\u001b[0m  0.0736\n",
            "     37        0.4423  0.0743\n",
            "     38        0.4468  0.0774\n",
            "     39        0.4441  0.0773\n",
            "     40        0.4433  0.0797\n",
            "     41        0.4438  0.0780\n",
            "     42        0.4415  0.0851\n",
            "     43        \u001b[36m0.4392\u001b[0m  0.0769\n",
            "     44        \u001b[36m0.4377\u001b[0m  0.0771\n",
            "     45        0.4378  0.0758\n",
            "     46        \u001b[36m0.4288\u001b[0m  0.0810\n",
            "     47        0.4331  0.0741\n",
            "     48        \u001b[36m0.4263\u001b[0m  0.0789\n",
            "     49        0.4272  0.0893\n",
            "     50        \u001b[36m0.4256\u001b[0m  0.0738\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0997\u001b[0m  0.0717\n",
            "      2        \u001b[36m0.8994\u001b[0m  0.0754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.8061\u001b[0m  0.0837\n",
            "      4        \u001b[36m0.7608\u001b[0m  0.0815\n",
            "      5        \u001b[36m0.7148\u001b[0m  0.0739\n",
            "      6        \u001b[36m0.6958\u001b[0m  0.0789\n",
            "      7        \u001b[36m0.6814\u001b[0m  0.0750\n",
            "      8        \u001b[36m0.6652\u001b[0m  0.0750\n",
            "      9        \u001b[36m0.6545\u001b[0m  0.0787\n",
            "     10        \u001b[36m0.6536\u001b[0m  0.0831\n",
            "     11        \u001b[36m0.6476\u001b[0m  0.0767\n",
            "     12        \u001b[36m0.6428\u001b[0m  0.0716\n",
            "     13        \u001b[36m0.6382\u001b[0m  0.0810\n",
            "     14        \u001b[36m0.6340\u001b[0m  0.0798\n",
            "     15        \u001b[36m0.6243\u001b[0m  0.0740\n",
            "     16        \u001b[36m0.6199\u001b[0m  0.0753\n",
            "     17        \u001b[36m0.6118\u001b[0m  0.0822\n",
            "     18        \u001b[36m0.6079\u001b[0m  0.0806\n",
            "     19        \u001b[36m0.6044\u001b[0m  0.0762\n",
            "     20        \u001b[36m0.6034\u001b[0m  0.0786\n",
            "     21        \u001b[36m0.6015\u001b[0m  0.0801\n",
            "     22        \u001b[36m0.5945\u001b[0m  0.0767\n",
            "     23        0.5950  0.0764\n",
            "     24        \u001b[36m0.5912\u001b[0m  0.0751\n",
            "     25        \u001b[36m0.5894\u001b[0m  0.0754\n",
            "     26        \u001b[36m0.5877\u001b[0m  0.0809\n",
            "     27        0.5955  0.0747\n",
            "     28        0.5935  0.0812\n",
            "     29        \u001b[36m0.5831\u001b[0m  0.0796\n",
            "     30        \u001b[36m0.5782\u001b[0m  0.0837\n",
            "     31        0.5812  0.0819\n",
            "     32        \u001b[36m0.5614\u001b[0m  0.0818\n",
            "     33        0.6115  0.0763\n",
            "     34        0.5875  0.0763\n",
            "     35        \u001b[36m0.5602\u001b[0m  0.0752\n",
            "     36        0.5617  0.0791\n",
            "     37        \u001b[36m0.5534\u001b[0m  0.0767\n",
            "     38        \u001b[36m0.5362\u001b[0m  0.0805\n",
            "     39        0.5598  0.0833\n",
            "     40        0.5546  0.0749\n",
            "     41        0.5575  0.0744\n",
            "     42        0.5433  0.0834\n",
            "     43        0.5380  0.0779\n",
            "     44        \u001b[36m0.5297\u001b[0m  0.0763\n",
            "     45        0.5478  0.0753\n",
            "     46        0.5461  0.0752\n",
            "     47        0.5531  0.0795\n",
            "     48        0.5467  0.0747\n",
            "     49        0.5347  0.0753\n",
            "     50        0.5312  0.0743\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9618\u001b[0m  0.0729\n",
            "      2        \u001b[36m0.7577\u001b[0m  0.0749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.6582\u001b[0m  0.0858\n",
            "      4        \u001b[36m0.6218\u001b[0m  0.0750\n",
            "      5        \u001b[36m0.5956\u001b[0m  0.0811\n",
            "      6        \u001b[36m0.5826\u001b[0m  0.0822\n",
            "      7        \u001b[36m0.5711\u001b[0m  0.0743\n",
            "      8        \u001b[36m0.5661\u001b[0m  0.0757\n",
            "      9        \u001b[36m0.5603\u001b[0m  0.0865\n",
            "     10        \u001b[36m0.5569\u001b[0m  0.0916\n",
            "     11        \u001b[36m0.5522\u001b[0m  0.0753\n",
            "     12        \u001b[36m0.5512\u001b[0m  0.0769\n",
            "     13        \u001b[36m0.5491\u001b[0m  0.0818\n",
            "     14        \u001b[36m0.5462\u001b[0m  0.0749\n",
            "     15        \u001b[36m0.5426\u001b[0m  0.0724\n",
            "     16        \u001b[36m0.5407\u001b[0m  0.0740\n",
            "     17        0.5407  0.0878\n",
            "     18        \u001b[36m0.5382\u001b[0m  0.0735\n",
            "     19        0.5384  0.0737\n",
            "     20        \u001b[36m0.5377\u001b[0m  0.0784\n",
            "     21        \u001b[36m0.5334\u001b[0m  0.0750\n",
            "     22        \u001b[36m0.5308\u001b[0m  0.0733\n",
            "     23        \u001b[36m0.5299\u001b[0m  0.0767\n",
            "     24        \u001b[36m0.5285\u001b[0m  0.0778\n",
            "     25        \u001b[36m0.5275\u001b[0m  0.0742\n",
            "     26        \u001b[36m0.5264\u001b[0m  0.0770\n",
            "     27        0.5266  0.0838\n",
            "     28        \u001b[36m0.5256\u001b[0m  0.0775\n",
            "     29        0.5329  0.0760\n",
            "     30        0.5414  0.0878\n",
            "     31        0.5393  0.0749\n",
            "     32        0.5380  0.0745\n",
            "     33        0.5370  0.0748\n",
            "     34        0.5359  0.0794\n",
            "     35        0.5340  0.0845\n",
            "     36        0.5341  0.0762\n",
            "     37        0.5332  0.0770\n",
            "     38        0.5322  0.0802\n",
            "     39        0.5462  0.0750\n",
            "     40        0.5640  0.0755\n",
            "     41        \u001b[36m0.5180\u001b[0m  0.0823\n",
            "     42        0.5239  0.0770\n",
            "     43        0.5211  0.0829\n",
            "     44        \u001b[36m0.5173\u001b[0m  0.0770\n",
            "     45        \u001b[36m0.5168\u001b[0m  0.0758\n",
            "     46        0.5171  0.0843\n",
            "     47        0.5191  0.0773\n",
            "     48        \u001b[36m0.5128\u001b[0m  0.0754\n",
            "     49        0.5397  0.0776\n",
            "     50        \u001b[36m0.5112\u001b[0m  0.0823\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.6252\u001b[0m  0.0739\n",
            "      2        \u001b[36m0.9333\u001b[0m  0.0762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.8615\u001b[0m  0.0850\n",
            "      4        \u001b[36m0.8310\u001b[0m  0.0764\n",
            "      5        \u001b[36m0.7796\u001b[0m  0.0848\n",
            "      6        \u001b[36m0.7346\u001b[0m  0.0746\n",
            "      7        \u001b[36m0.6898\u001b[0m  0.0839\n",
            "      8        \u001b[36m0.6639\u001b[0m  0.0775\n",
            "      9        \u001b[36m0.6344\u001b[0m  0.0773\n",
            "     10        \u001b[36m0.6191\u001b[0m  0.0760\n",
            "     11        \u001b[36m0.6062\u001b[0m  0.0758\n",
            "     12        \u001b[36m0.5950\u001b[0m  0.0760\n",
            "     13        \u001b[36m0.5861\u001b[0m  0.0785\n",
            "     14        \u001b[36m0.5803\u001b[0m  0.0746\n",
            "     15        \u001b[36m0.5704\u001b[0m  0.0800\n",
            "     16        \u001b[36m0.5508\u001b[0m  0.0754\n",
            "     17        \u001b[36m0.5403\u001b[0m  0.0788\n",
            "     18        0.5428  0.0822\n",
            "     19        \u001b[36m0.5294\u001b[0m  0.0776\n",
            "     20        \u001b[36m0.5269\u001b[0m  0.0753\n",
            "     21        \u001b[36m0.5239\u001b[0m  0.0751\n",
            "     22        \u001b[36m0.5230\u001b[0m  0.0884\n",
            "     23        0.5249  0.0819\n",
            "     24        \u001b[36m0.5162\u001b[0m  0.0754\n",
            "     25        \u001b[36m0.5151\u001b[0m  0.0797\n",
            "     26        \u001b[36m0.5138\u001b[0m  0.0751\n",
            "     27        \u001b[36m0.5112\u001b[0m  0.0742\n",
            "     28        \u001b[36m0.5095\u001b[0m  0.0753\n",
            "     29        \u001b[36m0.5064\u001b[0m  0.0781\n",
            "     30        0.5100  0.0749\n",
            "     31        \u001b[36m0.5063\u001b[0m  0.0824\n",
            "     32        \u001b[36m0.5038\u001b[0m  0.0765\n",
            "     33        \u001b[36m0.5037\u001b[0m  0.0770\n",
            "     34        0.5201  0.0781\n",
            "     35        \u001b[36m0.4983\u001b[0m  0.0783\n",
            "     36        \u001b[36m0.4914\u001b[0m  0.0755\n",
            "     37        0.5105  0.0749\n",
            "     38        0.5057  0.0754\n",
            "     39        0.5039  0.0766\n",
            "     40        0.5012  0.0760\n",
            "     41        0.5014  0.0733\n",
            "     42        0.4971  0.0744\n",
            "     43        \u001b[36m0.4889\u001b[0m  0.0779\n",
            "     44        \u001b[36m0.4856\u001b[0m  0.0800\n",
            "     45        \u001b[36m0.4843\u001b[0m  0.0885\n",
            "     46        \u001b[36m0.4789\u001b[0m  0.0754\n",
            "     47        \u001b[36m0.4773\u001b[0m  0.0739\n",
            "     48        0.4774  0.0738\n",
            "     49        \u001b[36m0.4702\u001b[0m  0.0737\n",
            "     50        0.4737  0.0812\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.1980\u001b[0m  0.0544\n",
            "      2        1.2511  0.0595\n",
            "      3        \u001b[36m1.1070\u001b[0m  0.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.0592\u001b[0m  0.0759\n",
            "      5        \u001b[36m0.9716\u001b[0m  0.0606\n",
            "      6        \u001b[36m0.8963\u001b[0m  0.0605\n",
            "      7        \u001b[36m0.8479\u001b[0m  0.0618\n",
            "      8        \u001b[36m0.8116\u001b[0m  0.0674\n",
            "      9        \u001b[36m0.7841\u001b[0m  0.0615\n",
            "     10        \u001b[36m0.7627\u001b[0m  0.0607\n",
            "     11        \u001b[36m0.7458\u001b[0m  0.0637\n",
            "     12        \u001b[36m0.7319\u001b[0m  0.0667\n",
            "     13        \u001b[36m0.7202\u001b[0m  0.0600\n",
            "     14        \u001b[36m0.7107\u001b[0m  0.0627\n",
            "     15        \u001b[36m0.7026\u001b[0m  0.0608\n",
            "     16        \u001b[36m0.6960\u001b[0m  0.0616\n",
            "     17        \u001b[36m0.6901\u001b[0m  0.0571\n",
            "     18        \u001b[36m0.6848\u001b[0m  0.0586\n",
            "     19        \u001b[36m0.6801\u001b[0m  0.0577\n",
            "     20        \u001b[36m0.6757\u001b[0m  0.0594\n",
            "     21        \u001b[36m0.6718\u001b[0m  0.0625\n",
            "     22        \u001b[36m0.6681\u001b[0m  0.0617\n",
            "     23        \u001b[36m0.6647\u001b[0m  0.0617\n",
            "     24        \u001b[36m0.6615\u001b[0m  0.0701\n",
            "     25        \u001b[36m0.6586\u001b[0m  0.0668\n",
            "     26        \u001b[36m0.6583\u001b[0m  0.0626\n",
            "     27        \u001b[36m0.6558\u001b[0m  0.0682\n",
            "     28        \u001b[36m0.6534\u001b[0m  0.0609\n",
            "     29        \u001b[36m0.6516\u001b[0m  0.0591\n",
            "     30        \u001b[36m0.6493\u001b[0m  0.0622\n",
            "     31        \u001b[36m0.6474\u001b[0m  0.0611\n",
            "     32        \u001b[36m0.6455\u001b[0m  0.0609\n",
            "     33        \u001b[36m0.6414\u001b[0m  0.0629\n",
            "     34        \u001b[36m0.6397\u001b[0m  0.0600\n",
            "     35        \u001b[36m0.6382\u001b[0m  0.0601\n",
            "     36        \u001b[36m0.6367\u001b[0m  0.0619\n",
            "     37        \u001b[36m0.6353\u001b[0m  0.0610\n",
            "     38        \u001b[36m0.6340\u001b[0m  0.0608\n",
            "     39        \u001b[36m0.6327\u001b[0m  0.0651\n",
            "     40        \u001b[36m0.6315\u001b[0m  0.0630\n",
            "     41        \u001b[36m0.6304\u001b[0m  0.0675\n",
            "     42        \u001b[36m0.6292\u001b[0m  0.0639\n",
            "     43        \u001b[36m0.6282\u001b[0m  0.0602\n",
            "     44        \u001b[36m0.6271\u001b[0m  0.0613\n",
            "     45        \u001b[36m0.6262\u001b[0m  0.0612\n",
            "     46        \u001b[36m0.6252\u001b[0m  0.0618\n",
            "     47        \u001b[36m0.6243\u001b[0m  0.0703\n",
            "     48        \u001b[36m0.6234\u001b[0m  0.0585\n",
            "     49        \u001b[36m0.6225\u001b[0m  0.0584\n",
            "     50        \u001b[36m0.6217\u001b[0m  0.0611\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.6293\u001b[0m  0.0565\n",
            "      2        \u001b[36m1.5330\u001b[0m  0.0653\n",
            "      3        \u001b[36m1.4410\u001b[0m  0.0583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.3614\u001b[0m  0.0692\n",
            "      5        \u001b[36m1.2962\u001b[0m  0.0750\n",
            "      6        \u001b[36m1.2392\u001b[0m  0.0619\n",
            "      7        \u001b[36m1.2073\u001b[0m  0.0636\n",
            "      8        \u001b[36m1.1947\u001b[0m  0.0610\n",
            "      9        \u001b[36m1.1264\u001b[0m  0.0680\n",
            "     10        \u001b[36m1.0747\u001b[0m  0.0608\n",
            "     11        \u001b[36m1.0343\u001b[0m  0.0618\n",
            "     12        \u001b[36m1.0058\u001b[0m  0.0620\n",
            "     13        \u001b[36m0.9515\u001b[0m  0.0600\n",
            "     14        0.9911  0.0625\n",
            "     15        0.9829  0.0593\n",
            "     16        0.9751  0.0617\n",
            "     17        0.9675  0.0626\n",
            "     18        0.9602  0.0626\n",
            "     19        0.9531  0.0606\n",
            "     20        \u001b[36m0.9462\u001b[0m  0.0590\n",
            "     21        \u001b[36m0.9395\u001b[0m  0.0660\n",
            "     22        \u001b[36m0.9330\u001b[0m  0.0610\n",
            "     23        \u001b[36m0.9266\u001b[0m  0.0646\n",
            "     24        \u001b[36m0.9203\u001b[0m  0.0704\n",
            "     25        \u001b[36m0.9142\u001b[0m  0.0602\n",
            "     26        \u001b[36m0.9082\u001b[0m  0.0595\n",
            "     27        \u001b[36m0.9024\u001b[0m  0.0628\n",
            "     28        \u001b[36m0.8967\u001b[0m  0.0630\n",
            "     29        \u001b[36m0.8911\u001b[0m  0.0600\n",
            "     30        \u001b[36m0.8856\u001b[0m  0.0605\n",
            "     31        \u001b[36m0.8802\u001b[0m  0.0623\n",
            "     32        \u001b[36m0.8749\u001b[0m  0.0617\n",
            "     33        \u001b[36m0.8697\u001b[0m  0.0669\n",
            "     34        \u001b[36m0.8646\u001b[0m  0.0703\n",
            "     35        \u001b[36m0.8596\u001b[0m  0.0640\n",
            "     36        \u001b[36m0.8547\u001b[0m  0.0659\n",
            "     37        \u001b[36m0.8499\u001b[0m  0.0656\n",
            "     38        \u001b[36m0.8452\u001b[0m  0.0624\n",
            "     39        \u001b[36m0.8406\u001b[0m  0.0609\n",
            "     40        \u001b[36m0.8360\u001b[0m  0.0606\n",
            "     41        \u001b[36m0.8315\u001b[0m  0.0597\n",
            "     42        \u001b[36m0.8271\u001b[0m  0.0645\n",
            "     43        \u001b[36m0.8228\u001b[0m  0.0626\n",
            "     44        \u001b[36m0.8185\u001b[0m  0.0604\n",
            "     45        \u001b[36m0.8144\u001b[0m  0.0624\n",
            "     46        \u001b[36m0.8103\u001b[0m  0.0610\n",
            "     47        \u001b[36m0.8062\u001b[0m  0.0608\n",
            "     48        \u001b[36m0.8022\u001b[0m  0.0614\n",
            "     49        \u001b[36m0.7983\u001b[0m  0.0620\n",
            "     50        \u001b[36m0.7945\u001b[0m  0.0615\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9884\u001b[0m  0.0621\n",
            "      2        \u001b[36m0.9606\u001b[0m  0.0745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.9232\u001b[0m  0.0654\n",
            "      4        0.9273  0.0642\n",
            "      5        \u001b[36m0.8881\u001b[0m  0.0614\n",
            "      6        \u001b[36m0.8852\u001b[0m  0.0596\n",
            "      7        \u001b[36m0.8059\u001b[0m  0.0612\n",
            "      8        \u001b[36m0.7935\u001b[0m  0.0610\n",
            "      9        \u001b[36m0.7817\u001b[0m  0.0586\n",
            "     10        \u001b[36m0.7704\u001b[0m  0.0606\n",
            "     11        \u001b[36m0.7597\u001b[0m  0.0603\n",
            "     12        \u001b[36m0.7494\u001b[0m  0.0629\n",
            "     13        \u001b[36m0.7395\u001b[0m  0.0597\n",
            "     14        \u001b[36m0.7289\u001b[0m  0.0631\n",
            "     15        \u001b[36m0.7198\u001b[0m  0.0635\n",
            "     16        \u001b[36m0.7090\u001b[0m  0.0600\n",
            "     17        \u001b[36m0.7010\u001b[0m  0.0608\n",
            "     18        \u001b[36m0.6950\u001b[0m  0.0702\n",
            "     19        \u001b[36m0.6877\u001b[0m  0.0675\n",
            "     20        \u001b[36m0.6808\u001b[0m  0.0613\n",
            "     21        \u001b[36m0.6742\u001b[0m  0.0598\n",
            "     22        \u001b[36m0.6679\u001b[0m  0.0605\n",
            "     23        \u001b[36m0.6620\u001b[0m  0.0639\n",
            "     24        \u001b[36m0.6564\u001b[0m  0.0673\n",
            "     25        \u001b[36m0.6465\u001b[0m  0.0601\n",
            "     26        \u001b[36m0.6372\u001b[0m  0.0631\n",
            "     27        \u001b[36m0.6336\u001b[0m  0.0600\n",
            "     28        \u001b[36m0.6281\u001b[0m  0.0609\n",
            "     29        \u001b[36m0.6247\u001b[0m  0.0640\n",
            "     30        \u001b[36m0.6210\u001b[0m  0.0611\n",
            "     31        \u001b[36m0.6174\u001b[0m  0.0603\n",
            "     32        \u001b[36m0.6141\u001b[0m  0.0634\n",
            "     33        \u001b[36m0.6108\u001b[0m  0.0725\n",
            "     34        \u001b[36m0.6077\u001b[0m  0.0694\n",
            "     35        \u001b[36m0.6047\u001b[0m  0.0605\n",
            "     36        \u001b[36m0.6019\u001b[0m  0.0618\n",
            "     37        \u001b[36m0.5991\u001b[0m  0.0608\n",
            "     38        \u001b[36m0.5965\u001b[0m  0.0632\n",
            "     39        \u001b[36m0.5940\u001b[0m  0.0614\n",
            "     40        \u001b[36m0.5915\u001b[0m  0.0611\n",
            "     41        \u001b[36m0.5891\u001b[0m  0.0592\n",
            "     42        \u001b[36m0.5868\u001b[0m  0.0629\n",
            "     43        \u001b[36m0.5845\u001b[0m  0.0598\n",
            "     44        \u001b[36m0.5823\u001b[0m  0.0620\n",
            "     45        \u001b[36m0.5801\u001b[0m  0.0603\n",
            "     46        \u001b[36m0.5780\u001b[0m  0.0621\n",
            "     47        \u001b[36m0.5759\u001b[0m  0.0719\n",
            "     48        \u001b[36m0.5738\u001b[0m  0.0594\n",
            "     49        \u001b[36m0.5718\u001b[0m  0.0687\n",
            "     50        \u001b[36m0.5698\u001b[0m  0.0606\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4640\u001b[0m  0.0554\n",
            "      2        \u001b[36m1.3709\u001b[0m  0.0622\n",
            "      3        1.6705  0.0628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        1.4104  0.0686\n",
            "      5        1.4056  0.0614\n",
            "      6        1.8287  0.0628\n",
            "      7        \u001b[36m1.1275\u001b[0m  0.0567\n",
            "      8        1.2370  0.0598\n",
            "      9        \u001b[36m1.0833\u001b[0m  0.0662\n",
            "     10        \u001b[36m1.0358\u001b[0m  0.0607\n",
            "     11        \u001b[36m0.9936\u001b[0m  0.0607\n",
            "     12        \u001b[36m0.9565\u001b[0m  0.0607\n",
            "     13        \u001b[36m0.9244\u001b[0m  0.0614\n",
            "     14        \u001b[36m0.8971\u001b[0m  0.0657\n",
            "     15        \u001b[36m0.8742\u001b[0m  0.0732\n",
            "     16        \u001b[36m0.8548\u001b[0m  0.0603\n",
            "     17        \u001b[36m0.8382\u001b[0m  0.0602\n",
            "     18        \u001b[36m0.8237\u001b[0m  0.0602\n",
            "     19        \u001b[36m0.8108\u001b[0m  0.0665\n",
            "     20        \u001b[36m0.7992\u001b[0m  0.0610\n",
            "     21        \u001b[36m0.7885\u001b[0m  0.0681\n",
            "     22        \u001b[36m0.7786\u001b[0m  0.0611\n",
            "     23        \u001b[36m0.7693\u001b[0m  0.0621\n",
            "     24        \u001b[36m0.7606\u001b[0m  0.0697\n",
            "     25        \u001b[36m0.7524\u001b[0m  0.0618\n",
            "     26        \u001b[36m0.7446\u001b[0m  0.0609\n",
            "     27        \u001b[36m0.7371\u001b[0m  0.0589\n",
            "     28        \u001b[36m0.7300\u001b[0m  0.0603\n",
            "     29        \u001b[36m0.7233\u001b[0m  0.0661\n",
            "     30        \u001b[36m0.7169\u001b[0m  0.0679\n",
            "     31        \u001b[36m0.7107\u001b[0m  0.0601\n",
            "     32        \u001b[36m0.7049\u001b[0m  0.0593\n",
            "     33        \u001b[36m0.6993\u001b[0m  0.0588\n",
            "     34        \u001b[36m0.6940\u001b[0m  0.0651\n",
            "     35        \u001b[36m0.6890\u001b[0m  0.0648\n",
            "     36        \u001b[36m0.6842\u001b[0m  0.0637\n",
            "     37        \u001b[36m0.6797\u001b[0m  0.0645\n",
            "     38        \u001b[36m0.6754\u001b[0m  0.0589\n",
            "     39        \u001b[36m0.6713\u001b[0m  0.0610\n",
            "     40        \u001b[36m0.6674\u001b[0m  0.0627\n",
            "     41        \u001b[36m0.6637\u001b[0m  0.0612\n",
            "     42        \u001b[36m0.6602\u001b[0m  0.0617\n",
            "     43        \u001b[36m0.6568\u001b[0m  0.0645\n",
            "     44        \u001b[36m0.6536\u001b[0m  0.0647\n",
            "     45        \u001b[36m0.6506\u001b[0m  0.0655\n",
            "     46        \u001b[36m0.6477\u001b[0m  0.0686\n",
            "     47        \u001b[36m0.6449\u001b[0m  0.0630\n",
            "     48        \u001b[36m0.6429\u001b[0m  0.0612\n",
            "     49        \u001b[36m0.6403\u001b[0m  0.0610\n",
            "     50        \u001b[36m0.6379\u001b[0m  0.0625\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9527\u001b[0m  0.0568\n",
            "      2        \u001b[36m0.9144\u001b[0m  0.0673\n",
            "      3        \u001b[36m0.9040\u001b[0m  0.0591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.8952\u001b[0m  0.0704\n",
            "      5        \u001b[36m0.8873\u001b[0m  0.0610\n",
            "      6        \u001b[36m0.8802\u001b[0m  0.0627\n",
            "      7        \u001b[36m0.8737\u001b[0m  0.0602\n",
            "      8        \u001b[36m0.8672\u001b[0m  0.0619\n",
            "      9        \u001b[36m0.8610\u001b[0m  0.0593\n",
            "     10        \u001b[36m0.8556\u001b[0m  0.0598\n",
            "     11        \u001b[36m0.8504\u001b[0m  0.0689\n",
            "     12        \u001b[36m0.8455\u001b[0m  0.0623\n",
            "     13        \u001b[36m0.8408\u001b[0m  0.0603\n",
            "     14        \u001b[36m0.8362\u001b[0m  0.0618\n",
            "     15        \u001b[36m0.8319\u001b[0m  0.0631\n",
            "     16        \u001b[36m0.8277\u001b[0m  0.0652\n",
            "     17        \u001b[36m0.8237\u001b[0m  0.0603\n",
            "     18        \u001b[36m0.8198\u001b[0m  0.0638\n",
            "     19        \u001b[36m0.8160\u001b[0m  0.0750\n",
            "     20        \u001b[36m0.8124\u001b[0m  0.0610\n",
            "     21        \u001b[36m0.8089\u001b[0m  0.0655\n",
            "     22        \u001b[36m0.8069\u001b[0m  0.0629\n",
            "     23        \u001b[36m0.8015\u001b[0m  0.0643\n",
            "     24        \u001b[36m0.7979\u001b[0m  0.0592\n",
            "     25        \u001b[36m0.7949\u001b[0m  0.0677\n",
            "     26        \u001b[36m0.7920\u001b[0m  0.0652\n",
            "     27        \u001b[36m0.7891\u001b[0m  0.0784\n",
            "     28        \u001b[36m0.7820\u001b[0m  0.0581\n",
            "     29        \u001b[36m0.7793\u001b[0m  0.0607\n",
            "     30        0.7811  0.0679\n",
            "     31        \u001b[36m0.7782\u001b[0m  0.0612\n",
            "     32        \u001b[36m0.7756\u001b[0m  0.0584\n",
            "     33        \u001b[36m0.7730\u001b[0m  0.0582\n",
            "     34        \u001b[36m0.7705\u001b[0m  0.0640\n",
            "     35        \u001b[36m0.7681\u001b[0m  0.0608\n",
            "     36        \u001b[36m0.7657\u001b[0m  0.0573\n",
            "     37        \u001b[36m0.7634\u001b[0m  0.0592\n",
            "     38        \u001b[36m0.7612\u001b[0m  0.0582\n",
            "     39        \u001b[36m0.7589\u001b[0m  0.0669\n",
            "     40        \u001b[36m0.7568\u001b[0m  0.0607\n",
            "     41        \u001b[36m0.7547\u001b[0m  0.0576\n",
            "     42        \u001b[36m0.7526\u001b[0m  0.0634\n",
            "     43        \u001b[36m0.7505\u001b[0m  0.0764\n",
            "     44        \u001b[36m0.7485\u001b[0m  0.0625\n",
            "     45        \u001b[36m0.7466\u001b[0m  0.0615\n",
            "     46        \u001b[36m0.7447\u001b[0m  0.0591\n",
            "     47        \u001b[36m0.7428\u001b[0m  0.0624\n",
            "     48        \u001b[36m0.7409\u001b[0m  0.0584\n",
            "     49        \u001b[36m0.7391\u001b[0m  0.0559\n",
            "     50        \u001b[36m0.7373\u001b[0m  0.0624\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.3086\u001b[0m  0.0559\n",
            "      2        1.4205  0.0652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        1.3828  0.0715\n",
            "      4        1.3399  0.0598\n",
            "      5        \u001b[36m1.2994\u001b[0m  0.0631\n",
            "      6        \u001b[36m1.2609\u001b[0m  0.0608\n",
            "      7        \u001b[36m1.2242\u001b[0m  0.0618\n",
            "      8        \u001b[36m1.1890\u001b[0m  0.0688\n",
            "      9        \u001b[36m1.1550\u001b[0m  0.0627\n",
            "     10        \u001b[36m1.1222\u001b[0m  0.0635\n",
            "     11        \u001b[36m1.0894\u001b[0m  0.0639\n",
            "     12        \u001b[36m1.0588\u001b[0m  0.0654\n",
            "     13        \u001b[36m1.0291\u001b[0m  0.0634\n",
            "     14        \u001b[36m1.0005\u001b[0m  0.0595\n",
            "     15        \u001b[36m0.9730\u001b[0m  0.0598\n",
            "     16        \u001b[36m0.9465\u001b[0m  0.0625\n",
            "     17        \u001b[36m0.9212\u001b[0m  0.0636\n",
            "     18        \u001b[36m0.8971\u001b[0m  0.0615\n",
            "     19        \u001b[36m0.8744\u001b[0m  0.0614\n",
            "     20        \u001b[36m0.8531\u001b[0m  0.0654\n",
            "     21        \u001b[36m0.8335\u001b[0m  0.0617\n",
            "     22        \u001b[36m0.8158\u001b[0m  0.0686\n",
            "     23        \u001b[36m0.8001\u001b[0m  0.0617\n",
            "     24        \u001b[36m0.7865\u001b[0m  0.0697\n",
            "     25        \u001b[36m0.7749\u001b[0m  0.0617\n",
            "     26        \u001b[36m0.7652\u001b[0m  0.0638\n",
            "     27        \u001b[36m0.7572\u001b[0m  0.0614\n",
            "     28        \u001b[36m0.7506\u001b[0m  0.0642\n",
            "     29        \u001b[36m0.7451\u001b[0m  0.0604\n",
            "     30        \u001b[36m0.7404\u001b[0m  0.0639\n",
            "     31        \u001b[36m0.7365\u001b[0m  0.0613\n",
            "     32        \u001b[36m0.7330\u001b[0m  0.0619\n",
            "     33        \u001b[36m0.7300\u001b[0m  0.0634\n",
            "     34        \u001b[36m0.7273\u001b[0m  0.0662\n",
            "     35        \u001b[36m0.7248\u001b[0m  0.0683\n",
            "     36        \u001b[36m0.7225\u001b[0m  0.0649\n",
            "     37        \u001b[36m0.7203\u001b[0m  0.0588\n",
            "     38        \u001b[36m0.7182\u001b[0m  0.0630\n",
            "     39        \u001b[36m0.7163\u001b[0m  0.0666\n",
            "     40        \u001b[36m0.7144\u001b[0m  0.0664\n",
            "     41        \u001b[36m0.7126\u001b[0m  0.0643\n",
            "     42        \u001b[36m0.7109\u001b[0m  0.0602\n",
            "     43        \u001b[36m0.7092\u001b[0m  0.0632\n",
            "     44        \u001b[36m0.7076\u001b[0m  0.0603\n",
            "     45        \u001b[36m0.7060\u001b[0m  0.0608\n",
            "     46        \u001b[36m0.7045\u001b[0m  0.0673\n",
            "     47        \u001b[36m0.7030\u001b[0m  0.0621\n",
            "     48        \u001b[36m0.7015\u001b[0m  0.0638\n",
            "     49        \u001b[36m0.7001\u001b[0m  0.0688\n",
            "     50        \u001b[36m0.6987\u001b[0m  0.0607\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.8547\u001b[0m  0.0581\n",
            "      2        \u001b[36m2.3956\u001b[0m  0.0626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m2.3328\u001b[0m  0.0720\n",
            "      4        \u001b[36m2.1867\u001b[0m  0.0660\n",
            "      5        \u001b[36m2.1012\u001b[0m  0.0693\n",
            "      6        2.4950  0.0649\n",
            "      7        2.3771  0.0650\n",
            "      8        2.2703  0.0602\n",
            "      9        2.1766  0.0608\n",
            "     10        2.1471  0.0632\n",
            "     11        \u001b[36m2.0746\u001b[0m  0.0635\n",
            "     12        2.2338  0.0631\n",
            "     13        \u001b[36m2.0605\u001b[0m  0.0631\n",
            "     14        \u001b[36m1.9642\u001b[0m  0.0611\n",
            "     15        \u001b[36m1.8723\u001b[0m  0.0609\n",
            "     16        \u001b[36m1.7851\u001b[0m  0.0622\n",
            "     17        \u001b[36m1.7035\u001b[0m  0.0660\n",
            "     18        \u001b[36m1.6284\u001b[0m  0.0643\n",
            "     19        \u001b[36m1.5602\u001b[0m  0.0638\n",
            "     20        \u001b[36m1.4988\u001b[0m  0.0655\n",
            "     21        \u001b[36m1.4437\u001b[0m  0.0647\n",
            "     22        \u001b[36m1.3941\u001b[0m  0.0599\n",
            "     23        \u001b[36m1.3491\u001b[0m  0.0614\n",
            "     24        \u001b[36m1.3079\u001b[0m  0.0610\n",
            "     25        \u001b[36m1.2699\u001b[0m  0.0616\n",
            "     26        \u001b[36m1.2345\u001b[0m  0.0610\n",
            "     27        \u001b[36m1.2015\u001b[0m  0.0609\n",
            "     28        \u001b[36m1.1706\u001b[0m  0.0599\n",
            "     29        \u001b[36m1.1415\u001b[0m  0.0702\n",
            "     30        \u001b[36m1.1142\u001b[0m  0.0634\n",
            "     31        \u001b[36m1.0885\u001b[0m  0.0657\n",
            "     32        \u001b[36m1.0643\u001b[0m  0.0665\n",
            "     33        \u001b[36m1.0417\u001b[0m  0.0611\n",
            "     34        \u001b[36m1.0204\u001b[0m  0.0627\n",
            "     35        \u001b[36m1.0004\u001b[0m  0.0603\n",
            "     36        \u001b[36m0.9816\u001b[0m  0.0724\n",
            "     37        \u001b[36m0.9640\u001b[0m  0.0610\n",
            "     38        \u001b[36m0.9475\u001b[0m  0.0610\n",
            "     39        \u001b[36m0.9319\u001b[0m  0.0652\n",
            "     40        \u001b[36m0.9172\u001b[0m  0.0621\n",
            "     41        \u001b[36m0.9033\u001b[0m  0.0609\n",
            "     42        \u001b[36m0.8902\u001b[0m  0.0651\n",
            "     43        \u001b[36m0.8778\u001b[0m  0.0610\n",
            "     44        \u001b[36m0.8660\u001b[0m  0.0625\n",
            "     45        \u001b[36m0.8548\u001b[0m  0.0663\n",
            "     46        \u001b[36m0.8441\u001b[0m  0.0645\n",
            "     47        \u001b[36m0.8340\u001b[0m  0.0657\n",
            "     48        \u001b[36m0.8243\u001b[0m  0.0675\n",
            "     49        \u001b[36m0.8152\u001b[0m  0.0626\n",
            "     50        \u001b[36m0.8064\u001b[0m  0.0647\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8234\u001b[0m  0.0657\n",
            "      2        \u001b[36m0.8179\u001b[0m  0.0622\n",
            "      3        \u001b[36m0.8000\u001b[0m  0.0621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.7809\u001b[0m  0.0696\n",
            "      5        \u001b[36m0.7702\u001b[0m  0.0598\n",
            "      6        \u001b[36m0.7628\u001b[0m  0.0626\n",
            "      7        \u001b[36m0.7588\u001b[0m  0.0630\n",
            "      8        \u001b[36m0.7551\u001b[0m  0.0629\n",
            "      9        \u001b[36m0.7516\u001b[0m  0.0613\n",
            "     10        \u001b[36m0.7482\u001b[0m  0.0671\n",
            "     11        \u001b[36m0.7449\u001b[0m  0.0616\n",
            "     12        \u001b[36m0.7419\u001b[0m  0.0613\n",
            "     13        \u001b[36m0.7389\u001b[0m  0.0719\n",
            "     14        \u001b[36m0.7361\u001b[0m  0.0607\n",
            "     15        \u001b[36m0.7335\u001b[0m  0.0664\n",
            "     16        \u001b[36m0.7309\u001b[0m  0.0634\n",
            "     17        \u001b[36m0.7284\u001b[0m  0.0649\n",
            "     18        \u001b[36m0.7261\u001b[0m  0.0611\n",
            "     19        \u001b[36m0.7238\u001b[0m  0.0624\n",
            "     20        \u001b[36m0.7216\u001b[0m  0.0670\n",
            "     21        \u001b[36m0.7195\u001b[0m  0.0642\n",
            "     22        \u001b[36m0.7175\u001b[0m  0.0620\n",
            "     23        \u001b[36m0.7156\u001b[0m  0.0624\n",
            "     24        \u001b[36m0.7137\u001b[0m  0.0625\n",
            "     25        \u001b[36m0.7119\u001b[0m  0.0633\n",
            "     26        \u001b[36m0.7101\u001b[0m  0.0666\n",
            "     27        \u001b[36m0.7084\u001b[0m  0.0648\n",
            "     28        \u001b[36m0.7067\u001b[0m  0.0610\n",
            "     29        \u001b[36m0.7051\u001b[0m  0.0636\n",
            "     30        \u001b[36m0.7036\u001b[0m  0.0623\n",
            "     31        \u001b[36m0.7021\u001b[0m  0.0645\n",
            "     32        \u001b[36m0.7006\u001b[0m  0.0733\n",
            "     33        \u001b[36m0.6992\u001b[0m  0.0617\n",
            "     34        \u001b[36m0.6978\u001b[0m  0.0615\n",
            "     35        \u001b[36m0.6964\u001b[0m  0.0630\n",
            "     36        \u001b[36m0.6951\u001b[0m  0.0706\n",
            "     37        \u001b[36m0.6938\u001b[0m  0.0711\n",
            "     38        \u001b[36m0.6925\u001b[0m  0.0618\n",
            "     39        \u001b[36m0.6913\u001b[0m  0.0596\n",
            "     40        \u001b[36m0.6901\u001b[0m  0.0664\n",
            "     41        \u001b[36m0.6889\u001b[0m  0.0617\n",
            "     42        \u001b[36m0.6878\u001b[0m  0.0617\n",
            "     43        \u001b[36m0.6867\u001b[0m  0.0668\n",
            "     44        \u001b[36m0.6856\u001b[0m  0.0612\n",
            "     45        \u001b[36m0.6845\u001b[0m  0.0625\n",
            "     46        \u001b[36m0.6835\u001b[0m  0.0656\n",
            "     47        \u001b[36m0.6824\u001b[0m  0.0693\n",
            "     48        \u001b[36m0.6814\u001b[0m  0.0621\n",
            "     49        \u001b[36m0.6805\u001b[0m  0.0644\n",
            "     50        \u001b[36m0.6795\u001b[0m  0.0609\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6727\u001b[0m  0.0559\n",
            "      2        \u001b[36m0.6644\u001b[0m  0.0654\n",
            "      3        \u001b[36m0.6608\u001b[0m  0.0666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.6581\u001b[0m  0.0701\n",
            "      5        \u001b[36m0.6557\u001b[0m  0.0616\n",
            "      6        \u001b[36m0.6537\u001b[0m  0.0639\n",
            "      7        \u001b[36m0.6518\u001b[0m  0.0618\n",
            "      8        \u001b[36m0.6501\u001b[0m  0.0689\n",
            "      9        \u001b[36m0.6487\u001b[0m  0.0645\n",
            "     10        \u001b[36m0.6474\u001b[0m  0.0608\n",
            "     11        \u001b[36m0.6461\u001b[0m  0.0618\n",
            "     12        \u001b[36m0.6450\u001b[0m  0.0611\n",
            "     13        \u001b[36m0.6439\u001b[0m  0.0636\n",
            "     14        \u001b[36m0.6428\u001b[0m  0.0656\n",
            "     15        \u001b[36m0.6418\u001b[0m  0.0593\n",
            "     16        \u001b[36m0.6409\u001b[0m  0.0603\n",
            "     17        \u001b[36m0.6399\u001b[0m  0.0632\n",
            "     18        \u001b[36m0.6391\u001b[0m  0.0597\n",
            "     19        \u001b[36m0.6382\u001b[0m  0.0597\n",
            "     20        \u001b[36m0.6374\u001b[0m  0.0603\n",
            "     21        \u001b[36m0.6366\u001b[0m  0.0620\n",
            "     22        \u001b[36m0.6359\u001b[0m  0.0646\n",
            "     23        \u001b[36m0.6352\u001b[0m  0.0619\n",
            "     24        \u001b[36m0.6345\u001b[0m  0.0679\n",
            "     25        \u001b[36m0.6338\u001b[0m  0.0622\n",
            "     26        \u001b[36m0.6332\u001b[0m  0.0639\n",
            "     27        \u001b[36m0.6326\u001b[0m  0.0644\n",
            "     28        \u001b[36m0.6320\u001b[0m  0.0700\n",
            "     29        \u001b[36m0.6315\u001b[0m  0.0626\n",
            "     30        \u001b[36m0.6309\u001b[0m  0.0607\n",
            "     31        \u001b[36m0.6304\u001b[0m  0.0635\n",
            "     32        \u001b[36m0.6299\u001b[0m  0.0643\n",
            "     33        \u001b[36m0.6294\u001b[0m  0.0635\n",
            "     34        \u001b[36m0.6289\u001b[0m  0.0650\n",
            "     35        \u001b[36m0.6285\u001b[0m  0.0607\n",
            "     36        \u001b[36m0.6280\u001b[0m  0.0675\n",
            "     37        \u001b[36m0.6276\u001b[0m  0.0654\n",
            "     38        \u001b[36m0.6272\u001b[0m  0.0608\n",
            "     39        \u001b[36m0.6268\u001b[0m  0.0623\n",
            "     40        \u001b[36m0.6264\u001b[0m  0.0627\n",
            "     41        \u001b[36m0.6261\u001b[0m  0.0630\n",
            "     42        \u001b[36m0.6257\u001b[0m  0.0640\n",
            "     43        \u001b[36m0.6253\u001b[0m  0.0602\n",
            "     44        \u001b[36m0.6250\u001b[0m  0.0676\n",
            "     45        \u001b[36m0.6247\u001b[0m  0.0687\n",
            "     46        \u001b[36m0.6244\u001b[0m  0.0613\n",
            "     47        \u001b[36m0.6240\u001b[0m  0.0590\n",
            "     48        \u001b[36m0.6237\u001b[0m  0.0626\n",
            "     49        \u001b[36m0.6234\u001b[0m  0.0600\n",
            "     50        \u001b[36m0.6232\u001b[0m  0.0679\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2186\u001b[0m  0.0530\n",
            "      2        \u001b[36m2.0553\u001b[0m  0.0758\n",
            "      3        \u001b[36m1.9719\u001b[0m  0.0614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.8401\u001b[0m  0.0702\n",
            "      5        \u001b[36m1.4598\u001b[0m  0.0606\n",
            "      6        \u001b[36m1.1792\u001b[0m  0.0697\n",
            "      7        \u001b[36m1.1466\u001b[0m  0.0634\n",
            "      8        \u001b[36m1.1177\u001b[0m  0.0598\n",
            "      9        \u001b[36m1.0520\u001b[0m  0.0706\n",
            "     10        \u001b[36m1.0359\u001b[0m  0.0590\n",
            "     11        \u001b[36m1.0216\u001b[0m  0.0610\n",
            "     12        \u001b[36m1.0087\u001b[0m  0.0624\n",
            "     13        \u001b[36m0.9968\u001b[0m  0.0619\n",
            "     14        \u001b[36m0.9858\u001b[0m  0.0616\n",
            "     15        \u001b[36m0.9756\u001b[0m  0.0627\n",
            "     16        \u001b[36m0.9661\u001b[0m  0.0607\n",
            "     17        \u001b[36m0.9573\u001b[0m  0.0600\n",
            "     18        \u001b[36m0.9490\u001b[0m  0.0720\n",
            "     19        \u001b[36m0.9412\u001b[0m  0.0609\n",
            "     20        \u001b[36m0.9339\u001b[0m  0.0642\n",
            "     21        \u001b[36m0.9270\u001b[0m  0.0610\n",
            "     22        \u001b[36m0.9204\u001b[0m  0.0612\n",
            "     23        \u001b[36m0.9142\u001b[0m  0.0617\n",
            "     24        \u001b[36m0.9083\u001b[0m  0.0591\n",
            "     25        \u001b[36m0.9027\u001b[0m  0.0705\n",
            "     26        \u001b[36m0.8973\u001b[0m  0.0601\n",
            "     27        \u001b[36m0.8922\u001b[0m  0.0598\n",
            "     28        \u001b[36m0.8872\u001b[0m  0.0599\n",
            "     29        \u001b[36m0.8825\u001b[0m  0.0601\n",
            "     30        \u001b[36m0.8779\u001b[0m  0.0595\n",
            "     31        \u001b[36m0.8734\u001b[0m  0.0636\n",
            "     32        \u001b[36m0.8691\u001b[0m  0.0687\n",
            "     33        \u001b[36m0.8649\u001b[0m  0.0609\n",
            "     34        \u001b[36m0.8608\u001b[0m  0.0621\n",
            "     35        \u001b[36m0.8568\u001b[0m  0.0616\n",
            "     36        \u001b[36m0.8529\u001b[0m  0.0636\n",
            "     37        \u001b[36m0.8492\u001b[0m  0.0686\n",
            "     38        \u001b[36m0.8455\u001b[0m  0.0599\n",
            "     39        \u001b[36m0.8418\u001b[0m  0.0603\n",
            "     40        \u001b[36m0.8383\u001b[0m  0.0608\n",
            "     41        \u001b[36m0.8348\u001b[0m  0.0713\n",
            "     42        \u001b[36m0.8314\u001b[0m  0.0612\n",
            "     43        \u001b[36m0.8280\u001b[0m  0.0678\n",
            "     44        \u001b[36m0.8247\u001b[0m  0.0633\n",
            "     45        \u001b[36m0.8214\u001b[0m  0.0616\n",
            "     46        \u001b[36m0.8182\u001b[0m  0.0657\n",
            "     47        \u001b[36m0.8150\u001b[0m  0.0654\n",
            "     48        \u001b[36m0.8119\u001b[0m  0.0609\n",
            "     49        \u001b[36m0.8088\u001b[0m  0.0615\n",
            "     50        \u001b[36m0.8058\u001b[0m  0.0619\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0735\n",
            "      2       37.1094  0.0777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.1094  0.0859\n",
            "      4       37.1094  0.0747\n",
            "      5       37.1094  0.0801\n",
            "      6       37.1094  0.0736\n",
            "      7       37.1094  0.0761\n",
            "      8       37.1094  0.0728\n",
            "      9       37.1094  0.0759\n",
            "     10       37.1094  0.0732\n",
            "     11       37.1094  0.0758\n",
            "     12       37.1094  0.0809\n",
            "     13       37.1094  0.0800\n",
            "     14       37.1094  0.0751\n",
            "     15       37.1094  0.0782\n",
            "     16       37.1094  0.0783\n",
            "     17       37.1094  0.0772\n",
            "     18       37.1094  0.0839\n",
            "     19       37.1094  0.0758\n",
            "     20       37.1094  0.0771\n",
            "     21       37.1094  0.0825\n",
            "     22       37.1094  0.0741\n",
            "     23       \u001b[36m12.9720\u001b[0m  0.0898\n",
            "     24        \u001b[36m0.5554\u001b[0m  0.0768\n",
            "     25        \u001b[36m0.5187\u001b[0m  0.0782\n",
            "     26        \u001b[36m0.4891\u001b[0m  0.0778\n",
            "     27        \u001b[36m0.4764\u001b[0m  0.0787\n",
            "     28        \u001b[36m0.4647\u001b[0m  0.0759\n",
            "     29        \u001b[36m0.4546\u001b[0m  0.0789\n",
            "     30        \u001b[36m0.4451\u001b[0m  0.0787\n",
            "     31        \u001b[36m0.4368\u001b[0m  0.0777\n",
            "     32        \u001b[36m0.4277\u001b[0m  0.0790\n",
            "     33        \u001b[36m0.4187\u001b[0m  0.0805\n",
            "     34        \u001b[36m0.4104\u001b[0m  0.0899\n",
            "     35        \u001b[36m0.4019\u001b[0m  0.0759\n",
            "     36        \u001b[36m0.3932\u001b[0m  0.0757\n",
            "     37        \u001b[36m0.3858\u001b[0m  0.0771\n",
            "     38        \u001b[36m0.3775\u001b[0m  0.0769\n",
            "     39        \u001b[36m0.3703\u001b[0m  0.0775\n",
            "     40        \u001b[36m0.3648\u001b[0m  0.0774\n",
            "     41        \u001b[36m0.3570\u001b[0m  0.0904\n",
            "     42        \u001b[36m0.3518\u001b[0m  0.0779\n",
            "     43        \u001b[36m0.3454\u001b[0m  0.0849\n",
            "     44        \u001b[36m0.3367\u001b[0m  0.0803\n",
            "     45        \u001b[36m0.3323\u001b[0m  0.0759\n",
            "     46        \u001b[36m0.3263\u001b[0m  0.0769\n",
            "     47        \u001b[36m0.3176\u001b[0m  0.0758\n",
            "     48        \u001b[36m0.3134\u001b[0m  0.0763\n",
            "     49        \u001b[36m0.3068\u001b[0m  0.0842\n",
            "     50        \u001b[36m0.3041\u001b[0m  0.0781\n",
            "     51        \u001b[36m0.2948\u001b[0m  0.0765\n",
            "     52        \u001b[36m0.2936\u001b[0m  0.0772\n",
            "     53        \u001b[36m0.2905\u001b[0m  0.0798\n",
            "     54        \u001b[36m0.2860\u001b[0m  0.0790\n",
            "     55        \u001b[36m0.2790\u001b[0m  0.0805\n",
            "     56        \u001b[36m0.2775\u001b[0m  0.0767\n",
            "     57        \u001b[36m0.2695\u001b[0m  0.0788\n",
            "     58        \u001b[36m0.2660\u001b[0m  0.0742\n",
            "     59        \u001b[36m0.2597\u001b[0m  0.0741\n",
            "     60        \u001b[36m0.2590\u001b[0m  0.0819\n",
            "     61        \u001b[36m0.2533\u001b[0m  0.0782\n",
            "     62        \u001b[36m0.2461\u001b[0m  0.0748\n",
            "     63        0.2476  0.0760\n",
            "     64        \u001b[36m0.2388\u001b[0m  0.0827\n",
            "     65        \u001b[36m0.2372\u001b[0m  0.0773\n",
            "     66        \u001b[36m0.2329\u001b[0m  0.0753\n",
            "     67        \u001b[36m0.2309\u001b[0m  0.0772\n",
            "     68        \u001b[36m0.2253\u001b[0m  0.0882\n",
            "     69        \u001b[36m0.2183\u001b[0m  0.0891\n",
            "     70        0.2219  0.0756\n",
            "     71        \u001b[36m0.2151\u001b[0m  0.0781\n",
            "     72        \u001b[36m0.2092\u001b[0m  0.0785\n",
            "     73        0.2154  0.0746\n",
            "     74        0.2161  0.0730\n",
            "     75        \u001b[36m0.2025\u001b[0m  0.0736\n",
            "     76        \u001b[36m0.1929\u001b[0m  0.0831\n",
            "     77        0.2012  0.0727\n",
            "     78        0.2191  0.0747\n",
            "     79        0.1993  0.0724\n",
            "     80        0.1984  0.0751\n",
            "     81        0.1951  0.0847\n",
            "     82        \u001b[36m0.1898\u001b[0m  0.0750\n",
            "     83        0.1917  0.0748\n",
            "     84        \u001b[36m0.1874\u001b[0m  0.0777\n",
            "     85        \u001b[36m0.1800\u001b[0m  0.0761\n",
            "     86        \u001b[36m0.1793\u001b[0m  0.0824\n",
            "     87        0.1870  0.0751\n",
            "     88        0.1858  0.0766\n",
            "     89        \u001b[36m0.1770\u001b[0m  0.0776\n",
            "     90        0.1785  0.0751\n",
            "     91        \u001b[36m0.1746\u001b[0m  0.0761\n",
            "     92        \u001b[36m0.1704\u001b[0m  0.0725\n",
            "     93        0.1731  0.0773\n",
            "     94        \u001b[36m0.1670\u001b[0m  0.0876\n",
            "     95        \u001b[36m0.1625\u001b[0m  0.0740\n",
            "     96        0.1630  0.0770\n",
            "     97        0.1670  0.0740\n",
            "     98        0.1630  0.0785\n",
            "     99        \u001b[36m0.1562\u001b[0m  0.0766\n",
            "    100        0.1619  0.0752\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0770\n",
            "      2       37.1094  0.0742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.1094  0.0846\n",
            "      4       37.1094  0.0714\n",
            "      5       37.1094  0.0741\n",
            "      6       37.1094  0.0732\n",
            "      7       37.1094  0.0836\n",
            "      8       37.1094  0.0738\n",
            "      9       37.1094  0.0814\n",
            "     10       37.1094  0.0747\n",
            "     11       37.1094  0.0750\n",
            "     12       37.1094  0.0749\n",
            "     13       37.1094  0.0740\n",
            "     14       37.1094  0.0790\n",
            "     15       37.1094  0.0798\n",
            "     16       37.1094  0.0787\n",
            "     17       37.1094  0.0799\n",
            "     18       37.1094  0.0791\n",
            "     19       37.1094  0.0851\n",
            "     20       37.1094  0.0744\n",
            "     21       37.1094  0.0804\n",
            "     22       37.1094  0.0778\n",
            "     23       \u001b[36m14.3968\u001b[0m  0.0824\n",
            "     24        \u001b[36m0.6872\u001b[0m  0.0798\n",
            "     25        \u001b[36m0.6811\u001b[0m  0.0751\n",
            "     26        \u001b[36m0.6770\u001b[0m  0.0791\n",
            "     27        \u001b[36m0.6741\u001b[0m  0.0734\n",
            "     28        \u001b[36m0.6718\u001b[0m  0.0771\n",
            "     29        \u001b[36m0.6700\u001b[0m  0.0742\n",
            "     30        \u001b[36m0.6685\u001b[0m  0.0810\n",
            "     31        \u001b[36m0.6673\u001b[0m  0.0761\n",
            "     32        \u001b[36m0.6663\u001b[0m  0.0830\n",
            "     33        \u001b[36m0.6655\u001b[0m  0.0777\n",
            "     34        \u001b[36m0.6647\u001b[0m  0.0746\n",
            "     35        \u001b[36m0.6641\u001b[0m  0.0761\n",
            "     36        \u001b[36m0.6636\u001b[0m  0.0784\n",
            "     37        \u001b[36m0.6632\u001b[0m  0.0788\n",
            "     38        \u001b[36m0.6628\u001b[0m  0.0812\n",
            "     39        \u001b[36m0.6624\u001b[0m  0.0767\n",
            "     40        \u001b[36m0.6621\u001b[0m  0.0774\n",
            "     41        \u001b[36m0.6619\u001b[0m  0.0753\n",
            "     42        \u001b[36m0.6617\u001b[0m  0.0763\n",
            "     43        \u001b[36m0.6615\u001b[0m  0.0735\n",
            "     44        \u001b[36m0.6613\u001b[0m  0.0778\n",
            "     45        \u001b[36m0.6611\u001b[0m  0.0806\n",
            "     46        \u001b[36m0.6610\u001b[0m  0.0803\n",
            "     47        \u001b[36m0.6609\u001b[0m  0.0813\n",
            "     48        \u001b[36m0.6608\u001b[0m  0.0770\n",
            "     49        \u001b[36m0.6607\u001b[0m  0.0736\n",
            "     50        \u001b[36m0.6606\u001b[0m  0.0729\n",
            "     51        \u001b[36m0.6605\u001b[0m  0.0773\n",
            "     52        \u001b[36m0.6604\u001b[0m  0.0817\n",
            "     53        \u001b[36m0.6604\u001b[0m  0.0791\n",
            "     54        \u001b[36m0.6603\u001b[0m  0.0815\n",
            "     55        \u001b[36m0.6603\u001b[0m  0.0768\n",
            "     56        \u001b[36m0.6602\u001b[0m  0.0777\n",
            "     57        \u001b[36m0.6602\u001b[0m  0.0799\n",
            "     58        \u001b[36m0.6602\u001b[0m  0.0904\n",
            "     59        \u001b[36m0.6601\u001b[0m  0.0756\n",
            "     60        \u001b[36m0.6601\u001b[0m  0.0831\n",
            "     61        \u001b[36m0.6601\u001b[0m  0.0793\n",
            "     62        \u001b[36m0.6601\u001b[0m  0.0762\n",
            "     63        \u001b[36m0.6600\u001b[0m  0.0760\n",
            "     64        \u001b[36m0.6600\u001b[0m  0.0768\n",
            "     65        \u001b[36m0.6600\u001b[0m  0.0776\n",
            "     66        \u001b[36m0.6600\u001b[0m  0.0761\n",
            "     67        \u001b[36m0.6600\u001b[0m  0.0829\n",
            "     68        \u001b[36m0.6600\u001b[0m  0.0764\n",
            "     69        \u001b[36m0.6600\u001b[0m  0.0763\n",
            "     70        \u001b[36m0.6599\u001b[0m  0.0832\n",
            "     71        \u001b[36m0.6599\u001b[0m  0.0755\n",
            "     72        \u001b[36m0.6599\u001b[0m  0.0782\n",
            "     73        \u001b[36m0.6599\u001b[0m  0.0823\n",
            "     74        \u001b[36m0.6599\u001b[0m  0.0759\n",
            "     75        \u001b[36m0.6599\u001b[0m  0.0875\n",
            "     76        \u001b[36m0.6599\u001b[0m  0.0866\n",
            "     77        \u001b[36m0.6599\u001b[0m  0.0749\n",
            "     78        \u001b[36m0.6599\u001b[0m  0.0727\n",
            "     79        \u001b[36m0.6599\u001b[0m  0.0713\n",
            "     80        \u001b[36m0.6599\u001b[0m  0.0738\n",
            "     81        \u001b[36m0.6599\u001b[0m  0.0772\n",
            "     82        \u001b[36m0.6599\u001b[0m  0.0749\n",
            "     83        \u001b[36m0.6599\u001b[0m  0.0835\n",
            "     84        \u001b[36m0.6599\u001b[0m  0.0869\n",
            "     85        \u001b[36m0.6599\u001b[0m  0.0791\n",
            "     86        \u001b[36m0.6599\u001b[0m  0.0756\n",
            "     87        \u001b[36m0.6599\u001b[0m  0.0792\n",
            "     88        \u001b[36m0.6599\u001b[0m  0.0788\n",
            "     89        \u001b[36m0.6599\u001b[0m  0.0740\n",
            "     90        \u001b[36m0.6599\u001b[0m  0.0758\n",
            "     91        \u001b[36m0.6599\u001b[0m  0.0794\n",
            "     92        \u001b[36m0.6599\u001b[0m  0.0779\n",
            "     93        \u001b[36m0.6599\u001b[0m  0.0791\n",
            "     94        \u001b[36m0.6599\u001b[0m  0.0790\n",
            "     95        \u001b[36m0.6599\u001b[0m  0.0839\n",
            "     96        \u001b[36m0.6599\u001b[0m  0.0804\n",
            "     97        \u001b[36m0.6599\u001b[0m  0.0868\n",
            "     98        \u001b[36m0.6599\u001b[0m  0.0804\n",
            "     99        \u001b[36m0.6599\u001b[0m  0.0795\n",
            "    100        \u001b[36m0.6599\u001b[0m  0.0776\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0721\n",
            "      2       37.3047  0.0826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0836\n",
            "      4       37.3047  0.0744\n",
            "      5       37.3047  0.0750\n",
            "      6       37.3047  0.0794\n",
            "      7       37.3047  0.0747\n",
            "      8       37.3047  0.0840\n",
            "      9       37.3047  0.0748\n",
            "     10       37.3047  0.0903\n",
            "     11       37.3047  0.0771\n",
            "     12       37.3047  0.0778\n",
            "     13       37.3047  0.0761\n",
            "     14       37.3047  0.0714\n",
            "     15       37.3047  0.0744\n",
            "     16       37.3047  0.0726\n",
            "     17       37.3047  0.0767\n",
            "     18       37.3047  0.0756\n",
            "     19       37.3047  0.0767\n",
            "     20       37.3047  0.0748\n",
            "     21       37.3047  0.0817\n",
            "     22       \u001b[36m15.0707\u001b[0m  0.0803\n",
            "     23        \u001b[36m0.5443\u001b[0m  0.0822\n",
            "     24        \u001b[36m0.5336\u001b[0m  0.0732\n",
            "     25        \u001b[36m0.5141\u001b[0m  0.0791\n",
            "     26        \u001b[36m0.5014\u001b[0m  0.0769\n",
            "     27        \u001b[36m0.4883\u001b[0m  0.0763\n",
            "     28        \u001b[36m0.4735\u001b[0m  0.0764\n",
            "     29        \u001b[36m0.4576\u001b[0m  0.0770\n",
            "     30        \u001b[36m0.4436\u001b[0m  0.0773\n",
            "     31        \u001b[36m0.4310\u001b[0m  0.0807\n",
            "     32        \u001b[36m0.4176\u001b[0m  0.0777\n",
            "     33        \u001b[36m0.4063\u001b[0m  0.0929\n",
            "     34        \u001b[36m0.3952\u001b[0m  0.0787\n",
            "     35        \u001b[36m0.3863\u001b[0m  0.0750\n",
            "     36        \u001b[36m0.3769\u001b[0m  0.0756\n",
            "     37        \u001b[36m0.3691\u001b[0m  0.0782\n",
            "     38        \u001b[36m0.3629\u001b[0m  0.0794\n",
            "     39        \u001b[36m0.3557\u001b[0m  0.0741\n",
            "     40        \u001b[36m0.3489\u001b[0m  0.0748\n",
            "     41        \u001b[36m0.3416\u001b[0m  0.0769\n",
            "     42        \u001b[36m0.3354\u001b[0m  0.0759\n",
            "     43        \u001b[36m0.3302\u001b[0m  0.0766\n",
            "     44        \u001b[36m0.3231\u001b[0m  0.0820\n",
            "     45        \u001b[36m0.3173\u001b[0m  0.0754\n",
            "     46        \u001b[36m0.3119\u001b[0m  0.0859\n",
            "     47        \u001b[36m0.3067\u001b[0m  0.0743\n",
            "     48        \u001b[36m0.3015\u001b[0m  0.0817\n",
            "     49        \u001b[36m0.2970\u001b[0m  0.0749\n",
            "     50        \u001b[36m0.2925\u001b[0m  0.0797\n",
            "     51        \u001b[36m0.2885\u001b[0m  0.0770\n",
            "     52        \u001b[36m0.2850\u001b[0m  0.0853\n",
            "     53        \u001b[36m0.2811\u001b[0m  0.0753\n",
            "     54        \u001b[36m0.2780\u001b[0m  0.0771\n",
            "     55        \u001b[36m0.2736\u001b[0m  0.0762\n",
            "     56        \u001b[36m0.2680\u001b[0m  0.0807\n",
            "     57        \u001b[36m0.2644\u001b[0m  0.0764\n",
            "     58        \u001b[36m0.2594\u001b[0m  0.0824\n",
            "     59        \u001b[36m0.2557\u001b[0m  0.0931\n",
            "     60        \u001b[36m0.2524\u001b[0m  0.0781\n",
            "     61        \u001b[36m0.2493\u001b[0m  0.0749\n",
            "     62        \u001b[36m0.2434\u001b[0m  0.0835\n",
            "     63        \u001b[36m0.2403\u001b[0m  0.0766\n",
            "     64        \u001b[36m0.2367\u001b[0m  0.0751\n",
            "     65        \u001b[36m0.2351\u001b[0m  0.0807\n",
            "     66        \u001b[36m0.2314\u001b[0m  0.0751\n",
            "     67        \u001b[36m0.2294\u001b[0m  0.0795\n",
            "     68        \u001b[36m0.2283\u001b[0m  0.0785\n",
            "     69        \u001b[36m0.2248\u001b[0m  0.0752\n",
            "     70        \u001b[36m0.2224\u001b[0m  0.0803\n",
            "     71        \u001b[36m0.2206\u001b[0m  0.0842\n",
            "     72        \u001b[36m0.2187\u001b[0m  0.0781\n",
            "     73        \u001b[36m0.2165\u001b[0m  0.0864\n",
            "     74        \u001b[36m0.2156\u001b[0m  0.0768\n",
            "     75        \u001b[36m0.2111\u001b[0m  0.0797\n",
            "     76        0.2121  0.0763\n",
            "     77        \u001b[36m0.2090\u001b[0m  0.0741\n",
            "     78        \u001b[36m0.2073\u001b[0m  0.0788\n",
            "     79        \u001b[36m0.2038\u001b[0m  0.0770\n",
            "     80        0.2055  0.0796\n",
            "     81        \u001b[36m0.2013\u001b[0m  0.0857\n",
            "     82        \u001b[36m0.2002\u001b[0m  0.0801\n",
            "     83        \u001b[36m0.1993\u001b[0m  0.0826\n",
            "     84        \u001b[36m0.1988\u001b[0m  0.0740\n",
            "     85        \u001b[36m0.1954\u001b[0m  0.0748\n",
            "     86        0.1955  0.0791\n",
            "     87        \u001b[36m0.1941\u001b[0m  0.0799\n",
            "     88        \u001b[36m0.1924\u001b[0m  0.0812\n",
            "     89        0.1951  0.0756\n",
            "     90        0.1930  0.0763\n",
            "     91        \u001b[36m0.1906\u001b[0m  0.0751\n",
            "     92        0.1919  0.0760\n",
            "     93        \u001b[36m0.1881\u001b[0m  0.0797\n",
            "     94        \u001b[36m0.1866\u001b[0m  0.0826\n",
            "     95        \u001b[36m0.1866\u001b[0m  0.0745\n",
            "     96        \u001b[36m0.1829\u001b[0m  0.0920\n",
            "     97        \u001b[36m0.1812\u001b[0m  0.0770\n",
            "     98        \u001b[36m0.1802\u001b[0m  0.0783\n",
            "     99        \u001b[36m0.1788\u001b[0m  0.0793\n",
            "    100        \u001b[36m0.1768\u001b[0m  0.0767\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0725\n",
            "      2       37.3047  0.0725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0838\n",
            "      4       37.3047  0.0729\n",
            "      5       37.3047  0.0940\n",
            "      6       37.3047  0.0745\n",
            "      7       37.3047  0.0836\n",
            "      8       37.3047  0.0800\n",
            "      9       37.3047  0.0791\n",
            "     10       37.3047  0.0761\n",
            "     11       37.3047  0.0793\n",
            "     12       37.3047  0.0731\n",
            "     13       37.3047  0.0731\n",
            "     14       37.3047  0.0733\n",
            "     15       37.3047  0.0751\n",
            "     16       37.3047  0.0823\n",
            "     17       37.3047  0.0758\n",
            "     18       37.3047  0.0799\n",
            "     19       37.3047  0.0867\n",
            "     20       37.3047  0.0754\n",
            "     21       37.3047  0.0833\n",
            "     22       37.3047  0.0750\n",
            "     23       37.3047  0.0812\n",
            "     24       37.3047  0.0773\n",
            "     25       37.3047  0.0731\n",
            "     26       37.3047  0.0789\n",
            "     27       37.3047  0.0760\n",
            "     28       37.3047  0.0742\n",
            "     29       37.3047  0.0790\n",
            "     30       37.3047  0.0765\n",
            "     31       37.3047  0.0748\n",
            "     32       37.3047  0.0770\n",
            "     33       37.3047  0.0788\n",
            "     34       37.3047  0.0868\n",
            "     35       37.3047  0.0826\n",
            "     36       37.3047  0.0777\n",
            "     37       37.3047  0.0744\n",
            "     38       37.3047  0.0745\n",
            "     39       37.3047  0.0760\n",
            "     40       37.3047  0.0743\n",
            "     41       37.3047  0.0752\n",
            "     42       37.3047  0.0779\n",
            "     43       37.3047  0.0781\n",
            "     44       37.3047  0.0751\n",
            "     45       37.3047  0.0822\n",
            "     46       37.3047  0.0759\n",
            "     47       37.3047  0.0778\n",
            "     48       37.3047  0.0751\n",
            "     49       37.3047  0.0813\n",
            "     50       37.3047  0.0740\n",
            "     51       37.3047  0.0740\n",
            "     52       37.3047  0.0824\n",
            "     53       37.3047  0.0756\n",
            "     54       37.3047  0.0748\n",
            "     55       37.3047  0.0789\n",
            "     56       37.3047  0.0821\n",
            "     57       37.3047  0.0818\n",
            "     58       37.3047  0.0758\n",
            "     59       37.3047  0.0915\n",
            "     60       37.3047  0.0743\n",
            "     61       37.3047  0.0797\n",
            "     62       37.3047  0.0747\n",
            "     63       37.3047  0.0747\n",
            "     64       37.3047  0.0732\n",
            "     65       37.3047  0.0785\n",
            "     66       37.3047  0.0737\n",
            "     67       37.3047  0.0783\n",
            "     68       37.3047  0.0731\n",
            "     69       37.3047  0.0755\n",
            "     70       37.3047  0.0779\n",
            "     71       37.3047  0.0789\n",
            "     72       37.3047  0.0848\n",
            "     73       37.3047  0.0746\n",
            "     74       37.3047  0.0774\n",
            "     75       37.3047  0.0742\n",
            "     76       37.3047  0.0723\n",
            "     77       37.3047  0.0775\n",
            "     78       37.3047  0.0745\n",
            "     79       37.3047  0.0793\n",
            "     80       37.3047  0.0759\n",
            "     81       37.3047  0.0747\n",
            "     82       37.3047  0.0744\n",
            "     83       37.3047  0.0771\n",
            "     84       37.3047  0.0763\n",
            "     85       37.3047  0.0804\n",
            "     86       37.3047  0.0823\n",
            "     87       37.3047  0.0858\n",
            "     88       37.3047  0.0746\n",
            "     89       37.3047  0.0759\n",
            "     90       37.3047  0.0744\n",
            "     91       37.3047  0.0743\n",
            "     92       37.3047  0.0751\n",
            "     93       37.3047  0.0770\n",
            "     94       37.3047  0.0786\n",
            "     95       37.3047  0.0798\n",
            "     96       37.3047  0.0762\n",
            "     97       37.3047  0.0768\n",
            "     98       37.3047  0.0813\n",
            "     99       37.3047  0.0770\n",
            "    100       37.3047  0.0740\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0670\n",
            "      2       37.3047  0.0785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0918\n",
            "      4       37.3047  0.0736\n",
            "      5       37.3047  0.0782\n",
            "      6       37.3047  0.0750\n",
            "      7       37.3047  0.0740\n",
            "      8       37.3047  0.0767\n",
            "      9       37.3047  0.0825\n",
            "     10       37.3047  0.0862\n",
            "     11       37.3047  0.0784\n",
            "     12       37.3047  0.0780\n",
            "     13       37.3047  0.0732\n",
            "     14       37.3047  0.0745\n",
            "     15       37.3047  0.0778\n",
            "     16       37.3047  0.0779\n",
            "     17       37.3047  0.0820\n",
            "     18       37.3047  0.0776\n",
            "     19       37.3047  0.0739\n",
            "     20       37.3047  0.0805\n",
            "     21       \u001b[36m24.5971\u001b[0m  0.0799\n",
            "     22        \u001b[36m0.6656\u001b[0m  0.0770\n",
            "     23        \u001b[36m0.5820\u001b[0m  0.0830\n",
            "     24        \u001b[36m0.5078\u001b[0m  0.0800\n",
            "     25        \u001b[36m0.4837\u001b[0m  0.0832\n",
            "     26        \u001b[36m0.4693\u001b[0m  0.0745\n",
            "     27        \u001b[36m0.4658\u001b[0m  0.0748\n",
            "     28        \u001b[36m0.4594\u001b[0m  0.0767\n",
            "     29        \u001b[36m0.4457\u001b[0m  0.0747\n",
            "     30        \u001b[36m0.4319\u001b[0m  0.0770\n",
            "     31        \u001b[36m0.4282\u001b[0m  0.0768\n",
            "     32        \u001b[36m0.4097\u001b[0m  0.0791\n",
            "     33        \u001b[36m0.4060\u001b[0m  0.0775\n",
            "     34        \u001b[36m0.3999\u001b[0m  0.0786\n",
            "     35        \u001b[36m0.3899\u001b[0m  0.0733\n",
            "     36        \u001b[36m0.3810\u001b[0m  0.0903\n",
            "     37        \u001b[36m0.3707\u001b[0m  0.0756\n",
            "     38        \u001b[36m0.3632\u001b[0m  0.0886\n",
            "     39        \u001b[36m0.3550\u001b[0m  0.0734\n",
            "     40        \u001b[36m0.3494\u001b[0m  0.0852\n",
            "     41        \u001b[36m0.3390\u001b[0m  0.0761\n",
            "     42        \u001b[36m0.3382\u001b[0m  0.0847\n",
            "     43        \u001b[36m0.3255\u001b[0m  0.0765\n",
            "     44        \u001b[36m0.3228\u001b[0m  0.0760\n",
            "     45        \u001b[36m0.3170\u001b[0m  0.0762\n",
            "     46        \u001b[36m0.3069\u001b[0m  0.0782\n",
            "     47        0.3084  0.0779\n",
            "     48        \u001b[36m0.2955\u001b[0m  0.0818\n",
            "     49        0.2967  0.0765\n",
            "     50        \u001b[36m0.2909\u001b[0m  0.0771\n",
            "     51        \u001b[36m0.2869\u001b[0m  0.0732\n",
            "     52        \u001b[36m0.2805\u001b[0m  0.0725\n",
            "     53        \u001b[36m0.2764\u001b[0m  0.0784\n",
            "     54        0.2774  0.0747\n",
            "     55        \u001b[36m0.2667\u001b[0m  0.0741\n",
            "     56        0.2677  0.0826\n",
            "     57        0.2679  0.0757\n",
            "     58        \u001b[36m0.2607\u001b[0m  0.0806\n",
            "     59        \u001b[36m0.2563\u001b[0m  0.0750\n",
            "     60        \u001b[36m0.2549\u001b[0m  0.0750\n",
            "     61        \u001b[36m0.2521\u001b[0m  0.0908\n",
            "     62        \u001b[36m0.2514\u001b[0m  0.0833\n",
            "     63        \u001b[36m0.2481\u001b[0m  0.0728\n",
            "     64        \u001b[36m0.2476\u001b[0m  0.0728\n",
            "     65        \u001b[36m0.2408\u001b[0m  0.0770\n",
            "     66        0.2444  0.0731\n",
            "     67        \u001b[36m0.2377\u001b[0m  0.0769\n",
            "     68        0.2392  0.0795\n",
            "     69        \u001b[36m0.2361\u001b[0m  0.0824\n",
            "     70        \u001b[36m0.2323\u001b[0m  0.0760\n",
            "     71        \u001b[36m0.2287\u001b[0m  0.0771\n",
            "     72        0.2311  0.0734\n",
            "     73        0.2290  0.0729\n",
            "     74        \u001b[36m0.2231\u001b[0m  0.0866\n",
            "     75        \u001b[36m0.2224\u001b[0m  0.0788\n",
            "     76        \u001b[36m0.2168\u001b[0m  0.0738\n",
            "     77        \u001b[36m0.2162\u001b[0m  0.0745\n",
            "     78        \u001b[36m0.2104\u001b[0m  0.0753\n",
            "     79        0.2140  0.0745\n",
            "     80        \u001b[36m0.2103\u001b[0m  0.0811\n",
            "     81        \u001b[36m0.2043\u001b[0m  0.0745\n",
            "     82        0.2047  0.0777\n",
            "     83        \u001b[36m0.2037\u001b[0m  0.0778\n",
            "     84        \u001b[36m0.2005\u001b[0m  0.0765\n",
            "     85        \u001b[36m0.1991\u001b[0m  0.0854\n",
            "     86        0.2034  0.0811\n",
            "     87        \u001b[36m0.1963\u001b[0m  0.0821\n",
            "     88        \u001b[36m0.1925\u001b[0m  0.0764\n",
            "     89        \u001b[36m0.1868\u001b[0m  0.0783\n",
            "     90        0.1890  0.0778\n",
            "     91        \u001b[36m0.1846\u001b[0m  0.0789\n",
            "     92        \u001b[36m0.1808\u001b[0m  0.0809\n",
            "     93        \u001b[36m0.1801\u001b[0m  0.0769\n",
            "     94        0.1827  0.0760\n",
            "     95        \u001b[36m0.1780\u001b[0m  0.0841\n",
            "     96        \u001b[36m0.1761\u001b[0m  0.0802\n",
            "     97        \u001b[36m0.1715\u001b[0m  0.0790\n",
            "     98        0.1727  0.0790\n",
            "     99        \u001b[36m0.1710\u001b[0m  0.0842\n",
            "    100        \u001b[36m0.1706\u001b[0m  0.0784\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0692\n",
            "      2       37.3047  0.0786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0875\n",
            "      4       37.3047  0.0787\n",
            "      5       37.3047  0.0809\n",
            "      6       37.3047  0.0867\n",
            "      7       37.3047  0.0749\n",
            "      8       37.3047  0.0784\n",
            "      9       37.3047  0.0753\n",
            "     10       37.3047  0.0761\n",
            "     11       37.3047  0.0890\n",
            "     12       37.3047  0.0758\n",
            "     13       37.3047  0.0739\n",
            "     14       37.3047  0.0732\n",
            "     15       37.3047  0.0746\n",
            "     16       37.3047  0.0790\n",
            "     17       37.3047  0.0788\n",
            "     18       37.3047  0.0780\n",
            "     19       37.3047  0.0784\n",
            "     20       37.3047  0.0751\n",
            "     21       37.3047  0.0747\n",
            "     22       37.3047  0.0749\n",
            "     23       \u001b[36m19.0823\u001b[0m  0.0794\n",
            "     24        \u001b[36m0.5921\u001b[0m  0.0818\n",
            "     25        \u001b[36m0.5540\u001b[0m  0.0743\n",
            "     26        \u001b[36m0.5247\u001b[0m  0.0772\n",
            "     27        \u001b[36m0.5065\u001b[0m  0.0792\n",
            "     28        \u001b[36m0.5042\u001b[0m  0.0752\n",
            "     29        \u001b[36m0.4835\u001b[0m  0.0783\n",
            "     30        \u001b[36m0.4733\u001b[0m  0.0756\n",
            "     31        \u001b[36m0.4649\u001b[0m  0.0763\n",
            "     32        \u001b[36m0.4547\u001b[0m  0.0860\n",
            "     33        \u001b[36m0.4428\u001b[0m  0.0791\n",
            "     34        \u001b[36m0.4255\u001b[0m  0.0811\n",
            "     35        0.4294  0.0768\n",
            "     36        \u001b[36m0.4056\u001b[0m  0.0745\n",
            "     37        \u001b[36m0.4052\u001b[0m  0.0823\n",
            "     38        \u001b[36m0.3869\u001b[0m  0.0779\n",
            "     39        \u001b[36m0.3768\u001b[0m  0.0820\n",
            "     40        \u001b[36m0.3633\u001b[0m  0.0779\n",
            "     41        \u001b[36m0.3427\u001b[0m  0.0822\n",
            "     42        \u001b[36m0.3365\u001b[0m  0.0762\n",
            "     43        \u001b[36m0.3279\u001b[0m  0.0843\n",
            "     44        \u001b[36m0.3189\u001b[0m  0.0803\n",
            "     45        \u001b[36m0.3137\u001b[0m  0.0753\n",
            "     46        \u001b[36m0.3064\u001b[0m  0.0827\n",
            "     47        \u001b[36m0.3002\u001b[0m  0.0745\n",
            "     48        \u001b[36m0.2950\u001b[0m  0.0767\n",
            "     49        \u001b[36m0.2891\u001b[0m  0.0792\n",
            "     50        \u001b[36m0.2848\u001b[0m  0.0715\n",
            "     51        \u001b[36m0.2796\u001b[0m  0.0757\n",
            "     52        \u001b[36m0.2766\u001b[0m  0.0745\n",
            "     53        \u001b[36m0.2740\u001b[0m  0.0803\n",
            "     54        \u001b[36m0.2723\u001b[0m  0.0758\n",
            "     55        \u001b[36m0.2710\u001b[0m  0.0804\n",
            "     56        \u001b[36m0.2671\u001b[0m  0.0756\n",
            "     57        \u001b[36m0.2639\u001b[0m  0.0741\n",
            "     58        \u001b[36m0.2602\u001b[0m  0.0775\n",
            "     59        \u001b[36m0.2591\u001b[0m  0.0810\n",
            "     60        \u001b[36m0.2563\u001b[0m  0.0797\n",
            "     61        0.2571  0.0748\n",
            "     62        \u001b[36m0.2500\u001b[0m  0.0818\n",
            "     63        \u001b[36m0.2481\u001b[0m  0.0765\n",
            "     64        0.2513  0.0751\n",
            "     65        0.2486  0.0756\n",
            "     66        \u001b[36m0.2451\u001b[0m  0.0750\n",
            "     67        \u001b[36m0.2376\u001b[0m  0.0848\n",
            "     68        0.2406  0.0795\n",
            "     69        \u001b[36m0.2306\u001b[0m  0.0748\n",
            "     70        0.2364  0.0951\n",
            "     71        \u001b[36m0.2275\u001b[0m  0.0756\n",
            "     72        0.2296  0.0774\n",
            "     73        0.2279  0.0855\n",
            "     74        \u001b[36m0.2208\u001b[0m  0.0740\n",
            "     75        0.2221  0.0824\n",
            "     76        \u001b[36m0.2188\u001b[0m  0.0757\n",
            "     77        \u001b[36m0.2157\u001b[0m  0.0758\n",
            "     78        \u001b[36m0.2119\u001b[0m  0.0785\n",
            "     79        \u001b[36m0.2105\u001b[0m  0.0772\n",
            "     80        \u001b[36m0.2083\u001b[0m  0.0784\n",
            "     81        \u001b[36m0.2022\u001b[0m  0.0857\n",
            "     82        0.2036  0.0800\n",
            "     83        \u001b[36m0.2005\u001b[0m  0.0773\n",
            "     84        \u001b[36m0.1971\u001b[0m  0.0752\n",
            "     85        \u001b[36m0.1955\u001b[0m  0.0799\n",
            "     86        0.1960  0.0773\n",
            "     87        \u001b[36m0.1925\u001b[0m  0.0880\n",
            "     88        0.1930  0.0770\n",
            "     89        \u001b[36m0.1879\u001b[0m  0.0771\n",
            "     90        0.1892  0.0785\n",
            "     91        \u001b[36m0.1854\u001b[0m  0.0778\n",
            "     92        \u001b[36m0.1847\u001b[0m  0.0863\n",
            "     93        \u001b[36m0.1843\u001b[0m  0.0762\n",
            "     94        \u001b[36m0.1803\u001b[0m  0.0755\n",
            "     95        \u001b[36m0.1785\u001b[0m  0.0799\n",
            "     96        0.1798  0.0763\n",
            "     97        \u001b[36m0.1750\u001b[0m  0.0756\n",
            "     98        0.1761  0.0769\n",
            "     99        \u001b[36m0.1731\u001b[0m  0.0718\n",
            "    100        0.1758  0.0804\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0730\n",
            "      2       37.3047  0.0765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0820\n",
            "      4       37.3047  0.0763\n",
            "      5       37.3047  0.0767\n",
            "      6       37.3047  0.0752\n",
            "      7       37.3047  0.0842\n",
            "      8       37.3047  0.0757\n",
            "      9       37.3047  0.0798\n",
            "     10       37.3047  0.0775\n",
            "     11       37.3047  0.0797\n",
            "     12       37.3047  0.0756\n",
            "     13       37.3047  0.0833\n",
            "     14       37.3047  0.0759\n",
            "     15       37.3047  0.0781\n",
            "     16       37.3047  0.0759\n",
            "     17       37.3047  0.0741\n",
            "     18       37.3047  0.0874\n",
            "     19       37.3047  0.0820\n",
            "     20       37.3047  0.0748\n",
            "     21       \u001b[36m18.3150\u001b[0m  0.0781\n",
            "     22        \u001b[36m0.6153\u001b[0m  0.0779\n",
            "     23        \u001b[36m0.5489\u001b[0m  0.0776\n",
            "     24        \u001b[36m0.5150\u001b[0m  0.0763\n",
            "     25        \u001b[36m0.5017\u001b[0m  0.0875\n",
            "     26        \u001b[36m0.4919\u001b[0m  0.0804\n",
            "     27        \u001b[36m0.4804\u001b[0m  0.0747\n",
            "     28        \u001b[36m0.4700\u001b[0m  0.0755\n",
            "     29        \u001b[36m0.4605\u001b[0m  0.0804\n",
            "     30        \u001b[36m0.4512\u001b[0m  0.0762\n",
            "     31        \u001b[36m0.4419\u001b[0m  0.0751\n",
            "     32        \u001b[36m0.4326\u001b[0m  0.0879\n",
            "     33        \u001b[36m0.4236\u001b[0m  0.0742\n",
            "     34        \u001b[36m0.4147\u001b[0m  0.0775\n",
            "     35        \u001b[36m0.4057\u001b[0m  0.0752\n",
            "     36        \u001b[36m0.3971\u001b[0m  0.0734\n",
            "     37        \u001b[36m0.3891\u001b[0m  0.0788\n",
            "     38        \u001b[36m0.3818\u001b[0m  0.0824\n",
            "     39        \u001b[36m0.3737\u001b[0m  0.0750\n",
            "     40        \u001b[36m0.3673\u001b[0m  0.0802\n",
            "     41        \u001b[36m0.3601\u001b[0m  0.0806\n",
            "     42        \u001b[36m0.3536\u001b[0m  0.0765\n",
            "     43        \u001b[36m0.3477\u001b[0m  0.0762\n",
            "     44        \u001b[36m0.3420\u001b[0m  0.0780\n",
            "     45        \u001b[36m0.3353\u001b[0m  0.0742\n",
            "     46        \u001b[36m0.3311\u001b[0m  0.0762\n",
            "     47        \u001b[36m0.3253\u001b[0m  0.0793\n",
            "     48        \u001b[36m0.3201\u001b[0m  0.0765\n",
            "     49        \u001b[36m0.3149\u001b[0m  0.0722\n",
            "     50        \u001b[36m0.3095\u001b[0m  0.0756\n",
            "     51        \u001b[36m0.3039\u001b[0m  0.0809\n",
            "     52        \u001b[36m0.2989\u001b[0m  0.0771\n",
            "     53        \u001b[36m0.2941\u001b[0m  0.0762\n",
            "     54        \u001b[36m0.2893\u001b[0m  0.0750\n",
            "     55        \u001b[36m0.2850\u001b[0m  0.0793\n",
            "     56        \u001b[36m0.2796\u001b[0m  0.0823\n",
            "     57        \u001b[36m0.2747\u001b[0m  0.0774\n",
            "     58        \u001b[36m0.2678\u001b[0m  0.0777\n",
            "     59        \u001b[36m0.2639\u001b[0m  0.0762\n",
            "     60        \u001b[36m0.2593\u001b[0m  0.0758\n",
            "     61        \u001b[36m0.2539\u001b[0m  0.0710\n",
            "     62        0.2544  0.0727\n",
            "     63        \u001b[36m0.2496\u001b[0m  0.0835\n",
            "     64        \u001b[36m0.2443\u001b[0m  0.0809\n",
            "     65        0.2466  0.0754\n",
            "     66        \u001b[36m0.2386\u001b[0m  0.0771\n",
            "     67        0.2390  0.0793\n",
            "     68        \u001b[36m0.2336\u001b[0m  0.0733\n",
            "     69        \u001b[36m0.2330\u001b[0m  0.0773\n",
            "     70        \u001b[36m0.2305\u001b[0m  0.0754\n",
            "     71        \u001b[36m0.2286\u001b[0m  0.0813\n",
            "     72        \u001b[36m0.2229\u001b[0m  0.0788\n",
            "     73        0.2319  0.0781\n",
            "     74        \u001b[36m0.2214\u001b[0m  0.0734\n",
            "     75        \u001b[36m0.2187\u001b[0m  0.0738\n",
            "     76        0.2205  0.0850\n",
            "     77        \u001b[36m0.2147\u001b[0m  0.0772\n",
            "     78        0.2224  0.0761\n",
            "     79        0.2171  0.0925\n",
            "     80        0.2164  0.0775\n",
            "     81        \u001b[36m0.2145\u001b[0m  0.0824\n",
            "     82        0.2150  0.0777\n",
            "     83        0.2196  0.0746\n",
            "     84        0.2324  0.0753\n",
            "     85        0.2267  0.0739\n",
            "     86        0.2285  0.0742\n",
            "     87        0.2239  0.0800\n",
            "     88        0.2178  0.0748\n",
            "     89        0.2255  0.0833\n",
            "     90        0.2183  0.0767\n",
            "     91        0.2207  0.0763\n",
            "     92        0.2200  0.0774\n",
            "     93        0.2195  0.0761\n",
            "     94        0.2214  0.0884\n",
            "     95        0.2153  0.0761\n",
            "     96        \u001b[36m0.2136\u001b[0m  0.0781\n",
            "     97        \u001b[36m0.2076\u001b[0m  0.0778\n",
            "     98        \u001b[36m0.2071\u001b[0m  0.0758\n",
            "     99        \u001b[36m0.2052\u001b[0m  0.0737\n",
            "    100        \u001b[36m0.2026\u001b[0m  0.0761\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0691\n",
            "      2       37.3047  0.0820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0960\n",
            "      4       37.3047  0.0858\n",
            "      5       37.3047  0.0842\n",
            "      6       37.3047  0.0752\n",
            "      7       37.3047  0.0765\n",
            "      8       37.3047  0.0746\n",
            "      9       37.3047  0.0776\n",
            "     10       37.3047  0.0739\n",
            "     11       37.3047  0.0782\n",
            "     12       37.3047  0.0779\n",
            "     13       37.3047  0.0765\n",
            "     14       37.3047  0.0948\n",
            "     15       37.3047  0.0756\n",
            "     16       37.3047  0.0820\n",
            "     17       37.3047  0.0744\n",
            "     18       \u001b[36m24.6426\u001b[0m  0.0812\n",
            "     19        \u001b[36m0.6188\u001b[0m  0.0746\n",
            "     20        \u001b[36m0.5433\u001b[0m  0.0732\n",
            "     21        \u001b[36m0.5225\u001b[0m  0.0801\n",
            "     22        \u001b[36m0.5105\u001b[0m  0.0752\n",
            "     23        \u001b[36m0.5037\u001b[0m  0.0745\n",
            "     24        \u001b[36m0.4948\u001b[0m  0.0747\n",
            "     25        \u001b[36m0.4881\u001b[0m  0.0759\n",
            "     26        \u001b[36m0.4814\u001b[0m  0.0769\n",
            "     27        \u001b[36m0.4743\u001b[0m  0.0862\n",
            "     28        \u001b[36m0.4686\u001b[0m  0.0804\n",
            "     29        \u001b[36m0.4605\u001b[0m  0.0753\n",
            "     30        \u001b[36m0.4549\u001b[0m  0.0775\n",
            "     31        \u001b[36m0.4493\u001b[0m  0.0788\n",
            "     32        \u001b[36m0.4449\u001b[0m  0.0752\n",
            "     33        \u001b[36m0.4379\u001b[0m  0.0827\n",
            "     34        \u001b[36m0.4332\u001b[0m  0.0760\n",
            "     35        \u001b[36m0.4291\u001b[0m  0.0738\n",
            "     36        \u001b[36m0.4233\u001b[0m  0.0712\n",
            "     37        \u001b[36m0.4199\u001b[0m  0.0723\n",
            "     38        \u001b[36m0.4133\u001b[0m  0.0726\n",
            "     39        \u001b[36m0.4115\u001b[0m  0.0753\n",
            "     40        \u001b[36m0.4073\u001b[0m  0.0811\n",
            "     41        \u001b[36m0.4022\u001b[0m  0.0800\n",
            "     42        \u001b[36m0.3975\u001b[0m  0.0809\n",
            "     43        \u001b[36m0.3927\u001b[0m  0.0748\n",
            "     44        \u001b[36m0.3889\u001b[0m  0.0788\n",
            "     45        \u001b[36m0.3843\u001b[0m  0.0730\n",
            "     46        \u001b[36m0.3787\u001b[0m  0.0736\n",
            "     47        \u001b[36m0.3730\u001b[0m  0.0768\n",
            "     48        \u001b[36m0.3676\u001b[0m  0.0758\n",
            "     49        \u001b[36m0.3639\u001b[0m  0.0746\n",
            "     50        \u001b[36m0.3585\u001b[0m  0.0786\n",
            "     51        \u001b[36m0.3535\u001b[0m  0.0791\n",
            "     52        \u001b[36m0.3488\u001b[0m  0.0761\n",
            "     53        \u001b[36m0.3443\u001b[0m  0.0851\n",
            "     54        \u001b[36m0.3385\u001b[0m  0.0820\n",
            "     55        \u001b[36m0.3349\u001b[0m  0.0747\n",
            "     56        \u001b[36m0.3302\u001b[0m  0.0773\n",
            "     57        \u001b[36m0.3260\u001b[0m  0.0752\n",
            "     58        \u001b[36m0.3228\u001b[0m  0.0761\n",
            "     59        \u001b[36m0.3180\u001b[0m  0.0835\n",
            "     60        \u001b[36m0.3156\u001b[0m  0.0755\n",
            "     61        \u001b[36m0.3104\u001b[0m  0.0776\n",
            "     62        0.3108  0.0766\n",
            "     63        \u001b[36m0.3029\u001b[0m  0.0744\n",
            "     64        \u001b[36m0.2997\u001b[0m  0.0755\n",
            "     65        \u001b[36m0.2953\u001b[0m  0.0828\n",
            "     66        \u001b[36m0.2923\u001b[0m  0.0797\n",
            "     67        0.2943  0.0786\n",
            "     68        \u001b[36m0.2859\u001b[0m  0.0809\n",
            "     69        0.2859  0.0813\n",
            "     70        \u001b[36m0.2855\u001b[0m  0.0789\n",
            "     71        \u001b[36m0.2780\u001b[0m  0.0785\n",
            "     72        \u001b[36m0.2719\u001b[0m  0.0740\n",
            "     73        0.2765  0.0774\n",
            "     74        \u001b[36m0.2690\u001b[0m  0.0746\n",
            "     75        \u001b[36m0.2667\u001b[0m  0.0768\n",
            "     76        \u001b[36m0.2632\u001b[0m  0.0783\n",
            "     77        \u001b[36m0.2590\u001b[0m  0.0807\n",
            "     78        0.2593  0.0861\n",
            "     79        \u001b[36m0.2560\u001b[0m  0.0730\n",
            "     80        \u001b[36m0.2530\u001b[0m  0.0791\n",
            "     81        \u001b[36m0.2511\u001b[0m  0.0887\n",
            "     82        \u001b[36m0.2435\u001b[0m  0.0769\n",
            "     83        \u001b[36m0.2407\u001b[0m  0.0784\n",
            "     84        \u001b[36m0.2390\u001b[0m  0.0781\n",
            "     85        \u001b[36m0.2358\u001b[0m  0.0767\n",
            "     86        \u001b[36m0.2335\u001b[0m  0.0735\n",
            "     87        \u001b[36m0.2312\u001b[0m  0.0762\n",
            "     88        0.2414  0.0743\n",
            "     89        \u001b[36m0.2288\u001b[0m  0.0793\n",
            "     90        \u001b[36m0.2253\u001b[0m  0.0755\n",
            "     91        \u001b[36m0.2244\u001b[0m  0.0897\n",
            "     92        \u001b[36m0.2214\u001b[0m  0.0766\n",
            "     93        \u001b[36m0.2183\u001b[0m  0.0759\n",
            "     94        0.2200  0.0801\n",
            "     95        \u001b[36m0.2166\u001b[0m  0.0812\n",
            "     96        0.2207  0.0788\n",
            "     97        \u001b[36m0.2117\u001b[0m  0.0738\n",
            "     98        \u001b[36m0.2074\u001b[0m  0.0767\n",
            "     99        \u001b[36m0.2055\u001b[0m  0.0742\n",
            "    100        0.2090  0.0729\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0688\n",
            "      2       37.3047  0.0766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0961\n",
            "      4       37.3047  0.0799\n",
            "      5       37.3047  0.0843\n",
            "      6       37.3047  0.0840\n",
            "      7       37.3047  0.0745\n",
            "      8       37.3047  0.0783\n",
            "      9       37.3047  0.0743\n",
            "     10       37.3047  0.0767\n",
            "     11       37.3047  0.0741\n",
            "     12       37.3047  0.0734\n",
            "     13       37.3047  0.0741\n",
            "     14       37.3047  0.0786\n",
            "     15       37.3047  0.0773\n",
            "     16       37.3047  0.0859\n",
            "     17       37.3047  0.0853\n",
            "     18       37.3047  0.0756\n",
            "     19       37.3047  0.0772\n",
            "     20       37.3047  0.0794\n",
            "     21       \u001b[36m18.6080\u001b[0m  0.0787\n",
            "     22        \u001b[36m0.6806\u001b[0m  0.0745\n",
            "     23        \u001b[36m0.5537\u001b[0m  0.0768\n",
            "     24        \u001b[36m0.5352\u001b[0m  0.0752\n",
            "     25        \u001b[36m0.5179\u001b[0m  0.0760\n",
            "     26        \u001b[36m0.5081\u001b[0m  0.0724\n",
            "     27        \u001b[36m0.4991\u001b[0m  0.0740\n",
            "     28        \u001b[36m0.4888\u001b[0m  0.0760\n",
            "     29        \u001b[36m0.4829\u001b[0m  0.0971\n",
            "     30        \u001b[36m0.4758\u001b[0m  0.0795\n",
            "     31        \u001b[36m0.4702\u001b[0m  0.0739\n",
            "     32        \u001b[36m0.4663\u001b[0m  0.0740\n",
            "     33        \u001b[36m0.4611\u001b[0m  0.0761\n",
            "     34        \u001b[36m0.4567\u001b[0m  0.0773\n",
            "     35        \u001b[36m0.4517\u001b[0m  0.0784\n",
            "     36        \u001b[36m0.4452\u001b[0m  0.0749\n",
            "     37        \u001b[36m0.4388\u001b[0m  0.0760\n",
            "     38        \u001b[36m0.4336\u001b[0m  0.0781\n",
            "     39        \u001b[36m0.4265\u001b[0m  0.0760\n",
            "     40        \u001b[36m0.4209\u001b[0m  0.0835\n",
            "     41        \u001b[36m0.4155\u001b[0m  0.0918\n",
            "     42        \u001b[36m0.4062\u001b[0m  0.0869\n",
            "     43        \u001b[36m0.3997\u001b[0m  0.0749\n",
            "     44        \u001b[36m0.3921\u001b[0m  0.0740\n",
            "     45        \u001b[36m0.3841\u001b[0m  0.0749\n",
            "     46        \u001b[36m0.3773\u001b[0m  0.0757\n",
            "     47        \u001b[36m0.3690\u001b[0m  0.0800\n",
            "     48        \u001b[36m0.3612\u001b[0m  0.0733\n",
            "     49        \u001b[36m0.3559\u001b[0m  0.0734\n",
            "     50        \u001b[36m0.3494\u001b[0m  0.0761\n",
            "     51        \u001b[36m0.3438\u001b[0m  0.0779\n",
            "     52        \u001b[36m0.3419\u001b[0m  0.0744\n",
            "     53        \u001b[36m0.3386\u001b[0m  0.0760\n",
            "     54        \u001b[36m0.3301\u001b[0m  0.0834\n",
            "     55        \u001b[36m0.3200\u001b[0m  0.0798\n",
            "     56        \u001b[36m0.3185\u001b[0m  0.0823\n",
            "     57        \u001b[36m0.3125\u001b[0m  0.0759\n",
            "     58        \u001b[36m0.3100\u001b[0m  0.0784\n",
            "     59        \u001b[36m0.2981\u001b[0m  0.0775\n",
            "     60        \u001b[36m0.2926\u001b[0m  0.0739\n",
            "     61        \u001b[36m0.2885\u001b[0m  0.0748\n",
            "     62        \u001b[36m0.2844\u001b[0m  0.0766\n",
            "     63        \u001b[36m0.2767\u001b[0m  0.0765\n",
            "     64        0.2775  0.0793\n",
            "     65        \u001b[36m0.2701\u001b[0m  0.0751\n",
            "     66        0.2807  0.0815\n",
            "     67        \u001b[36m0.2638\u001b[0m  0.0841\n",
            "     68        \u001b[36m0.2597\u001b[0m  0.0794\n",
            "     69        \u001b[36m0.2555\u001b[0m  0.0740\n",
            "     70        0.2667  0.0760\n",
            "     71        \u001b[36m0.2541\u001b[0m  0.0832\n",
            "     72        \u001b[36m0.2502\u001b[0m  0.0744\n",
            "     73        \u001b[36m0.2465\u001b[0m  0.0730\n",
            "     74        \u001b[36m0.2439\u001b[0m  0.0755\n",
            "     75        \u001b[36m0.2405\u001b[0m  0.0741\n",
            "     76        \u001b[36m0.2371\u001b[0m  0.0761\n",
            "     77        \u001b[36m0.2359\u001b[0m  0.0773\n",
            "     78        \u001b[36m0.2341\u001b[0m  0.0827\n",
            "     79        \u001b[36m0.2251\u001b[0m  0.0762\n",
            "     80        \u001b[36m0.2219\u001b[0m  0.0887\n",
            "     81        \u001b[36m0.2201\u001b[0m  0.0817\n",
            "     82        0.2218  0.0746\n",
            "     83        \u001b[36m0.2199\u001b[0m  0.0771\n",
            "     84        \u001b[36m0.2080\u001b[0m  0.0722\n",
            "     85        0.2154  0.0743\n",
            "     86        0.2096  0.0709\n",
            "     87        \u001b[36m0.2059\u001b[0m  0.0750\n",
            "     88        0.2103  0.0772\n",
            "     89        0.2071  0.0766\n",
            "     90        \u001b[36m0.2024\u001b[0m  0.0765\n",
            "     91        0.2095  0.0803\n",
            "     92        \u001b[36m0.1989\u001b[0m  0.0767\n",
            "     93        \u001b[36m0.1987\u001b[0m  0.0872\n",
            "     94        \u001b[36m0.1967\u001b[0m  0.0764\n",
            "     95        0.1995  0.0808\n",
            "     96        \u001b[36m0.1919\u001b[0m  0.0778\n",
            "     97        0.1955  0.0770\n",
            "     98        0.1990  0.0788\n",
            "     99        0.1980  0.0779\n",
            "    100        0.1960  0.0754\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.2320\u001b[0m  0.0725\n",
            "      2       37.2320  0.0753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.2320  0.0844\n",
            "      4       37.2320  0.0839\n",
            "      5       37.2320  0.0835\n",
            "      6       37.2320  0.0759\n",
            "      7       37.2320  0.0794\n",
            "      8       37.2320  0.0785\n",
            "      9       37.2320  0.0757\n",
            "     10       37.2320  0.0746\n",
            "     11       37.2320  0.0732\n",
            "     12       37.2320  0.0770\n",
            "     13       37.2320  0.0748\n",
            "     14       37.2320  0.0736\n",
            "     15       37.2320  0.0828\n",
            "     16       37.2320  0.0789\n",
            "     17       37.2320  0.0803\n",
            "     18       37.2320  0.0835\n",
            "     19       37.2320  0.0789\n",
            "     20       37.2320  0.0761\n",
            "     21       37.2320  0.0769\n",
            "     22       \u001b[36m16.5156\u001b[0m  0.0767\n",
            "     23        \u001b[36m0.6249\u001b[0m  0.0727\n",
            "     24        \u001b[36m0.6117\u001b[0m  0.0721\n",
            "     25        \u001b[36m0.5957\u001b[0m  0.0740\n",
            "     26        \u001b[36m0.5888\u001b[0m  0.0810\n",
            "     27        \u001b[36m0.5872\u001b[0m  0.0723\n",
            "     28        \u001b[36m0.5805\u001b[0m  0.0743\n",
            "     29        \u001b[36m0.5780\u001b[0m  0.0726\n",
            "     30        \u001b[36m0.5720\u001b[0m  0.0755\n",
            "     31        \u001b[36m0.5577\u001b[0m  0.0876\n",
            "     32        \u001b[36m0.5071\u001b[0m  0.0765\n",
            "     33        \u001b[36m0.5063\u001b[0m  0.0790\n",
            "     34        \u001b[36m0.4957\u001b[0m  0.0774\n",
            "     35        \u001b[36m0.4855\u001b[0m  0.0783\n",
            "     36        \u001b[36m0.4726\u001b[0m  0.0788\n",
            "     37        \u001b[36m0.4610\u001b[0m  0.0779\n",
            "     38        \u001b[36m0.4287\u001b[0m  0.0767\n",
            "     39        0.5054  0.0764\n",
            "     40        0.4375  0.0772\n",
            "     41        \u001b[36m0.4231\u001b[0m  0.0748\n",
            "     42        \u001b[36m0.4143\u001b[0m  0.0839\n",
            "     43        \u001b[36m0.4058\u001b[0m  0.0841\n",
            "     44        \u001b[36m0.3969\u001b[0m  0.0816\n",
            "     45        \u001b[36m0.3887\u001b[0m  0.0755\n",
            "     46        \u001b[36m0.3796\u001b[0m  0.0813\n",
            "     47        \u001b[36m0.3695\u001b[0m  0.0742\n",
            "     48        \u001b[36m0.3529\u001b[0m  0.0771\n",
            "     49        \u001b[36m0.3478\u001b[0m  0.0729\n",
            "     50        \u001b[36m0.3418\u001b[0m  0.0744\n",
            "     51        \u001b[36m0.3285\u001b[0m  0.0764\n",
            "     52        \u001b[36m0.3159\u001b[0m  0.0738\n",
            "     53        \u001b[36m0.3087\u001b[0m  0.0883\n",
            "     54        \u001b[36m0.2992\u001b[0m  0.0781\n",
            "     55        \u001b[36m0.2944\u001b[0m  0.0770\n",
            "     56        \u001b[36m0.2827\u001b[0m  0.0835\n",
            "     57        \u001b[36m0.2711\u001b[0m  0.0804\n",
            "     58        \u001b[36m0.2649\u001b[0m  0.0769\n",
            "     59        \u001b[36m0.2562\u001b[0m  0.0747\n",
            "     60        0.2662  0.0758\n",
            "     61        \u001b[36m0.2533\u001b[0m  0.0807\n",
            "     62        \u001b[36m0.2497\u001b[0m  0.0770\n",
            "     63        \u001b[36m0.2471\u001b[0m  0.0751\n",
            "     64        \u001b[36m0.2404\u001b[0m  0.0760\n",
            "     65        \u001b[36m0.2376\u001b[0m  0.0748\n",
            "     66        \u001b[36m0.2338\u001b[0m  0.0742\n",
            "     67        \u001b[36m0.2301\u001b[0m  0.0793\n",
            "     68        \u001b[36m0.2254\u001b[0m  0.0806\n",
            "     69        \u001b[36m0.2200\u001b[0m  0.0880\n",
            "     70        \u001b[36m0.2197\u001b[0m  0.0740\n",
            "     71        \u001b[36m0.2139\u001b[0m  0.0751\n",
            "     72        \u001b[36m0.2130\u001b[0m  0.0849\n",
            "     73        \u001b[36m0.2108\u001b[0m  0.0734\n",
            "     74        \u001b[36m0.2056\u001b[0m  0.0730\n",
            "     75        \u001b[36m0.2055\u001b[0m  0.0748\n",
            "     76        \u001b[36m0.1999\u001b[0m  0.0758\n",
            "     77        \u001b[36m0.1996\u001b[0m  0.0767\n",
            "     78        \u001b[36m0.1971\u001b[0m  0.0931\n",
            "     79        \u001b[36m0.1930\u001b[0m  0.0823\n",
            "     80        \u001b[36m0.1927\u001b[0m  0.0775\n",
            "     81        0.1932  0.0821\n",
            "     82        \u001b[36m0.1839\u001b[0m  0.0791\n",
            "     83        0.1842  0.0778\n",
            "     84        0.1843  0.0759\n",
            "     85        \u001b[36m0.1811\u001b[0m  0.0780\n",
            "     86        \u001b[36m0.1796\u001b[0m  0.0736\n",
            "     87        \u001b[36m0.1789\u001b[0m  0.0787\n",
            "     88        0.1811  0.0751\n",
            "     89        \u001b[36m0.1740\u001b[0m  0.0764\n",
            "     90        \u001b[36m0.1708\u001b[0m  0.0861\n",
            "     91        0.1727  0.0808\n",
            "     92        \u001b[36m0.1705\u001b[0m  0.0784\n",
            "     93        \u001b[36m0.1684\u001b[0m  0.0764\n",
            "     94        0.1739  0.0819\n",
            "     95        \u001b[36m0.1669\u001b[0m  0.0780\n",
            "     96        \u001b[36m0.1663\u001b[0m  0.0742\n",
            "     97        \u001b[36m0.1604\u001b[0m  0.0751\n",
            "     98        0.1610  0.0815\n",
            "     99        0.1656  0.0747\n",
            "    100        \u001b[36m0.1578\u001b[0m  0.0743\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0518\n",
            "      2       37.1094  0.0649\n",
            "      3       37.1094  0.0649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.1094  0.0724\n",
            "      5       37.1094  0.0578\n",
            "      6       37.1094  0.0660\n",
            "      7       37.1094  0.0610\n",
            "      8       37.1094  0.0671\n",
            "      9       37.1094  0.0599\n",
            "     10       37.1094  0.0611\n",
            "     11       37.1094  0.0607\n",
            "     12       37.1094  0.0578\n",
            "     13       37.1094  0.0599\n",
            "     14       37.1094  0.0633\n",
            "     15       37.1094  0.0618\n",
            "     16       37.1094  0.0612\n",
            "     17       37.1094  0.0628\n",
            "     18       37.1094  0.0618\n",
            "     19       37.1094  0.0627\n",
            "     20       37.1094  0.0603\n",
            "     21       37.1094  0.0712\n",
            "     22       37.1094  0.0595\n",
            "     23       37.1094  0.0619\n",
            "     24       37.1094  0.0691\n",
            "     25       37.1094  0.0618\n",
            "     26       37.1094  0.0564\n",
            "     27       37.1094  0.0592\n",
            "     28       37.1094  0.0570\n",
            "     29       37.1094  0.0587\n",
            "     30       37.1094  0.0602\n",
            "     31       37.1094  0.0587\n",
            "     32       37.1094  0.0582\n",
            "     33       37.1094  0.0608\n",
            "     34       37.1094  0.0591\n",
            "     35       37.1094  0.0682\n",
            "     36       37.1094  0.0577\n",
            "     37       37.1094  0.0571\n",
            "     38       37.1094  0.0639\n",
            "     39       37.1094  0.0637\n",
            "     40       37.1094  0.0607\n",
            "     41       37.1094  0.0676\n",
            "     42       37.1094  0.0590\n",
            "     43       37.1094  0.0595\n",
            "     44       37.1094  0.0579\n",
            "     45       37.1094  0.0607\n",
            "     46       37.1094  0.0605\n",
            "     47       37.1094  0.0631\n",
            "     48       37.1094  0.0594\n",
            "     49       37.1094  0.0682\n",
            "     50       37.1094  0.0650\n",
            "     51       37.1094  0.0610\n",
            "     52       37.1094  0.0636\n",
            "     53       37.1094  0.0630\n",
            "     54       37.1094  0.0608\n",
            "     55       37.1094  0.0601\n",
            "     56       37.1094  0.0613\n",
            "     57       37.1094  0.0684\n",
            "     58       37.1094  0.0645\n",
            "     59       37.1094  0.0605\n",
            "     60       37.1094  0.0596\n",
            "     61       37.1094  0.0600\n",
            "     62       37.1094  0.0609\n",
            "     63       37.1094  0.0654\n",
            "     64       37.1094  0.0604\n",
            "     65       37.1094  0.0627\n",
            "     66       37.1094  0.0638\n",
            "     67       37.1094  0.0604\n",
            "     68       37.1094  0.0698\n",
            "     69       37.1094  0.0626\n",
            "     70       37.1094  0.0709\n",
            "     71       37.1094  0.0629\n",
            "     72       37.1094  0.0706\n",
            "     73       37.1094  0.0637\n",
            "     74       37.1094  0.0603\n",
            "     75       37.1094  0.0652\n",
            "     76       37.1094  0.0620\n",
            "     77       37.1094  0.0626\n",
            "     78       37.1094  0.0608\n",
            "     79       37.1094  0.0666\n",
            "     80       37.1094  0.0600\n",
            "     81       37.1094  0.0624\n",
            "     82       37.1094  0.0686\n",
            "     83       37.1094  0.0607\n",
            "     84       37.1094  0.0633\n",
            "     85       37.1094  0.0627\n",
            "     86       37.1094  0.0614\n",
            "     87       37.1094  0.0637\n",
            "     88       37.1094  0.0719\n",
            "     89       37.1094  0.0632\n",
            "     90       37.1094  0.0596\n",
            "     91       37.1094  0.0631\n",
            "     92       37.1094  0.0641\n",
            "     93       37.1094  0.0586\n",
            "     94       37.1094  0.0593\n",
            "     95       37.1094  0.0602\n",
            "     96       37.1094  0.0737\n",
            "     97       37.1094  0.0590\n",
            "     98       37.1094  0.0594\n",
            "     99       37.1094  0.0619\n",
            "    100       37.1094  0.0688\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0542\n",
            "      2       37.1094  0.0650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.1094  0.0696\n",
            "      4       37.1094  0.0703\n",
            "      5       37.1094  0.0613\n",
            "      6       37.1094  0.0607\n",
            "      7       37.1094  0.0594\n",
            "      8       37.1094  0.0635\n",
            "      9       37.1094  0.0621\n",
            "     10       37.1094  0.0644\n",
            "     11       37.1094  0.0617\n",
            "     12       37.1094  0.0604\n",
            "     13       37.1094  0.0635\n",
            "     14       37.1094  0.0652\n",
            "     15       37.1094  0.0599\n",
            "     16       37.1094  0.0598\n",
            "     17       37.1094  0.0614\n",
            "     18       37.1094  0.0658\n",
            "     19       37.1094  0.0673\n",
            "     20       37.1094  0.0649\n",
            "     21       37.1094  0.0591\n",
            "     22       37.1094  0.0593\n",
            "     23       37.1094  0.0657\n",
            "     24       37.1094  0.0598\n",
            "     25       37.1094  0.0642\n",
            "     26       37.1094  0.0606\n",
            "     27       37.1094  0.0613\n",
            "     28       37.1094  0.0750\n",
            "     29       37.1094  0.0613\n",
            "     30       37.1094  0.0643\n",
            "     31       37.1094  0.0617\n",
            "     32       37.1094  0.0629\n",
            "     33       37.1094  0.0636\n",
            "     34       37.1094  0.0602\n",
            "     35       37.1094  0.0662\n",
            "     36       37.1094  0.0607\n",
            "     37       37.1094  0.0732\n",
            "     38       37.1094  0.0649\n",
            "     39       37.1094  0.0633\n",
            "     40       37.1094  0.0595\n",
            "     41       37.1094  0.0627\n",
            "     42       37.1094  0.0698\n",
            "     43       37.1094  0.0628\n",
            "     44       37.1094  0.0604\n",
            "     45       37.1094  0.0620\n",
            "     46       37.1094  0.0593\n",
            "     47       37.1094  0.0615\n",
            "     48       37.1094  0.0611\n",
            "     49       37.1094  0.0580\n",
            "     50       37.1094  0.0598\n",
            "     51       37.1094  0.0668\n",
            "     52       37.1094  0.0564\n",
            "     53       37.1094  0.0572\n",
            "     54       37.1094  0.0610\n",
            "     55       37.1094  0.0630\n",
            "     56       37.1094  0.0580\n",
            "     57       37.1094  0.0586\n",
            "     58       37.1094  0.0633\n",
            "     59       37.1094  0.0593\n",
            "     60       37.1094  0.0617\n",
            "     61       37.1094  0.0656\n",
            "     62       37.1094  0.0597\n",
            "     63       37.1094  0.0611\n",
            "     64       37.1094  0.0654\n",
            "     65       37.1094  0.0617\n",
            "     66       37.1094  0.0595\n",
            "     67       37.1094  0.0659\n",
            "     68       37.1094  0.0593\n",
            "     69       37.1094  0.0610\n",
            "     70       37.1094  0.0615\n",
            "     71       37.1094  0.0602\n",
            "     72       37.1094  0.0622\n",
            "     73       37.1094  0.0703\n",
            "     74       37.1094  0.0631\n",
            "     75       37.1094  0.0665\n",
            "     76       37.1094  0.0611\n",
            "     77       37.1094  0.0601\n",
            "     78       37.1094  0.0632\n",
            "     79       37.1094  0.0612\n",
            "     80       37.1094  0.0637\n",
            "     81       37.1094  0.0601\n",
            "     82       37.1094  0.0617\n",
            "     83       37.1094  0.0735\n",
            "     84       37.1094  0.0615\n",
            "     85       37.1094  0.0634\n",
            "     86       37.1094  0.0602\n",
            "     87       37.1094  0.0602\n",
            "     88       37.1094  0.0588\n",
            "     89       37.1094  0.0688\n",
            "     90       37.1094  0.0590\n",
            "     91       37.1094  0.0583\n",
            "     92       37.1094  0.0612\n",
            "     93       37.1094  0.0598\n",
            "     94       37.1094  0.0745\n",
            "     95       37.1094  0.0645\n",
            "     96       37.1094  0.0593\n",
            "     97       37.1094  0.0596\n",
            "     98       37.1094  0.0610\n",
            "     99       37.1094  0.0666\n",
            "    100       37.1094  0.0595\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0578\n",
            "      2       37.3047  0.0600\n",
            "      3       37.3047  0.0632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0708\n",
            "      5       37.3047  0.0629\n",
            "      6       37.3047  0.0605\n",
            "      7       37.3047  0.0639\n",
            "      8       37.3047  0.0595\n",
            "      9       37.3047  0.0615\n",
            "     10       37.3047  0.0622\n",
            "     11       37.3047  0.0606\n",
            "     12       37.3047  0.0610\n",
            "     13       37.3047  0.0616\n",
            "     14       37.3047  0.0625\n",
            "     15       37.3047  0.0634\n",
            "     16       37.3047  0.0622\n",
            "     17       37.3047  0.0591\n",
            "     18       37.3047  0.0600\n",
            "     19       37.3047  0.0622\n",
            "     20       37.3047  0.0600\n",
            "     21       37.3047  0.0617\n",
            "     22       37.3047  0.0680\n",
            "     23       37.3047  0.0628\n",
            "     24       37.3047  0.0621\n",
            "     25       37.3047  0.0594\n",
            "     26       37.3047  0.0617\n",
            "     27       37.3047  0.0601\n",
            "     28       37.3047  0.0661\n",
            "     29       37.3047  0.0589\n",
            "     30       37.3047  0.0637\n",
            "     31       37.3047  0.0628\n",
            "     32       37.3047  0.0649\n",
            "     33       37.3047  0.0594\n",
            "     34       37.3047  0.0611\n",
            "     35       37.3047  0.0612\n",
            "     36       37.3047  0.0694\n",
            "     37       37.3047  0.0637\n",
            "     38       37.3047  0.0640\n",
            "     39       37.3047  0.0597\n",
            "     40       37.3047  0.0617\n",
            "     41       37.3047  0.0658\n",
            "     42       37.3047  0.0586\n",
            "     43       37.3047  0.0614\n",
            "     44       37.3047  0.0587\n",
            "     45       37.3047  0.0579\n",
            "     46       37.3047  0.0612\n",
            "     47       37.3047  0.0647\n",
            "     48       37.3047  0.0615\n",
            "     49       37.3047  0.0643\n",
            "     50       37.3047  0.0703\n",
            "     51       37.3047  0.0656\n",
            "     52       37.3047  0.0623\n",
            "     53       37.3047  0.0608\n",
            "     54       37.3047  0.0622\n",
            "     55       37.3047  0.0624\n",
            "     56       37.3047  0.0619\n",
            "     57       37.3047  0.0643\n",
            "     58       37.3047  0.0654\n",
            "     59       37.3047  0.0634\n",
            "     60       37.3047  0.0617\n",
            "     61       37.3047  0.0570\n",
            "     62       37.3047  0.0676\n",
            "     63       37.3047  0.0612\n",
            "     64       37.3047  0.0601\n",
            "     65       37.3047  0.0635\n",
            "     66       37.3047  0.0610\n",
            "     67       37.3047  0.0611\n",
            "     68       37.3047  0.0618\n",
            "     69       37.3047  0.0681\n",
            "     70       37.3047  0.0616\n",
            "     71       37.3047  0.0664\n",
            "     72       37.3047  0.0688\n",
            "     73       37.3047  0.0596\n",
            "     74       37.3047  0.0610\n",
            "     75       37.3047  0.0624\n",
            "     76       37.3047  0.0598\n",
            "     77       37.3047  0.0628\n",
            "     78       37.3047  0.0687\n",
            "     79       37.3047  0.0650\n",
            "     80       37.3047  0.0614\n",
            "     81       37.3047  0.0635\n",
            "     82       37.3047  0.0687\n",
            "     83       37.3047  0.0607\n",
            "     84       37.3047  0.0616\n",
            "     85       37.3047  0.0626\n",
            "     86       37.3047  0.0613\n",
            "     87       37.3047  0.0617\n",
            "     88       37.3047  0.0614\n",
            "     89       37.3047  0.0652\n",
            "     90       37.3047  0.0628\n",
            "     91       37.3047  0.0592\n",
            "     92       37.3047  0.0587\n",
            "     93       37.3047  0.0602\n",
            "     94       37.3047  0.0718\n",
            "     95       37.3047  0.0665\n",
            "     96       37.3047  0.0681\n",
            "     97       37.3047  0.0708\n",
            "     98       37.3047  0.0642\n",
            "     99       37.3047  0.0619\n",
            "    100       37.3047  0.0640\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0528\n",
            "      2       37.3047  0.0827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0689\n",
            "      4       37.3047  0.0635\n",
            "      5       37.3047  0.0594\n",
            "      6       37.3047  0.0593\n",
            "      7       37.3047  0.0629\n",
            "      8       37.3047  0.0611\n",
            "      9       37.3047  0.0710\n",
            "     10       37.3047  0.0611\n",
            "     11       37.3047  0.0605\n",
            "     12       37.3047  0.0636\n",
            "     13       37.3047  0.0622\n",
            "     14       37.3047  0.0662\n",
            "     15       37.3047  0.0592\n",
            "     16       37.3047  0.0633\n",
            "     17       37.3047  0.0609\n",
            "     18       37.3047  0.0614\n",
            "     19       37.3047  0.0621\n",
            "     20       37.3047  0.0656\n",
            "     21       37.3047  0.0586\n",
            "     22       37.3047  0.0586\n",
            "     23       37.3047  0.0622\n",
            "     24       37.3047  0.0612\n",
            "     25       37.3047  0.0674\n",
            "     26       37.3047  0.0607\n",
            "     27       37.3047  0.0670\n",
            "     28       37.3047  0.0660\n",
            "     29       37.3047  0.0617\n",
            "     30       37.3047  0.0651\n",
            "     31       37.3047  0.0597\n",
            "     32       37.3047  0.0604\n",
            "     33       37.3047  0.0660\n",
            "     34       37.3047  0.0595\n",
            "     35       37.3047  0.0595\n",
            "     36       37.3047  0.0639\n",
            "     37       37.3047  0.0632\n",
            "     38       37.3047  0.0607\n",
            "     39       37.3047  0.0603\n",
            "     40       37.3047  0.0627\n",
            "     41       37.3047  0.0681\n",
            "     42       37.3047  0.0672\n",
            "     43       37.3047  0.0624\n",
            "     44       37.3047  0.0630\n",
            "     45       37.3047  0.0647\n",
            "     46       37.3047  0.0602\n",
            "     47       37.3047  0.0634\n",
            "     48       37.3047  0.0639\n",
            "     49       37.3047  0.0615\n",
            "     50       37.3047  0.0635\n",
            "     51       37.3047  0.0608\n",
            "     52       37.3047  0.0626\n",
            "     53       37.3047  0.0595\n",
            "     54       37.3047  0.0601\n",
            "     55       37.3047  0.0626\n",
            "     56       37.3047  0.0637\n",
            "     57       37.3047  0.0648\n",
            "     58       37.3047  0.0654\n",
            "     59       37.3047  0.0618\n",
            "     60       37.3047  0.0628\n",
            "     61       37.3047  0.0674\n",
            "     62       37.3047  0.0655\n",
            "     63       37.3047  0.0607\n",
            "     64       37.3047  0.0630\n",
            "     65       37.3047  0.0615\n",
            "     66       37.3047  0.0628\n",
            "     67       37.3047  0.0603\n",
            "     68       37.3047  0.0619\n",
            "     69       37.3047  0.0654\n",
            "     70       37.3047  0.0625\n",
            "     71       37.3047  0.0606\n",
            "     72       37.3047  0.0745\n",
            "     73       37.3047  0.0631\n",
            "     74       37.3047  0.0652\n",
            "     75       37.3047  0.0665\n",
            "     76       37.3047  0.0578\n",
            "     77       37.3047  0.0596\n",
            "     78       37.3047  0.0615\n",
            "     79       37.3047  0.0668\n",
            "     80       37.3047  0.0612\n",
            "     81       37.3047  0.0651\n",
            "     82       37.3047  0.0628\n",
            "     83       37.3047  0.0593\n",
            "     84       37.3047  0.0624\n",
            "     85       37.3047  0.0647\n",
            "     86       37.3047  0.0601\n",
            "     87       37.3047  0.0618\n",
            "     88       37.3047  0.0773\n",
            "     89       37.3047  0.0631\n",
            "     90       37.3047  0.0655\n",
            "     91       37.3047  0.0609\n",
            "     92       37.3047  0.0636\n",
            "     93       37.3047  0.0608\n",
            "     94       37.3047  0.0639\n",
            "     95       37.3047  0.0647\n",
            "     96       37.3047  0.0605\n",
            "     97       37.3047  0.0606\n",
            "     98       37.3047  0.0623\n",
            "     99       37.3047  0.0606\n",
            "    100       37.3047  0.0645\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0538\n",
            "      2       37.3047  0.0699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0732\n",
            "      4       37.3047  0.0674\n",
            "      5       37.3047  0.0605\n",
            "      6       37.3047  0.0607\n",
            "      7       37.3047  0.0623\n",
            "      8       37.3047  0.0594\n",
            "      9       37.3047  0.0663\n",
            "     10       37.3047  0.0589\n",
            "     11       37.3047  0.0652\n",
            "     12       37.3047  0.0581\n",
            "     13       37.3047  0.0598\n",
            "     14       37.3047  0.0590\n",
            "     15       37.3047  0.0617\n",
            "     16       37.3047  0.0592\n",
            "     17       37.3047  0.0590\n",
            "     18       37.3047  0.0645\n",
            "     19       37.3047  0.0733\n",
            "     20       37.3047  0.0625\n",
            "     21       37.3047  0.0658\n",
            "     22       37.3047  0.0624\n",
            "     23       37.3047  0.0594\n",
            "     24       37.3047  0.0643\n",
            "     25       37.3047  0.0641\n",
            "     26       37.3047  0.0610\n",
            "     27       37.3047  0.0641\n",
            "     28       37.3047  0.0612\n",
            "     29       37.3047  0.0692\n",
            "     30       37.3047  0.0631\n",
            "     31       37.3047  0.0600\n",
            "     32       37.3047  0.0607\n",
            "     33       37.3047  0.0609\n",
            "     34       37.3047  0.0677\n",
            "     35       37.3047  0.0684\n",
            "     36       37.3047  0.0607\n",
            "     37       37.3047  0.0651\n",
            "     38       37.3047  0.0621\n",
            "     39       37.3047  0.0676\n",
            "     40       37.3047  0.0643\n",
            "     41       37.3047  0.0633\n",
            "     42       37.3047  0.0611\n",
            "     43       37.3047  0.0616\n",
            "     44       37.3047  0.0611\n",
            "     45       37.3047  0.0592\n",
            "     46       37.3047  0.0611\n",
            "     47       37.3047  0.0579\n",
            "     48       37.3047  0.0661\n",
            "     49       37.3047  0.0629\n",
            "     50       37.3047  0.0685\n",
            "     51       37.3047  0.0635\n",
            "     52       37.3047  0.0635\n",
            "     53       37.3047  0.0603\n",
            "     54       37.3047  0.0609\n",
            "     55       37.3047  0.0611\n",
            "     56       37.3047  0.0627\n",
            "     57       37.3047  0.0606\n",
            "     58       37.3047  0.0693\n",
            "     59       37.3047  0.0588\n",
            "     60       37.3047  0.0602\n",
            "     61       37.3047  0.0603\n",
            "     62       37.3047  0.0602\n",
            "     63       37.3047  0.0599\n",
            "     64       37.3047  0.0637\n",
            "     65       37.3047  0.0608\n",
            "     66       37.3047  0.0680\n",
            "     67       37.3047  0.0644\n",
            "     68       37.3047  0.0641\n",
            "     69       37.3047  0.0608\n",
            "     70       37.3047  0.0585\n",
            "     71       37.3047  0.0711\n",
            "     72       37.3047  0.0589\n",
            "     73       37.3047  0.0619\n",
            "     74       37.3047  0.0597\n",
            "     75       37.3047  0.0637\n",
            "     76       37.3047  0.0617\n",
            "     77       37.3047  0.0658\n",
            "     78       37.3047  0.0599\n",
            "     79       37.3047  0.0646\n",
            "     80       37.3047  0.0649\n",
            "     81       37.3047  0.0691\n",
            "     82       37.3047  0.0702\n",
            "     83       37.3047  0.0616\n",
            "     84       37.3047  0.0607\n",
            "     85       37.3047  0.0597\n",
            "     86       37.3047  0.0652\n",
            "     87       37.3047  0.0594\n",
            "     88       37.3047  0.0629\n",
            "     89       37.3047  0.0584\n",
            "     90       37.3047  0.0603\n",
            "     91       37.3047  0.0613\n",
            "     92       37.3047  0.0608\n",
            "     93       37.3047  0.0641\n",
            "     94       37.3047  0.0591\n",
            "     95       37.3047  0.0648\n",
            "     96       37.3047  0.0622\n",
            "     97       37.3047  0.0660\n",
            "     98       37.3047  0.0663\n",
            "     99       37.3047  0.0599\n",
            "    100       37.3047  0.0594\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0549\n",
            "      2       37.3047  0.0619\n",
            "      3       37.3047  0.0574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0696\n",
            "      5       37.3047  0.0571\n",
            "      6       37.3047  0.0614\n",
            "      7       37.3047  0.0640\n",
            "      8       37.3047  0.0617\n",
            "      9       37.3047  0.0596\n",
            "     10       37.3047  0.0628\n",
            "     11       37.3047  0.0589\n",
            "     12       37.3047  0.0598\n",
            "     13       37.3047  0.0596\n",
            "     14       37.3047  0.0761\n",
            "     15       37.3047  0.0611\n",
            "     16       37.3047  0.0575\n",
            "     17       37.3047  0.0614\n",
            "     18       37.3047  0.0683\n",
            "     19       37.3047  0.0595\n",
            "     20       37.3047  0.0615\n",
            "     21       37.3047  0.0591\n",
            "     22       37.3047  0.0632\n",
            "     23       37.3047  0.0593\n",
            "     24       37.3047  0.0623\n",
            "     25       37.3047  0.0601\n",
            "     26       37.3047  0.0613\n",
            "     27       37.3047  0.0611\n",
            "     28       37.3047  0.0702\n",
            "     29       37.3047  0.0589\n",
            "     30       37.3047  0.0663\n",
            "     31       37.3047  0.0598\n",
            "     32       37.3047  0.0667\n",
            "     33       37.3047  0.0603\n",
            "     34       37.3047  0.0578\n",
            "     35       37.3047  0.0606\n",
            "     36       37.3047  0.0589\n",
            "     37       37.3047  0.0595\n",
            "     38       37.3047  0.0611\n",
            "     39       37.3047  0.0601\n",
            "     40       37.3047  0.0604\n",
            "     41       37.3047  0.0592\n",
            "     42       37.3047  0.0676\n",
            "     43       37.3047  0.0625\n",
            "     44       37.3047  0.0599\n",
            "     45       37.3047  0.0622\n",
            "     46       37.3047  0.0676\n",
            "     47       37.3047  0.0597\n",
            "     48       37.3047  0.0591\n",
            "     49       37.3047  0.0646\n",
            "     50       37.3047  0.0595\n",
            "     51       37.3047  0.0584\n",
            "     52       37.3047  0.0586\n",
            "     53       37.3047  0.0607\n",
            "     54       37.3047  0.0600\n",
            "     55       37.3047  0.0648\n",
            "     56       37.3047  0.0606\n",
            "     57       37.3047  0.0634\n",
            "     58       37.3047  0.0603\n",
            "     59       37.3047  0.0660\n",
            "     60       37.3047  0.0654\n",
            "     61       37.3047  0.0669\n",
            "     62       37.3047  0.0675\n",
            "     63       37.3047  0.0575\n",
            "     64       37.3047  0.0640\n",
            "     65       37.3047  0.0581\n",
            "     66       37.3047  0.0580\n",
            "     67       37.3047  0.0561\n",
            "     68       37.3047  0.0600\n",
            "     69       37.3047  0.0609\n",
            "     70       37.3047  0.0637\n",
            "     71       37.3047  0.0590\n",
            "     72       37.3047  0.0596\n",
            "     73       37.3047  0.0638\n",
            "     74       37.3047  0.0623\n",
            "     75       37.3047  0.0667\n",
            "     76       37.3047  0.0584\n",
            "     77       37.3047  0.0611\n",
            "     78       37.3047  0.0655\n",
            "     79       37.3047  0.0590\n",
            "     80       37.3047  0.0668\n",
            "     81       37.3047  0.0585\n",
            "     82       37.3047  0.0638\n",
            "     83       37.3047  0.0571\n",
            "     84       37.3047  0.0607\n",
            "     85       37.3047  0.0630\n",
            "     86       37.3047  0.0637\n",
            "     87       37.3047  0.0593\n",
            "     88       37.3047  0.0587\n",
            "     89       37.3047  0.0659\n",
            "     90       37.3047  0.0602\n",
            "     91       37.3047  0.0631\n",
            "     92       37.3047  0.0597\n",
            "     93       37.3047  0.0598\n",
            "     94       37.3047  0.0662\n",
            "     95       37.3047  0.0601\n",
            "     96       37.3047  0.0647\n",
            "     97       37.3047  0.0600\n",
            "     98       37.3047  0.0620\n",
            "     99       37.3047  0.0653\n",
            "    100       37.3047  0.0613\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0535\n",
            "      2       37.3047  0.0602\n",
            "      3       37.3047  0.0624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0688\n",
            "      5       37.3047  0.0613\n",
            "      6       37.3047  0.0612\n",
            "      7       37.3047  0.0594\n",
            "      8       37.3047  0.0740\n",
            "      9       37.3047  0.0703\n",
            "     10       37.3047  0.0605\n",
            "     11       37.3047  0.0615\n",
            "     12       37.3047  0.0570\n",
            "     13       37.3047  0.0593\n",
            "     14       37.3047  0.0589\n",
            "     15       37.3047  0.0584\n",
            "     16       37.3047  0.0624\n",
            "     17       37.3047  0.0602\n",
            "     18       37.3047  0.0593\n",
            "     19       37.3047  0.0687\n",
            "     20       37.3047  0.0615\n",
            "     21       37.3047  0.0604\n",
            "     22       37.3047  0.0667\n",
            "     23       37.3047  0.0611\n",
            "     24       37.3047  0.0630\n",
            "     25       37.3047  0.0691\n",
            "     26       37.3047  0.0600\n",
            "     27       37.3047  0.0616\n",
            "     28       37.3047  0.0584\n",
            "     29       37.3047  0.0690\n",
            "     30       37.3047  0.0600\n",
            "     31       37.3047  0.0609\n",
            "     32       37.3047  0.0625\n",
            "     33       37.3047  0.0604\n",
            "     34       37.3047  0.0610\n",
            "     35       37.3047  0.0609\n",
            "     36       37.3047  0.0677\n",
            "     37       37.3047  0.0636\n",
            "     38       37.3047  0.0614\n",
            "     39       37.3047  0.0630\n",
            "     40       37.3047  0.0639\n",
            "     41       37.3047  0.0681\n",
            "     42       37.3047  0.0797\n",
            "     43       37.3047  0.0604\n",
            "     44       37.3047  0.0607\n",
            "     45       37.3047  0.0593\n",
            "     46       37.3047  0.0611\n",
            "     47       37.3047  0.0594\n",
            "     48       37.3047  0.0584\n",
            "     49       37.3047  0.0594\n",
            "     50       37.3047  0.0702\n",
            "     51       37.3047  0.0608\n",
            "     52       37.3047  0.0684\n",
            "     53       37.3047  0.0598\n",
            "     54       37.3047  0.0600\n",
            "     55       37.3047  0.0640\n",
            "     56       37.3047  0.0611\n",
            "     57       37.3047  0.0679\n",
            "     58       37.3047  0.0600\n",
            "     59       37.3047  0.0693\n",
            "     60       37.3047  0.0644\n",
            "     61       37.3047  0.0636\n",
            "     62       37.3047  0.0614\n",
            "     63       37.3047  0.0598\n",
            "     64       37.3047  0.0601\n",
            "     65       37.3047  0.0630\n",
            "     66       37.3047  0.0592\n",
            "     67       37.3047  0.0595\n",
            "     68       37.3047  0.0654\n",
            "     69       37.3047  0.0709\n",
            "     70       37.3047  0.0633\n",
            "     71       37.3047  0.0608\n",
            "     72       37.3047  0.0672\n",
            "     73       37.3047  0.0639\n",
            "     74       37.3047  0.0615\n",
            "     75       37.3047  0.0578\n",
            "     76       37.3047  0.0598\n",
            "     77       37.3047  0.0579\n",
            "     78       37.3047  0.0630\n",
            "     79       37.3047  0.0618\n",
            "     80       37.3047  0.0615\n",
            "     81       37.3047  0.0619\n",
            "     82       37.3047  0.0580\n",
            "     83       37.3047  0.0699\n",
            "     84       37.3047  0.0600\n",
            "     85       37.3047  0.0587\n",
            "     86       37.3047  0.0629\n",
            "     87       37.3047  0.0659\n",
            "     88       37.3047  0.0665\n",
            "     89       37.3047  0.0587\n",
            "     90       37.3047  0.0588\n",
            "     91       37.3047  0.0585\n",
            "     92       37.3047  0.0619\n",
            "     93       37.3047  0.0585\n",
            "     94       37.3047  0.0594\n",
            "     95       37.3047  0.0654\n",
            "     96       37.3047  0.0592\n",
            "     97       37.3047  0.0669\n",
            "     98       37.3047  0.0587\n",
            "     99       37.3047  0.0639\n",
            "    100       37.3047  0.0582\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0573\n",
            "      2       37.3047  0.0711\n",
            "      3       37.3047  0.0598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0799\n",
            "      5       37.3047  0.0582\n",
            "      6       37.3047  0.0585\n",
            "      7       37.3047  0.0583\n",
            "      8       37.3047  0.0617\n",
            "      9       37.3047  0.0630\n",
            "     10       37.3047  0.0613\n",
            "     11       37.3047  0.0582\n",
            "     12       37.3047  0.0587\n",
            "     13       37.3047  0.0596\n",
            "     14       37.3047  0.0578\n",
            "     15       37.3047  0.0648\n",
            "     16       37.3047  0.0695\n",
            "     17       37.3047  0.0618\n",
            "     18       37.3047  0.0602\n",
            "     19       37.3047  0.0670\n",
            "     20       37.3047  0.0670\n",
            "     21       37.3047  0.0623\n",
            "     22       37.3047  0.0593\n",
            "     23       37.3047  0.0632\n",
            "     24       37.3047  0.0615\n",
            "     25       37.3047  0.0609\n",
            "     26       37.3047  0.0633\n",
            "     27       37.3047  0.0605\n",
            "     28       37.3047  0.0660\n",
            "     29       37.3047  0.0639\n",
            "     30       37.3047  0.0647\n",
            "     31       37.3047  0.0603\n",
            "     32       37.3047  0.0655\n",
            "     33       37.3047  0.0608\n",
            "     34       37.3047  0.0615\n",
            "     35       37.3047  0.0660\n",
            "     36       37.3047  0.0670\n",
            "     37       37.3047  0.0621\n",
            "     38       37.3047  0.0610\n",
            "     39       37.3047  0.0600\n",
            "     40       37.3047  0.0607\n",
            "     41       37.3047  0.0643\n",
            "     42       37.3047  0.0614\n",
            "     43       37.3047  0.0610\n",
            "     44       37.3047  0.0672\n",
            "     45       37.3047  0.0624\n",
            "     46       37.3047  0.0641\n",
            "     47       37.3047  0.0605\n",
            "     48       37.3047  0.0695\n",
            "     49       37.3047  0.0630\n",
            "     50       37.3047  0.0630\n",
            "     51       37.3047  0.0656\n",
            "     52       37.3047  0.0617\n",
            "     53       37.3047  0.0603\n",
            "     54       37.3047  0.0607\n",
            "     55       37.3047  0.0647\n",
            "     56       37.3047  0.0657\n",
            "     57       37.3047  0.0633\n",
            "     58       37.3047  0.0643\n",
            "     59       37.3047  0.0589\n",
            "     60       37.3047  0.0608\n",
            "     61       37.3047  0.0615\n",
            "     62       37.3047  0.0720\n",
            "     63       37.3047  0.0637\n",
            "     64       37.3047  0.0584\n",
            "     65       37.3047  0.0663\n",
            "     66       37.3047  0.0594\n",
            "     67       37.3047  0.0665\n",
            "     68       37.3047  0.0581\n",
            "     69       37.3047  0.0636\n",
            "     70       37.3047  0.0660\n",
            "     71       37.3047  0.0601\n",
            "     72       37.3047  0.0605\n",
            "     73       37.3047  0.0621\n",
            "     74       37.3047  0.0616\n",
            "     75       37.3047  0.0591\n",
            "     76       37.3047  0.0706\n",
            "     77       37.3047  0.0589\n",
            "     78       37.3047  0.0617\n",
            "     79       37.3047  0.0620\n",
            "     80       37.3047  0.0633\n",
            "     81       37.3047  0.0645\n",
            "     82       37.3047  0.0609\n",
            "     83       37.3047  0.0753\n",
            "     84       37.3047  0.0592\n",
            "     85       37.3047  0.0615\n",
            "     86       37.3047  0.0598\n",
            "     87       37.3047  0.0613\n",
            "     88       37.3047  0.0612\n",
            "     89       37.3047  0.0640\n",
            "     90       37.3047  0.0654\n",
            "     91       37.3047  0.0639\n",
            "     92       37.3047  0.0603\n",
            "     93       37.3047  0.0625\n",
            "     94       37.3047  0.0633\n",
            "     95       37.3047  0.0610\n",
            "     96       37.3047  0.0685\n",
            "     97       37.3047  0.0581\n",
            "     98       37.3047  0.0589\n",
            "     99       37.3047  0.0660\n",
            "    100       37.3047  0.0606\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0538\n",
            "      2       37.3047  0.0705\n",
            "      3       37.3047  0.0606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0729\n",
            "      5       37.3047  0.0626\n",
            "      6       37.3047  0.0648\n",
            "      7       37.3047  0.0620\n",
            "      8       37.3047  0.0698\n",
            "      9       37.3047  0.0611\n",
            "     10       37.3047  0.0613\n",
            "     11       37.3047  0.0631\n",
            "     12       37.3047  0.0741\n",
            "     13       37.3047  0.0621\n",
            "     14       37.3047  0.0668\n",
            "     15       37.3047  0.0594\n",
            "     16       37.3047  0.0639\n",
            "     17       37.3047  0.0611\n",
            "     18       37.3047  0.0659\n",
            "     19       37.3047  0.0590\n",
            "     20       37.3047  0.0600\n",
            "     21       37.3047  0.0633\n",
            "     22       37.3047  0.0691\n",
            "     23       37.3047  0.0602\n",
            "     24       37.3047  0.0639\n",
            "     25       37.3047  0.0599\n",
            "     26       37.3047  0.0633\n",
            "     27       37.3047  0.0614\n",
            "     28       37.3047  0.0613\n",
            "     29       37.3047  0.0709\n",
            "     30       37.3047  0.0632\n",
            "     31       37.3047  0.0635\n",
            "     32       37.3047  0.0605\n",
            "     33       37.3047  0.0613\n",
            "     34       37.3047  0.0603\n",
            "     35       37.3047  0.0598\n",
            "     36       37.3047  0.0671\n",
            "     37       37.3047  0.0645\n",
            "     38       37.3047  0.0628\n",
            "     39       37.3047  0.0628\n",
            "     40       37.3047  0.0633\n",
            "     41       37.3047  0.0604\n",
            "     42       37.3047  0.0692\n",
            "     43       37.3047  0.0606\n",
            "     44       37.3047  0.0627\n",
            "     45       37.3047  0.0659\n",
            "     46       37.3047  0.0572\n",
            "     47       37.3047  0.0605\n",
            "     48       37.3047  0.0613\n",
            "     49       37.3047  0.0586\n",
            "     50       37.3047  0.0663\n",
            "     51       37.3047  0.0638\n",
            "     52       37.3047  0.0704\n",
            "     53       37.3047  0.0622\n",
            "     54       37.3047  0.0676\n",
            "     55       37.3047  0.0674\n",
            "     56       37.3047  0.0628\n",
            "     57       37.3047  0.0669\n",
            "     58       37.3047  0.0625\n",
            "     59       37.3047  0.0610\n",
            "     60       37.3047  0.0599\n",
            "     61       37.3047  0.0704\n",
            "     62       37.3047  0.0611\n",
            "     63       37.3047  0.0690\n",
            "     64       37.3047  0.0620\n",
            "     65       37.3047  0.0593\n",
            "     66       37.3047  0.0589\n",
            "     67       37.3047  0.0645\n",
            "     68       37.3047  0.0715\n",
            "     69       37.3047  0.0617\n",
            "     70       37.3047  0.0609\n",
            "     71       37.3047  0.0623\n",
            "     72       37.3047  0.0624\n",
            "     73       37.3047  0.0610\n",
            "     74       37.3047  0.0604\n",
            "     75       37.3047  0.0664\n",
            "     76       37.3047  0.0643\n",
            "     77       37.3047  0.0678\n",
            "     78       37.3047  0.0605\n",
            "     79       37.3047  0.0595\n",
            "     80       37.3047  0.0615\n",
            "     81       37.3047  0.0624\n",
            "     82       37.3047  0.0688\n",
            "     83       37.3047  0.0629\n",
            "     84       37.3047  0.0641\n",
            "     85       37.3047  0.0651\n",
            "     86       37.3047  0.0606\n",
            "     87       37.3047  0.0639\n",
            "     88       37.3047  0.0601\n",
            "     89       37.3047  0.0634\n",
            "     90       37.3047  0.0610\n",
            "     91       37.3047  0.0612\n",
            "     92       37.3047  0.0711\n",
            "     93       37.3047  0.0608\n",
            "     94       37.3047  0.0612\n",
            "     95       37.3047  0.0627\n",
            "     96       37.3047  0.0707\n",
            "     97       37.3047  0.0637\n",
            "     98       37.3047  0.0649\n",
            "     99       37.3047  0.0647\n",
            "    100       37.3047  0.0614\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.2320\u001b[0m  0.0544\n",
            "      2       37.2320  0.0599\n",
            "      3       37.2320  0.0639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.2320  0.0719\n",
            "      5       37.2320  0.0670\n",
            "      6       37.2320  0.0589\n",
            "      7       37.2320  0.0661\n",
            "      8       37.2320  0.0631\n",
            "      9       37.2320  0.0605\n",
            "     10       37.2320  0.0641\n",
            "     11       37.2320  0.0606\n",
            "     12       37.2320  0.0609\n",
            "     13       37.2320  0.0614\n",
            "     14       37.2320  0.0678\n",
            "     15       37.2320  0.0655\n",
            "     16       37.2320  0.0616\n",
            "     17       37.2320  0.0641\n",
            "     18       37.2320  0.0646\n",
            "     19       37.2320  0.0598\n",
            "     20       37.2320  0.0611\n",
            "     21       37.2320  0.0604\n",
            "     22       37.2320  0.0629\n",
            "     23       37.2320  0.0705\n",
            "     24       37.2320  0.0618\n",
            "     25       37.2320  0.0632\n",
            "     26       37.2320  0.0597\n",
            "     27       37.2320  0.0647\n",
            "     28       37.2320  0.0750\n",
            "     29       37.2320  0.0602\n",
            "     30       37.2320  0.0614\n",
            "     31       37.2320  0.0591\n",
            "     32       37.2320  0.0605\n",
            "     33       37.2320  0.0662\n",
            "     34       37.2320  0.0593\n",
            "     35       37.2320  0.0623\n",
            "     36       37.2320  0.0608\n",
            "     37       37.2320  0.0596\n",
            "     38       37.2320  0.0625\n",
            "     39       37.2320  0.0730\n",
            "     40       37.2320  0.0633\n",
            "     41       37.2320  0.0619\n",
            "     42       37.2320  0.0669\n",
            "     43       37.2320  0.0604\n",
            "     44       37.2320  0.0646\n",
            "     45       37.2320  0.0615\n",
            "     46       37.2320  0.0677\n",
            "     47       37.2320  0.0615\n",
            "     48       37.2320  0.0633\n",
            "     49       37.2320  0.0609\n",
            "     50       37.2320  0.0630\n",
            "     51       37.2320  0.0652\n",
            "     52       37.2320  0.0604\n",
            "     53       37.2320  0.0637\n",
            "     54       37.2320  0.0709\n",
            "     55       37.2320  0.0608\n",
            "     56       37.2320  0.0621\n",
            "     57       37.2320  0.0698\n",
            "     58       37.2320  0.0613\n",
            "     59       37.2320  0.0623\n",
            "     60       37.2320  0.0671\n",
            "     61       37.2320  0.0681\n",
            "     62       37.2320  0.0611\n",
            "     63       37.2320  0.0631\n",
            "     64       37.2320  0.0617\n",
            "     65       37.2320  0.0615\n",
            "     66       37.2320  0.0621\n",
            "     67       37.2320  0.0595\n",
            "     68       37.2320  0.0632\n",
            "     69       37.2320  0.0611\n",
            "     70       37.2320  0.0736\n",
            "     71       37.2320  0.0614\n",
            "     72       37.2320  0.0668\n",
            "     73       37.2320  0.0613\n",
            "     74       37.2320  0.0807\n",
            "     75       37.2320  0.0676\n",
            "     76       37.2320  0.0620\n",
            "     77       37.2320  0.0630\n",
            "     78       37.2320  0.0648\n",
            "     79       37.2320  0.0598\n",
            "     80       37.2320  0.0612\n",
            "     81       37.2320  0.0628\n",
            "     82       37.2320  0.0617\n",
            "     83       37.2320  0.0677\n",
            "     84       37.2320  0.0601\n",
            "     85       37.2320  0.0691\n",
            "     86       37.2320  0.0615\n",
            "     87       37.2320  0.0639\n",
            "     88       37.2320  0.0671\n",
            "     89       37.2320  0.0629\n",
            "     90       37.2320  0.0601\n",
            "     91       37.2320  0.0617\n",
            "     92       37.2320  0.0625\n",
            "     93       37.2320  0.0614\n",
            "     94       37.2320  0.0641\n",
            "     95       37.2320  0.0582\n",
            "     96       37.2320  0.0673\n",
            "     97       37.2320  0.0613\n",
            "     98       37.2320  0.0606\n",
            "     99       37.2320  0.0622\n",
            "    100       37.2320  0.0627\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0768\n",
            "      2       37.1094  0.0735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.1094  0.0949\n",
            "      4       37.1094  0.0818\n",
            "      5       37.1094  0.0738\n",
            "      6       37.1094  0.0762\n",
            "      7       37.1094  0.0809\n",
            "      8       37.1094  0.0766\n",
            "      9       37.1094  0.0747\n",
            "     10       37.1094  0.0751\n",
            "     11       37.1094  0.0765\n",
            "     12       37.1094  0.0757\n",
            "     13       37.1094  0.0886\n",
            "     14       37.1094  0.0794\n",
            "     15       37.1094  0.0747\n",
            "     16       37.1094  0.0835\n",
            "     17       37.1094  0.0759\n",
            "     18       37.1094  0.0801\n",
            "     19       37.1094  0.0794\n",
            "     20       37.1094  0.0776\n",
            "     21       37.1094  0.0752\n",
            "     22       \u001b[36m13.8902\u001b[0m  0.0752\n",
            "     23        \u001b[36m0.6171\u001b[0m  0.0773\n",
            "     24        \u001b[36m0.4926\u001b[0m  0.0756\n",
            "     25        \u001b[36m0.4753\u001b[0m  0.0795\n",
            "     26        \u001b[36m0.4632\u001b[0m  0.0834\n",
            "     27        \u001b[36m0.4532\u001b[0m  0.0743\n",
            "     28        \u001b[36m0.4412\u001b[0m  0.0789\n",
            "     29        \u001b[36m0.4308\u001b[0m  0.0774\n",
            "     30        \u001b[36m0.4203\u001b[0m  0.0774\n",
            "     31        \u001b[36m0.4076\u001b[0m  0.0835\n",
            "     32        \u001b[36m0.3961\u001b[0m  0.0768\n",
            "     33        \u001b[36m0.3844\u001b[0m  0.0746\n",
            "     34        \u001b[36m0.3713\u001b[0m  0.0746\n",
            "     35        \u001b[36m0.3591\u001b[0m  0.0719\n",
            "     36        \u001b[36m0.3445\u001b[0m  0.0721\n",
            "     37        \u001b[36m0.3316\u001b[0m  0.0781\n",
            "     38        \u001b[36m0.3205\u001b[0m  0.0739\n",
            "     39        \u001b[36m0.3105\u001b[0m  0.0901\n",
            "     40        \u001b[36m0.2978\u001b[0m  0.0829\n",
            "     41        \u001b[36m0.2893\u001b[0m  0.0751\n",
            "     42        \u001b[36m0.2785\u001b[0m  0.0846\n",
            "     43        \u001b[36m0.2710\u001b[0m  0.0739\n",
            "     44        \u001b[36m0.2645\u001b[0m  0.0752\n",
            "     45        \u001b[36m0.2588\u001b[0m  0.0752\n",
            "     46        \u001b[36m0.2526\u001b[0m  0.0774\n",
            "     47        \u001b[36m0.2483\u001b[0m  0.0728\n",
            "     48        \u001b[36m0.2422\u001b[0m  0.0750\n",
            "     49        \u001b[36m0.2366\u001b[0m  0.0752\n",
            "     50        \u001b[36m0.2365\u001b[0m  0.0814\n",
            "     51        \u001b[36m0.2272\u001b[0m  0.0846\n",
            "     52        \u001b[36m0.2233\u001b[0m  0.0791\n",
            "     53        \u001b[36m0.2219\u001b[0m  0.0749\n",
            "     54        0.2222  0.0839\n",
            "     55        \u001b[36m0.2207\u001b[0m  0.0771\n",
            "     56        \u001b[36m0.2186\u001b[0m  0.0744\n",
            "     57        \u001b[36m0.2059\u001b[0m  0.0755\n",
            "     58        0.2105  0.0724\n",
            "     59        \u001b[36m0.1979\u001b[0m  0.0743\n",
            "     60        0.2033  0.0825\n",
            "     61        \u001b[36m0.1921\u001b[0m  0.0742\n",
            "     62        \u001b[36m0.1883\u001b[0m  0.0734\n",
            "     63        \u001b[36m0.1802\u001b[0m  0.0744\n",
            "     64        0.1866  0.0825\n",
            "     65        \u001b[36m0.1791\u001b[0m  0.0805\n",
            "     66        \u001b[36m0.1718\u001b[0m  0.0812\n",
            "     67        0.1861  0.0751\n",
            "     68        \u001b[36m0.1698\u001b[0m  0.0771\n",
            "     69        0.1712  0.0786\n",
            "     70        \u001b[36m0.1642\u001b[0m  0.0785\n",
            "     71        \u001b[36m0.1577\u001b[0m  0.0786\n",
            "     72        \u001b[36m0.1557\u001b[0m  0.0824\n",
            "     73        \u001b[36m0.1531\u001b[0m  0.0773\n",
            "     74        \u001b[36m0.1524\u001b[0m  0.0782\n",
            "     75        \u001b[36m0.1518\u001b[0m  0.0783\n",
            "     76        0.1567  0.0770\n",
            "     77        \u001b[36m0.1387\u001b[0m  0.0876\n",
            "     78        0.1540  0.0776\n",
            "     79        \u001b[36m0.1365\u001b[0m  0.0780\n",
            "     80        0.1386  0.0798\n",
            "     81        \u001b[36m0.1313\u001b[0m  0.0756\n",
            "     82        0.1325  0.0808\n",
            "     83        0.1365  0.0751\n",
            "     84        0.1374  0.0803\n",
            "     85        0.1361  0.0793\n",
            "     86        \u001b[36m0.1222\u001b[0m  0.0769\n",
            "     87        0.1239  0.0760\n",
            "     88        0.1342  0.0774\n",
            "     89        0.1240  0.0821\n",
            "     90        0.1334  0.0792\n",
            "     91        \u001b[36m0.1217\u001b[0m  0.0773\n",
            "     92        0.1239  0.0711\n",
            "     93        \u001b[36m0.1191\u001b[0m  0.0803\n",
            "     94        0.1223  0.0766\n",
            "     95        \u001b[36m0.1137\u001b[0m  0.0850\n",
            "     96        0.1183  0.0753\n",
            "     97        \u001b[36m0.1081\u001b[0m  0.0835\n",
            "     98        \u001b[36m0.1079\u001b[0m  0.0752\n",
            "     99        0.1139  0.0781\n",
            "    100        \u001b[36m0.1003\u001b[0m  0.0760\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0675\n",
            "      2       37.1094  0.0888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.1094  0.0949\n",
            "      4       37.1094  0.0795\n",
            "      5       37.1094  0.0755\n",
            "      6       37.1094  0.0783\n",
            "      7       37.1094  0.0744\n",
            "      8       37.1094  0.0736\n",
            "      9       37.1094  0.0760\n",
            "     10       37.1094  0.0741\n",
            "     11       37.1094  0.0790\n",
            "     12       37.1094  0.0899\n",
            "     13       37.1094  0.0780\n",
            "     14       37.1094  0.0908\n",
            "     15       37.1094  0.0796\n",
            "     16       37.1094  0.0800\n",
            "     17       37.1094  0.0764\n",
            "     18       37.1094  0.0745\n",
            "     19       37.1094  0.0830\n",
            "     20       37.1094  0.0752\n",
            "     21       37.1094  0.0730\n",
            "     22       37.1094  0.0766\n",
            "     23       37.1094  0.0747\n",
            "     24       37.1094  0.0750\n",
            "     25       37.1094  0.0771\n",
            "     26       37.1094  0.0759\n",
            "     27       \u001b[36m12.8894\u001b[0m  0.0869\n",
            "     28        \u001b[36m0.5582\u001b[0m  0.0765\n",
            "     29        \u001b[36m0.5294\u001b[0m  0.0838\n",
            "     30        \u001b[36m0.5173\u001b[0m  0.0747\n",
            "     31        \u001b[36m0.5064\u001b[0m  0.0790\n",
            "     32        \u001b[36m0.4848\u001b[0m  0.0767\n",
            "     33        \u001b[36m0.4645\u001b[0m  0.0766\n",
            "     34        \u001b[36m0.4479\u001b[0m  0.0805\n",
            "     35        \u001b[36m0.4306\u001b[0m  0.0744\n",
            "     36        \u001b[36m0.4120\u001b[0m  0.0749\n",
            "     37        \u001b[36m0.3952\u001b[0m  0.0807\n",
            "     38        \u001b[36m0.3802\u001b[0m  0.0751\n",
            "     39        \u001b[36m0.3672\u001b[0m  0.0768\n",
            "     40        \u001b[36m0.3548\u001b[0m  0.0901\n",
            "     41        \u001b[36m0.3469\u001b[0m  0.0764\n",
            "     42        \u001b[36m0.3372\u001b[0m  0.0745\n",
            "     43        \u001b[36m0.3298\u001b[0m  0.0766\n",
            "     44        \u001b[36m0.3228\u001b[0m  0.0784\n",
            "     45        \u001b[36m0.3176\u001b[0m  0.0762\n",
            "     46        \u001b[36m0.3140\u001b[0m  0.0749\n",
            "     47        \u001b[36m0.3087\u001b[0m  0.0819\n",
            "     48        \u001b[36m0.3063\u001b[0m  0.0746\n",
            "     49        \u001b[36m0.3039\u001b[0m  0.0748\n",
            "     50        \u001b[36m0.2955\u001b[0m  0.0761\n",
            "     51        0.2987  0.0828\n",
            "     52        \u001b[36m0.2931\u001b[0m  0.0885\n",
            "     53        \u001b[36m0.2905\u001b[0m  0.0771\n",
            "     54        \u001b[36m0.2876\u001b[0m  0.0767\n",
            "     55        \u001b[36m0.2850\u001b[0m  0.0782\n",
            "     56        0.2851  0.0830\n",
            "     57        0.2870  0.0766\n",
            "     58        \u001b[36m0.2839\u001b[0m  0.0759\n",
            "     59        \u001b[36m0.2835\u001b[0m  0.0764\n",
            "     60        \u001b[36m0.2782\u001b[0m  0.0784\n",
            "     61        \u001b[36m0.2764\u001b[0m  0.0754\n",
            "     62        \u001b[36m0.2746\u001b[0m  0.0754\n",
            "     63        0.2787  0.0778\n",
            "     64        0.2775  0.0755\n",
            "     65        \u001b[36m0.2699\u001b[0m  0.0818\n",
            "     66        \u001b[36m0.2695\u001b[0m  0.0866\n",
            "     67        0.2707  0.0794\n",
            "     68        \u001b[36m0.2649\u001b[0m  0.0779\n",
            "     69        \u001b[36m0.2609\u001b[0m  0.0786\n",
            "     70        0.2621  0.0777\n",
            "     71        0.2631  0.0748\n",
            "     72        0.2622  0.0738\n",
            "     73        \u001b[36m0.2601\u001b[0m  0.0845\n",
            "     74        \u001b[36m0.2522\u001b[0m  0.0795\n",
            "     75        0.2539  0.0744\n",
            "     76        0.2562  0.0766\n",
            "     77        0.2528  0.0806\n",
            "     78        \u001b[36m0.2475\u001b[0m  0.0900\n",
            "     79        0.2479  0.0769\n",
            "     80        \u001b[36m0.2445\u001b[0m  0.0767\n",
            "     81        \u001b[36m0.2413\u001b[0m  0.0857\n",
            "     82        \u001b[36m0.2386\u001b[0m  0.0752\n",
            "     83        \u001b[36m0.2351\u001b[0m  0.0746\n",
            "     84        0.2385  0.0788\n",
            "     85        \u001b[36m0.2306\u001b[0m  0.0776\n",
            "     86        0.2356  0.0771\n",
            "     87        \u001b[36m0.2270\u001b[0m  0.0801\n",
            "     88        0.2275  0.0823\n",
            "     89        \u001b[36m0.2245\u001b[0m  0.0834\n",
            "     90        \u001b[36m0.2184\u001b[0m  0.0835\n",
            "     91        \u001b[36m0.2182\u001b[0m  0.0842\n",
            "     92        \u001b[36m0.2111\u001b[0m  0.0767\n",
            "     93        0.2183  0.0801\n",
            "     94        0.2162  0.0746\n",
            "     95        0.2116  0.0733\n",
            "     96        0.2186  0.0738\n",
            "     97        \u001b[36m0.2051\u001b[0m  0.0785\n",
            "     98        0.2137  0.0749\n",
            "     99        0.2095  0.0757\n",
            "    100        0.2074  0.0882\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0696\n",
            "      2       37.3047  0.0776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0918\n",
            "      4       37.3047  0.0738\n",
            "      5       37.3047  0.0772\n",
            "      6       37.3047  0.0736\n",
            "      7       37.3047  0.0736\n",
            "      8       37.3047  0.0797\n",
            "      9       37.3047  0.0750\n",
            "     10       37.3047  0.0812\n",
            "     11       37.3047  0.0753\n",
            "     12       37.3047  0.0782\n",
            "     13       37.3047  0.0742\n",
            "     14       37.3047  0.0748\n",
            "     15       37.3047  0.0789\n",
            "     16       37.3047  0.0857\n",
            "     17       37.3047  0.0750\n",
            "     18       37.3047  0.0773\n",
            "     19       37.3047  0.0770\n",
            "     20       37.3047  0.0771\n",
            "     21       37.3047  0.0728\n",
            "     22       37.3047  0.0743\n",
            "     23       37.3047  0.0768\n",
            "     24       37.3047  0.0798\n",
            "     25       \u001b[36m12.4531\u001b[0m  0.0740\n",
            "     26        \u001b[36m0.6284\u001b[0m  0.0811\n",
            "     27        \u001b[36m0.6142\u001b[0m  0.0798\n",
            "     28        \u001b[36m0.6122\u001b[0m  0.0883\n",
            "     29        \u001b[36m0.6079\u001b[0m  0.0791\n",
            "     30        \u001b[36m0.5987\u001b[0m  0.0807\n",
            "     31        \u001b[36m0.5823\u001b[0m  0.0742\n",
            "     32        \u001b[36m0.5680\u001b[0m  0.0772\n",
            "     33        \u001b[36m0.5554\u001b[0m  0.0738\n",
            "     34        \u001b[36m0.5122\u001b[0m  0.0766\n",
            "     35        \u001b[36m0.5114\u001b[0m  0.0764\n",
            "     36        \u001b[36m0.4805\u001b[0m  0.0789\n",
            "     37        \u001b[36m0.4714\u001b[0m  0.0820\n",
            "     38        \u001b[36m0.4595\u001b[0m  0.0838\n",
            "     39        \u001b[36m0.4563\u001b[0m  0.0779\n",
            "     40        \u001b[36m0.4514\u001b[0m  0.0816\n",
            "     41        \u001b[36m0.4458\u001b[0m  0.0835\n",
            "     42        \u001b[36m0.4352\u001b[0m  0.0752\n",
            "     43        \u001b[36m0.4308\u001b[0m  0.0813\n",
            "     44        \u001b[36m0.4161\u001b[0m  0.0766\n",
            "     45        \u001b[36m0.4039\u001b[0m  0.0884\n",
            "     46        \u001b[36m0.3918\u001b[0m  0.0762\n",
            "     47        \u001b[36m0.3796\u001b[0m  0.0815\n",
            "     48        \u001b[36m0.3683\u001b[0m  0.0803\n",
            "     49        \u001b[36m0.3530\u001b[0m  0.0754\n",
            "     50        \u001b[36m0.3419\u001b[0m  0.0765\n",
            "     51        \u001b[36m0.3362\u001b[0m  0.0774\n",
            "     52        \u001b[36m0.3216\u001b[0m  0.0860\n",
            "     53        \u001b[36m0.3116\u001b[0m  0.0844\n",
            "     54        \u001b[36m0.3082\u001b[0m  0.0802\n",
            "     55        \u001b[36m0.3047\u001b[0m  0.0761\n",
            "     56        \u001b[36m0.3036\u001b[0m  0.0769\n",
            "     57        \u001b[36m0.2927\u001b[0m  0.0754\n",
            "     58        \u001b[36m0.2817\u001b[0m  0.0763\n",
            "     59        \u001b[36m0.2756\u001b[0m  0.0795\n",
            "     60        \u001b[36m0.2714\u001b[0m  0.0780\n",
            "     61        \u001b[36m0.2642\u001b[0m  0.0749\n",
            "     62        0.2644  0.0747\n",
            "     63        \u001b[36m0.2542\u001b[0m  0.0869\n",
            "     64        \u001b[36m0.2493\u001b[0m  0.0773\n",
            "     65        \u001b[36m0.2301\u001b[0m  0.0822\n",
            "     66        0.2404  0.0880\n",
            "     67        \u001b[36m0.2283\u001b[0m  0.0777\n",
            "     68        \u001b[36m0.2275\u001b[0m  0.0757\n",
            "     69        \u001b[36m0.2223\u001b[0m  0.0750\n",
            "     70        \u001b[36m0.2214\u001b[0m  0.0752\n",
            "     71        0.2223  0.0794\n",
            "     72        \u001b[36m0.2172\u001b[0m  0.0739\n",
            "     73        0.2186  0.0766\n",
            "     74        \u001b[36m0.2145\u001b[0m  0.0797\n",
            "     75        \u001b[36m0.2087\u001b[0m  0.0820\n",
            "     76        \u001b[36m0.2068\u001b[0m  0.0793\n",
            "     77        \u001b[36m0.1971\u001b[0m  0.0764\n",
            "     78        \u001b[36m0.1896\u001b[0m  0.0797\n",
            "     79        0.1909  0.0824\n",
            "     80        \u001b[36m0.1855\u001b[0m  0.0770\n",
            "     81        \u001b[36m0.1812\u001b[0m  0.0771\n",
            "     82        \u001b[36m0.1808\u001b[0m  0.0784\n",
            "     83        \u001b[36m0.1768\u001b[0m  0.0743\n",
            "     84        \u001b[36m0.1756\u001b[0m  0.0841\n",
            "     85        0.1793  0.0759\n",
            "     86        \u001b[36m0.1751\u001b[0m  0.0726\n",
            "     87        \u001b[36m0.1728\u001b[0m  0.0748\n",
            "     88        0.1736  0.0749\n",
            "     89        \u001b[36m0.1716\u001b[0m  0.0806\n",
            "     90        \u001b[36m0.1672\u001b[0m  0.0823\n",
            "     91        \u001b[36m0.1669\u001b[0m  0.0823\n",
            "     92        \u001b[36m0.1652\u001b[0m  0.0776\n",
            "     93        0.1700  0.0765\n",
            "     94        0.1697  0.0816\n",
            "     95        0.1662  0.0753\n",
            "     96        0.1657  0.0757\n",
            "     97        \u001b[36m0.1599\u001b[0m  0.0791\n",
            "     98        0.1713  0.0768\n",
            "     99        0.1928  0.0755\n",
            "    100        0.1705  0.0797\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0736\n",
            "      2       37.3047  0.0791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0893\n",
            "      4       37.3047  0.0837\n",
            "      5       37.3047  0.0762\n",
            "      6       37.3047  0.0712\n",
            "      7       37.3047  0.0735\n",
            "      8       37.3047  0.0753\n",
            "      9       37.3047  0.0750\n",
            "     10       37.3047  0.0751\n",
            "     11       37.3047  0.0782\n",
            "     12       37.3047  0.0880\n",
            "     13       37.3047  0.0755\n",
            "     14       37.3047  0.0779\n",
            "     15       37.3047  0.0756\n",
            "     16       37.3047  0.0784\n",
            "     17       37.3047  0.0852\n",
            "     18       37.3047  0.0746\n",
            "     19       37.3047  0.0740\n",
            "     20       37.3047  0.0837\n",
            "     21       37.3047  0.0744\n",
            "     22       37.3047  0.0761\n",
            "     23       37.3047  0.0756\n",
            "     24       37.3047  0.0774\n",
            "     25       37.3047  0.0751\n",
            "     26       37.3047  0.0764\n",
            "     27       37.3047  0.0844\n",
            "     28       37.3047  0.0745\n",
            "     29       37.3047  0.0833\n",
            "     30       37.3047  0.0835\n",
            "     31       37.3047  0.0792\n",
            "     32       37.3047  0.0744\n",
            "     33       37.3047  0.0751\n",
            "     34       37.3047  0.0797\n",
            "     35       37.3047  0.0762\n",
            "     36       37.3047  0.0757\n",
            "     37       37.3047  0.0784\n",
            "     38       37.3047  0.0846\n",
            "     39       37.3047  0.0760\n",
            "     40       37.3047  0.0825\n",
            "     41       37.3047  0.0771\n",
            "     42       37.3047  0.0882\n",
            "     43       37.3047  0.0732\n",
            "     44       37.3047  0.0742\n",
            "     45       37.3047  0.0740\n",
            "     46       37.3047  0.0729\n",
            "     47       37.3047  0.0790\n",
            "     48       37.3047  0.0773\n",
            "     49       37.3047  0.0844\n",
            "     50       37.3047  0.0832\n",
            "     51       37.3047  0.0780\n",
            "     52       37.3047  0.0792\n",
            "     53       37.3047  0.0762\n",
            "     54       37.3047  0.0758\n",
            "     55       37.3047  0.0817\n",
            "     56       37.3047  0.0744\n",
            "     57       37.3047  0.0749\n",
            "     58       37.3047  0.0725\n",
            "     59       37.3047  0.0817\n",
            "     60       37.3047  0.0764\n",
            "     61       37.3047  0.0855\n",
            "     62       37.3047  0.0755\n",
            "     63       37.3047  0.0776\n",
            "     64       37.3047  0.0759\n",
            "     65       37.3047  0.0766\n",
            "     66       37.3047  0.0756\n",
            "     67       37.3047  0.0772\n",
            "     68       37.3047  0.0791\n",
            "     69       37.3047  0.0774\n",
            "     70       37.3047  0.0775\n",
            "     71       37.3047  0.0727\n",
            "     72       37.3047  0.0733\n",
            "     73       37.3047  0.0745\n",
            "     74       37.3047  0.0740\n",
            "     75       37.3047  0.0787\n",
            "     76       37.3047  0.0781\n",
            "     77       37.3047  0.0746\n",
            "     78       37.3047  0.0887\n",
            "     79       37.3047  0.0809\n",
            "     80       37.3047  0.0904\n",
            "     81       37.3047  0.0746\n",
            "     82       37.3047  0.0776\n",
            "     83       37.3047  0.0766\n",
            "     84       37.3047  0.0752\n",
            "     85       37.3047  0.0762\n",
            "     86       37.3047  0.0746\n",
            "     87       37.3047  0.0811\n",
            "     88       37.3047  0.0795\n",
            "     89       37.3047  0.0753\n",
            "     90       37.3047  0.0759\n",
            "     91       37.3047  0.0761\n",
            "     92       37.3047  0.0787\n",
            "     93       37.3047  0.0836\n",
            "     94       37.3047  0.0786\n",
            "     95       37.3047  0.0727\n",
            "     96       37.3047  0.0753\n",
            "     97       37.3047  0.0790\n",
            "     98       37.3047  0.0754\n",
            "     99       37.3047  0.0841\n",
            "    100       37.3047  0.0748\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0703\n",
            "      2       37.3047  0.0799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0938\n",
            "      4       37.3047  0.0797\n",
            "      5       37.3047  0.0755\n",
            "      6       37.3047  0.0818\n",
            "      7       37.3047  0.0767\n",
            "      8       37.3047  0.0753\n",
            "      9       37.3047  0.0760\n",
            "     10       37.3047  0.0794\n",
            "     11       37.3047  0.0768\n",
            "     12       37.3047  0.0813\n",
            "     13       37.3047  0.0867\n",
            "     14       37.3047  0.0759\n",
            "     15       37.3047  0.0750\n",
            "     16       37.3047  0.0891\n",
            "     17       37.3047  0.0764\n",
            "     18       37.3047  0.0815\n",
            "     19       37.3047  0.0771\n",
            "     20       37.3047  0.0757\n",
            "     21       37.3047  0.0832\n",
            "     22       37.3047  0.0761\n",
            "     23       37.3047  0.0760\n",
            "     24       37.3047  0.0803\n",
            "     25       \u001b[36m15.7621\u001b[0m  0.0782\n",
            "     26        \u001b[36m0.5786\u001b[0m  0.0788\n",
            "     27        \u001b[36m0.5141\u001b[0m  0.0738\n",
            "     28        \u001b[36m0.4814\u001b[0m  0.0818\n",
            "     29        \u001b[36m0.4499\u001b[0m  0.0776\n",
            "     30        \u001b[36m0.4390\u001b[0m  0.0824\n",
            "     31        \u001b[36m0.4095\u001b[0m  0.0820\n",
            "     32        \u001b[36m0.3994\u001b[0m  0.0756\n",
            "     33        \u001b[36m0.3805\u001b[0m  0.0740\n",
            "     34        0.3877  0.0794\n",
            "     35        \u001b[36m0.3592\u001b[0m  0.0754\n",
            "     36        \u001b[36m0.3472\u001b[0m  0.0840\n",
            "     37        \u001b[36m0.3360\u001b[0m  0.0827\n",
            "     38        \u001b[36m0.3299\u001b[0m  0.0774\n",
            "     39        \u001b[36m0.3215\u001b[0m  0.0799\n",
            "     40        \u001b[36m0.3043\u001b[0m  0.0764\n",
            "     41        \u001b[36m0.2972\u001b[0m  0.0776\n",
            "     42        \u001b[36m0.2863\u001b[0m  0.0769\n",
            "     43        \u001b[36m0.2785\u001b[0m  0.0857\n",
            "     44        \u001b[36m0.2698\u001b[0m  0.0736\n",
            "     45        \u001b[36m0.2601\u001b[0m  0.0741\n",
            "     46        \u001b[36m0.2549\u001b[0m  0.0747\n",
            "     47        \u001b[36m0.2470\u001b[0m  0.0832\n",
            "     48        \u001b[36m0.2439\u001b[0m  0.0747\n",
            "     49        \u001b[36m0.2357\u001b[0m  0.0772\n",
            "     50        \u001b[36m0.2326\u001b[0m  0.0746\n",
            "     51        \u001b[36m0.2229\u001b[0m  0.0878\n",
            "     52        \u001b[36m0.2218\u001b[0m  0.0766\n",
            "     53        0.2223  0.0820\n",
            "     54        \u001b[36m0.2195\u001b[0m  0.0754\n",
            "     55        \u001b[36m0.2093\u001b[0m  0.0790\n",
            "     56        0.2112  0.0809\n",
            "     57        \u001b[36m0.2055\u001b[0m  0.0823\n",
            "     58        \u001b[36m0.1965\u001b[0m  0.0761\n",
            "     59        \u001b[36m0.1948\u001b[0m  0.0752\n",
            "     60        0.1956  0.0744\n",
            "     61        \u001b[36m0.1895\u001b[0m  0.0787\n",
            "     62        0.1964  0.0830\n",
            "     63        \u001b[36m0.1842\u001b[0m  0.0784\n",
            "     64        \u001b[36m0.1813\u001b[0m  0.0764\n",
            "     65        0.1814  0.0813\n",
            "     66        \u001b[36m0.1796\u001b[0m  0.0806\n",
            "     67        0.1831  0.0800\n",
            "     68        \u001b[36m0.1704\u001b[0m  0.0764\n",
            "     69        0.1786  0.0829\n",
            "     70        0.2060  0.0832\n",
            "     71        0.2007  0.0785\n",
            "     72        0.1809  0.0764\n",
            "     73        0.1770  0.0809\n",
            "     74        0.1749  0.0811\n",
            "     75        0.1738  0.0787\n",
            "     76        \u001b[36m0.1699\u001b[0m  0.0823\n",
            "     77        \u001b[36m0.1688\u001b[0m  0.0799\n",
            "     78        \u001b[36m0.1654\u001b[0m  0.0795\n",
            "     79        \u001b[36m0.1631\u001b[0m  0.0789\n",
            "     80        0.1652  0.0755\n",
            "     81        0.1672  0.0819\n",
            "     82        0.1844  0.0748\n",
            "     83        0.1790  0.0787\n",
            "     84        0.1633  0.0906\n",
            "     85        0.1652  0.0797\n",
            "     86        \u001b[36m0.1592\u001b[0m  0.0798\n",
            "     87        0.1727  0.0750\n",
            "     88        0.2104  0.0777\n",
            "     89        0.1743  0.0757\n",
            "     90        0.1629  0.0779\n",
            "     91        0.1899  0.0737\n",
            "     92        0.1641  0.0768\n",
            "     93        0.1631  0.0756\n",
            "     94        0.1878  0.0822\n",
            "     95        0.1635  0.0775\n",
            "     96        0.1627  0.0751\n",
            "     97        0.1657  0.0750\n",
            "     98        0.1635  0.0734\n",
            "     99        0.1679  0.0838\n",
            "    100        0.1971  0.0775\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0729\n",
            "      2       37.3047  0.0835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0883\n",
            "      4       37.3047  0.0747\n",
            "      5       37.3047  0.0743\n",
            "      6       37.3047  0.0807\n",
            "      7       37.3047  0.0766\n",
            "      8       37.3047  0.0744\n",
            "      9       37.3047  0.0750\n",
            "     10       37.3047  0.1007\n",
            "     11       37.3047  0.0810\n",
            "     12       37.3047  0.0807\n",
            "     13       37.3047  0.0752\n",
            "     14       37.3047  0.0744\n",
            "     15       37.3047  0.0777\n",
            "     16       37.3047  0.0725\n",
            "     17       37.3047  0.0727\n",
            "     18       37.3047  0.0737\n",
            "     19       37.3047  0.0834\n",
            "     20       37.3047  0.0781\n",
            "     21       37.3047  0.0721\n",
            "     22       37.3047  0.0766\n",
            "     23       37.3047  0.0744\n",
            "     24       37.3047  0.0756\n",
            "     25       \u001b[36m15.8519\u001b[0m  0.0735\n",
            "     26        \u001b[36m0.5775\u001b[0m  0.0721\n",
            "     27        \u001b[36m0.5309\u001b[0m  0.0761\n",
            "     28        \u001b[36m0.5062\u001b[0m  0.0748\n",
            "     29        \u001b[36m0.4860\u001b[0m  0.0715\n",
            "     30        \u001b[36m0.4716\u001b[0m  0.0778\n",
            "     31        \u001b[36m0.4575\u001b[0m  0.0726\n",
            "     32        \u001b[36m0.4410\u001b[0m  0.0859\n",
            "     33        \u001b[36m0.4286\u001b[0m  0.0771\n",
            "     34        \u001b[36m0.4152\u001b[0m  0.0726\n",
            "     35        \u001b[36m0.4038\u001b[0m  0.0738\n",
            "     36        \u001b[36m0.3922\u001b[0m  0.0768\n",
            "     37        \u001b[36m0.3791\u001b[0m  0.0820\n",
            "     38        \u001b[36m0.3708\u001b[0m  0.0733\n",
            "     39        \u001b[36m0.3654\u001b[0m  0.0733\n",
            "     40        \u001b[36m0.3517\u001b[0m  0.0754\n",
            "     41        \u001b[36m0.3412\u001b[0m  0.0743\n",
            "     42        \u001b[36m0.3331\u001b[0m  0.0774\n",
            "     43        \u001b[36m0.3247\u001b[0m  0.0742\n",
            "     44        \u001b[36m0.3173\u001b[0m  0.0776\n",
            "     45        \u001b[36m0.3102\u001b[0m  0.0801\n",
            "     46        \u001b[36m0.3033\u001b[0m  0.0737\n",
            "     47        \u001b[36m0.2983\u001b[0m  0.0742\n",
            "     48        \u001b[36m0.2911\u001b[0m  0.0765\n",
            "     49        \u001b[36m0.2855\u001b[0m  0.0802\n",
            "     50        \u001b[36m0.2810\u001b[0m  0.0755\n",
            "     51        \u001b[36m0.2768\u001b[0m  0.0768\n",
            "     52        \u001b[36m0.2727\u001b[0m  0.0770\n",
            "     53        \u001b[36m0.2669\u001b[0m  0.0780\n",
            "     54        \u001b[36m0.2598\u001b[0m  0.0741\n",
            "     55        \u001b[36m0.2549\u001b[0m  0.0746\n",
            "     56        \u001b[36m0.2492\u001b[0m  0.0770\n",
            "     57        \u001b[36m0.2440\u001b[0m  0.0739\n",
            "     58        \u001b[36m0.2398\u001b[0m  0.0794\n",
            "     59        \u001b[36m0.2349\u001b[0m  0.0817\n",
            "     60        \u001b[36m0.2298\u001b[0m  0.0781\n",
            "     61        \u001b[36m0.2261\u001b[0m  0.0739\n",
            "     62        \u001b[36m0.2213\u001b[0m  0.0758\n",
            "     63        \u001b[36m0.2178\u001b[0m  0.0760\n",
            "     64        \u001b[36m0.2144\u001b[0m  0.0761\n",
            "     65        \u001b[36m0.2109\u001b[0m  0.0745\n",
            "     66        \u001b[36m0.2075\u001b[0m  0.0800\n",
            "     67        \u001b[36m0.2059\u001b[0m  0.0771\n",
            "     68        \u001b[36m0.2031\u001b[0m  0.0767\n",
            "     69        \u001b[36m0.2009\u001b[0m  0.0799\n",
            "     70        \u001b[36m0.1957\u001b[0m  0.0750\n",
            "     71        0.1976  0.0834\n",
            "     72        \u001b[36m0.1915\u001b[0m  0.0749\n",
            "     73        \u001b[36m0.1895\u001b[0m  0.0764\n",
            "     74        \u001b[36m0.1877\u001b[0m  0.0768\n",
            "     75        0.1888  0.0822\n",
            "     76        \u001b[36m0.1837\u001b[0m  0.0796\n",
            "     77        0.1859  0.0807\n",
            "     78        0.1847  0.0811\n",
            "     79        \u001b[36m0.1787\u001b[0m  0.0724\n",
            "     80        0.1789  0.0742\n",
            "     81        \u001b[36m0.1775\u001b[0m  0.0761\n",
            "     82        0.1779  0.0836\n",
            "     83        \u001b[36m0.1757\u001b[0m  0.0759\n",
            "     84        0.1763  0.0833\n",
            "     85        \u001b[36m0.1744\u001b[0m  0.0748\n",
            "     86        0.1750  0.0876\n",
            "     87        \u001b[36m0.1735\u001b[0m  0.0756\n",
            "     88        \u001b[36m0.1692\u001b[0m  0.0822\n",
            "     89        0.1719  0.0786\n",
            "     90        \u001b[36m0.1679\u001b[0m  0.0770\n",
            "     91        0.1702  0.0794\n",
            "     92        \u001b[36m0.1649\u001b[0m  0.0795\n",
            "     93        0.1653  0.0741\n",
            "     94        \u001b[36m0.1637\u001b[0m  0.0749\n",
            "     95        0.1651  0.0757\n",
            "     96        \u001b[36m0.1632\u001b[0m  0.0882\n",
            "     97        0.1646  0.0780\n",
            "     98        0.1959  0.0795\n",
            "     99        0.1790  0.0758\n",
            "    100        0.1675  0.0810\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0703\n",
            "      2       37.3047  0.0728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0855\n",
            "      4       37.3047  0.0714\n",
            "      5       37.3047  0.0749\n",
            "      6       37.3047  0.0791\n",
            "      7       37.3047  0.0723\n",
            "      8       37.3047  0.0768\n",
            "      9       37.3047  0.0792\n",
            "     10       37.3047  0.0712\n",
            "     11       37.3047  0.0764\n",
            "     12       37.3047  0.0740\n",
            "     13       37.3047  0.0804\n",
            "     14       37.3047  0.0752\n",
            "     15       37.3047  0.0783\n",
            "     16       37.3047  0.0849\n",
            "     17       37.3047  0.0753\n",
            "     18       37.3047  0.0767\n",
            "     19       37.3047  0.0759\n",
            "     20       37.3047  0.0750\n",
            "     21       37.3047  0.0776\n",
            "     22       37.3047  0.0822\n",
            "     23       37.3047  0.0728\n",
            "     24       37.3047  0.0908\n",
            "     25       \u001b[36m15.8157\u001b[0m  0.0774\n",
            "     26        \u001b[36m0.6215\u001b[0m  0.0770\n",
            "     27        \u001b[36m0.5732\u001b[0m  0.0807\n",
            "     28        \u001b[36m0.5606\u001b[0m  0.0784\n",
            "     29        \u001b[36m0.5529\u001b[0m  0.0743\n",
            "     30        \u001b[36m0.5523\u001b[0m  0.0759\n",
            "     31        \u001b[36m0.5492\u001b[0m  0.0737\n",
            "     32        \u001b[36m0.5450\u001b[0m  0.0858\n",
            "     33        \u001b[36m0.5383\u001b[0m  0.0748\n",
            "     34        \u001b[36m0.5045\u001b[0m  0.0866\n",
            "     35        \u001b[36m0.4990\u001b[0m  0.0808\n",
            "     36        \u001b[36m0.4900\u001b[0m  0.0810\n",
            "     37        \u001b[36m0.4827\u001b[0m  0.0761\n",
            "     38        \u001b[36m0.4783\u001b[0m  0.0776\n",
            "     39        \u001b[36m0.4663\u001b[0m  0.0754\n",
            "     40        \u001b[36m0.4515\u001b[0m  0.0844\n",
            "     41        \u001b[36m0.4468\u001b[0m  0.0774\n",
            "     42        \u001b[36m0.4388\u001b[0m  0.0745\n",
            "     43        \u001b[36m0.4263\u001b[0m  0.0795\n",
            "     44        \u001b[36m0.4215\u001b[0m  0.0889\n",
            "     45        \u001b[36m0.4148\u001b[0m  0.0762\n",
            "     46        \u001b[36m0.3996\u001b[0m  0.0770\n",
            "     47        0.4086  0.0826\n",
            "     48        \u001b[36m0.3854\u001b[0m  0.0745\n",
            "     49        \u001b[36m0.3827\u001b[0m  0.0766\n",
            "     50        \u001b[36m0.3638\u001b[0m  0.0788\n",
            "     51        \u001b[36m0.3619\u001b[0m  0.0789\n",
            "     52        \u001b[36m0.3441\u001b[0m  0.0774\n",
            "     53        0.3444  0.0768\n",
            "     54        \u001b[36m0.3344\u001b[0m  0.0744\n",
            "     55        \u001b[36m0.3312\u001b[0m  0.0784\n",
            "     56        \u001b[36m0.3237\u001b[0m  0.0759\n",
            "     57        \u001b[36m0.3170\u001b[0m  0.0770\n",
            "     58        \u001b[36m0.3095\u001b[0m  0.0771\n",
            "     59        \u001b[36m0.3050\u001b[0m  0.0737\n",
            "     60        \u001b[36m0.3005\u001b[0m  0.0859\n",
            "     61        \u001b[36m0.2975\u001b[0m  0.0838\n",
            "     62        \u001b[36m0.2894\u001b[0m  0.0755\n",
            "     63        0.2895  0.0756\n",
            "     64        \u001b[36m0.2815\u001b[0m  0.0736\n",
            "     65        \u001b[36m0.2724\u001b[0m  0.0790\n",
            "     66        \u001b[36m0.2683\u001b[0m  0.0766\n",
            "     67        \u001b[36m0.2651\u001b[0m  0.0760\n",
            "     68        0.2676  0.0738\n",
            "     69        \u001b[36m0.2607\u001b[0m  0.0817\n",
            "     70        \u001b[36m0.2586\u001b[0m  0.0758\n",
            "     71        \u001b[36m0.2577\u001b[0m  0.0782\n",
            "     72        \u001b[36m0.2562\u001b[0m  0.0815\n",
            "     73        \u001b[36m0.2536\u001b[0m  0.0837\n",
            "     74        \u001b[36m0.2499\u001b[0m  0.0803\n",
            "     75        0.2548  0.0761\n",
            "     76        0.2500  0.0741\n",
            "     77        \u001b[36m0.2472\u001b[0m  0.0796\n",
            "     78        0.2480  0.0873\n",
            "     79        \u001b[36m0.2448\u001b[0m  0.0799\n",
            "     80        \u001b[36m0.2410\u001b[0m  0.0754\n",
            "     81        0.2419  0.0781\n",
            "     82        \u001b[36m0.2344\u001b[0m  0.0764\n",
            "     83        0.2348  0.0743\n",
            "     84        \u001b[36m0.2314\u001b[0m  0.0748\n",
            "     85        0.2317  0.0847\n",
            "     86        \u001b[36m0.2281\u001b[0m  0.0780\n",
            "     87        \u001b[36m0.2260\u001b[0m  0.0825\n",
            "     88        \u001b[36m0.2248\u001b[0m  0.0810\n",
            "     89        \u001b[36m0.2246\u001b[0m  0.0754\n",
            "     90        \u001b[36m0.2203\u001b[0m  0.0807\n",
            "     91        \u001b[36m0.2172\u001b[0m  0.0736\n",
            "     92        0.2175  0.0742\n",
            "     93        \u001b[36m0.2078\u001b[0m  0.0774\n",
            "     94        0.2095  0.0749\n",
            "     95        \u001b[36m0.2043\u001b[0m  0.0763\n",
            "     96        \u001b[36m0.2014\u001b[0m  0.0793\n",
            "     97        0.2023  0.0749\n",
            "     98        \u001b[36m0.1976\u001b[0m  0.0907\n",
            "     99        \u001b[36m0.1969\u001b[0m  0.0837\n",
            "    100        \u001b[36m0.1884\u001b[0m  0.0777\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0700\n",
            "      2       37.3047  0.0796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0856\n",
            "      4       37.3047  0.0747\n",
            "      5       37.3047  0.0720\n",
            "      6       37.3047  0.0787\n",
            "      7       37.3047  0.0767\n",
            "      8       37.3047  0.0749\n",
            "      9       37.3047  0.0771\n",
            "     10       37.3047  0.0894\n",
            "     11       37.3047  0.0761\n",
            "     12       37.3047  0.0765\n",
            "     13       37.3047  0.0780\n",
            "     14       37.3047  0.0792\n",
            "     15       37.3047  0.0778\n",
            "     16       37.3047  0.0809\n",
            "     17       37.3047  0.0778\n",
            "     18       37.3047  0.0751\n",
            "     19       37.3047  0.0748\n",
            "     20       37.3047  0.0787\n",
            "     21       37.3047  0.0830\n",
            "     22       37.3047  0.0757\n",
            "     23       37.3047  0.0868\n",
            "     24       37.3047  0.0741\n",
            "     25       \u001b[36m16.3706\u001b[0m  0.0848\n",
            "     26        \u001b[36m0.5265\u001b[0m  0.0789\n",
            "     27        \u001b[36m0.5084\u001b[0m  0.0781\n",
            "     28        \u001b[36m0.4952\u001b[0m  0.0787\n",
            "     29        \u001b[36m0.4749\u001b[0m  0.0762\n",
            "     30        \u001b[36m0.4531\u001b[0m  0.0754\n",
            "     31        \u001b[36m0.4335\u001b[0m  0.0787\n",
            "     32        \u001b[36m0.4069\u001b[0m  0.0771\n",
            "     33        \u001b[36m0.3812\u001b[0m  0.0793\n",
            "     34        \u001b[36m0.3586\u001b[0m  0.0776\n",
            "     35        \u001b[36m0.3472\u001b[0m  0.0791\n",
            "     36        \u001b[36m0.3259\u001b[0m  0.0856\n",
            "     37        \u001b[36m0.3163\u001b[0m  0.0769\n",
            "     38        \u001b[36m0.3090\u001b[0m  0.0797\n",
            "     39        \u001b[36m0.3082\u001b[0m  0.0781\n",
            "     40        \u001b[36m0.3039\u001b[0m  0.0747\n",
            "     41        \u001b[36m0.2928\u001b[0m  0.0751\n",
            "     42        \u001b[36m0.2808\u001b[0m  0.0742\n",
            "     43        0.2829  0.0777\n",
            "     44        0.2847  0.0801\n",
            "     45        0.2885  0.0753\n",
            "     46        0.2896  0.0773\n",
            "     47        0.2845  0.0816\n",
            "     48        0.2809  0.0853\n",
            "     49        \u001b[36m0.2803\u001b[0m  0.0752\n",
            "     50        \u001b[36m0.2733\u001b[0m  0.0789\n",
            "     51        0.2864  0.0756\n",
            "     52        0.2741  0.0763\n",
            "     53        0.2855  0.0803\n",
            "     54        0.2807  0.0780\n",
            "     55        \u001b[36m0.2656\u001b[0m  0.0757\n",
            "     56        \u001b[36m0.2591\u001b[0m  0.0750\n",
            "     57        \u001b[36m0.2530\u001b[0m  0.0743\n",
            "     58        \u001b[36m0.2528\u001b[0m  0.0765\n",
            "     59        \u001b[36m0.2435\u001b[0m  0.0819\n",
            "     60        0.2454  0.0752\n",
            "     61        \u001b[36m0.2235\u001b[0m  0.0877\n",
            "     62        0.2367  0.0781\n",
            "     63        0.2242  0.0802\n",
            "     64        0.2319  0.0798\n",
            "     65        \u001b[36m0.2159\u001b[0m  0.0781\n",
            "     66        0.2166  0.0797\n",
            "     67        0.2290  0.0728\n",
            "     68        \u001b[36m0.2091\u001b[0m  0.0773\n",
            "     69        0.2116  0.0769\n",
            "     70        \u001b[36m0.2077\u001b[0m  0.0770\n",
            "     71        0.2114  0.0785\n",
            "     72        0.2125  0.0752\n",
            "     73        \u001b[36m0.2052\u001b[0m  0.0763\n",
            "     74        \u001b[36m0.1911\u001b[0m  0.0893\n",
            "     75        \u001b[36m0.1843\u001b[0m  0.0782\n",
            "     76        \u001b[36m0.1809\u001b[0m  0.0784\n",
            "     77        0.1906  0.0773\n",
            "     78        \u001b[36m0.1780\u001b[0m  0.0791\n",
            "     79        \u001b[36m0.1724\u001b[0m  0.0783\n",
            "     80        0.1727  0.0910\n",
            "     81        \u001b[36m0.1654\u001b[0m  0.0770\n",
            "     82        0.1663  0.0776\n",
            "     83        \u001b[36m0.1585\u001b[0m  0.0763\n",
            "     84        \u001b[36m0.1545\u001b[0m  0.0763\n",
            "     85        \u001b[36m0.1502\u001b[0m  0.0837\n",
            "     86        0.1513  0.0880\n",
            "     87        \u001b[36m0.1493\u001b[0m  0.0825\n",
            "     88        \u001b[36m0.1482\u001b[0m  0.0793\n",
            "     89        \u001b[36m0.1465\u001b[0m  0.0760\n",
            "     90        \u001b[36m0.1382\u001b[0m  0.0774\n",
            "     91        0.1410  0.0754\n",
            "     92        \u001b[36m0.1355\u001b[0m  0.0766\n",
            "     93        0.1409  0.0793\n",
            "     94        0.1361  0.0755\n",
            "     95        \u001b[36m0.1322\u001b[0m  0.0755\n",
            "     96        0.1356  0.0822\n",
            "     97        \u001b[36m0.1295\u001b[0m  0.0767\n",
            "     98        0.1353  0.0761\n",
            "     99        0.1363  0.0911\n",
            "    100        0.1493  0.0775\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0706\n",
            "      2       37.3047  0.0761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0821\n",
            "      4       37.3047  0.0740\n",
            "      5       37.3047  0.0767\n",
            "      6       37.3047  0.0766\n",
            "      7       37.3047  0.0740\n",
            "      8       37.3047  0.0783\n",
            "      9       37.3047  0.0746\n",
            "     10       37.3047  0.0765\n",
            "     11       37.3047  0.0817\n",
            "     12       37.3047  0.0866\n",
            "     13       37.3047  0.0748\n",
            "     14       37.3047  0.0750\n",
            "     15       37.3047  0.0724\n",
            "     16       37.3047  0.0725\n",
            "     17       37.3047  0.0721\n",
            "     18       37.3047  0.0762\n",
            "     19       37.3047  0.0787\n",
            "     20       37.3047  0.0740\n",
            "     21       37.3047  0.0720\n",
            "     22       37.3047  0.0798\n",
            "     23       37.3047  0.0746\n",
            "     24       37.3047  0.0753\n",
            "     25       37.3047  0.0819\n",
            "     26       \u001b[36m15.1645\u001b[0m  0.0810\n",
            "     27        \u001b[36m0.6161\u001b[0m  0.0747\n",
            "     28        \u001b[36m0.5679\u001b[0m  0.0805\n",
            "     29        \u001b[36m0.5292\u001b[0m  0.0742\n",
            "     30        \u001b[36m0.4684\u001b[0m  0.0773\n",
            "     31        \u001b[36m0.4539\u001b[0m  0.0748\n",
            "     32        \u001b[36m0.4257\u001b[0m  0.0717\n",
            "     33        \u001b[36m0.3998\u001b[0m  0.0768\n",
            "     34        \u001b[36m0.3877\u001b[0m  0.0783\n",
            "     35        \u001b[36m0.3748\u001b[0m  0.0742\n",
            "     36        \u001b[36m0.3709\u001b[0m  0.0754\n",
            "     37        \u001b[36m0.3571\u001b[0m  0.0819\n",
            "     38        \u001b[36m0.3531\u001b[0m  0.0876\n",
            "     39        \u001b[36m0.3450\u001b[0m  0.0759\n",
            "     40        \u001b[36m0.3392\u001b[0m  0.0733\n",
            "     41        \u001b[36m0.3313\u001b[0m  0.0746\n",
            "     42        \u001b[36m0.3283\u001b[0m  0.0773\n",
            "     43        \u001b[36m0.3232\u001b[0m  0.0749\n",
            "     44        \u001b[36m0.3206\u001b[0m  0.0755\n",
            "     45        \u001b[36m0.3125\u001b[0m  0.0858\n",
            "     46        \u001b[36m0.3067\u001b[0m  0.0818\n",
            "     47        \u001b[36m0.3015\u001b[0m  0.0750\n",
            "     48        \u001b[36m0.2963\u001b[0m  0.0790\n",
            "     49        \u001b[36m0.2915\u001b[0m  0.0862\n",
            "     50        \u001b[36m0.2853\u001b[0m  0.0846\n",
            "     51        \u001b[36m0.2811\u001b[0m  0.0759\n",
            "     52        \u001b[36m0.2782\u001b[0m  0.0773\n",
            "     53        \u001b[36m0.2756\u001b[0m  0.0757\n",
            "     54        \u001b[36m0.2738\u001b[0m  0.0747\n",
            "     55        \u001b[36m0.2695\u001b[0m  0.0791\n",
            "     56        \u001b[36m0.2686\u001b[0m  0.0763\n",
            "     57        \u001b[36m0.2632\u001b[0m  0.0743\n",
            "     58        \u001b[36m0.2629\u001b[0m  0.0796\n",
            "     59        \u001b[36m0.2611\u001b[0m  0.0744\n",
            "     60        \u001b[36m0.2564\u001b[0m  0.0823\n",
            "     61        \u001b[36m0.2553\u001b[0m  0.0762\n",
            "     62        \u001b[36m0.2537\u001b[0m  0.0781\n",
            "     63        \u001b[36m0.2480\u001b[0m  0.0822\n",
            "     64        \u001b[36m0.2446\u001b[0m  0.0847\n",
            "     65        \u001b[36m0.2368\u001b[0m  0.0759\n",
            "     66        \u001b[36m0.2333\u001b[0m  0.0764\n",
            "     67        \u001b[36m0.2302\u001b[0m  0.0740\n",
            "     68        \u001b[36m0.2296\u001b[0m  0.0778\n",
            "     69        \u001b[36m0.2265\u001b[0m  0.0751\n",
            "     70        \u001b[36m0.2255\u001b[0m  0.0798\n",
            "     71        \u001b[36m0.2231\u001b[0m  0.0804\n",
            "     72        \u001b[36m0.2189\u001b[0m  0.0797\n",
            "     73        0.2206  0.0806\n",
            "     74        0.2198  0.0755\n",
            "     75        \u001b[36m0.2168\u001b[0m  0.0810\n",
            "     76        \u001b[36m0.2111\u001b[0m  0.0874\n",
            "     77        0.2127  0.0757\n",
            "     78        \u001b[36m0.2086\u001b[0m  0.0757\n",
            "     79        0.2090  0.0784\n",
            "     80        \u001b[36m0.2062\u001b[0m  0.0728\n",
            "     81        \u001b[36m0.2021\u001b[0m  0.0832\n",
            "     82        0.2082  0.0747\n",
            "     83        \u001b[36m0.2016\u001b[0m  0.0786\n",
            "     84        \u001b[36m0.1984\u001b[0m  0.0786\n",
            "     85        0.2069  0.0765\n",
            "     86        \u001b[36m0.1981\u001b[0m  0.0768\n",
            "     87        0.2029  0.0801\n",
            "     88        \u001b[36m0.1940\u001b[0m  0.0880\n",
            "     89        0.1982  0.0792\n",
            "     90        \u001b[36m0.1893\u001b[0m  0.0775\n",
            "     91        0.1946  0.0765\n",
            "     92        \u001b[36m0.1875\u001b[0m  0.0796\n",
            "     93        0.1939  0.0781\n",
            "     94        \u001b[36m0.1854\u001b[0m  0.0785\n",
            "     95        \u001b[36m0.1838\u001b[0m  0.0809\n",
            "     96        0.1989  0.0824\n",
            "     97        \u001b[36m0.1835\u001b[0m  0.0845\n",
            "     98        0.2228  0.0771\n",
            "     99        0.1842  0.0823\n",
            "    100        0.1853  0.0777\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.2320\u001b[0m  0.0803\n",
            "      2       37.2320  0.0783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.2320  0.0959\n",
            "      4       37.2320  0.0755\n",
            "      5       37.2320  0.0753\n",
            "      6       37.2320  0.0772\n",
            "      7       37.2320  0.0746\n",
            "      8       37.2320  0.0791\n",
            "      9       37.2320  0.0801\n",
            "     10       37.2320  0.0730\n",
            "     11       37.2320  0.0772\n",
            "     12       37.2320  0.0937\n",
            "     13       37.2320  0.0973\n",
            "     14       37.2320  0.0747\n",
            "     15       37.2320  0.0756\n",
            "     16       37.2320  0.0757\n",
            "     17       37.2320  0.0762\n",
            "     18       37.2320  0.0780\n",
            "     19       37.2320  0.0839\n",
            "     20       37.2320  0.0732\n",
            "     21       37.2320  0.0767\n",
            "     22       37.2320  0.0753\n",
            "     23       37.2320  0.0775\n",
            "     24       37.2320  0.0806\n",
            "     25       \u001b[36m15.7742\u001b[0m  0.0769\n",
            "     26        \u001b[36m0.6050\u001b[0m  0.0825\n",
            "     27        \u001b[36m0.5122\u001b[0m  0.0759\n",
            "     28        0.5438  0.0742\n",
            "     29        \u001b[36m0.5028\u001b[0m  0.0731\n",
            "     30        \u001b[36m0.4805\u001b[0m  0.0744\n",
            "     31        \u001b[36m0.4648\u001b[0m  0.0771\n",
            "     32        \u001b[36m0.4484\u001b[0m  0.0749\n",
            "     33        \u001b[36m0.4330\u001b[0m  0.0768\n",
            "     34        \u001b[36m0.4135\u001b[0m  0.0765\n",
            "     35        \u001b[36m0.4000\u001b[0m  0.0782\n",
            "     36        \u001b[36m0.3873\u001b[0m  0.0769\n",
            "     37        \u001b[36m0.3630\u001b[0m  0.0857\n",
            "     38        \u001b[36m0.3495\u001b[0m  0.0787\n",
            "     39        \u001b[36m0.3344\u001b[0m  0.0828\n",
            "     40        \u001b[36m0.3274\u001b[0m  0.0750\n",
            "     41        \u001b[36m0.3114\u001b[0m  0.0780\n",
            "     42        \u001b[36m0.3046\u001b[0m  0.0756\n",
            "     43        \u001b[36m0.2925\u001b[0m  0.0775\n",
            "     44        \u001b[36m0.2846\u001b[0m  0.0788\n",
            "     45        \u001b[36m0.2714\u001b[0m  0.0783\n",
            "     46        \u001b[36m0.2599\u001b[0m  0.0849\n",
            "     47        \u001b[36m0.2524\u001b[0m  0.0841\n",
            "     48        \u001b[36m0.2453\u001b[0m  0.0745\n",
            "     49        \u001b[36m0.2379\u001b[0m  0.0808\n",
            "     50        \u001b[36m0.2293\u001b[0m  0.0769\n",
            "     51        0.2314  0.0838\n",
            "     52        \u001b[36m0.2211\u001b[0m  0.0751\n",
            "     53        \u001b[36m0.2153\u001b[0m  0.0751\n",
            "     54        \u001b[36m0.2106\u001b[0m  0.0802\n",
            "     55        0.2109  0.0745\n",
            "     56        \u001b[36m0.2058\u001b[0m  0.0778\n",
            "     57        \u001b[36m0.2015\u001b[0m  0.0832\n",
            "     58        \u001b[36m0.1987\u001b[0m  0.0765\n",
            "     59        0.2057  0.0774\n",
            "     60        \u001b[36m0.1893\u001b[0m  0.0745\n",
            "     61        \u001b[36m0.1860\u001b[0m  0.0756\n",
            "     62        \u001b[36m0.1824\u001b[0m  0.0853\n",
            "     63        \u001b[36m0.1757\u001b[0m  0.0741\n",
            "     64        \u001b[36m0.1754\u001b[0m  0.0818\n",
            "     65        \u001b[36m0.1737\u001b[0m  0.0739\n",
            "     66        0.1759  0.0738\n",
            "     67        \u001b[36m0.1695\u001b[0m  0.0750\n",
            "     68        \u001b[36m0.1677\u001b[0m  0.0743\n",
            "     69        \u001b[36m0.1670\u001b[0m  0.0760\n",
            "     70        \u001b[36m0.1629\u001b[0m  0.0771\n",
            "     71        \u001b[36m0.1608\u001b[0m  0.0775\n",
            "     72        \u001b[36m0.1587\u001b[0m  0.0814\n",
            "     73        \u001b[36m0.1576\u001b[0m  0.0758\n",
            "     74        0.1679  0.0781\n",
            "     75        0.1673  0.0807\n",
            "     76        0.1592  0.0776\n",
            "     77        \u001b[36m0.1467\u001b[0m  0.0814\n",
            "     78        0.1536  0.0748\n",
            "     79        0.1516  0.0755\n",
            "     80        0.1557  0.0809\n",
            "     81        \u001b[36m0.1426\u001b[0m  0.0786\n",
            "     82        \u001b[36m0.1387\u001b[0m  0.0783\n",
            "     83        \u001b[36m0.1376\u001b[0m  0.0816\n",
            "     84        \u001b[36m0.1346\u001b[0m  0.0781\n",
            "     85        \u001b[36m0.1331\u001b[0m  0.0758\n",
            "     86        0.1402  0.0797\n",
            "     87        \u001b[36m0.1285\u001b[0m  0.0807\n",
            "     88        \u001b[36m0.1280\u001b[0m  0.0755\n",
            "     89        0.1328  0.0792\n",
            "     90        0.1300  0.0800\n",
            "     91        0.1355  0.0826\n",
            "     92        \u001b[36m0.1256\u001b[0m  0.0768\n",
            "     93        0.1286  0.0753\n",
            "     94        \u001b[36m0.1225\u001b[0m  0.0787\n",
            "     95        \u001b[36m0.1184\u001b[0m  0.0799\n",
            "     96        0.1207  0.0806\n",
            "     97        0.1245  0.0749\n",
            "     98        0.1237  0.0727\n",
            "     99        0.1196  0.0794\n",
            "    100        0.1199  0.0828\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0557\n",
            "      2       37.1094  0.0593\n",
            "      3       37.1094  0.0651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.1094  0.0730\n",
            "      5       37.1094  0.0586\n",
            "      6       37.1094  0.0583\n",
            "      7       37.1094  0.0602\n",
            "      8       37.1094  0.0620\n",
            "      9       37.1094  0.0582\n",
            "     10       37.1094  0.0606\n",
            "     11       37.1094  0.0638\n",
            "     12       37.1094  0.0789\n",
            "     13       37.1094  0.0628\n",
            "     14       37.1094  0.0654\n",
            "     15       37.1094  0.0626\n",
            "     16       37.1094  0.0578\n",
            "     17       37.1094  0.0607\n",
            "     18       37.1094  0.0742\n",
            "     19       37.1094  0.0578\n",
            "     20       37.1094  0.0610\n",
            "     21       37.1094  0.0661\n",
            "     22       37.1094  0.0616\n",
            "     23       37.1094  0.0620\n",
            "     24       37.1094  0.0623\n",
            "     25       37.1094  0.0610\n",
            "     26       37.1094  0.0593\n",
            "     27       37.1094  0.0637\n",
            "     28       37.1094  0.0608\n",
            "     29       37.1094  0.0647\n",
            "     30       37.1094  0.0649\n",
            "     31       37.1094  0.0608\n",
            "     32       37.1094  0.0627\n",
            "     33       37.1094  0.0597\n",
            "     34       37.1094  0.0686\n",
            "     35       37.1094  0.0603\n",
            "     36       37.1094  0.0648\n",
            "     37       37.1094  0.0599\n",
            "     38       37.1094  0.0620\n",
            "     39       37.1094  0.0632\n",
            "     40       37.1094  0.0713\n",
            "     41       37.1094  0.0639\n",
            "     42       37.1094  0.0666\n",
            "     43       37.1094  0.0617\n",
            "     44       37.1094  0.0652\n",
            "     45       37.1094  0.0661\n",
            "     46       37.1094  0.0617\n",
            "     47       37.1094  0.0616\n",
            "     48       37.1094  0.0646\n",
            "     49       37.1094  0.0703\n",
            "     50       37.1094  0.0598\n",
            "     51       37.1094  0.0623\n",
            "     52       37.1094  0.0628\n",
            "     53       37.1094  0.0662\n",
            "     54       37.1094  0.0850\n",
            "     55       37.1094  0.0606\n",
            "     56       37.1094  0.0657\n",
            "     57       37.1094  0.0625\n",
            "     58       37.1094  0.0658\n",
            "     59       37.1094  0.0613\n",
            "     60       37.1094  0.0673\n",
            "     61       37.1094  0.0643\n",
            "     62       37.1094  0.0583\n",
            "     63       37.1094  0.0627\n",
            "     64       37.1094  0.0657\n",
            "     65       37.1094  0.0607\n",
            "     66       37.1094  0.0619\n",
            "     67       37.1094  0.0645\n",
            "     68       37.1094  0.0616\n",
            "     69       37.1094  0.0630\n",
            "     70       37.1094  0.0619\n",
            "     71       37.1094  0.0680\n",
            "     72       37.1094  0.0622\n",
            "     73       37.1094  0.0648\n",
            "     74       37.1094  0.0644\n",
            "     75       37.1094  0.0643\n",
            "     76       37.1094  0.0587\n",
            "     77       37.1094  0.0601\n",
            "     78       37.1094  0.0615\n",
            "     79       37.1094  0.0621\n",
            "     80       37.1094  0.0695\n",
            "     81       37.1094  0.0614\n",
            "     82       37.1094  0.0604\n",
            "     83       37.1094  0.0597\n",
            "     84       37.1094  0.0597\n",
            "     85       37.1094  0.0740\n",
            "     86       37.1094  0.0604\n",
            "     87       37.1094  0.0606\n",
            "     88       37.1094  0.0611\n",
            "     89       37.1094  0.0645\n",
            "     90       37.1094  0.0632\n",
            "     91       37.1094  0.0632\n",
            "     92       37.1094  0.0633\n",
            "     93       37.1094  0.0599\n",
            "     94       37.1094  0.0629\n",
            "     95       37.1094  0.0588\n",
            "     96       37.1094  0.0672\n",
            "     97       37.1094  0.0631\n",
            "     98       37.1094  0.0655\n",
            "     99       37.1094  0.0703\n",
            "    100       37.1094  0.0628\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0547\n",
            "      2       37.1094  0.0600\n",
            "      3       37.1094  0.0638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.1094  0.0690\n",
            "      5       37.1094  0.0642\n",
            "      6       37.1094  0.0630\n",
            "      7       37.1094  0.0720\n",
            "      8       37.1094  0.0609\n",
            "      9       37.1094  0.0589\n",
            "     10       37.1094  0.0619\n",
            "     11       37.1094  0.0686\n",
            "     12       37.1094  0.0651\n",
            "     13       37.1094  0.0605\n",
            "     14       37.1094  0.0606\n",
            "     15       37.1094  0.0613\n",
            "     16       37.1094  0.0638\n",
            "     17       37.1094  0.0660\n",
            "     18       37.1094  0.0616\n",
            "     19       37.1094  0.0632\n",
            "     20       37.1094  0.0653\n",
            "     21       37.1094  0.0662\n",
            "     22       37.1094  0.0599\n",
            "     23       37.1094  0.0602\n",
            "     24       37.1094  0.0606\n",
            "     25       37.1094  0.0626\n",
            "     26       37.1094  0.0613\n",
            "     27       37.1094  0.0694\n",
            "     28       37.1094  0.0594\n",
            "     29       37.1094  0.0618\n",
            "     30       37.1094  0.0611\n",
            "     31       37.1094  0.0753\n",
            "     32       37.1094  0.0611\n",
            "     33       37.1094  0.0601\n",
            "     34       37.1094  0.0624\n",
            "     35       37.1094  0.0611\n",
            "     36       37.1094  0.0630\n",
            "     37       37.1094  0.0661\n",
            "     38       37.1094  0.0588\n",
            "     39       37.1094  0.0637\n",
            "     40       37.1094  0.0626\n",
            "     41       37.1094  0.0607\n",
            "     42       37.1094  0.0600\n",
            "     43       37.1094  0.0677\n",
            "     44       37.1094  0.0621\n",
            "     45       37.1094  0.0670\n",
            "     46       37.1094  0.0607\n",
            "     47       37.1094  0.0611\n",
            "     48       37.1094  0.0605\n",
            "     49       37.1094  0.0668\n",
            "     50       37.1094  0.0625\n",
            "     51       37.1094  0.0624\n",
            "     52       37.1094  0.0629\n",
            "     53       37.1094  0.0634\n",
            "     54       37.1094  0.0601\n",
            "     55       37.1094  0.0635\n",
            "     56       37.1094  0.0595\n",
            "     57       37.1094  0.0620\n",
            "     58       37.1094  0.0615\n",
            "     59       37.1094  0.0739\n",
            "     60       37.1094  0.0636\n",
            "     61       37.1094  0.0595\n",
            "     62       37.1094  0.0633\n",
            "     63       37.1094  0.0610\n",
            "     64       37.1094  0.0666\n",
            "     65       37.1094  0.0605\n",
            "     66       37.1094  0.0648\n",
            "     67       37.1094  0.0633\n",
            "     68       37.1094  0.0711\n",
            "     69       37.1094  0.0601\n",
            "     70       37.1094  0.0586\n",
            "     71       37.1094  0.0603\n",
            "     72       37.1094  0.0606\n",
            "     73       37.1094  0.0630\n",
            "     74       37.1094  0.0677\n",
            "     75       37.1094  0.0594\n",
            "     76       37.1094  0.0606\n",
            "     77       37.1094  0.0697\n",
            "     78       37.1094  0.0622\n",
            "     79       37.1094  0.0632\n",
            "     80       37.1094  0.0638\n",
            "     81       37.1094  0.0631\n",
            "     82       37.1094  0.0614\n",
            "     83       37.1094  0.0629\n",
            "     84       37.1094  0.0610\n",
            "     85       37.1094  0.0626\n",
            "     86       37.1094  0.0615\n",
            "     87       37.1094  0.0625\n",
            "     88       37.1094  0.0613\n",
            "     89       37.1094  0.0653\n",
            "     90       37.1094  0.0762\n",
            "     91       37.1094  0.0670\n",
            "     92       37.1094  0.0644\n",
            "     93       37.1094  0.0621\n",
            "     94       37.1094  0.0629\n",
            "     95       37.1094  0.0594\n",
            "     96       37.1094  0.0653\n",
            "     97       37.1094  0.0618\n",
            "     98       37.1094  0.0696\n",
            "     99       37.1094  0.0619\n",
            "    100       37.1094  0.0621\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0583\n",
            "      2       37.3047  0.0616\n",
            "      3       37.3047  0.0603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0715\n",
            "      5       37.3047  0.0690\n",
            "      6       37.3047  0.0625\n",
            "      7       37.3047  0.0632\n",
            "      8       37.3047  0.0666\n",
            "      9       37.3047  0.0693\n",
            "     10       37.3047  0.0642\n",
            "     11       37.3047  0.0602\n",
            "     12       37.3047  0.0648\n",
            "     13       37.3047  0.0676\n",
            "     14       37.3047  0.0584\n",
            "     15       37.3047  0.0693\n",
            "     16       37.3047  0.0602\n",
            "     17       37.3047  0.0641\n",
            "     18       37.3047  0.0723\n",
            "     19       37.3047  0.0689\n",
            "     20       37.3047  0.0678\n",
            "     21       37.3047  0.0642\n",
            "     22       37.3047  0.0599\n",
            "     23       37.3047  0.0664\n",
            "     24       37.3047  0.0616\n",
            "     25       37.3047  0.0654\n",
            "     26       37.3047  0.0609\n",
            "     27       37.3047  0.0621\n",
            "     28       37.3047  0.0637\n",
            "     29       37.3047  0.0640\n",
            "     30       37.3047  0.0623\n",
            "     31       37.3047  0.0661\n",
            "     32       37.3047  0.0592\n",
            "     33       37.3047  0.0612\n",
            "     34       37.3047  0.0658\n",
            "     35       37.3047  0.0620\n",
            "     36       37.3047  0.0785\n",
            "     37       37.3047  0.0605\n",
            "     38       37.3047  0.0608\n",
            "     39       37.3047  0.0629\n",
            "     40       37.3047  0.0618\n",
            "     41       37.3047  0.0668\n",
            "     42       37.3047  0.0623\n",
            "     43       37.3047  0.0674\n",
            "     44       37.3047  0.0604\n",
            "     45       37.3047  0.0626\n",
            "     46       37.3047  0.0584\n",
            "     47       37.3047  0.0624\n",
            "     48       37.3047  0.0614\n",
            "     49       37.3047  0.0615\n",
            "     50       37.3047  0.0627\n",
            "     51       37.3047  0.0630\n",
            "     52       37.3047  0.0673\n",
            "     53       37.3047  0.0664\n",
            "     54       37.3047  0.0626\n",
            "     55       37.3047  0.0703\n",
            "     56       37.3047  0.0628\n",
            "     57       37.3047  0.0625\n",
            "     58       37.3047  0.0629\n",
            "     59       37.3047  0.0597\n",
            "     60       37.3047  0.0618\n",
            "     61       37.3047  0.0599\n",
            "     62       37.3047  0.0595\n",
            "     63       37.3047  0.0597\n",
            "     64       37.3047  0.0677\n",
            "     65       37.3047  0.0652\n",
            "     66       37.3047  0.0624\n",
            "     67       37.3047  0.0703\n",
            "     68       37.3047  0.0707\n",
            "     69       37.3047  0.0688\n",
            "     70       37.3047  0.0668\n",
            "     71       37.3047  0.0647\n",
            "     72       37.3047  0.0611\n",
            "     73       37.3047  0.0622\n",
            "     74       37.3047  0.0591\n",
            "     75       37.3047  0.0690\n",
            "     76       37.3047  0.0584\n",
            "     77       37.3047  0.0576\n",
            "     78       37.3047  0.0638\n",
            "     79       37.3047  0.0588\n",
            "     80       37.3047  0.0615\n",
            "     81       37.3047  0.0599\n",
            "     82       37.3047  0.0600\n",
            "     83       37.3047  0.0752\n",
            "     84       37.3047  0.0614\n",
            "     85       37.3047  0.0614\n",
            "     86       37.3047  0.0626\n",
            "     87       37.3047  0.0665\n",
            "     88       37.3047  0.0600\n",
            "     89       37.3047  0.0611\n",
            "     90       37.3047  0.0586\n",
            "     91       37.3047  0.0602\n",
            "     92       37.3047  0.0584\n",
            "     93       37.3047  0.0581\n",
            "     94       37.3047  0.0582\n",
            "     95       37.3047  0.0624\n",
            "     96       37.3047  0.0603\n",
            "     97       37.3047  0.0645\n",
            "     98       37.3047  0.0648\n",
            "     99       37.3047  0.0720\n",
            "    100       37.3047  0.0588\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0561\n",
            "      2       37.3047  0.0593\n",
            "      3       37.3047  0.0642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0729\n",
            "      5       37.3047  0.0588\n",
            "      6       37.3047  0.0603\n",
            "      7       37.3047  0.0579\n",
            "      8       37.3047  0.0575\n",
            "      9       37.3047  0.0599\n",
            "     10       37.3047  0.0685\n",
            "     11       37.3047  0.0587\n",
            "     12       37.3047  0.0584\n",
            "     13       37.3047  0.0601\n",
            "     14       37.3047  0.0577\n",
            "     15       37.3047  0.0661\n",
            "     16       37.3047  0.0664\n",
            "     17       37.3047  0.0575\n",
            "     18       37.3047  0.0601\n",
            "     19       37.3047  0.0629\n",
            "     20       37.3047  0.0641\n",
            "     21       37.3047  0.0678\n",
            "     22       37.3047  0.0600\n",
            "     23       37.3047  0.0610\n",
            "     24       37.3047  0.0608\n",
            "     25       37.3047  0.0604\n",
            "     26       37.3047  0.0637\n",
            "     27       37.3047  0.0607\n",
            "     28       37.3047  0.0608\n",
            "     29       37.3047  0.0605\n",
            "     30       37.3047  0.0643\n",
            "     31       37.3047  0.0710\n",
            "     32       37.3047  0.0626\n",
            "     33       37.3047  0.0631\n",
            "     34       37.3047  0.0631\n",
            "     35       37.3047  0.0632\n",
            "     36       37.3047  0.0586\n",
            "     37       37.3047  0.0611\n",
            "     38       37.3047  0.0586\n",
            "     39       37.3047  0.0588\n",
            "     40       37.3047  0.0614\n",
            "     41       37.3047  0.0592\n",
            "     42       37.3047  0.0609\n",
            "     43       37.3047  0.0604\n",
            "     44       37.3047  0.0694\n",
            "     45       37.3047  0.0663\n",
            "     46       37.3047  0.0607\n",
            "     47       37.3047  0.0624\n",
            "     48       37.3047  0.0633\n",
            "     49       37.3047  0.0647\n",
            "     50       37.3047  0.0629\n",
            "     51       37.3047  0.0632\n",
            "     52       37.3047  0.0596\n",
            "     53       37.3047  0.0610\n",
            "     54       37.3047  0.0669\n",
            "     55       37.3047  0.0587\n",
            "     56       37.3047  0.0616\n",
            "     57       37.3047  0.0600\n",
            "     58       37.3047  0.0644\n",
            "     59       37.3047  0.0609\n",
            "     60       37.3047  0.0638\n",
            "     61       37.3047  0.0606\n",
            "     62       37.3047  0.0642\n",
            "     63       37.3047  0.0703\n",
            "     64       37.3047  0.0650\n",
            "     65       37.3047  0.0641\n",
            "     66       37.3047  0.0669\n",
            "     67       37.3047  0.0636\n",
            "     68       37.3047  0.0608\n",
            "     69       37.3047  0.0612\n",
            "     70       37.3047  0.0655\n",
            "     71       37.3047  0.0616\n",
            "     72       37.3047  0.0634\n",
            "     73       37.3047  0.0614\n",
            "     74       37.3047  0.0621\n",
            "     75       37.3047  0.0611\n",
            "     76       37.3047  0.0735\n",
            "     77       37.3047  0.0604\n",
            "     78       37.3047  0.0687\n",
            "     79       37.3047  0.0622\n",
            "     80       37.3047  0.0667\n",
            "     81       37.3047  0.0620\n",
            "     82       37.3047  0.0629\n",
            "     83       37.3047  0.0628\n",
            "     84       37.3047  0.0594\n",
            "     85       37.3047  0.0582\n",
            "     86       37.3047  0.0627\n",
            "     87       37.3047  0.0783\n",
            "     88       37.3047  0.0629\n",
            "     89       37.3047  0.0674\n",
            "     90       37.3047  0.0721\n",
            "     91       37.3047  0.0606\n",
            "     92       37.3047  0.0606\n",
            "     93       37.3047  0.0694\n",
            "     94       37.3047  0.0600\n",
            "     95       37.3047  0.0611\n",
            "     96       37.3047  0.0649\n",
            "     97       37.3047  0.0634\n",
            "     98       37.3047  0.0595\n",
            "     99       37.3047  0.0650\n",
            "    100       37.3047  0.0619\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0551\n",
            "      2       37.3047  0.0709\n",
            "      3       37.3047  0.0626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0700\n",
            "      5       37.3047  0.0623\n",
            "      6       37.3047  0.0656\n",
            "      7       37.3047  0.0608\n",
            "      8       37.3047  0.0656\n",
            "      9       37.3047  0.0712\n",
            "     10       37.3047  0.0638\n",
            "     11       37.3047  0.0631\n",
            "     12       37.3047  0.0630\n",
            "     13       37.3047  0.0637\n",
            "     14       37.3047  0.0617\n",
            "     15       37.3047  0.0627\n",
            "     16       37.3047  0.0613\n",
            "     17       37.3047  0.0674\n",
            "     18       37.3047  0.0637\n",
            "     19       37.3047  0.0631\n",
            "     20       37.3047  0.0621\n",
            "     21       37.3047  0.0622\n",
            "     22       37.3047  0.0686\n",
            "     23       37.3047  0.0624\n",
            "     24       37.3047  0.0708\n",
            "     25       37.3047  0.0629\n",
            "     26       37.3047  0.0629\n",
            "     27       37.3047  0.0646\n",
            "     28       37.3047  0.0617\n",
            "     29       37.3047  0.0606\n",
            "     30       37.3047  0.0604\n",
            "     31       37.3047  0.0596\n",
            "     32       37.3047  0.0643\n",
            "     33       37.3047  0.0624\n",
            "     34       37.3047  0.0606\n",
            "     35       37.3047  0.0665\n",
            "     36       37.3047  0.0702\n",
            "     37       37.3047  0.0690\n",
            "     38       37.3047  0.0626\n",
            "     39       37.3047  0.0605\n",
            "     40       37.3047  0.0695\n",
            "     41       37.3047  0.0648\n",
            "     42       37.3047  0.0620\n",
            "     43       37.3047  0.0582\n",
            "     44       37.3047  0.0594\n",
            "     45       37.3047  0.0633\n",
            "     46       37.3047  0.0625\n",
            "     47       37.3047  0.0684\n",
            "     48       37.3047  0.0636\n",
            "     49       37.3047  0.0603\n",
            "     50       37.3047  0.0597\n",
            "     51       37.3047  0.0643\n",
            "     52       37.3047  0.0638\n",
            "     53       37.3047  0.0617\n",
            "     54       37.3047  0.0704\n",
            "     55       37.3047  0.0695\n",
            "     56       37.3047  0.0645\n",
            "     57       37.3047  0.0660\n",
            "     58       37.3047  0.0673\n",
            "     59       37.3047  0.0640\n",
            "     60       37.3047  0.0587\n",
            "     61       37.3047  0.0582\n",
            "     62       37.3047  0.0623\n",
            "     63       37.3047  0.0637\n",
            "     64       37.3047  0.0604\n",
            "     65       37.3047  0.0628\n",
            "     66       37.3047  0.0598\n",
            "     67       37.3047  0.0625\n",
            "     68       37.3047  0.0694\n",
            "     69       37.3047  0.0646\n",
            "     70       37.3047  0.0624\n",
            "     71       37.3047  0.0689\n",
            "     72       37.3047  0.0665\n",
            "     73       37.3047  0.0692\n",
            "     74       37.3047  0.0619\n",
            "     75       37.3047  0.0619\n",
            "     76       37.3047  0.0643\n",
            "     77       37.3047  0.0625\n",
            "     78       37.3047  0.0617\n",
            "     79       37.3047  0.0617\n",
            "     80       37.3047  0.0654\n",
            "     81       37.3047  0.0605\n",
            "     82       37.3047  0.0744\n",
            "     83       37.3047  0.0621\n",
            "     84       37.3047  0.0628\n",
            "     85       37.3047  0.0598\n",
            "     86       37.3047  0.0742\n",
            "     87       37.3047  0.0631\n",
            "     88       37.3047  0.0615\n",
            "     89       37.3047  0.0580\n",
            "     90       37.3047  0.0602\n",
            "     91       37.3047  0.0594\n",
            "     92       37.3047  0.0620\n",
            "     93       37.3047  0.0594\n",
            "     94       37.3047  0.0599\n",
            "     95       37.3047  0.0583\n",
            "     96       37.3047  0.0640\n",
            "     97       37.3047  0.0604\n",
            "     98       37.3047  0.0651\n",
            "     99       37.3047  0.0637\n",
            "    100       37.3047  0.0616\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0542\n",
            "      2       37.3047  0.0734\n",
            "      3       37.3047  0.0642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0710\n",
            "      5       37.3047  0.0589\n",
            "      6       37.3047  0.0603\n",
            "      7       37.3047  0.0600\n",
            "      8       37.3047  0.0591\n",
            "      9       37.3047  0.0598\n",
            "     10       37.3047  0.0635\n",
            "     11       37.3047  0.0606\n",
            "     12       37.3047  0.0601\n",
            "     13       37.3047  0.0579\n",
            "     14       37.3047  0.0674\n",
            "     15       37.3047  0.0595\n",
            "     16       37.3047  0.0600\n",
            "     17       37.3047  0.0630\n",
            "     18       37.3047  0.0776\n",
            "     19       37.3047  0.0595\n",
            "     20       37.3047  0.0634\n",
            "     21       37.3047  0.0579\n",
            "     22       37.3047  0.0621\n",
            "     23       37.3047  0.0585\n",
            "     24       37.3047  0.0620\n",
            "     25       37.3047  0.0592\n",
            "     26       37.3047  0.0606\n",
            "     27       37.3047  0.0588\n",
            "     28       37.3047  0.0605\n",
            "     29       37.3047  0.0708\n",
            "     30       37.3047  0.0596\n",
            "     31       37.3047  0.0627\n",
            "     32       37.3047  0.0607\n",
            "     33       37.3047  0.0633\n",
            "     34       37.3047  0.0740\n",
            "     35       37.3047  0.0622\n",
            "     36       37.3047  0.0591\n",
            "     37       37.3047  0.0607\n",
            "     38       37.3047  0.0613\n",
            "     39       37.3047  0.0676\n",
            "     40       37.3047  0.0595\n",
            "     41       37.3047  0.0635\n",
            "     42       37.3047  0.0695\n",
            "     43       37.3047  0.0613\n",
            "     44       37.3047  0.0626\n",
            "     45       37.3047  0.0629\n",
            "     46       37.3047  0.0644\n",
            "     47       37.3047  0.0608\n",
            "     48       37.3047  0.0621\n",
            "     49       37.3047  0.0802\n",
            "     50       37.3047  0.0710\n",
            "     51       37.3047  0.0685\n",
            "     52       37.3047  0.0609\n",
            "     53       37.3047  0.0607\n",
            "     54       37.3047  0.0628\n",
            "     55       37.3047  0.0610\n",
            "     56       37.3047  0.0609\n",
            "     57       37.3047  0.0652\n",
            "     58       37.3047  0.0615\n",
            "     59       37.3047  0.0607\n",
            "     60       37.3047  0.0707\n",
            "     61       37.3047  0.0634\n",
            "     62       37.3047  0.0596\n",
            "     63       37.3047  0.0632\n",
            "     64       37.3047  0.0657\n",
            "     65       37.3047  0.0651\n",
            "     66       37.3047  0.0638\n",
            "     67       37.3047  0.0602\n",
            "     68       37.3047  0.0614\n",
            "     69       37.3047  0.0642\n",
            "     70       37.3047  0.0635\n",
            "     71       37.3047  0.0639\n",
            "     72       37.3047  0.0620\n",
            "     73       37.3047  0.0668\n",
            "     74       37.3047  0.0692\n",
            "     75       37.3047  0.0650\n",
            "     76       37.3047  0.0646\n",
            "     77       37.3047  0.0620\n",
            "     78       37.3047  0.0613\n",
            "     79       37.3047  0.0664\n",
            "     80       37.3047  0.0691\n",
            "     81       37.3047  0.0601\n",
            "     82       37.3047  0.0602\n",
            "     83       37.3047  0.0683\n",
            "     84       37.3047  0.0631\n",
            "     85       37.3047  0.0652\n",
            "     86       37.3047  0.0604\n",
            "     87       37.3047  0.0643\n",
            "     88       37.3047  0.0686\n",
            "     89       37.3047  0.0646\n",
            "     90       37.3047  0.0616\n",
            "     91       37.3047  0.0623\n",
            "     92       37.3047  0.0591\n",
            "     93       37.3047  0.0649\n",
            "     94       37.3047  0.0666\n",
            "     95       37.3047  0.0609\n",
            "     96       37.3047  0.0756\n",
            "     97       37.3047  0.0592\n",
            "     98       37.3047  0.0658\n",
            "     99       37.3047  0.0612\n",
            "    100       37.3047  0.0659\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0551\n",
            "      2       37.3047  0.0625\n",
            "      3       37.3047  0.0590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0830\n",
            "      5       37.3047  0.0622\n",
            "      6       37.3047  0.0677\n",
            "      7       37.3047  0.0656\n",
            "      8       37.3047  0.0612\n",
            "      9       37.3047  0.0662\n",
            "     10       37.3047  0.0595\n",
            "     11       37.3047  0.0752\n",
            "     12       37.3047  0.0611\n",
            "     13       37.3047  0.0628\n",
            "     14       37.3047  0.0642\n",
            "     15       37.3047  0.0623\n",
            "     16       37.3047  0.0626\n",
            "     17       37.3047  0.0652\n",
            "     18       37.3047  0.0608\n",
            "     19       37.3047  0.0744\n",
            "     20       37.3047  0.0623\n",
            "     21       37.3047  0.0627\n",
            "     22       37.3047  0.0626\n",
            "     23       37.3047  0.0695\n",
            "     24       37.3047  0.0654\n",
            "     25       37.3047  0.0628\n",
            "     26       37.3047  0.0702\n",
            "     27       37.3047  0.0625\n",
            "     28       37.3047  0.0602\n",
            "     29       37.3047  0.0714\n",
            "     30       37.3047  0.0652\n",
            "     31       37.3047  0.0611\n",
            "     32       37.3047  0.0637\n",
            "     33       37.3047  0.0688\n",
            "     34       37.3047  0.0595\n",
            "     35       37.3047  0.0618\n",
            "     36       37.3047  0.0623\n",
            "     37       37.3047  0.0645\n",
            "     38       37.3047  0.0616\n",
            "     39       37.3047  0.0637\n",
            "     40       37.3047  0.0604\n",
            "     41       37.3047  0.0611\n",
            "     42       37.3047  0.0733\n",
            "     43       37.3047  0.0609\n",
            "     44       37.3047  0.0628\n",
            "     45       37.3047  0.0608\n",
            "     46       37.3047  0.0645\n",
            "     47       37.3047  0.0602\n",
            "     48       37.3047  0.0604\n",
            "     49       37.3047  0.0673\n",
            "     50       37.3047  0.0604\n",
            "     51       37.3047  0.0748\n",
            "     52       37.3047  0.0646\n",
            "     53       37.3047  0.0646\n",
            "     54       37.3047  0.0713\n",
            "     55       37.3047  0.0623\n",
            "     56       37.3047  0.0642\n",
            "     57       37.3047  0.0673\n",
            "     58       37.3047  0.0623\n",
            "     59       37.3047  0.0591\n",
            "     60       37.3047  0.0635\n",
            "     61       37.3047  0.0620\n",
            "     62       37.3047  0.0629\n",
            "     63       37.3047  0.0607\n",
            "     64       37.3047  0.0623\n",
            "     65       37.3047  0.0670\n",
            "     66       37.3047  0.0653\n",
            "     67       37.3047  0.0639\n",
            "     68       37.3047  0.0708\n",
            "     69       37.3047  0.0635\n",
            "     70       37.3047  0.0622\n",
            "     71       37.3047  0.0602\n",
            "     72       37.3047  0.0607\n",
            "     73       37.3047  0.0696\n",
            "     74       37.3047  0.0633\n",
            "     75       37.3047  0.0650\n",
            "     76       37.3047  0.0622\n",
            "     77       37.3047  0.0621\n",
            "     78       37.3047  0.0679\n",
            "     79       37.3047  0.0676\n",
            "     80       37.3047  0.0664\n",
            "     81       37.3047  0.0616\n",
            "     82       37.3047  0.0623\n",
            "     83       37.3047  0.0652\n",
            "     84       37.3047  0.0690\n",
            "     85       37.3047  0.0617\n",
            "     86       37.3047  0.0666\n",
            "     87       37.3047  0.0609\n",
            "     88       37.3047  0.0721\n",
            "     89       37.3047  0.0600\n",
            "     90       37.3047  0.0662\n",
            "     91       37.3047  0.0622\n",
            "     92       37.3047  0.0650\n",
            "     93       37.3047  0.0595\n",
            "     94       37.3047  0.0640\n",
            "     95       37.3047  0.0691\n",
            "     96       37.3047  0.0618\n",
            "     97       37.3047  0.0703\n",
            "     98       37.3047  0.0628\n",
            "     99       37.3047  0.0604\n",
            "    100       37.3047  0.0583\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0538\n",
            "      2       37.3047  0.0611\n",
            "      3       37.3047  0.0648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0725\n",
            "      5       37.3047  0.0584\n",
            "      6       37.3047  0.0631\n",
            "      7       37.3047  0.0623\n",
            "      8       37.3047  0.0579\n",
            "      9       37.3047  0.0664\n",
            "     10       37.3047  0.0708\n",
            "     11       37.3047  0.0674\n",
            "     12       37.3047  0.0625\n",
            "     13       37.3047  0.0644\n",
            "     14       37.3047  0.0631\n",
            "     15       37.3047  0.0700\n",
            "     16       37.3047  0.0632\n",
            "     17       37.3047  0.0618\n",
            "     18       37.3047  0.0608\n",
            "     19       37.3047  0.0648\n",
            "     20       37.3047  0.0630\n",
            "     21       37.3047  0.0605\n",
            "     22       37.3047  0.0649\n",
            "     23       37.3047  0.0607\n",
            "     24       37.3047  0.0610\n",
            "     25       37.3047  0.0664\n",
            "     26       37.3047  0.0799\n",
            "     27       37.3047  0.0666\n",
            "     28       37.3047  0.0613\n",
            "     29       37.3047  0.0616\n",
            "     30       37.3047  0.0608\n",
            "     31       37.3047  0.0612\n",
            "     32       37.3047  0.0637\n",
            "     33       37.3047  0.0599\n",
            "     34       37.3047  0.0681\n",
            "     35       37.3047  0.0623\n",
            "     36       37.3047  0.0620\n",
            "     37       37.3047  0.0586\n",
            "     38       37.3047  0.0652\n",
            "     39       37.3047  0.0572\n",
            "     40       37.3047  0.0603\n",
            "     41       37.3047  0.0642\n",
            "     42       37.3047  0.0599\n",
            "     43       37.3047  0.0621\n",
            "     44       37.3047  0.0612\n",
            "     45       37.3047  0.0665\n",
            "     46       37.3047  0.0663\n",
            "     47       37.3047  0.0641\n",
            "     48       37.3047  0.0608\n",
            "     49       37.3047  0.0616\n",
            "     50       37.3047  0.0714\n",
            "     51       37.3047  0.0612\n",
            "     52       37.3047  0.0620\n",
            "     53       37.3047  0.0612\n",
            "     54       37.3047  0.0615\n",
            "     55       37.3047  0.0699\n",
            "     56       37.3047  0.0638\n",
            "     57       37.3047  0.0690\n",
            "     58       37.3047  0.0604\n",
            "     59       37.3047  0.0632\n",
            "     60       37.3047  0.0610\n",
            "     61       37.3047  0.0584\n",
            "     62       37.3047  0.0622\n",
            "     63       37.3047  0.0603\n",
            "     64       37.3047  0.0590\n",
            "     65       37.3047  0.0648\n",
            "     66       37.3047  0.0664\n",
            "     67       37.3047  0.0664\n",
            "     68       37.3047  0.0611\n",
            "     69       37.3047  0.0628\n",
            "     70       37.3047  0.0591\n",
            "     71       37.3047  0.0668\n",
            "     72       37.3047  0.0585\n",
            "     73       37.3047  0.0623\n",
            "     74       37.3047  0.0615\n",
            "     75       37.3047  0.0630\n",
            "     76       37.3047  0.0646\n",
            "     77       37.3047  0.0631\n",
            "     78       37.3047  0.0606\n",
            "     79       37.3047  0.0594\n",
            "     80       37.3047  0.0657\n",
            "     81       37.3047  0.0716\n",
            "     82       37.3047  0.0611\n",
            "     83       37.3047  0.0614\n",
            "     84       37.3047  0.0615\n",
            "     85       37.3047  0.0733\n",
            "     86       37.3047  0.0631\n",
            "     87       37.3047  0.0659\n",
            "     88       37.3047  0.0613\n",
            "     89       37.3047  0.0609\n",
            "     90       37.3047  0.0610\n",
            "     91       37.3047  0.0714\n",
            "     92       37.3047  0.0592\n",
            "     93       37.3047  0.0620\n",
            "     94       37.3047  0.0626\n",
            "     95       37.3047  0.0638\n",
            "     96       37.3047  0.0595\n",
            "     97       37.3047  0.0725\n",
            "     98       37.3047  0.0614\n",
            "     99       37.3047  0.0588\n",
            "    100       37.3047  0.0598\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0573\n",
            "      2       37.3047  0.0673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0657\n",
            "      4       37.3047  0.0750\n",
            "      5       37.3047  0.0603\n",
            "      6       37.3047  0.0665\n",
            "      7       37.3047  0.0616\n",
            "      8       37.3047  0.0600\n",
            "      9       37.3047  0.0584\n",
            "     10       37.3047  0.0594\n",
            "     11       37.3047  0.0616\n",
            "     12       37.3047  0.0688\n",
            "     13       37.3047  0.0593\n",
            "     14       37.3047  0.0608\n",
            "     15       37.3047  0.0573\n",
            "     16       37.3047  0.0622\n",
            "     17       37.3047  0.0685\n",
            "     18       37.3047  0.0621\n",
            "     19       37.3047  0.0632\n",
            "     20       37.3047  0.0616\n",
            "     21       37.3047  0.0677\n",
            "     22       37.3047  0.0660\n",
            "     23       37.3047  0.0632\n",
            "     24       37.3047  0.0611\n",
            "     25       37.3047  0.0605\n",
            "     26       37.3047  0.0615\n",
            "     27       37.3047  0.0630\n",
            "     28       37.3047  0.0689\n",
            "     29       37.3047  0.0641\n",
            "     30       37.3047  0.0606\n",
            "     31       37.3047  0.0661\n",
            "     32       37.3047  0.0632\n",
            "     33       37.3047  0.0717\n",
            "     34       37.3047  0.0614\n",
            "     35       37.3047  0.0619\n",
            "     36       37.3047  0.0583\n",
            "     37       37.3047  0.0630\n",
            "     38       37.3047  0.0589\n",
            "     39       37.3047  0.0609\n",
            "     40       37.3047  0.0596\n",
            "     41       37.3047  0.0595\n",
            "     42       37.3047  0.0615\n",
            "     43       37.3047  0.0602\n",
            "     44       37.3047  0.0693\n",
            "     45       37.3047  0.0696\n",
            "     46       37.3047  0.0602\n",
            "     47       37.3047  0.0590\n",
            "     48       37.3047  0.0624\n",
            "     49       37.3047  0.0610\n",
            "     50       37.3047  0.0610\n",
            "     51       37.3047  0.0654\n",
            "     52       37.3047  0.0630\n",
            "     53       37.3047  0.0718\n",
            "     54       37.3047  0.0610\n",
            "     55       37.3047  0.0596\n",
            "     56       37.3047  0.0592\n",
            "     57       37.3047  0.0621\n",
            "     58       37.3047  0.0661\n",
            "     59       37.3047  0.0613\n",
            "     60       37.3047  0.0733\n",
            "     61       37.3047  0.0613\n",
            "     62       37.3047  0.0678\n",
            "     63       37.3047  0.0713\n",
            "     64       37.3047  0.0753\n",
            "     65       37.3047  0.0635\n",
            "     66       37.3047  0.0636\n",
            "     67       37.3047  0.0658\n",
            "     68       37.3047  0.0585\n",
            "     69       37.3047  0.0592\n",
            "     70       37.3047  0.0589\n",
            "     71       37.3047  0.0641\n",
            "     72       37.3047  0.0618\n",
            "     73       37.3047  0.0645\n",
            "     74       37.3047  0.0662\n",
            "     75       37.3047  0.0678\n",
            "     76       37.3047  0.0611\n",
            "     77       37.3047  0.0827\n",
            "     78       37.3047  0.0616\n",
            "     79       37.3047  0.0625\n",
            "     80       37.3047  0.0667\n",
            "     81       37.3047  0.0646\n",
            "     82       37.3047  0.0666\n",
            "     83       37.3047  0.0662\n",
            "     84       37.3047  0.0621\n",
            "     85       37.3047  0.0644\n",
            "     86       37.3047  0.0627\n",
            "     87       37.3047  0.0611\n",
            "     88       37.3047  0.0608\n",
            "     89       37.3047  0.0607\n",
            "     90       37.3047  0.0697\n",
            "     91       37.3047  0.0611\n",
            "     92       37.3047  0.0614\n",
            "     93       37.3047  0.0611\n",
            "     94       37.3047  0.0661\n",
            "     95       37.3047  0.0610\n",
            "     96       37.3047  0.0600\n",
            "     97       37.3047  0.0647\n",
            "     98       37.3047  0.0604\n",
            "     99       37.3047  0.0670\n",
            "    100       37.3047  0.0601\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.2320\u001b[0m  0.0579\n",
            "      2       37.2320  0.0609\n",
            "      3       37.2320  0.0594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.2320  0.0711\n",
            "      5       37.2320  0.0618\n",
            "      6       37.2320  0.0649\n",
            "      7       37.2320  0.0598\n",
            "      8       37.2320  0.0617\n",
            "      9       37.2320  0.0756\n",
            "     10       37.2320  0.0602\n",
            "     11       37.2320  0.0663\n",
            "     12       37.2320  0.0642\n",
            "     13       37.2320  0.0628\n",
            "     14       37.2320  0.0602\n",
            "     15       37.2320  0.0621\n",
            "     16       37.2320  0.0611\n",
            "     17       37.2320  0.0653\n",
            "     18       37.2320  0.0609\n",
            "     19       37.2320  0.0640\n",
            "     20       37.2320  0.0685\n",
            "     21       37.2320  0.0676\n",
            "     22       37.2320  0.0601\n",
            "     23       37.2320  0.0658\n",
            "     24       37.2320  0.0640\n",
            "     25       37.2320  0.0642\n",
            "     26       37.2320  0.0619\n",
            "     27       37.2320  0.0649\n",
            "     28       37.2320  0.0602\n",
            "     29       37.2320  0.0643\n",
            "     30       37.2320  0.0579\n",
            "     31       37.2320  0.0598\n",
            "     32       37.2320  0.0595\n",
            "     33       37.2320  0.0605\n",
            "     34       37.2320  0.0621\n",
            "     35       37.2320  0.0573\n",
            "     36       37.2320  0.0585\n",
            "     37       37.2320  0.0752\n",
            "     38       37.2320  0.0589\n",
            "     39       37.2320  0.0600\n",
            "     40       37.2320  0.0624\n",
            "     41       37.2320  0.0589\n",
            "     42       37.2320  0.0638\n",
            "     43       37.2320  0.0633\n",
            "     44       37.2320  0.0601\n",
            "     45       37.2320  0.0596\n",
            "     46       37.2320  0.0612\n",
            "     47       37.2320  0.0624\n",
            "     48       37.2320  0.0596\n",
            "     49       37.2320  0.0589\n",
            "     50       37.2320  0.0602\n",
            "     51       37.2320  0.0666\n",
            "     52       37.2320  0.0654\n",
            "     53       37.2320  0.0710\n",
            "     54       37.2320  0.0619\n",
            "     55       37.2320  0.0624\n",
            "     56       37.2320  0.0661\n",
            "     57       37.2320  0.0618\n",
            "     58       37.2320  0.0648\n",
            "     59       37.2320  0.0619\n",
            "     60       37.2320  0.0603\n",
            "     61       37.2320  0.0627\n",
            "     62       37.2320  0.0635\n",
            "     63       37.2320  0.0652\n",
            "     64       37.2320  0.0641\n",
            "     65       37.2320  0.0615\n",
            "     66       37.2320  0.0663\n",
            "     67       37.2320  0.0628\n",
            "     68       37.2320  0.0702\n",
            "     69       37.2320  0.0715\n",
            "     70       37.2320  0.0667\n",
            "     71       37.2320  0.0691\n",
            "     72       37.2320  0.0634\n",
            "     73       37.2320  0.0678\n",
            "     74       37.2320  0.0610\n",
            "     75       37.2320  0.0664\n",
            "     76       37.2320  0.0610\n",
            "     77       37.2320  0.0613\n",
            "     78       37.2320  0.0628\n",
            "     79       37.2320  0.0662\n",
            "     80       37.2320  0.0676\n",
            "     81       37.2320  0.0621\n",
            "     82       37.2320  0.0603\n",
            "     83       37.2320  0.0749\n",
            "     84       37.2320  0.0644\n",
            "     85       37.2320  0.0598\n",
            "     86       37.2320  0.0642\n",
            "     87       37.2320  0.0609\n",
            "     88       37.2320  0.0621\n",
            "     89       37.2320  0.0619\n",
            "     90       37.2320  0.0592\n",
            "     91       37.2320  0.0653\n",
            "     92       37.2320  0.0589\n",
            "     93       37.2320  0.0638\n",
            "     94       37.2320  0.0649\n",
            "     95       37.2320  0.0608\n",
            "     96       37.2320  0.0612\n",
            "     97       37.2320  0.0690\n",
            "     98       37.2320  0.0596\n",
            "     99       37.2320  0.0674\n",
            "    100       37.2320  0.0660\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m60.5469\u001b[0m  0.0727\n",
            "      2       61.3025  0.0771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       61.3282  0.0897\n",
            "      4       60.7001  0.0759\n",
            "      5       60.7422  0.0730\n",
            "      6       60.7422  0.0751\n",
            "      7       60.7422  0.0837\n",
            "      8       60.7422  0.0796\n",
            "      9       60.7422  0.0742\n",
            "     10       60.7422  0.0773\n",
            "     11       60.7422  0.0774\n",
            "     12       60.7422  0.0851\n",
            "     13       60.7422  0.0773\n",
            "     14       60.7422  0.0792\n",
            "     15       60.7422  0.0799\n",
            "     16       60.7422  0.0751\n",
            "     17       60.7422  0.0786\n",
            "     18       60.7422  0.0761\n",
            "     19       60.7422  0.0763\n",
            "     20       60.5469  0.0790\n",
            "     21       \u001b[36m60.5237\u001b[0m  0.0771\n",
            "     22       \u001b[36m60.1929\u001b[0m  0.0782\n",
            "     23       \u001b[36m60.1562\u001b[0m  0.0826\n",
            "     24       60.1562  0.0920\n",
            "     25       60.1562  0.0776\n",
            "     26       60.1562  0.0794\n",
            "     27       60.1562  0.0756\n",
            "     28       60.1562  0.0788\n",
            "     29       60.1562  0.0787\n",
            "     30       60.1562  0.0748\n",
            "     31       60.1562  0.0759\n",
            "     32       60.1564  0.0757\n",
            "     33       \u001b[36m60.0518\u001b[0m  0.0812\n",
            "     34       60.0521  0.0838\n",
            "     35       \u001b[36m60.0356\u001b[0m  0.0935\n",
            "     36       60.1714  0.0784\n",
            "     37       60.1562  0.0829\n",
            "     38       60.1565  0.0780\n",
            "     39       60.5469  0.0744\n",
            "     40       60.5469  0.0779\n",
            "     41       60.5469  0.0786\n",
            "     42       60.5469  0.0744\n",
            "     43       60.5469  0.0772\n",
            "     44       60.5469  0.0750\n",
            "     45       60.5469  0.0777\n",
            "     46       60.5469  0.0759\n",
            "     47       60.5469  0.0789\n",
            "     48       60.5469  0.0773\n",
            "     49       60.5469  0.0843\n",
            "     50       60.5469  0.0847\n",
            "     51       60.5469  0.0759\n",
            "     52       60.5469  0.0820\n",
            "     53       60.5469  0.0779\n",
            "     54       60.5469  0.0831\n",
            "     55       60.5469  0.0765\n",
            "     56       60.5469  0.0783\n",
            "     57       60.5238  0.0789\n",
            "     58       60.5220  0.0773\n",
            "     59       60.5202  0.0796\n",
            "     60       60.5183  0.0845\n",
            "     61       60.5164  0.0811\n",
            "     62       60.5144  0.0902\n",
            "     63       60.5124  0.0749\n",
            "     64       60.5103  0.0810\n",
            "     65       60.5082  0.0768\n",
            "     66       60.5060  0.0779\n",
            "     67       60.5037  0.0741\n",
            "     68       60.5013  0.0761\n",
            "     69       60.4989  0.0769\n",
            "     70       60.4964  0.0780\n",
            "     71       60.4938  0.0843\n",
            "     72       60.4911  0.0753\n",
            "     73       60.4883  0.0745\n",
            "     74       60.4855  0.0813\n",
            "     75       60.4825  0.0847\n",
            "     76       60.4795  0.0777\n",
            "     77       60.4764  0.0819\n",
            "     78       60.4732  0.0749\n",
            "     79       60.4699  0.0743\n",
            "     80       60.4665  0.0755\n",
            "     81       60.4630  0.0860\n",
            "     82       60.4594  0.0740\n",
            "     83       60.4557  0.0740\n",
            "     84       60.4519  0.0760\n",
            "     85       60.4479  0.0781\n",
            "     86       60.4438  0.0788\n",
            "     87       60.4396  0.0871\n",
            "     88       60.4352  0.0768\n",
            "     89       60.4306  0.0801\n",
            "     90       60.4243  0.0854\n",
            "     91       60.2744  0.0754\n",
            "     92       60.7422  0.0782\n",
            "     93       60.7422  0.0759\n",
            "     94       60.7422  0.0788\n",
            "     95       60.7422  0.0750\n",
            "     96       60.7422  0.0793\n",
            "     97       60.7422  0.0843\n",
            "     98       60.7422  0.0786\n",
            "     99       60.7422  0.0797\n",
            "    100       60.7422  0.0830\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0828\n",
            "      2       37.1094  0.0770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.1094  0.0854\n",
            "      4       37.1094  0.0735\n",
            "      5       37.1094  0.0776\n",
            "      6       37.1094  0.0769\n",
            "      7       37.1094  0.0793\n",
            "      8       37.1094  0.0811\n",
            "      9       37.1094  0.0758\n",
            "     10       37.1094  0.0748\n",
            "     11       37.1094  0.0863\n",
            "     12       37.1094  0.0848\n",
            "     13       37.1094  0.0771\n",
            "     14       37.1094  0.0837\n",
            "     15       37.1094  0.0751\n",
            "     16       37.1094  0.0756\n",
            "     17       37.1094  0.0757\n",
            "     18       37.1094  0.0750\n",
            "     19       37.1094  0.0766\n",
            "     20       37.1094  0.0770\n",
            "     21       37.1094  0.0738\n",
            "     22       37.1094  0.0743\n",
            "     23       37.1094  0.0841\n",
            "     24       37.1094  0.0746\n",
            "     25       37.1094  0.0846\n",
            "     26       37.1094  0.0780\n",
            "     27       37.1094  0.0790\n",
            "     28       37.1094  0.0757\n",
            "     29       37.1094  0.0728\n",
            "     30       37.1094  0.0835\n",
            "     31       37.1094  0.0798\n",
            "     32       37.1094  0.0773\n",
            "     33       37.1094  0.0732\n",
            "     34       37.1094  0.0744\n",
            "     35       37.1094  0.0823\n",
            "     36       37.1094  0.0791\n",
            "     37       37.1094  0.0779\n",
            "     38       37.1094  0.0853\n",
            "     39       37.1094  0.0806\n",
            "     40       37.1094  0.0772\n",
            "     41       37.1094  0.0774\n",
            "     42       37.1094  0.0762\n",
            "     43       37.1094  0.0808\n",
            "     44       \u001b[36m13.7513\u001b[0m  0.0769\n",
            "     45        \u001b[36m0.6494\u001b[0m  0.0749\n",
            "     46        \u001b[36m0.6340\u001b[0m  0.0830\n",
            "     47        \u001b[36m0.6322\u001b[0m  0.0797\n",
            "     48        \u001b[36m0.6308\u001b[0m  0.0785\n",
            "     49        \u001b[36m0.6297\u001b[0m  0.0757\n",
            "     50        \u001b[36m0.6283\u001b[0m  0.0898\n",
            "     51        \u001b[36m0.6258\u001b[0m  0.0835\n",
            "     52        \u001b[36m0.6223\u001b[0m  0.0793\n",
            "     53        \u001b[36m0.6179\u001b[0m  0.0735\n",
            "     54        \u001b[36m0.5913\u001b[0m  0.0740\n",
            "     55        \u001b[36m0.5676\u001b[0m  0.0831\n",
            "     56        \u001b[36m0.5595\u001b[0m  0.0764\n",
            "     57        0.5614  0.0832\n",
            "     58        \u001b[36m0.5530\u001b[0m  0.0787\n",
            "     59        0.5615  0.0759\n",
            "     60        0.5622  0.0779\n",
            "     61        0.5633  0.0779\n",
            "     62        0.5653  0.0798\n",
            "     63        0.5612  0.0873\n",
            "     64        \u001b[36m0.5528\u001b[0m  0.0774\n",
            "     65        \u001b[36m0.5513\u001b[0m  0.0759\n",
            "     66        \u001b[36m0.5455\u001b[0m  0.0750\n",
            "     67        0.5503  0.0786\n",
            "     68        0.5465  0.0778\n",
            "     69        \u001b[36m0.5449\u001b[0m  0.0917\n",
            "     70        0.5468  0.0769\n",
            "     71        \u001b[36m0.5439\u001b[0m  0.0770\n",
            "     72        \u001b[36m0.5371\u001b[0m  0.0837\n",
            "     73        \u001b[36m0.5331\u001b[0m  0.0784\n",
            "     74        \u001b[36m0.5290\u001b[0m  0.0775\n",
            "     75        \u001b[36m0.5268\u001b[0m  0.0904\n",
            "     76        0.5368  0.0770\n",
            "     77        \u001b[36m0.5090\u001b[0m  0.0745\n",
            "     78        \u001b[36m0.4881\u001b[0m  0.0768\n",
            "     79        \u001b[36m0.4590\u001b[0m  0.0744\n",
            "     80        \u001b[36m0.4520\u001b[0m  0.0754\n",
            "     81        \u001b[36m0.4445\u001b[0m  0.0773\n",
            "     82        \u001b[36m0.4347\u001b[0m  0.0782\n",
            "     83        \u001b[36m0.4258\u001b[0m  0.0804\n",
            "     84        \u001b[36m0.4173\u001b[0m  0.0804\n",
            "     85        \u001b[36m0.4133\u001b[0m  0.0801\n",
            "     86        \u001b[36m0.4093\u001b[0m  0.0741\n",
            "     87        \u001b[36m0.4037\u001b[0m  0.0734\n",
            "     88        \u001b[36m0.3964\u001b[0m  0.0837\n",
            "     89        \u001b[36m0.3913\u001b[0m  0.0751\n",
            "     90        \u001b[36m0.3886\u001b[0m  0.0766\n",
            "     91        \u001b[36m0.3775\u001b[0m  0.0734\n",
            "     92        \u001b[36m0.3739\u001b[0m  0.0738\n",
            "     93        \u001b[36m0.3677\u001b[0m  0.0753\n",
            "     94        \u001b[36m0.3613\u001b[0m  0.0817\n",
            "     95        \u001b[36m0.3599\u001b[0m  0.0811\n",
            "     96        \u001b[36m0.3534\u001b[0m  0.0740\n",
            "     97        \u001b[36m0.3500\u001b[0m  0.0750\n",
            "     98        \u001b[36m0.3477\u001b[0m  0.0756\n",
            "     99        \u001b[36m0.3465\u001b[0m  0.0762\n",
            "    100        \u001b[36m0.3356\u001b[0m  0.0783\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m61.6081\u001b[0m  0.0777\n",
            "      2       \u001b[36m61.1399\u001b[0m  0.0789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m59.4302\u001b[0m  0.0955\n",
            "      4       \u001b[36m58.9543\u001b[0m  0.0763\n",
            "      5       \u001b[36m58.4080\u001b[0m  0.0765\n",
            "      6       \u001b[36m58.2908\u001b[0m  0.0797\n",
            "      7       58.4999  0.0760\n",
            "      8       58.4621  0.0777\n",
            "      9       58.4522  0.0862\n",
            "     10       \u001b[36m58.2532\u001b[0m  0.0773\n",
            "     11       58.2605  0.0772\n",
            "     12       58.2621  0.0781\n",
            "     13       58.2637  0.0842\n",
            "     14       58.2653  0.0797\n",
            "     15       58.2668  0.0740\n",
            "     16       58.2683  0.0740\n",
            "     17       58.2698  0.0776\n",
            "     18       \u001b[36m58.1860\u001b[0m  0.0748\n",
            "     19       58.4785  0.0775\n",
            "     20       58.6849  0.0829\n",
            "     21       58.6845  0.0756\n",
            "     22       58.6842  0.0796\n",
            "     23       58.6839  0.0735\n",
            "     24       58.6835  0.0787\n",
            "     25       58.6832  0.0754\n",
            "     26       58.6828  0.0841\n",
            "     27       58.6824  0.0705\n",
            "     28       58.6820  0.0744\n",
            "     29       58.6816  0.0714\n",
            "     30       58.6812  0.0781\n",
            "     31       58.6808  0.0742\n",
            "     32       58.6803  0.0851\n",
            "     33       58.6799  0.0760\n",
            "     34       58.6794  0.0793\n",
            "     35       58.6789  0.0765\n",
            "     36       58.6784  0.0805\n",
            "     37       58.6779  0.0764\n",
            "     38       58.6774  0.0723\n",
            "     39       58.6769  0.0831\n",
            "     40       58.6763  0.0724\n",
            "     41       58.6758  0.0805\n",
            "     42       58.6752  0.0742\n",
            "     43       58.6746  0.0765\n",
            "     44       58.6740  0.0734\n",
            "     45       58.6734  0.0732\n",
            "     46       58.6728  0.0727\n",
            "     47       58.6722  0.0798\n",
            "     48       58.6715  0.0765\n",
            "     49       58.6708  0.0795\n",
            "     50       58.6702  0.0780\n",
            "     51       58.6695  0.0827\n",
            "     52       58.6688  0.0827\n",
            "     53       58.6680  0.0770\n",
            "     54       58.6673  0.0758\n",
            "     55       58.6665  0.0764\n",
            "     56       58.6658  0.0792\n",
            "     57       58.6650  0.0769\n",
            "     58       58.6641  0.0856\n",
            "     59       58.6633  0.0759\n",
            "     60       58.6624  0.0805\n",
            "     61       58.6614  0.0784\n",
            "     62       58.6603  0.0802\n",
            "     63       58.6591  0.0754\n",
            "     64       58.6575  0.0862\n",
            "     65       58.6554  0.0759\n",
            "     66       58.6522  0.0762\n",
            "     67       58.5949  0.0757\n",
            "     68       58.2271  0.0777\n",
            "     69       58.2014  0.0756\n",
            "     70       \u001b[36m58.1677\u001b[0m  0.0837\n",
            "     71       \u001b[36m58.1353\u001b[0m  0.0777\n",
            "     72       \u001b[36m58.1041\u001b[0m  0.0826\n",
            "     73       \u001b[36m57.1756\u001b[0m  0.0779\n",
            "     74       \u001b[36m57.0313\u001b[0m  0.0765\n",
            "     75       \u001b[36m57.0313\u001b[0m  0.0806\n",
            "     76       \u001b[36m57.0313\u001b[0m  0.0769\n",
            "     77       \u001b[36m57.0313\u001b[0m  0.0853\n",
            "     78       \u001b[36m57.0313\u001b[0m  0.0744\n",
            "     79       \u001b[36m57.0313\u001b[0m  0.0749\n",
            "     80       \u001b[36m57.0313\u001b[0m  0.0778\n",
            "     81       \u001b[36m57.0313\u001b[0m  0.0833\n",
            "     82       \u001b[36m57.0313\u001b[0m  0.0790\n",
            "     83       \u001b[36m57.0313\u001b[0m  0.0783\n",
            "     84       \u001b[36m57.0313\u001b[0m  0.0827\n",
            "     85       \u001b[36m57.0313\u001b[0m  0.0770\n",
            "     86       \u001b[36m57.0313\u001b[0m  0.0739\n",
            "     87       \u001b[36m57.0313\u001b[0m  0.0799\n",
            "     88       \u001b[36m57.0313\u001b[0m  0.0729\n",
            "     89       \u001b[36m57.0313\u001b[0m  0.0772\n",
            "     90       \u001b[36m57.0313\u001b[0m  0.0800\n",
            "     91       \u001b[36m57.0313\u001b[0m  0.0785\n",
            "     92       \u001b[36m57.0313\u001b[0m  0.0778\n",
            "     93       \u001b[36m57.0313\u001b[0m  0.0788\n",
            "     94       \u001b[36m57.0313\u001b[0m  0.0793\n",
            "     95       \u001b[36m57.0313\u001b[0m  0.0756\n",
            "     96       \u001b[36m57.0313\u001b[0m  0.0877\n",
            "     97       \u001b[36m57.0313\u001b[0m  0.0770\n",
            "     98       \u001b[36m57.0313\u001b[0m  0.0776\n",
            "     99       \u001b[36m57.0313\u001b[0m  0.0838\n",
            "    100       \u001b[36m57.0313\u001b[0m  0.0789\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.5342\u001b[0m  0.0681\n",
            "      2       39.1446  0.0861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m33.6943\u001b[0m  0.0940\n",
            "      4       36.7961  0.0832\n",
            "      5       37.9669  0.0751\n",
            "      6       37.3451  0.0833\n",
            "      7       37.3502  0.0743\n",
            "      8       37.3511  0.0819\n",
            "      9       36.9548  0.0806\n",
            "     10       \u001b[36m30.2715\u001b[0m  0.0763\n",
            "     11       33.4168  0.0776\n",
            "     12       33.4355  0.0740\n",
            "     13       33.2871  0.0762\n",
            "     14       33.1579  0.0800\n",
            "     15       33.3253  0.0801\n",
            "     16       33.1033  0.0815\n",
            "     17       35.0672  0.0831\n",
            "     18       \u001b[36m28.3446\u001b[0m  0.0777\n",
            "     19       \u001b[36m28.0314\u001b[0m  0.0745\n",
            "     20       28.5121  0.0742\n",
            "     21       31.7895  0.0794\n",
            "     22       \u001b[36m24.9412\u001b[0m  0.0758\n",
            "     23       30.6467  0.0775\n",
            "     24       32.4440  0.0780\n",
            "     25       32.7788  0.0759\n",
            "     26       30.2711  0.0760\n",
            "     27       28.4682  0.0818\n",
            "     28       28.9364  0.0782\n",
            "     29       28.4202  0.0750\n",
            "     30       30.1465  0.0779\n",
            "     31       32.0312  0.0740\n",
            "     32       32.2266  0.0741\n",
            "     33       32.2266  0.0876\n",
            "     34       32.2266  0.0788\n",
            "     35       32.2266  0.0803\n",
            "     36       32.2266  0.0791\n",
            "     37       32.2266  0.0756\n",
            "     38       32.2266  0.0781\n",
            "     39       32.2266  0.0774\n",
            "     40       32.2266  0.0857\n",
            "     41       32.2266  0.0804\n",
            "     42       32.2266  0.0777\n",
            "     43       32.2266  0.0791\n",
            "     44       32.2266  0.0815\n",
            "     45       32.2266  0.0792\n",
            "     46       32.2266  0.0832\n",
            "     47       32.2266  0.0776\n",
            "     48       32.2266  0.0781\n",
            "     49       32.2266  0.0760\n",
            "     50       32.2266  0.0815\n",
            "     51       32.2266  0.0741\n",
            "     52       32.2266  0.0867\n",
            "     53       32.2266  0.0813\n",
            "     54       32.2266  0.0808\n",
            "     55       32.2266  0.0852\n",
            "     56       32.2266  0.0812\n",
            "     57       32.2266  0.0775\n",
            "     58       32.2266  0.0772\n",
            "     59       32.2266  0.0773\n",
            "     60       32.2266  0.0834\n",
            "     61       32.2266  0.0822\n",
            "     62       32.2266  0.0786\n",
            "     63       32.2266  0.0770\n",
            "     64       32.2266  0.0796\n",
            "     65       32.2266  0.0883\n",
            "     66       32.2266  0.0778\n",
            "     67       32.2266  0.0770\n",
            "     68       32.2266  0.0781\n",
            "     69       32.2266  0.0798\n",
            "     70       32.2266  0.0851\n",
            "     71       32.2266  0.0845\n",
            "     72       32.2266  0.0758\n",
            "     73       32.2266  0.0822\n",
            "     74       32.2266  0.0771\n",
            "     75       32.2266  0.0751\n",
            "     76       32.2266  0.0766\n",
            "     77       32.2266  0.0860\n",
            "     78       32.2266  0.0757\n",
            "     79       32.2266  0.0779\n",
            "     80       32.2266  0.0798\n",
            "     81       32.2266  0.0909\n",
            "     82       32.2266  0.0772\n",
            "     83       32.2266  0.0770\n",
            "     84       32.2266  0.0775\n",
            "     85       32.2266  0.0800\n",
            "     86       32.2266  0.0770\n",
            "     87       32.2266  0.0766\n",
            "     88       32.2266  0.0828\n",
            "     89       32.2266  0.0779\n",
            "     90       32.2266  0.0896\n",
            "     91       32.2266  0.0762\n",
            "     92       32.2266  0.0832\n",
            "     93       32.2266  0.0805\n",
            "     94       32.2266  0.0775\n",
            "     95       32.2266  0.0791\n",
            "     96       32.2266  0.0793\n",
            "     97       32.2266  0.0813\n",
            "     98       32.2044  0.0755\n",
            "     99       32.2032  0.0760\n",
            "    100       32.2020  0.0787\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m62.5374\u001b[0m  0.0699\n",
            "      2       \u001b[36m61.9140\u001b[0m  0.0830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m60.8948\u001b[0m  0.0904\n",
            "      4       \u001b[36m57.8963\u001b[0m  0.0760\n",
            "      5       \u001b[36m36.9846\u001b[0m  0.0826\n",
            "      6       47.9792  0.0878\n",
            "      7       47.9649  0.0763\n",
            "      8       47.9489  0.0756\n",
            "      9       47.9082  0.0842\n",
            "     10       47.8841  0.0763\n",
            "     11       47.8769  0.0757\n",
            "     12       47.8740  0.0763\n",
            "     13       47.8710  0.0778\n",
            "     14       47.8640  0.0781\n",
            "     15       47.8611  0.0840\n",
            "     16       47.8548  0.0795\n",
            "     17       47.8491  0.0772\n",
            "     18       47.8429  0.0818\n",
            "     19       47.8383  0.0799\n",
            "     20       47.7066  0.0757\n",
            "     21       47.3239  0.0786\n",
            "     22       47.3195  0.0772\n",
            "     23       47.2890  0.0800\n",
            "     24       45.5562  0.0747\n",
            "     25       42.4748  0.0790\n",
            "     26       42.4600  0.0802\n",
            "     27       42.4634  0.0851\n",
            "     28       42.4634  0.0777\n",
            "     29       42.4632  0.0805\n",
            "     30       42.4630  0.0746\n",
            "     31       42.4629  0.0800\n",
            "     32       42.4627  0.0746\n",
            "     33       42.4623  0.0762\n",
            "     34       42.4616  0.0800\n",
            "     35       42.3150  0.0790\n",
            "     36       42.2916  0.0752\n",
            "     37       42.2708  0.0893\n",
            "     38       42.2652  0.0780\n",
            "     39       42.2669  0.0793\n",
            "     40       42.2666  0.0898\n",
            "     41       42.2661  0.0785\n",
            "     42       42.2656  0.0747\n",
            "     43       42.2652  0.0784\n",
            "     44       42.2644  0.0742\n",
            "     45       42.2643  0.0794\n",
            "     46       42.2644  0.0791\n",
            "     47       42.2640  0.0753\n",
            "     48       42.2638  0.0745\n",
            "     49       42.2635  0.0764\n",
            "     50       42.2632  0.0782\n",
            "     51       42.3162  0.0762\n",
            "     52       42.3186  0.0779\n",
            "     53       42.3197  0.0829\n",
            "     54       42.3207  0.0807\n",
            "     55       42.3217  0.0816\n",
            "     56       42.3225  0.0752\n",
            "     57       42.3233  0.0756\n",
            "     58       42.3240  0.0821\n",
            "     59       42.3247  0.0738\n",
            "     60       42.3472  0.0841\n",
            "     61       42.3477  0.0764\n",
            "     62       42.3480  0.0769\n",
            "     63       42.3484  0.0758\n",
            "     64       42.3487  0.0772\n",
            "     65       42.3490  0.0863\n",
            "     66       42.3493  0.0828\n",
            "     67       42.3496  0.0749\n",
            "     68       42.3498  0.0796\n",
            "     69       42.3500  0.0781\n",
            "     70       42.3502  0.0782\n",
            "     71       42.3504  0.0811\n",
            "     72       42.3730  0.0735\n",
            "     73       42.3753  0.0747\n",
            "     74       42.3761  0.0763\n",
            "     75       42.3769  0.0748\n",
            "     76       42.3757  0.0758\n",
            "     77       42.3802  0.0917\n",
            "     78       42.3800  0.0843\n",
            "     79       42.3805  0.0772\n",
            "     80       42.3809  0.0765\n",
            "     81       42.3812  0.0775\n",
            "     82       42.3815  0.0791\n",
            "     83       42.3817  0.0790\n",
            "     84       42.3819  0.0781\n",
            "     85       42.3820  0.0772\n",
            "     86       42.3821  0.0755\n",
            "     87       42.3821  0.0830\n",
            "     88       42.3821  0.0775\n",
            "     89       42.3821  0.0757\n",
            "     90       42.3820  0.0862\n",
            "     91       42.3819  0.0765\n",
            "     92       42.3818  0.0801\n",
            "     93       42.3816  0.0797\n",
            "     94       42.3813  0.0769\n",
            "     95       42.3810  0.0810\n",
            "     96       42.3807  0.0794\n",
            "     97       42.3804  0.0811\n",
            "     98       42.3800  0.0780\n",
            "     99       42.3795  0.0775\n",
            "    100       42.3791  0.0807\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.0640\u001b[0m  0.0685\n",
            "      2       \u001b[36m36.6484\u001b[0m  0.0774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m36.5234\u001b[0m  0.1012\n",
            "      4       36.5266  0.0754\n",
            "      5       36.9141  0.0757\n",
            "      6       36.9141  0.0761\n",
            "      7       36.9141  0.0817\n",
            "      8       36.9141  0.0784\n",
            "      9       36.9141  0.0771\n",
            "     10       36.9141  0.0775\n",
            "     11       36.9141  0.0785\n",
            "     12       36.9141  0.0779\n",
            "     13       36.9141  0.0759\n",
            "     14       36.9141  0.0850\n",
            "     15       36.9141  0.0828\n",
            "     16       36.9141  0.0763\n",
            "     17       36.9141  0.0800\n",
            "     18       36.9141  0.0763\n",
            "     19       36.9141  0.0824\n",
            "     20       36.9141  0.0797\n",
            "     21       36.9141  0.0762\n",
            "     22       37.0715  0.0784\n",
            "     23       37.0645  0.0778\n",
            "     24       37.0576  0.0768\n",
            "     25       37.0507  0.0851\n",
            "     26       37.0438  0.0786\n",
            "     27       37.0368  0.0750\n",
            "     28       37.0299  0.0824\n",
            "     29       37.0229  0.0902\n",
            "     30       37.0160  0.0762\n",
            "     31       37.0091  0.0752\n",
            "     32       37.0023  0.0797\n",
            "     33       36.9954  0.0750\n",
            "     34       36.9880  0.0765\n",
            "     35       36.9460  0.0782\n",
            "     36       37.5000  0.0813\n",
            "     37       37.5000  0.0760\n",
            "     38       37.5000  0.0824\n",
            "     39       37.5000  0.0765\n",
            "     40       37.5000  0.0897\n",
            "     41       37.5000  0.0768\n",
            "     42       37.3337  0.0748\n",
            "     43       36.7716  0.0777\n",
            "     44       37.1094  0.0811\n",
            "     45       37.1094  0.0790\n",
            "     46       37.1094  0.0739\n",
            "     47       37.1094  0.0727\n",
            "     48       37.1094  0.0751\n",
            "     49       37.1094  0.0749\n",
            "     50       37.1094  0.0760\n",
            "     51       37.1094  0.0750\n",
            "     52       37.1094  0.0778\n",
            "     53       37.1094  0.0806\n",
            "     54       37.1094  0.0747\n",
            "     55       37.1094  0.0806\n",
            "     56       37.1094  0.0760\n",
            "     57       37.1094  0.0820\n",
            "     58       37.1094  0.0782\n",
            "     59       37.1094  0.0769\n",
            "     60       37.1094  0.0760\n",
            "     61       37.1094  0.0780\n",
            "     62       37.1094  0.0754\n",
            "     63       37.1094  0.0747\n",
            "     64       37.1094  0.0762\n",
            "     65       37.1094  0.0753\n",
            "     66       37.1094  0.0876\n",
            "     67       37.1094  0.0823\n",
            "     68       37.1094  0.0766\n",
            "     69       37.1094  0.0803\n",
            "     70       37.1094  0.0759\n",
            "     71       37.1094  0.0792\n",
            "     72       37.1094  0.0963\n",
            "     73       37.1094  0.0764\n",
            "     74       37.1094  0.0815\n",
            "     75       37.1094  0.0765\n",
            "     76       37.1094  0.0751\n",
            "     77       37.1094  0.0788\n",
            "     78       37.1094  0.0911\n",
            "     79       37.1094  0.0765\n",
            "     80       37.1094  0.0785\n",
            "     81       37.1094  0.0791\n",
            "     82       37.1094  0.0756\n",
            "     83       37.1094  0.0728\n",
            "     84       37.1094  0.0751\n",
            "     85       37.1094  0.0755\n",
            "     86       37.1094  0.0739\n",
            "     87       37.1094  0.0755\n",
            "     88       37.1094  0.0829\n",
            "     89       37.1094  0.0823\n",
            "     90       37.1094  0.0760\n",
            "     91       37.1094  0.0859\n",
            "     92       37.1094  0.0768\n",
            "     93       37.1094  0.0786\n",
            "     94       37.1094  0.0779\n",
            "     95       37.1094  0.0752\n",
            "     96       37.1094  0.0773\n",
            "     97       37.1094  0.0814\n",
            "     98       37.1094  0.0788\n",
            "     99       37.1094  0.0758\n",
            "    100       37.1094  0.0790\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m61.9141\u001b[0m  0.0747\n",
            "      2       61.9141  0.0761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       61.9141  0.1014\n",
            "      4       61.9141  0.0878\n",
            "      5       61.9141  0.0762\n",
            "      6       61.9141  0.0783\n",
            "      7       61.9141  0.0759\n",
            "      8       61.9141  0.0746\n",
            "      9       61.9141  0.0774\n",
            "     10       62.1413  0.0740\n",
            "     11       61.9141  0.0789\n",
            "     12       \u001b[36m61.8902\u001b[0m  0.0767\n",
            "     13       \u001b[36m61.8490\u001b[0m  0.0759\n",
            "     14       \u001b[36m61.8116\u001b[0m  0.0755\n",
            "     15       \u001b[36m61.5135\u001b[0m  0.0828\n",
            "     16       \u001b[36m61.0363\u001b[0m  0.0832\n",
            "     17       \u001b[36m60.5937\u001b[0m  0.0807\n",
            "     18       \u001b[36m60.5416\u001b[0m  0.0781\n",
            "     19       \u001b[36m60.3907\u001b[0m  0.0753\n",
            "     20       60.3918  0.0758\n",
            "     21       \u001b[36m60.3507\u001b[0m  0.0760\n",
            "     22       \u001b[36m60.3491\u001b[0m  0.0755\n",
            "     23       \u001b[36m60.3486\u001b[0m  0.0768\n",
            "     24       \u001b[36m60.3481\u001b[0m  0.0757\n",
            "     25       \u001b[36m60.3477\u001b[0m  0.0764\n",
            "     26       \u001b[36m60.3473\u001b[0m  0.0812\n",
            "     27       \u001b[36m60.3469\u001b[0m  0.0765\n",
            "     28       \u001b[36m60.3466\u001b[0m  0.0781\n",
            "     29       \u001b[36m60.3463\u001b[0m  0.0880\n",
            "     30       \u001b[36m60.3460\u001b[0m  0.0767\n",
            "     31       \u001b[36m60.3457\u001b[0m  0.0853\n",
            "     32       \u001b[36m60.3454\u001b[0m  0.0762\n",
            "     33       \u001b[36m60.3451\u001b[0m  0.0738\n",
            "     34       \u001b[36m60.3448\u001b[0m  0.0739\n",
            "     35       \u001b[36m60.3445\u001b[0m  0.0771\n",
            "     36       \u001b[36m60.3441\u001b[0m  0.0752\n",
            "     37       \u001b[36m60.3438\u001b[0m  0.0744\n",
            "     38       \u001b[36m60.3434\u001b[0m  0.0854\n",
            "     39       \u001b[36m60.3430\u001b[0m  0.0839\n",
            "     40       \u001b[36m60.3425\u001b[0m  0.0781\n",
            "     41       \u001b[36m60.3421\u001b[0m  0.0885\n",
            "     42       \u001b[36m60.3169\u001b[0m  0.0773\n",
            "     43       \u001b[36m60.0131\u001b[0m  0.0782\n",
            "     44       \u001b[36m59.9485\u001b[0m  0.0791\n",
            "     45       \u001b[36m59.9481\u001b[0m  0.0803\n",
            "     46       \u001b[36m59.9474\u001b[0m  0.0825\n",
            "     47       \u001b[36m59.9463\u001b[0m  0.0768\n",
            "     48       \u001b[36m59.9445\u001b[0m  0.0762\n",
            "     49       \u001b[36m59.9408\u001b[0m  0.0802\n",
            "     50       60.1207  0.0798\n",
            "     51       60.3391  0.0774\n",
            "     52       60.0700  0.0882\n",
            "     53       60.2461  0.0804\n",
            "     54       60.2467  0.0857\n",
            "     55       60.2467  0.0798\n",
            "     56       60.2466  0.0787\n",
            "     57       60.2466  0.0769\n",
            "     58       60.2465  0.0750\n",
            "     59       60.2464  0.0848\n",
            "     60       60.2463  0.0767\n",
            "     61       60.2463  0.0815\n",
            "     62       60.2462  0.0752\n",
            "     63       60.2461  0.0814\n",
            "     64       60.2460  0.0795\n",
            "     65       60.2459  0.0752\n",
            "     66       60.2458  0.0829\n",
            "     67       60.2457  0.0779\n",
            "     68       60.2456  0.0804\n",
            "     69       60.2454  0.0738\n",
            "     70       60.2453  0.0774\n",
            "     71       60.2452  0.0739\n",
            "     72       60.2451  0.0765\n",
            "     73       60.2449  0.0760\n",
            "     74       60.2448  0.0799\n",
            "     75       60.2447  0.0840\n",
            "     76       60.2445  0.0752\n",
            "     77       60.2444  0.0772\n",
            "     78       60.2442  0.0822\n",
            "     79       60.2441  0.0861\n",
            "     80       60.2439  0.0794\n",
            "     81       60.2438  0.0789\n",
            "     82       60.2436  0.0854\n",
            "     83       60.2434  0.0814\n",
            "     84       60.2433  0.0767\n",
            "     85       60.2431  0.0797\n",
            "     86       60.2430  0.0780\n",
            "     87       60.2428  0.0786\n",
            "     88       60.2426  0.0780\n",
            "     89       60.2425  0.0938\n",
            "     90       60.2423  0.0809\n",
            "     91       60.2422  0.0851\n",
            "     92       60.2420  0.0824\n",
            "     93       60.2419  0.0772\n",
            "     94       60.2417  0.0762\n",
            "     95       60.2416  0.0777\n",
            "     96       60.2124  0.0827\n",
            "     97       60.2045  0.0776\n",
            "     98       60.1968  0.0842\n",
            "     99       60.1892  0.0777\n",
            "    100       60.1818  0.0867\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m62.6953\u001b[0m  0.0721\n",
            "      2       62.6953  0.0804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       62.6953  0.1058\n",
            "      4       62.6953  0.0924\n",
            "      5       62.6953  0.0769\n",
            "      6       \u001b[36m62.5213\u001b[0m  0.0796\n",
            "      7       \u001b[36m62.0350\u001b[0m  0.0786\n",
            "      8       \u001b[36m50.3340\u001b[0m  0.0782\n",
            "      9       \u001b[36m48.8253\u001b[0m  0.0812\n",
            "     10       50.9368  0.0939\n",
            "     11       \u001b[36m47.9238\u001b[0m  0.0771\n",
            "     12       \u001b[36m46.9787\u001b[0m  0.0777\n",
            "     13       \u001b[36m44.5805\u001b[0m  0.0793\n",
            "     14       \u001b[36m43.3902\u001b[0m  0.0783\n",
            "     15       \u001b[36m43.3000\u001b[0m  0.0904\n",
            "     16       \u001b[36m42.8470\u001b[0m  0.0837\n",
            "     17       \u001b[36m42.0882\u001b[0m  0.0787\n",
            "     18       \u001b[36m41.5449\u001b[0m  0.0822\n",
            "     19       \u001b[36m40.4576\u001b[0m  0.0757\n",
            "     20       41.4698  0.0764\n",
            "     21       41.3846  0.0792\n",
            "     22       \u001b[36m40.3738\u001b[0m  0.0777\n",
            "     23       40.5775  0.0772\n",
            "     24       40.9551  0.0779\n",
            "     25       40.8702  0.0929\n",
            "     26       \u001b[36m39.3769\u001b[0m  0.0758\n",
            "     27       \u001b[36m36.5460\u001b[0m  0.0865\n",
            "     28       \u001b[36m36.2341\u001b[0m  0.0752\n",
            "     29       \u001b[36m36.0246\u001b[0m  0.0777\n",
            "     30       36.2611  0.0764\n",
            "     31       36.2439  0.0829\n",
            "     32       36.2011  0.0792\n",
            "     33       36.3128  0.0806\n",
            "     34       36.2869  0.0768\n",
            "     35       36.2871  0.0758\n",
            "     36       36.2877  0.0878\n",
            "     37       36.2885  0.0807\n",
            "     38       36.2897  0.0777\n",
            "     39       36.2910  0.0757\n",
            "     40       36.2698  0.0872\n",
            "     41       36.2692  0.0765\n",
            "     42       36.2689  0.0747\n",
            "     43       36.2688  0.0743\n",
            "     44       36.2907  0.0798\n",
            "     45       36.2885  0.0803\n",
            "     46       36.2864  0.0751\n",
            "     47       36.2845  0.0811\n",
            "     48       36.2827  0.0754\n",
            "     49       36.2810  0.0745\n",
            "     50       36.2793  0.0802\n",
            "     51       36.2777  0.0865\n",
            "     52       36.2762  0.0866\n",
            "     53       36.2747  0.0793\n",
            "     54       36.2732  0.0793\n",
            "     55       36.2718  0.0775\n",
            "     56       36.2704  0.0788\n",
            "     57       36.2691  0.0771\n",
            "     58       36.2673  0.0788\n",
            "     59       36.2655  0.0792\n",
            "     60       36.2638  0.0803\n",
            "     61       36.2621  0.0782\n",
            "     62       36.2605  0.0932\n",
            "     63       36.2589  0.0836\n",
            "     64       36.2573  0.0800\n",
            "     65       36.2558  0.0876\n",
            "     66       36.2543  0.0767\n",
            "     67       36.2528  0.0800\n",
            "     68       36.2513  0.0776\n",
            "     69       36.2498  0.0791\n",
            "     70       36.2482  0.0790\n",
            "     71       36.2467  0.0774\n",
            "     72       36.2451  0.0764\n",
            "     73       36.2435  0.0808\n",
            "     74       36.2419  0.0818\n",
            "     75       36.2402  0.0783\n",
            "     76       36.2384  0.0848\n",
            "     77       36.2114  0.0872\n",
            "     78       38.5182  0.0792\n",
            "     79       \u001b[36m34.9147\u001b[0m  0.0764\n",
            "     80       38.2814  0.0765\n",
            "     81       38.2814  0.0827\n",
            "     82       38.2814  0.0793\n",
            "     83       38.2814  0.0848\n",
            "     84       38.2814  0.0830\n",
            "     85       38.2814  0.0822\n",
            "     86       38.2814  0.0809\n",
            "     87       38.2814  0.0788\n",
            "     88       38.2814  0.0802\n",
            "     89       38.2814  0.0835\n",
            "     90       38.2814  0.0791\n",
            "     91       38.2814  0.0819\n",
            "     92       38.2814  0.0818\n",
            "     93       38.2814  0.0816\n",
            "     94       38.2814  0.0829\n",
            "     95       38.2814  0.0852\n",
            "     96       38.2814  0.0761\n",
            "     97       38.2814  0.0766\n",
            "     98       38.2814  0.0825\n",
            "     99       38.2814  0.0855\n",
            "    100       38.2814  0.0805\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m44.9587\u001b[0m  0.0776\n",
            "      2       45.2614  0.0781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m44.5328\u001b[0m  0.0884\n",
            "      4       \u001b[36m44.5312\u001b[0m  0.0768\n",
            "      5       44.5312  0.0766\n",
            "      6       \u001b[36m44.3359\u001b[0m  0.0765\n",
            "      7       44.3359  0.0810\n",
            "      8       44.3359  0.0805\n",
            "      9       44.3359  0.0815\n",
            "     10       44.3359  0.0799\n",
            "     11       \u001b[36m44.2731\u001b[0m  0.0802\n",
            "     12       \u001b[36m44.1421\u001b[0m  0.0773\n",
            "     13       \u001b[36m44.1421\u001b[0m  0.0777\n",
            "     14       \u001b[36m44.1420\u001b[0m  0.0821\n",
            "     15       \u001b[36m44.1420\u001b[0m  0.0770\n",
            "     16       \u001b[36m44.1420\u001b[0m  0.0822\n",
            "     17       44.3671  0.0770\n",
            "     18       44.6434  0.0780\n",
            "     19       \u001b[36m44.0103\u001b[0m  0.0771\n",
            "     20       \u001b[36m43.5560\u001b[0m  0.0834\n",
            "     21       \u001b[36m43.5560\u001b[0m  0.0753\n",
            "     22       \u001b[36m43.5560\u001b[0m  0.0794\n",
            "     23       \u001b[36m43.5560\u001b[0m  0.0766\n",
            "     24       \u001b[36m43.5559\u001b[0m  0.0851\n",
            "     25       \u001b[36m43.5559\u001b[0m  0.0794\n",
            "     26       \u001b[36m43.5559\u001b[0m  0.0849\n",
            "     27       \u001b[36m43.5559\u001b[0m  0.0772\n",
            "     28       \u001b[36m43.5559\u001b[0m  0.0758\n",
            "     29       \u001b[36m43.5559\u001b[0m  0.0807\n",
            "     30       \u001b[36m43.5558\u001b[0m  0.0763\n",
            "     31       \u001b[36m43.5558\u001b[0m  0.0831\n",
            "     32       \u001b[36m43.5558\u001b[0m  0.0781\n",
            "     33       \u001b[36m43.5558\u001b[0m  0.0810\n",
            "     34       \u001b[36m43.5558\u001b[0m  0.0778\n",
            "     35       \u001b[36m43.5558\u001b[0m  0.0809\n",
            "     36       \u001b[36m43.5558\u001b[0m  0.0905\n",
            "     37       \u001b[36m43.5557\u001b[0m  0.0794\n",
            "     38       \u001b[36m43.5557\u001b[0m  0.0775\n",
            "     39       \u001b[36m43.5557\u001b[0m  0.0827\n",
            "     40       \u001b[36m43.5557\u001b[0m  0.0831\n",
            "     41       \u001b[36m43.5557\u001b[0m  0.0783\n",
            "     42       \u001b[36m43.5557\u001b[0m  0.0801\n",
            "     43       \u001b[36m43.5557\u001b[0m  0.0761\n",
            "     44       \u001b[36m43.5557\u001b[0m  0.0738\n",
            "     45       \u001b[36m43.5557\u001b[0m  0.0789\n",
            "     46       \u001b[36m43.5557\u001b[0m  0.0836\n",
            "     47       \u001b[36m43.5557\u001b[0m  0.0780\n",
            "     48       \u001b[36m43.5556\u001b[0m  0.0951\n",
            "     49       \u001b[36m43.5556\u001b[0m  0.0801\n",
            "     50       \u001b[36m43.5556\u001b[0m  0.0743\n",
            "     51       \u001b[36m43.5556\u001b[0m  0.0890\n",
            "     52       \u001b[36m43.5556\u001b[0m  0.0773\n",
            "     53       \u001b[36m43.5556\u001b[0m  0.0807\n",
            "     54       \u001b[36m43.5556\u001b[0m  0.0786\n",
            "     55       \u001b[36m43.5556\u001b[0m  0.0791\n",
            "     56       \u001b[36m43.5556\u001b[0m  0.0752\n",
            "     57       \u001b[36m43.5556\u001b[0m  0.0839\n",
            "     58       \u001b[36m43.5555\u001b[0m  0.0769\n",
            "     59       \u001b[36m43.5555\u001b[0m  0.0763\n",
            "     60       \u001b[36m43.5555\u001b[0m  0.0858\n",
            "     61       \u001b[36m43.0892\u001b[0m  0.0796\n",
            "     62       \u001b[36m43.0849\u001b[0m  0.0836\n",
            "     63       43.0865  0.0869\n",
            "     64       43.0882  0.0763\n",
            "     65       43.0899  0.0803\n",
            "     66       43.0918  0.0757\n",
            "     67       43.0937  0.0766\n",
            "     68       43.0956  0.0854\n",
            "     69       43.0975  0.0831\n",
            "     70       43.0997  0.0774\n",
            "     71       43.1018  0.0790\n",
            "     72       43.1038  0.0787\n",
            "     73       43.1060  0.0818\n",
            "     74       43.1083  0.0790\n",
            "     75       43.1106  0.0752\n",
            "     76       43.1129  0.0863\n",
            "     77       43.1153  0.0762\n",
            "     78       43.1177  0.0802\n",
            "     79       43.1200  0.0774\n",
            "     80       43.1225  0.0756\n",
            "     81       43.1251  0.0781\n",
            "     82       43.1277  0.0877\n",
            "     83       43.1303  0.0761\n",
            "     84       43.1330  0.0793\n",
            "     85       43.1357  0.0820\n",
            "     86       \u001b[36m42.0494\u001b[0m  0.0773\n",
            "     87       42.6009  0.0759\n",
            "     88       42.3834  0.0836\n",
            "     89       42.3834  0.0809\n",
            "     90       42.3833  0.0773\n",
            "     91       42.3833  0.0770\n",
            "     92       42.3833  0.0821\n",
            "     93       42.3833  0.0764\n",
            "     94       42.3833  0.0848\n",
            "     95       42.3833  0.0788\n",
            "     96       42.3833  0.0763\n",
            "     97       42.3833  0.0887\n",
            "     98       42.3833  0.0776\n",
            "     99       42.3833  0.0803\n",
            "    100       42.3833  0.0771\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m61.0136\u001b[0m  0.0800\n",
            "      2       \u001b[36m60.8187\u001b[0m  0.0770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       60.8187  0.0888\n",
            "      4       60.8187  0.0806\n",
            "      5       \u001b[36m60.8103\u001b[0m  0.0782\n",
            "      6       \u001b[36m60.7581\u001b[0m  0.0827\n",
            "      7       \u001b[36m60.7252\u001b[0m  0.0793\n",
            "      8       \u001b[36m60.6963\u001b[0m  0.0779\n",
            "      9       \u001b[36m60.5366\u001b[0m  0.0788\n",
            "     10       \u001b[36m60.5155\u001b[0m  0.0776\n",
            "     11       60.8187  0.0757\n",
            "     12       60.8187  0.0774\n",
            "     13       60.8187  0.0890\n",
            "     14       60.8187  0.0757\n",
            "     15       60.8187  0.0836\n",
            "     16       60.8187  0.0804\n",
            "     17       60.8187  0.0769\n",
            "     18       60.8187  0.0762\n",
            "     19       60.8187  0.0785\n",
            "     20       60.8187  0.0784\n",
            "     21       60.8187  0.0825\n",
            "     22       60.8187  0.0799\n",
            "     23       60.8187  0.0763\n",
            "     24       60.8187  0.0801\n",
            "     25       60.8187  0.0838\n",
            "     26       60.8187  0.0773\n",
            "     27       60.8187  0.0766\n",
            "     28       60.8187  0.0826\n",
            "     29       60.8187  0.0759\n",
            "     30       60.8187  0.0857\n",
            "     31       60.8187  0.0764\n",
            "     32       60.8187  0.0741\n",
            "     33       60.7957  0.0790\n",
            "     34       60.7491  0.0790\n",
            "     35       60.6388  0.0860\n",
            "     36       60.7029  0.0805\n",
            "     37       60.5626  0.0764\n",
            "     38       60.5489  0.0852\n",
            "     39       60.5490  0.0836\n",
            "     40       60.5490  0.0779\n",
            "     41       60.5489  0.0867\n",
            "     42       60.5489  0.0819\n",
            "     43       60.5488  0.0788\n",
            "     44       60.5488  0.0807\n",
            "     45       60.5488  0.0767\n",
            "     46       60.5487  0.0814\n",
            "     47       60.5487  0.0810\n",
            "     48       60.5486  0.0812\n",
            "     49       60.5486  0.0774\n",
            "     50       60.5485  0.0885\n",
            "     51       60.5485  0.0781\n",
            "     52       60.5484  0.0837\n",
            "     53       60.5484  0.0855\n",
            "     54       60.5483  0.0792\n",
            "     55       60.5482  0.0763\n",
            "     56       60.5482  0.0812\n",
            "     57       60.5481  0.0807\n",
            "     58       60.5481  0.0810\n",
            "     59       60.5480  0.0748\n",
            "     60       60.5480  0.0838\n",
            "     61       60.5479  0.0783\n",
            "     62       60.5478  0.0824\n",
            "     63       60.5478  0.0784\n",
            "     64       60.5477  0.0782\n",
            "     65       60.5476  0.0803\n",
            "     66       60.5476  0.0791\n",
            "     67       60.5475  0.0941\n",
            "     68       60.5474  0.0851\n",
            "     69       60.5473  0.0804\n",
            "     70       60.5472  0.0835\n",
            "     71       60.5471  0.0776\n",
            "     72       60.5470  0.0856\n",
            "     73       60.5468  0.0797\n",
            "     74       60.5467  0.0877\n",
            "     75       60.5466  0.0785\n",
            "     76       60.5465  0.0812\n",
            "     77       60.5464  0.0821\n",
            "     78       60.5463  0.0777\n",
            "     79       60.5462  0.0766\n",
            "     80       60.5460  0.0818\n",
            "     81       60.5459  0.0806\n",
            "     82       60.5458  0.0807\n",
            "     83       60.5457  0.0765\n",
            "     84       60.5455  0.0772\n",
            "     85       60.5454  0.0763\n",
            "     86       60.5453  0.0787\n",
            "     87       60.5451  0.0897\n",
            "     88       60.5450  0.0839\n",
            "     89       60.5448  0.0809\n",
            "     90       60.5447  0.0834\n",
            "     91       60.5446  0.0771\n",
            "     92       60.5444  0.0843\n",
            "     93       60.5443  0.0782\n",
            "     94       60.5441  0.0809\n",
            "     95       60.5440  0.0809\n",
            "     96       60.5438  0.0757\n",
            "     97       60.5436  0.0836\n",
            "     98       60.5435  0.0824\n",
            "     99       60.5433  0.0935\n",
            "    100       60.5432  0.0761\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1094\u001b[0m  0.0574\n",
            "      2       37.1094  0.0647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.1094  0.0774\n",
            "      4       37.1094  0.0707\n",
            "      5       37.1094  0.0626\n",
            "      6       37.1094  0.0683\n",
            "      7       37.1094  0.0616\n",
            "      8       37.1094  0.0646\n",
            "      9       37.1094  0.0608\n",
            "     10       37.1094  0.0635\n",
            "     11       37.1094  0.0658\n",
            "     12       37.1094  0.0607\n",
            "     13       37.1094  0.0678\n",
            "     14       37.1094  0.0653\n",
            "     15       37.1094  0.0589\n",
            "     16       37.1094  0.0686\n",
            "     17       37.1094  0.0638\n",
            "     18       37.1094  0.0630\n",
            "     19       37.1094  0.0630\n",
            "     20       37.1094  0.0616\n",
            "     21       37.1094  0.0620\n",
            "     22       37.1094  0.0664\n",
            "     23       37.1094  0.0646\n",
            "     24       37.1094  0.0588\n",
            "     25       37.1094  0.0658\n",
            "     26       37.1094  0.0630\n",
            "     27       37.1094  0.0622\n",
            "     28       37.1094  0.0615\n",
            "     29       37.1094  0.0692\n",
            "     30       37.1094  0.0736\n",
            "     31       37.1094  0.0661\n",
            "     32       37.1094  0.0655\n",
            "     33       37.1094  0.0644\n",
            "     34       37.1094  0.0660\n",
            "     35       37.1094  0.0658\n",
            "     36       37.1094  0.0605\n",
            "     37       37.1094  0.0655\n",
            "     38       37.1094  0.0686\n",
            "     39       37.1094  0.0624\n",
            "     40       37.1094  0.0612\n",
            "     41       37.1094  0.0634\n",
            "     42       37.1094  0.0628\n",
            "     43       37.1094  0.0615\n",
            "     44       37.1094  0.0812\n",
            "     45       37.1094  0.0640\n",
            "     46       37.1094  0.0620\n",
            "     47       37.1094  0.0618\n",
            "     48       37.1094  0.0678\n",
            "     49       37.1094  0.0681\n",
            "     50       37.1094  0.0647\n",
            "     51       37.1094  0.0682\n",
            "     52       37.1094  0.0642\n",
            "     53       37.1094  0.0609\n",
            "     54       37.1094  0.0588\n",
            "     55       37.1094  0.0645\n",
            "     56       37.1094  0.0617\n",
            "     57       37.1094  0.0603\n",
            "     58       37.1094  0.0676\n",
            "     59       37.1094  0.0688\n",
            "     60       37.1094  0.0660\n",
            "     61       37.1094  0.0619\n",
            "     62       37.1094  0.0745\n",
            "     63       37.1094  0.0619\n",
            "     64       37.1094  0.0698\n",
            "     65       37.1094  0.0620\n",
            "     66       37.1094  0.0633\n",
            "     67       37.1094  0.0635\n",
            "     68       37.1094  0.0606\n",
            "     69       37.1094  0.0610\n",
            "     70       37.1094  0.0633\n",
            "     71       37.1094  0.0650\n",
            "     72       37.1094  0.0628\n",
            "     73       37.1094  0.0619\n",
            "     74       37.1094  0.0684\n",
            "     75       37.1094  0.0675\n",
            "     76       37.1094  0.0621\n",
            "     77       37.1094  0.0614\n",
            "     78       37.1094  0.0645\n",
            "     79       37.1094  0.0652\n",
            "     80       37.1094  0.0654\n",
            "     81       37.1094  0.0634\n",
            "     82       37.1094  0.0616\n",
            "     83       37.1094  0.0642\n",
            "     84       37.1094  0.0610\n",
            "     85       37.1094  0.0651\n",
            "     86       37.1094  0.0636\n",
            "     87       37.1094  0.0606\n",
            "     88       37.1094  0.0638\n",
            "     89       37.1094  0.0630\n",
            "     90       37.1094  0.0687\n",
            "     91       37.1094  0.0620\n",
            "     92       37.1094  0.0647\n",
            "     93       37.1094  0.0699\n",
            "     94       37.1094  0.0668\n",
            "     95       37.1094  0.0627\n",
            "     96       37.1094  0.0634\n",
            "     97       37.1094  0.0647\n",
            "     98       37.1094  0.0628\n",
            "     99       37.1094  0.0617\n",
            "    100       37.1094  0.0696\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m62.8906\u001b[0m  0.0587\n",
            "      2       62.8906  0.0684\n",
            "      3       62.8906  0.0605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       62.8906  0.0738\n",
            "      5       62.8906  0.0674\n",
            "      6       62.8906  0.0652\n",
            "      7       62.8906  0.0670\n",
            "      8       62.8906  0.0694\n",
            "      9       62.8906  0.0637\n",
            "     10       62.8906  0.0614\n",
            "     11       62.8906  0.0656\n",
            "     12       62.8906  0.0658\n",
            "     13       62.8906  0.0735\n",
            "     14       62.8906  0.0611\n",
            "     15       62.8906  0.0717\n",
            "     16       62.8906  0.0613\n",
            "     17       62.8906  0.0649\n",
            "     18       62.8906  0.0612\n",
            "     19       62.8906  0.0638\n",
            "     20       62.8906  0.0747\n",
            "     21       62.8906  0.0658\n",
            "     22       62.8906  0.0648\n",
            "     23       62.8906  0.0792\n",
            "     24       62.8906  0.0622\n",
            "     25       62.8906  0.0718\n",
            "     26       62.8906  0.0675\n",
            "     27       62.8906  0.0600\n",
            "     28       62.8906  0.0625\n",
            "     29       62.8906  0.0660\n",
            "     30       62.8906  0.0636\n",
            "     31       62.8906  0.0634\n",
            "     32       62.8906  0.0651\n",
            "     33       62.8906  0.0695\n",
            "     34       62.8906  0.0669\n",
            "     35       62.8906  0.0704\n",
            "     36       62.8906  0.0638\n",
            "     37       62.8906  0.0686\n",
            "     38       62.8906  0.0670\n",
            "     39       62.8906  0.0621\n",
            "     40       62.8906  0.0637\n",
            "     41       62.8906  0.0639\n",
            "     42       62.8906  0.0708\n",
            "     43       62.8906  0.0628\n",
            "     44       62.8906  0.0653\n",
            "     45       62.8906  0.0629\n",
            "     46       62.8906  0.0648\n",
            "     47       62.8906  0.0655\n",
            "     48       62.8906  0.0689\n",
            "     49       62.8906  0.0623\n",
            "     50       62.8906  0.0694\n",
            "     51       62.8906  0.0660\n",
            "     52       62.8906  0.0695\n",
            "     53       62.8906  0.0639\n",
            "     54       62.8906  0.0611\n",
            "     55       62.8906  0.0672\n",
            "     56       62.8906  0.0599\n",
            "     57       62.8906  0.0659\n",
            "     58       62.8906  0.0634\n",
            "     59       62.8906  0.0606\n",
            "     60       62.8906  0.0599\n",
            "     61       62.8906  0.0641\n",
            "     62       62.8906  0.0610\n",
            "     63       62.8906  0.0624\n",
            "     64       62.8906  0.0692\n",
            "     65       62.8906  0.0728\n",
            "     66       62.8906  0.0632\n",
            "     67       62.8906  0.0664\n",
            "     68       62.8906  0.0648\n",
            "     69       62.8906  0.0657\n",
            "     70       62.8906  0.0670\n",
            "     71       62.8906  0.0663\n",
            "     72       62.8906  0.0654\n",
            "     73       62.8906  0.0626\n",
            "     74       62.8906  0.0633\n",
            "     75       62.8906  0.0688\n",
            "     76       62.8906  0.0619\n",
            "     77       62.8906  0.0633\n",
            "     78       62.8906  0.0707\n",
            "     79       62.8906  0.0678\n",
            "     80       62.8906  0.0736\n",
            "     81       62.8906  0.0731\n",
            "     82       62.8906  0.0632\n",
            "     83       62.8906  0.0654\n",
            "     84       62.8906  0.0687\n",
            "     85       62.8906  0.0628\n",
            "     86       62.8906  0.0621\n",
            "     87       62.8906  0.0685\n",
            "     88       62.8906  0.0633\n",
            "     89       62.8906  0.0658\n",
            "     90       62.8906  0.0620\n",
            "     91       62.8906  0.0644\n",
            "     92       62.8906  0.0617\n",
            "     93       62.8906  0.0740\n",
            "     94       62.8906  0.0630\n",
            "     95       62.8906  0.0733\n",
            "     96       62.8906  0.0701\n",
            "     97       62.8906  0.0638\n",
            "     98       62.8906  0.0663\n",
            "     99       62.8906  0.0660\n",
            "    100       62.8906  0.0668\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0557\n",
            "      2       37.3047  0.0655\n",
            "      3       37.3047  0.0655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0742\n",
            "      5       37.3047  0.0629\n",
            "      6       37.3047  0.0634\n",
            "      7       37.3047  0.0707\n",
            "      8       37.3047  0.0616\n",
            "      9       37.3047  0.0685\n",
            "     10       37.3047  0.0730\n",
            "     11       37.3047  0.0618\n",
            "     12       37.3047  0.0624\n",
            "     13       37.3047  0.0647\n",
            "     14       37.3047  0.0711\n",
            "     15       37.3047  0.0603\n",
            "     16       37.3047  0.0605\n",
            "     17       37.3047  0.0614\n",
            "     18       37.3047  0.0624\n",
            "     19       37.3047  0.0610\n",
            "     20       37.3047  0.0649\n",
            "     21       37.3047  0.0622\n",
            "     22       37.3047  0.0739\n",
            "     23       37.3047  0.0639\n",
            "     24       37.3047  0.0610\n",
            "     25       37.3047  0.0788\n",
            "     26       37.3047  0.0617\n",
            "     27       37.3047  0.0630\n",
            "     28       37.3047  0.0678\n",
            "     29       37.3047  0.0633\n",
            "     30       37.3047  0.0626\n",
            "     31       37.3047  0.0589\n",
            "     32       37.3047  0.0616\n",
            "     33       37.3047  0.0608\n",
            "     34       37.3047  0.0619\n",
            "     35       37.3047  0.0625\n",
            "     36       37.3047  0.0620\n",
            "     37       37.3047  0.0626\n",
            "     38       37.3047  0.0606\n",
            "     39       37.3047  0.0624\n",
            "     40       37.3047  0.0609\n",
            "     41       37.3047  0.0789\n",
            "     42       37.3047  0.0652\n",
            "     43       37.3047  0.0636\n",
            "     44       37.3047  0.0634\n",
            "     45       37.3047  0.0654\n",
            "     46       37.3047  0.0621\n",
            "     47       37.3047  0.0606\n",
            "     48       37.3047  0.0599\n",
            "     49       37.3047  0.0638\n",
            "     50       37.3047  0.0609\n",
            "     51       37.3047  0.0620\n",
            "     52       37.3047  0.0637\n",
            "     53       37.3047  0.0604\n",
            "     54       37.3047  0.0623\n",
            "     55       37.3047  0.0724\n",
            "     56       37.3047  0.0652\n",
            "     57       37.3047  0.0639\n",
            "     58       37.3047  0.0641\n",
            "     59       37.3047  0.0647\n",
            "     60       37.3047  0.0626\n",
            "     61       37.3047  0.0640\n",
            "     62       37.3047  0.0710\n",
            "     63       37.3047  0.0633\n",
            "     64       37.3047  0.0639\n",
            "     65       37.3047  0.0634\n",
            "     66       37.3047  0.0654\n",
            "     67       37.3047  0.0615\n",
            "     68       37.3047  0.0698\n",
            "     69       37.3047  0.0618\n",
            "     70       37.3047  0.0679\n",
            "     71       37.3047  0.0616\n",
            "     72       37.3047  0.0683\n",
            "     73       37.3047  0.0629\n",
            "     74       37.3047  0.0677\n",
            "     75       37.3047  0.0622\n",
            "     76       37.3047  0.0623\n",
            "     77       37.3047  0.0699\n",
            "     78       37.3047  0.0634\n",
            "     79       37.3047  0.0601\n",
            "     80       37.3047  0.0647\n",
            "     81       37.3047  0.0745\n",
            "     82       37.3047  0.0607\n",
            "     83       37.3047  0.0679\n",
            "     84       37.3047  0.0595\n",
            "     85       37.3047  0.0620\n",
            "     86       37.3047  0.0722\n",
            "     87       37.3047  0.0702\n",
            "     88       37.3047  0.0670\n",
            "     89       37.3047  0.0657\n",
            "     90       37.3047  0.0678\n",
            "     91       37.3047  0.0658\n",
            "     92       37.3047  0.0614\n",
            "     93       37.3047  0.0647\n",
            "     94       37.3047  0.0644\n",
            "     95       37.3047  0.0628\n",
            "     96       37.3047  0.0676\n",
            "     97       37.3047  0.0648\n",
            "     98       37.3047  0.0635\n",
            "     99       37.3047  0.0672\n",
            "    100       37.3047  0.0714\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0564\n",
            "      2       37.3047  0.0732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0724\n",
            "      4       37.3047  0.0668\n",
            "      5       37.3047  0.0612\n",
            "      6       37.3047  0.0649\n",
            "      7       37.3047  0.0611\n",
            "      8       37.3047  0.0623\n",
            "      9       37.3047  0.0653\n",
            "     10       37.3047  0.0612\n",
            "     11       37.3047  0.0694\n",
            "     12       37.3047  0.0621\n",
            "     13       37.3047  0.0628\n",
            "     14       37.3047  0.0739\n",
            "     15       37.3047  0.0625\n",
            "     16       37.3047  0.0613\n",
            "     17       37.3047  0.0748\n",
            "     18       37.3047  0.0641\n",
            "     19       37.3047  0.0680\n",
            "     20       37.3047  0.0657\n",
            "     21       37.3047  0.0635\n",
            "     22       37.3047  0.0628\n",
            "     23       37.3047  0.0634\n",
            "     24       37.3047  0.0611\n",
            "     25       37.3047  0.0611\n",
            "     26       37.3047  0.0701\n",
            "     27       37.3047  0.0613\n",
            "     28       37.3047  0.0671\n",
            "     29       37.3047  0.0652\n",
            "     30       37.3047  0.0623\n",
            "     31       37.3047  0.0657\n",
            "     32       37.3047  0.0712\n",
            "     33       37.3047  0.0646\n",
            "     34       37.3047  0.0634\n",
            "     35       37.3047  0.0663\n",
            "     36       37.3047  0.0627\n",
            "     37       37.3047  0.0630\n",
            "     38       37.3047  0.0657\n",
            "     39       37.3047  0.0624\n",
            "     40       37.3047  0.0627\n",
            "     41       37.3047  0.0626\n",
            "     42       37.3047  0.0654\n",
            "     43       37.3047  0.0620\n",
            "     44       37.3047  0.0709\n",
            "     45       37.3047  0.0677\n",
            "     46       37.3047  0.0706\n",
            "     47       37.3047  0.0691\n",
            "     48       37.3047  0.0667\n",
            "     49       37.3047  0.0607\n",
            "     50       37.3047  0.0614\n",
            "     51       37.3047  0.0639\n",
            "     52       37.3047  0.0644\n",
            "     53       37.3047  0.0622\n",
            "     54       37.3047  0.0627\n",
            "     55       37.3047  0.0638\n",
            "     56       37.3047  0.0641\n",
            "     57       37.3047  0.0672\n",
            "     58       37.3047  0.0665\n",
            "     59       37.3047  0.0604\n",
            "     60       37.3047  0.0655\n",
            "     61       37.3047  0.0636\n",
            "     62       37.3047  0.0627\n",
            "     63       37.3047  0.0723\n",
            "     64       37.3047  0.0596\n",
            "     65       37.3047  0.0599\n",
            "     66       37.3047  0.0625\n",
            "     67       37.3047  0.0626\n",
            "     68       37.3047  0.0671\n",
            "     69       37.3047  0.0607\n",
            "     70       37.3047  0.0631\n",
            "     71       37.3047  0.0667\n",
            "     72       37.3047  0.0654\n",
            "     73       37.3047  0.0622\n",
            "     74       37.3047  0.0618\n",
            "     75       37.3047  0.0669\n",
            "     76       37.3047  0.0677\n",
            "     77       37.3047  0.0681\n",
            "     78       37.3047  0.0738\n",
            "     79       37.3047  0.0641\n",
            "     80       37.3047  0.0668\n",
            "     81       37.3047  0.0639\n",
            "     82       37.3047  0.0654\n",
            "     83       37.3047  0.0671\n",
            "     84       37.3047  0.0634\n",
            "     85       37.3047  0.0659\n",
            "     86       37.3047  0.0668\n",
            "     87       37.3047  0.0627\n",
            "     88       37.3047  0.0626\n",
            "     89       37.3047  0.0687\n",
            "     90       37.3047  0.0733\n",
            "     91       37.3047  0.0630\n",
            "     92       37.3047  0.0693\n",
            "     93       37.3047  0.0710\n",
            "     94       37.3047  0.0644\n",
            "     95       37.3047  0.0643\n",
            "     96       37.3047  0.0597\n",
            "     97       37.3047  0.0666\n",
            "     98       37.3047  0.0645\n",
            "     99       37.3047  0.0668\n",
            "    100       37.3047  0.0615\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m38.9652\u001b[0m  0.0540\n",
            "      2       \u001b[36m37.3047\u001b[0m  0.0725\n",
            "      3       37.3047  0.0628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0753\n",
            "      5       37.3047  0.0614\n",
            "      6       37.3047  0.0705\n",
            "      7       37.3047  0.0661\n",
            "      8       37.3047  0.0688\n",
            "      9       37.3047  0.0656\n",
            "     10       37.3047  0.0621\n",
            "     11       37.3047  0.0633\n",
            "     12       37.3047  0.0625\n",
            "     13       37.3047  0.0631\n",
            "     14       37.3047  0.0654\n",
            "     15       37.3047  0.0615\n",
            "     16       37.3047  0.0658\n",
            "     17       37.3047  0.0619\n",
            "     18       37.3047  0.0616\n",
            "     19       37.3047  0.0640\n",
            "     20       37.3047  0.0649\n",
            "     21       37.3047  0.0686\n",
            "     22       37.3047  0.0656\n",
            "     23       37.3047  0.0717\n",
            "     24       37.3047  0.0621\n",
            "     25       37.3047  0.0608\n",
            "     26       37.3047  0.0640\n",
            "     27       37.3047  0.0621\n",
            "     28       37.3047  0.0651\n",
            "     29       37.3047  0.0626\n",
            "     30       37.3047  0.0656\n",
            "     31       37.3047  0.0701\n",
            "     32       37.3047  0.0625\n",
            "     33       37.3047  0.0617\n",
            "     34       37.3047  0.0715\n",
            "     35       37.3047  0.0615\n",
            "     36       37.3047  0.0729\n",
            "     37       37.3047  0.0707\n",
            "     38       37.3047  0.0740\n",
            "     39       37.3047  0.0625\n",
            "     40       37.3047  0.0616\n",
            "     41       37.3047  0.0644\n",
            "     42       37.3047  0.0654\n",
            "     43       37.3047  0.0632\n",
            "     44       37.3047  0.0590\n",
            "     45       37.3047  0.0624\n",
            "     46       37.3047  0.0664\n",
            "     47       37.3047  0.0669\n",
            "     48       37.3047  0.0628\n",
            "     49       37.3047  0.0636\n",
            "     50       37.3047  0.0656\n",
            "     51       37.3047  0.0619\n",
            "     52       37.3047  0.0702\n",
            "     53       37.3047  0.0695\n",
            "     54       37.3047  0.0640\n",
            "     55       37.3047  0.0618\n",
            "     56       37.3047  0.0627\n",
            "     57       37.3047  0.0648\n",
            "     58       37.3047  0.0648\n",
            "     59       37.3047  0.0657\n",
            "     60       37.3047  0.0712\n",
            "     61       37.3047  0.0785\n",
            "     62       37.3047  0.0639\n",
            "     63       37.3047  0.0637\n",
            "     64       37.3047  0.0652\n",
            "     65       37.3047  0.0630\n",
            "     66       37.3047  0.0639\n",
            "     67       37.3047  0.0656\n",
            "     68       37.3047  0.0621\n",
            "     69       37.3047  0.0718\n",
            "     70       37.3047  0.0616\n",
            "     71       37.3047  0.0625\n",
            "     72       37.3047  0.0644\n",
            "     73       37.3047  0.0633\n",
            "     74       37.3047  0.0718\n",
            "     75       37.3047  0.0650\n",
            "     76       37.3047  0.0615\n",
            "     77       37.3047  0.0623\n",
            "     78       37.3047  0.0651\n",
            "     79       37.3047  0.0619\n",
            "     80       37.3047  0.0616\n",
            "     81       37.3047  0.0658\n",
            "     82       37.3047  0.0629\n",
            "     83       37.3047  0.0657\n",
            "     84       37.3047  0.0666\n",
            "     85       37.3047  0.0629\n",
            "     86       37.3047  0.0622\n",
            "     87       37.3047  0.0611\n",
            "     88       37.3047  0.0635\n",
            "     89       37.3047  0.0639\n",
            "     90       37.3047  0.0617\n",
            "     91       37.3047  0.0603\n",
            "     92       37.3047  0.0742\n",
            "     93       37.3047  0.0646\n",
            "     94       37.3047  0.0620\n",
            "     95       37.3047  0.0626\n",
            "     96       37.3047  0.0624\n",
            "     97       37.3047  0.0675\n",
            "     98       37.3047  0.0641\n",
            "     99       37.3047  0.0731\n",
            "    100       37.3047  0.0611\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m44.1406\u001b[0m  0.0578\n",
            "      2       44.1406  0.0654\n",
            "      3       44.1406  0.0615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       44.1406  0.0734\n",
            "      5       44.1406  0.0595\n",
            "      6       44.1406  0.0715\n",
            "      7       44.1406  0.0616\n",
            "      8       44.1406  0.0646\n",
            "      9       44.1406  0.0605\n",
            "     10       44.1406  0.0619\n",
            "     11       44.1406  0.0654\n",
            "     12       44.1406  0.0621\n",
            "     13       44.1406  0.0602\n",
            "     14       44.1406  0.0617\n",
            "     15       44.1406  0.0756\n",
            "     16       44.1406  0.0631\n",
            "     17       44.1406  0.0610\n",
            "     18       44.1406  0.0608\n",
            "     19       44.1406  0.0652\n",
            "     20       44.1406  0.0685\n",
            "     21       44.1406  0.0636\n",
            "     22       44.1406  0.0648\n",
            "     23       44.1406  0.0613\n",
            "     24       44.1406  0.0635\n",
            "     25       44.1406  0.0600\n",
            "     26       44.1406  0.0689\n",
            "     27       44.1406  0.0648\n",
            "     28       44.1406  0.0665\n",
            "     29       44.1406  0.0638\n",
            "     30       44.1406  0.0774\n",
            "     31       44.1406  0.0627\n",
            "     32       44.1406  0.0638\n",
            "     33       44.1406  0.0611\n",
            "     34       44.1406  0.0618\n",
            "     35       44.1406  0.0647\n",
            "     36       44.1406  0.0618\n",
            "     37       44.1406  0.0630\n",
            "     38       44.1406  0.0714\n",
            "     39       44.1406  0.0652\n",
            "     40       44.1406  0.0626\n",
            "     41       44.1406  0.0624\n",
            "     42       44.1406  0.0581\n",
            "     43       44.1406  0.0617\n",
            "     44       44.1406  0.0591\n",
            "     45       44.1406  0.0598\n",
            "     46       44.1406  0.0651\n",
            "     47       44.1406  0.0603\n",
            "     48       44.1406  0.0634\n",
            "     49       44.1406  0.0628\n",
            "     50       44.1406  0.0597\n",
            "     51       44.1406  0.0608\n",
            "     52       44.1406  0.0647\n",
            "     53       44.1406  0.0660\n",
            "     54       44.1406  0.0618\n",
            "     55       44.1406  0.0634\n",
            "     56       44.1406  0.0647\n",
            "     57       44.1406  0.0639\n",
            "     58       44.1406  0.0636\n",
            "     59       44.1406  0.0604\n",
            "     60       44.1406  0.0605\n",
            "     61       44.1406  0.0677\n",
            "     62       44.1406  0.0649\n",
            "     63       44.1406  0.0644\n",
            "     64       44.1406  0.0664\n",
            "     65       44.1406  0.0765\n",
            "     66       44.1406  0.0613\n",
            "     67       44.1406  0.0615\n",
            "     68       44.1406  0.0623\n",
            "     69       44.1406  0.0687\n",
            "     70       44.1406  0.0634\n",
            "     71       44.1406  0.0617\n",
            "     72       44.1406  0.0685\n",
            "     73       44.1406  0.0606\n",
            "     74       44.1406  0.0636\n",
            "     75       44.1406  0.0672\n",
            "     76       44.1406  0.0631\n",
            "     77       44.1406  0.0711\n",
            "     78       44.1406  0.0667\n",
            "     79       44.1406  0.0619\n",
            "     80       44.1406  0.0672\n",
            "     81       44.1406  0.0614\n",
            "     82       44.1406  0.0621\n",
            "     83       44.1406  0.0654\n",
            "     84       44.1406  0.0682\n",
            "     85       44.1406  0.0652\n",
            "     86       44.1406  0.0612\n",
            "     87       44.1406  0.0664\n",
            "     88       44.1406  0.0632\n",
            "     89       44.1406  0.0609\n",
            "     90       44.1406  0.0639\n",
            "     91       44.1406  0.0637\n",
            "     92       44.1406  0.0727\n",
            "     93       44.1406  0.0649\n",
            "     94       44.1406  0.0636\n",
            "     95       44.1406  0.0634\n",
            "     96       44.1406  0.0798\n",
            "     97       44.1406  0.0655\n",
            "     98       44.1406  0.0675\n",
            "     99       44.1406  0.0629\n",
            "    100       44.1406  0.0648\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m52.3703\u001b[0m  0.0594\n",
            "      2       \u001b[36m51.1719\u001b[0m  0.0663\n",
            "      3       51.1719  0.0606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       51.1719  0.0684\n",
            "      5       51.1719  0.0653\n",
            "      6       51.1719  0.0634\n",
            "      7       51.1719  0.0692\n",
            "      8       51.1719  0.0660\n",
            "      9       51.1719  0.0649\n",
            "     10       51.1719  0.0708\n",
            "     11       51.1719  0.0689\n",
            "     12       51.1719  0.0640\n",
            "     13       51.1719  0.0662\n",
            "     14       51.1719  0.0614\n",
            "     15       51.1719  0.0629\n",
            "     16       51.1719  0.0658\n",
            "     17       51.1719  0.0608\n",
            "     18       51.1719  0.0619\n",
            "     19       51.1719  0.0612\n",
            "     20       51.1719  0.0638\n",
            "     21       51.1719  0.0622\n",
            "     22       51.1719  0.0690\n",
            "     23       51.1719  0.0642\n",
            "     24       51.1719  0.0596\n",
            "     25       51.1719  0.0596\n",
            "     26       51.1719  0.0630\n",
            "     27       51.1719  0.0621\n",
            "     28       51.1719  0.0708\n",
            "     29       51.1719  0.0691\n",
            "     30       51.1719  0.0625\n",
            "     31       51.1719  0.0683\n",
            "     32       51.1719  0.0611\n",
            "     33       51.1719  0.0605\n",
            "     34       51.1719  0.0604\n",
            "     35       51.1719  0.0705\n",
            "     36       51.1719  0.0657\n",
            "     37       51.1719  0.0675\n",
            "     38       51.1719  0.0611\n",
            "     39       51.1719  0.0596\n",
            "     40       51.1719  0.0622\n",
            "     41       51.1719  0.0620\n",
            "     42       51.1719  0.0666\n",
            "     43       51.1719  0.0608\n",
            "     44       51.1719  0.0655\n",
            "     45       51.1719  0.0639\n",
            "     46       51.1719  0.0668\n",
            "     47       51.1719  0.0611\n",
            "     48       51.1719  0.0639\n",
            "     49       51.1719  0.0670\n",
            "     50       51.1719  0.0618\n",
            "     51       51.1719  0.0701\n",
            "     52       51.1719  0.0646\n",
            "     53       51.1719  0.0702\n",
            "     54       51.1719  0.0645\n",
            "     55       51.1719  0.0694\n",
            "     56       51.1719  0.0654\n",
            "     57       51.1719  0.0635\n",
            "     58       51.1719  0.0670\n",
            "     59       51.1719  0.0648\n",
            "     60       51.1719  0.0647\n",
            "     61       51.1719  0.0645\n",
            "     62       51.1719  0.0652\n",
            "     63       51.1719  0.0646\n",
            "     64       51.1719  0.0620\n",
            "     65       51.1719  0.0712\n",
            "     66       51.1719  0.0654\n",
            "     67       51.1719  0.0630\n",
            "     68       51.1719  0.0717\n",
            "     69       51.1719  0.0639\n",
            "     70       51.1719  0.0625\n",
            "     71       51.1719  0.0651\n",
            "     72       51.1719  0.0632\n",
            "     73       51.1719  0.0698\n",
            "     74       51.1719  0.0620\n",
            "     75       51.1719  0.0633\n",
            "     76       51.1719  0.0669\n",
            "     77       51.1719  0.0629\n",
            "     78       51.1719  0.0630\n",
            "     79       51.1719  0.0641\n",
            "     80       51.1719  0.0649\n",
            "     81       51.1719  0.0687\n",
            "     82       51.1719  0.0636\n",
            "     83       51.1719  0.0713\n",
            "     84       51.1719  0.0652\n",
            "     85       51.1719  0.0638\n",
            "     86       51.1719  0.0709\n",
            "     87       51.1719  0.0654\n",
            "     88       51.1719  0.0680\n",
            "     89       51.1719  0.0637\n",
            "     90       51.1719  0.0668\n",
            "     91       51.1719  0.0668\n",
            "     92       51.1719  0.0631\n",
            "     93       51.1719  0.0641\n",
            "     94       51.1719  0.0657\n",
            "     95       51.1719  0.0671\n",
            "     96       51.1719  0.0640\n",
            "     97       51.1719  0.0652\n",
            "     98       51.1719  0.0744\n",
            "     99       51.1719  0.0633\n",
            "    100       51.1719  0.0675\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m62.3047\u001b[0m  0.0582\n",
            "      2       62.3047  0.0664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       62.3047  0.0716\n",
            "      4       62.3047  0.0673\n",
            "      5       62.3047  0.0675\n",
            "      6       62.3047  0.0655\n",
            "      7       62.3047  0.0621\n",
            "      8       62.3047  0.0628\n",
            "      9       62.3047  0.0638\n",
            "     10       62.3047  0.0702\n",
            "     11       62.3047  0.0632\n",
            "     12       62.3047  0.0642\n",
            "     13       62.3047  0.0768\n",
            "     14       62.3047  0.0638\n",
            "     15       62.3047  0.0621\n",
            "     16       62.3047  0.0661\n",
            "     17       62.3047  0.0754\n",
            "     18       62.3047  0.0642\n",
            "     19       62.3047  0.0674\n",
            "     20       62.3047  0.0592\n",
            "     21       62.3047  0.0625\n",
            "     22       62.3047  0.0672\n",
            "     23       62.3047  0.0614\n",
            "     24       62.3047  0.0614\n",
            "     25       62.3047  0.0689\n",
            "     26       62.3047  0.0633\n",
            "     27       62.3047  0.0738\n",
            "     28       62.3047  0.0741\n",
            "     29       62.3047  0.0646\n",
            "     30       62.3047  0.0646\n",
            "     31       62.3047  0.0673\n",
            "     32       62.3047  0.0649\n",
            "     33       62.3047  0.0755\n",
            "     34       62.3047  0.0667\n",
            "     35       62.3047  0.0637\n",
            "     36       62.3047  0.0630\n",
            "     37       62.3047  0.0647\n",
            "     38       62.3047  0.0643\n",
            "     39       62.3047  0.0630\n",
            "     40       62.3047  0.0586\n",
            "     41       62.3047  0.0654\n",
            "     42       62.3047  0.0645\n",
            "     43       62.3047  0.0685\n",
            "     44       62.3047  0.0653\n",
            "     45       62.3047  0.0630\n",
            "     46       62.3047  0.0672\n",
            "     47       62.3047  0.0661\n",
            "     48       62.3047  0.0642\n",
            "     49       62.3047  0.0681\n",
            "     50       62.3047  0.0622\n",
            "     51       62.3047  0.0775\n",
            "     52       62.3047  0.0677\n",
            "     53       62.3047  0.0619\n",
            "     54       62.3047  0.0641\n",
            "     55       62.3047  0.0645\n",
            "     56       62.3047  0.0695\n",
            "     57       62.3047  0.0684\n",
            "     58       62.3047  0.0712\n",
            "     59       62.3047  0.0649\n",
            "     60       62.3047  0.0618\n",
            "     61       62.3047  0.0673\n",
            "     62       62.3047  0.0616\n",
            "     63       62.3047  0.0685\n",
            "     64       62.3047  0.0647\n",
            "     65       62.3047  0.0617\n",
            "     66       62.3047  0.0707\n",
            "     67       62.3047  0.0674\n",
            "     68       62.3047  0.0649\n",
            "     69       62.3047  0.0621\n",
            "     70       62.3047  0.0637\n",
            "     71       62.3047  0.0637\n",
            "     72       62.3047  0.0631\n",
            "     73       62.3047  0.0735\n",
            "     74       62.3047  0.0675\n",
            "     75       62.3047  0.0687\n",
            "     76       62.3047  0.0620\n",
            "     77       62.3047  0.0638\n",
            "     78       62.3047  0.0673\n",
            "     79       62.3047  0.0616\n",
            "     80       62.3047  0.0647\n",
            "     81       62.3047  0.0686\n",
            "     82       62.3047  0.0631\n",
            "     83       62.3047  0.0657\n",
            "     84       62.3047  0.0624\n",
            "     85       62.3047  0.0611\n",
            "     86       62.3047  0.0634\n",
            "     87       62.3047  0.0630\n",
            "     88       62.3047  0.0785\n",
            "     89       62.3047  0.0664\n",
            "     90       62.3047  0.0643\n",
            "     91       62.3047  0.0644\n",
            "     92       62.3047  0.0628\n",
            "     93       62.3047  0.0652\n",
            "     94       62.3047  0.0651\n",
            "     95       62.3047  0.0612\n",
            "     96       62.3047  0.0669\n",
            "     97       62.3047  0.0647\n",
            "     98       62.3047  0.0640\n",
            "     99       62.3047  0.0636\n",
            "    100       62.3047  0.0654\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m47.8516\u001b[0m  0.0567\n",
            "      2       47.8516  0.0752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       47.8516  0.0848\n",
            "      4       47.8516  0.0653\n",
            "      5       47.8516  0.0624\n",
            "      6       47.8516  0.0648\n",
            "      7       47.8516  0.0672\n",
            "      8       47.8516  0.0606\n",
            "      9       47.8516  0.0679\n",
            "     10       47.8516  0.0624\n",
            "     11       47.8516  0.0658\n",
            "     12       47.8516  0.0625\n",
            "     13       47.8516  0.0631\n",
            "     14       47.8516  0.0626\n",
            "     15       47.8516  0.0650\n",
            "     16       47.8516  0.0615\n",
            "     17       47.8516  0.0644\n",
            "     18       47.8516  0.0720\n",
            "     19       47.8516  0.0688\n",
            "     20       47.8516  0.0678\n",
            "     21       47.8516  0.0622\n",
            "     22       47.8516  0.0681\n",
            "     23       47.8516  0.0616\n",
            "     24       47.8516  0.0703\n",
            "     25       47.8516  0.0625\n",
            "     26       47.8516  0.0644\n",
            "     27       47.8516  0.0611\n",
            "     28       47.8516  0.0621\n",
            "     29       47.8516  0.0659\n",
            "     30       47.8516  0.0620\n",
            "     31       47.8516  0.0654\n",
            "     32       47.8516  0.0614\n",
            "     33       47.8516  0.0817\n",
            "     34       47.8516  0.0620\n",
            "     35       47.8516  0.0668\n",
            "     36       47.8516  0.0620\n",
            "     37       47.8516  0.0641\n",
            "     38       47.8516  0.0657\n",
            "     39       47.8516  0.0659\n",
            "     40       47.8516  0.0628\n",
            "     41       47.8516  0.0614\n",
            "     42       47.8516  0.0641\n",
            "     43       47.8516  0.0653\n",
            "     44       47.8516  0.0613\n",
            "     45       47.8516  0.0629\n",
            "     46       47.8516  0.0759\n",
            "     47       47.8516  0.0631\n",
            "     48       47.8516  0.0735\n",
            "     49       47.8516  0.0630\n",
            "     50       47.8516  0.0626\n",
            "     51       47.8516  0.0622\n",
            "     52       47.8516  0.0655\n",
            "     53       47.8516  0.0638\n",
            "     54       47.8516  0.0606\n",
            "     55       47.8516  0.0634\n",
            "     56       47.8516  0.0628\n",
            "     57       47.8516  0.0629\n",
            "     58       47.8516  0.0656\n",
            "     59       47.8516  0.0610\n",
            "     60       47.8516  0.0661\n",
            "     61       47.8516  0.0621\n",
            "     62       47.8516  0.0639\n",
            "     63       47.8516  0.0603\n",
            "     64       47.8516  0.0707\n",
            "     65       47.8516  0.0614\n",
            "     66       47.8516  0.0621\n",
            "     67       47.8516  0.0667\n",
            "     68       47.8516  0.0618\n",
            "     69       47.8516  0.0615\n",
            "     70       47.8516  0.0625\n",
            "     71       47.8516  0.0611\n",
            "     72       47.8516  0.0609\n",
            "     73       47.8516  0.0646\n",
            "     74       47.8516  0.0620\n",
            "     75       47.8516  0.0628\n",
            "     76       47.8516  0.0634\n",
            "     77       47.8516  0.0665\n",
            "     78       47.8516  0.0656\n",
            "     79       47.8516  0.0675\n",
            "     80       47.8516  0.0662\n",
            "     81       47.8516  0.0636\n",
            "     82       47.8516  0.0704\n",
            "     83       47.8516  0.0607\n",
            "     84       47.8516  0.0639\n",
            "     85       47.8516  0.0626\n",
            "     86       47.8516  0.0632\n",
            "     87       47.8516  0.0623\n",
            "     88       47.8516  0.0641\n",
            "     89       47.8516  0.0637\n",
            "     90       47.8516  0.0643\n",
            "     91       47.8516  0.0677\n",
            "     92       47.8516  0.0688\n",
            "     93       47.8516  0.0661\n",
            "     94       47.8516  0.0689\n",
            "     95       47.8516  0.0648\n",
            "     96       47.8516  0.0638\n",
            "     97       47.8516  0.0680\n",
            "     98       47.8516  0.0703\n",
            "     99       47.8516  0.0655\n",
            "    100       47.8516  0.0641\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m38.0515\u001b[0m  0.0568\n",
            "      2       \u001b[36m37.2320\u001b[0m  0.0654\n",
            "      3       37.2320  0.0646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.2320  0.0710\n",
            "      5       37.2320  0.0756\n",
            "      6       37.2320  0.0651\n",
            "      7       37.2320  0.0627\n",
            "      8       37.2320  0.0619\n",
            "      9       37.2320  0.0768\n",
            "     10       37.2320  0.0732\n",
            "     11       37.2320  0.0652\n",
            "     12       37.2320  0.0712\n",
            "     13       37.2320  0.0617\n",
            "     14       37.2320  0.0620\n",
            "     15       37.2320  0.0640\n",
            "     16       37.2320  0.0616\n",
            "     17       37.2320  0.0656\n",
            "     18       37.2320  0.0637\n",
            "     19       37.2320  0.0654\n",
            "     20       37.2320  0.0611\n",
            "     21       37.2320  0.0645\n",
            "     22       37.2320  0.0616\n",
            "     23       37.2320  0.0739\n",
            "     24       37.2320  0.0801\n",
            "     25       37.2320  0.0622\n",
            "     26       37.2320  0.0646\n",
            "     27       37.2320  0.0632\n",
            "     28       37.2320  0.0622\n",
            "     29       37.2320  0.0632\n",
            "     30       37.2320  0.0650\n",
            "     31       37.2320  0.0621\n",
            "     32       37.2320  0.0686\n",
            "     33       37.2320  0.0643\n",
            "     34       37.2320  0.0637\n",
            "     35       37.2320  0.0650\n",
            "     36       37.2320  0.0698\n",
            "     37       37.2320  0.0653\n",
            "     38       37.2320  0.0616\n",
            "     39       37.2320  0.0749\n",
            "     40       37.2320  0.0681\n",
            "     41       37.2320  0.0681\n",
            "     42       37.2320  0.0629\n",
            "     43       37.2320  0.0606\n",
            "     44       37.2320  0.0657\n",
            "     45       37.2320  0.0609\n",
            "     46       37.2320  0.0614\n",
            "     47       37.2320  0.0707\n",
            "     48       37.2320  0.0712\n",
            "     49       37.2320  0.0679\n",
            "     50       37.2320  0.0654\n",
            "     51       37.2320  0.0607\n",
            "     52       37.2320  0.0636\n",
            "     53       37.2320  0.0625\n",
            "     54       37.2320  0.0726\n",
            "     55       37.2320  0.0692\n",
            "     56       37.2320  0.0601\n",
            "     57       37.2320  0.0628\n",
            "     58       37.2320  0.0613\n",
            "     59       37.2320  0.0606\n",
            "     60       37.2320  0.0644\n",
            "     61       37.2320  0.0609\n",
            "     62       37.2320  0.0624\n",
            "     63       37.2320  0.0647\n",
            "     64       37.2320  0.0649\n",
            "     65       37.2320  0.0618\n",
            "     66       37.2320  0.0644\n",
            "     67       37.2320  0.0607\n",
            "     68       37.2320  0.0729\n",
            "     69       37.2320  0.0755\n",
            "     70       37.2320  0.0615\n",
            "     71       37.2320  0.0631\n",
            "     72       37.2320  0.0623\n",
            "     73       37.2320  0.0615\n",
            "     74       37.2320  0.0616\n",
            "     75       37.2320  0.0637\n",
            "     76       37.2320  0.0637\n",
            "     77       37.2320  0.0633\n",
            "     78       37.2320  0.0641\n",
            "     79       37.2320  0.0609\n",
            "     80       37.2320  0.0640\n",
            "     81       37.2320  0.0649\n",
            "     82       37.2320  0.0635\n",
            "     83       37.2320  0.0627\n",
            "     84       37.2320  0.0668\n",
            "     85       37.2320  0.0692\n",
            "     86       37.2320  0.0647\n",
            "     87       37.2320  0.0620\n",
            "     88       37.2320  0.0607\n",
            "     89       37.2320  0.0602\n",
            "     90       37.2320  0.0656\n",
            "     91       37.2320  0.0652\n",
            "     92       37.2320  0.0639\n",
            "     93       37.2320  0.0621\n",
            "     94       37.2320  0.0647\n",
            "     95       37.2320  0.0687\n",
            "     96       37.2320  0.0684\n",
            "     97       37.2320  0.0628\n",
            "     98       37.2320  0.0672\n",
            "     99       37.2320  0.0647\n",
            "    100       37.2320  0.0678\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m41.0156\u001b[0m  0.0727\n",
            "      2       41.4062  0.0794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       41.7549  0.0885\n",
            "      4       41.9922  0.0766\n",
            "      5       42.5856  0.0852\n",
            "      6       42.7091  0.0774\n",
            "      7       43.3594  0.0824\n",
            "      8       43.7500  0.0789\n",
            "      9       44.3359  0.0766\n",
            "     10       44.5312  0.0755\n",
            "     11       44.5312  0.0799\n",
            "     12       44.5312  0.0840\n",
            "     13       44.7266  0.0828\n",
            "     14       44.7266  0.0808\n",
            "     15       44.7266  0.0807\n",
            "     16       44.7266  0.0796\n",
            "     17       44.7266  0.0774\n",
            "     18       44.7266  0.0825\n",
            "     19       44.7266  0.0812\n",
            "     20       44.7266  0.0770\n",
            "     21       44.7266  0.0843\n",
            "     22       44.7266  0.0782\n",
            "     23       44.7266  0.0767\n",
            "     24       44.7266  0.0814\n",
            "     25       44.7266  0.0842\n",
            "     26       44.7266  0.0756\n",
            "     27       44.7266  0.0782\n",
            "     28       44.7266  0.0778\n",
            "     29       44.7266  0.0768\n",
            "     30       44.7266  0.0809\n",
            "     31       44.7266  0.0863\n",
            "     32       44.7266  0.0869\n",
            "     33       44.7266  0.0834\n",
            "     34       44.7266  0.0794\n",
            "     35       44.8462  0.0793\n",
            "     36       44.8832  0.0811\n",
            "     37       44.7976  0.0932\n",
            "     38       44.7266  0.0782\n",
            "     39       44.7266  0.0799\n",
            "     40       44.7266  0.0773\n",
            "     41       44.5527  0.0790\n",
            "     42       \u001b[36m40.7887\u001b[0m  0.0855\n",
            "     43       44.6100  0.0895\n",
            "     44       44.7269  0.0801\n",
            "     45       44.7266  0.0769\n",
            "     46       44.7266  0.0826\n",
            "     47       44.7266  0.0837\n",
            "     48       44.7266  0.0823\n",
            "     49       44.7266  0.0892\n",
            "     50       44.7266  0.0820\n",
            "     51       44.7266  0.0764\n",
            "     52       44.7266  0.0808\n",
            "     53       44.7266  0.0888\n",
            "     54       44.7266  0.0867\n",
            "     55       44.7266  0.0862\n",
            "     56       44.7266  0.0796\n",
            "     57       44.7266  0.0897\n",
            "     58       44.7266  0.0790\n",
            "     59       44.7266  0.0794\n",
            "     60       44.7266  0.0851\n",
            "     61       44.7266  0.0859\n",
            "     62       44.7266  0.0811\n",
            "     63       44.7266  0.0784\n",
            "     64       44.7266  0.0843\n",
            "     65       44.7266  0.0829\n",
            "     66       44.7266  0.0789\n",
            "     67       44.7266  0.0797\n",
            "     68       44.7266  0.0865\n",
            "     69       44.7266  0.0794\n",
            "     70       44.7266  0.0802\n",
            "     71       44.7266  0.0792\n",
            "     72       44.7266  0.0851\n",
            "     73       44.7266  0.0875\n",
            "     74       44.7266  0.0845\n",
            "     75       44.7266  0.0807\n",
            "     76       44.7266  0.0823\n",
            "     77       44.7266  0.0812\n",
            "     78       44.7266  0.0838\n",
            "     79       44.7266  0.0881\n",
            "     80       44.7266  0.0794\n",
            "     81       44.7266  0.0869\n",
            "     82       44.7266  0.0802\n",
            "     83       44.7266  0.0826\n",
            "     84       44.7266  0.0830\n",
            "     85       44.7266  0.0858\n",
            "     86       44.7266  0.0786\n",
            "     87       44.7266  0.0808\n",
            "     88       44.7266  0.0790\n",
            "     89       44.7266  0.0900\n",
            "     90       44.7266  0.0807\n",
            "     91       44.7266  0.0808\n",
            "     92       44.7266  0.0812\n",
            "     93       44.7266  0.0844\n",
            "     94       44.7266  0.0818\n",
            "     95       44.7045  0.0810\n",
            "     96       44.7034  0.0873\n",
            "     97       44.7022  0.0922\n",
            "     98       44.6998  0.0847\n",
            "     99       44.6986  0.0815\n",
            "    100       44.6983  0.0779\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m42.2038\u001b[0m  0.0724\n",
            "      2       \u001b[36m38.8814\u001b[0m  0.0790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m38.8000\u001b[0m  0.0960\n",
            "      4       38.9923  0.0832\n",
            "      5       39.3822  0.0761\n",
            "      6       39.7720  0.0790\n",
            "      7       39.9665  0.0812\n",
            "      8       38.8391  0.0778\n",
            "      9       \u001b[36m38.7654\u001b[0m  0.0862\n",
            "     10       38.7692  0.0770\n",
            "     11       \u001b[36m38.6924\u001b[0m  0.0775\n",
            "     12       \u001b[36m38.4341\u001b[0m  0.0752\n",
            "     13       \u001b[36m37.5745\u001b[0m  0.0799\n",
            "     14       37.5760  0.0825\n",
            "     15       \u001b[36m37.1249\u001b[0m  0.0761\n",
            "     16       \u001b[36m36.8221\u001b[0m  0.0777\n",
            "     17       36.8344  0.0772\n",
            "     18       36.8341  0.0796\n",
            "     19       36.8341  0.0812\n",
            "     20       36.8341  0.0827\n",
            "     21       36.8341  0.0904\n",
            "     22       37.0294  0.0788\n",
            "     23       37.2247  0.0809\n",
            "     24       37.2247  0.0790\n",
            "     25       37.2248  0.0788\n",
            "     26       37.2248  0.0783\n",
            "     27       37.2248  0.0763\n",
            "     28       37.2248  0.0850\n",
            "     29       37.2248  0.0842\n",
            "     30       37.2796  0.0793\n",
            "     31       36.9141  0.0792\n",
            "     32       36.9141  0.0780\n",
            "     33       36.9141  0.0767\n",
            "     34       36.9141  0.0902\n",
            "     35       36.9141  0.0816\n",
            "     36       36.9141  0.0753\n",
            "     37       36.9141  0.0796\n",
            "     38       36.9141  0.0756\n",
            "     39       36.9141  0.0770\n",
            "     40       36.9141  0.0822\n",
            "     41       36.9141  0.0729\n",
            "     42       36.9141  0.0887\n",
            "     43       36.9141  0.0790\n",
            "     44       36.9141  0.0810\n",
            "     45       36.9141  0.0792\n",
            "     46       36.9141  0.0872\n",
            "     47       36.9141  0.0783\n",
            "     48       36.9141  0.0777\n",
            "     49       36.9141  0.0808\n",
            "     50       36.9141  0.0832\n",
            "     51       36.9141  0.0865\n",
            "     52       36.9141  0.0801\n",
            "     53       36.9141  0.0789\n",
            "     54       36.9141  0.0801\n",
            "     55       36.9141  0.0831\n",
            "     56       36.9141  0.0847\n",
            "     57       36.9141  0.0803\n",
            "     58       36.9141  0.0888\n",
            "     59       36.9141  0.0772\n",
            "     60       36.9141  0.0793\n",
            "     61       36.9141  0.0801\n",
            "     62       36.9141  0.0808\n",
            "     63       36.9141  0.0844\n",
            "     64       36.9141  0.0796\n",
            "     65       36.9141  0.0885\n",
            "     66       36.9141  0.0794\n",
            "     67       36.9141  0.0774\n",
            "     68       36.9141  0.0836\n",
            "     69       36.9141  0.0787\n",
            "     70       36.9141  0.0935\n",
            "     71       36.9141  0.0937\n",
            "     72       36.9141  0.0806\n",
            "     73       36.9141  0.0795\n",
            "     74       36.9141  0.0815\n",
            "     75       36.9141  0.0776\n",
            "     76       36.9141  0.0846\n",
            "     77       36.9141  0.0916\n",
            "     78       36.9141  0.0853\n",
            "     79       36.9141  0.0821\n",
            "     80       36.9141  0.0787\n",
            "     81       36.9141  0.0771\n",
            "     82       36.9141  0.0860\n",
            "     83       36.9141  0.0800\n",
            "     84       36.9141  0.0763\n",
            "     85       36.9141  0.0763\n",
            "     86       36.9141  0.0781\n",
            "     87       36.9141  0.0856\n",
            "     88       36.9141  0.0822\n",
            "     89       36.9141  0.0818\n",
            "     90       36.9141  0.0775\n",
            "     91       36.9141  0.0819\n",
            "     92       36.9141  0.0800\n",
            "     93       36.9141  0.0790\n",
            "     94       36.9141  0.0909\n",
            "     95       36.9141  0.0832\n",
            "     96       36.9141  0.0802\n",
            "     97       36.9141  0.0827\n",
            "     98       36.9141  0.0839\n",
            "     99       36.9141  0.0798\n",
            "    100       36.9141  0.0830\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m45.1172\u001b[0m  0.0713\n",
            "      2       45.1172  0.0807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       45.1172  0.0885\n",
            "      4       45.1172  0.0804\n",
            "      5       \u001b[36m44.9219\u001b[0m  0.0757\n",
            "      6       \u001b[36m44.1406\u001b[0m  0.0836\n",
            "      7       \u001b[36m43.3594\u001b[0m  0.0783\n",
            "      8       \u001b[36m41.4062\u001b[0m  0.0767\n",
            "      9       \u001b[36m40.2344\u001b[0m  0.0783\n",
            "     10       \u001b[36m37.3047\u001b[0m  0.0739\n",
            "     11       37.3047  0.0745\n",
            "     12       37.3047  0.0856\n",
            "     13       37.3047  0.0766\n",
            "     14       37.3047  0.0809\n",
            "     15       37.3047  0.0795\n",
            "     16       37.3047  0.0774\n",
            "     17       37.3047  0.0775\n",
            "     18       37.3047  0.0760\n",
            "     19       37.3047  0.0872\n",
            "     20       37.3047  0.0822\n",
            "     21       37.3047  0.0816\n",
            "     22       37.3047  0.0780\n",
            "     23       37.3047  0.0820\n",
            "     24       37.3047  0.0804\n",
            "     25       37.3869  0.0772\n",
            "     26       37.4320  0.0762\n",
            "     27       37.4338  0.0789\n",
            "     28       37.3047  0.0858\n",
            "     29       37.3047  0.0795\n",
            "     30       37.3047  0.0754\n",
            "     31       37.3047  0.0806\n",
            "     32       37.3047  0.0777\n",
            "     33       37.3047  0.0799\n",
            "     34       37.3047  0.0832\n",
            "     35       37.3047  0.0760\n",
            "     36       37.3047  0.0796\n",
            "     37       37.3047  0.0805\n",
            "     38       37.3047  0.0782\n",
            "     39       37.3047  0.0773\n",
            "     40       37.3047  0.0827\n",
            "     41       37.3047  0.0773\n",
            "     42       37.3047  0.0845\n",
            "     43       37.3047  0.0793\n",
            "     44       37.3047  0.0853\n",
            "     45       37.3047  0.0827\n",
            "     46       37.3047  0.0802\n",
            "     47       37.3047  0.0842\n",
            "     48       37.3047  0.0798\n",
            "     49       37.3047  0.0838\n",
            "     50       37.3047  0.0858\n",
            "     51       37.3047  0.0795\n",
            "     52       37.3047  0.0868\n",
            "     53       37.3047  0.0823\n",
            "     54       37.3047  0.0794\n",
            "     55       37.3047  0.0798\n",
            "     56       37.3047  0.0927\n",
            "     57       37.3047  0.0801\n",
            "     58       37.3047  0.0823\n",
            "     59       37.3047  0.0848\n",
            "     60       37.3047  0.0799\n",
            "     61       37.3047  0.0750\n",
            "     62       37.3047  0.0802\n",
            "     63       37.3047  0.0883\n",
            "     64       37.3047  0.0797\n",
            "     65       37.3047  0.0816\n",
            "     66       37.3047  0.0772\n",
            "     67       37.3047  0.0775\n",
            "     68       37.3047  0.0856\n",
            "     69       37.3047  0.0767\n",
            "     70       37.3047  0.0940\n",
            "     71       37.3047  0.0786\n",
            "     72       37.3047  0.0809\n",
            "     73       37.3047  0.0803\n",
            "     74       37.3047  0.0823\n",
            "     75       37.3047  0.0823\n",
            "     76       37.3047  0.0857\n",
            "     77       37.3047  0.0818\n",
            "     78       37.3047  0.0781\n",
            "     79       37.3047  0.0799\n",
            "     80       37.3047  0.0862\n",
            "     81       37.3047  0.0796\n",
            "     82       37.3047  0.0848\n",
            "     83       37.3047  0.0764\n",
            "     84       37.3047  0.0821\n",
            "     85       37.3047  0.0806\n",
            "     86       37.3047  0.0818\n",
            "     87       37.3047  0.0833\n",
            "     88       37.3047  0.0800\n",
            "     89       37.3047  0.0871\n",
            "     90       37.3047  0.0894\n",
            "     91       37.3047  0.0829\n",
            "     92       37.3047  0.0918\n",
            "     93       37.3047  0.0844\n",
            "     94       37.3047  0.0823\n",
            "     95       37.3047  0.0899\n",
            "     96       37.3047  0.0811\n",
            "     97       37.3047  0.0789\n",
            "     98       37.3047  0.0804\n",
            "     99       37.3047  0.0862\n",
            "    100       37.3047  0.0806\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m60.8098\u001b[0m  0.0728\n",
            "      2       \u001b[36m60.3516\u001b[0m  0.0871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m60.1562\u001b[0m  0.0916\n",
            "      4       60.4695  0.0839\n",
            "      5       \u001b[36m56.4001\u001b[0m  0.0847\n",
            "      6       58.7891  0.0758\n",
            "      7       \u001b[36m50.6630\u001b[0m  0.0838\n",
            "      8       \u001b[36m48.3651\u001b[0m  0.0797\n",
            "      9       \u001b[36m44.5207\u001b[0m  0.0794\n",
            "     10       46.7022  0.0791\n",
            "     11       46.0938  0.0782\n",
            "     12       46.2891  0.0764\n",
            "     13       46.2891  0.0787\n",
            "     14       46.2891  0.0747\n",
            "     15       46.2891  0.0757\n",
            "     16       46.2891  0.0880\n",
            "     17       46.2891  0.0812\n",
            "     18       45.9703  0.0744\n",
            "     19       45.7031  0.0796\n",
            "     20       45.7031  0.0848\n",
            "     21       45.7031  0.0767\n",
            "     22       45.7031  0.0801\n",
            "     23       45.7031  0.0805\n",
            "     24       45.7031  0.0812\n",
            "     25       45.7031  0.0799\n",
            "     26       45.7031  0.0771\n",
            "     27       45.7031  0.0792\n",
            "     28       45.7031  0.0774\n",
            "     29       45.7031  0.0842\n",
            "     30       45.7031  0.0755\n",
            "     31       45.7031  0.0850\n",
            "     32       45.7031  0.0859\n",
            "     33       45.7031  0.0818\n",
            "     34       45.7031  0.0790\n",
            "     35       45.7031  0.0802\n",
            "     36       45.7031  0.0803\n",
            "     37       45.7031  0.0775\n",
            "     38       45.7031  0.0797\n",
            "     39       45.7031  0.0833\n",
            "     40       45.7031  0.0793\n",
            "     41       45.7031  0.0876\n",
            "     42       45.7031  0.0837\n",
            "     43       45.7031  0.0816\n",
            "     44       45.7031  0.0792\n",
            "     45       45.7031  0.0850\n",
            "     46       45.7031  0.0788\n",
            "     47       45.7031  0.0769\n",
            "     48       45.7031  0.0774\n",
            "     49       45.7031  0.0782\n",
            "     50       45.7031  0.0812\n",
            "     51       45.7031  0.0770\n",
            "     52       45.7031  0.0833\n",
            "     53       45.7031  0.0855\n",
            "     54       45.7031  0.0768\n",
            "     55       45.7031  0.0775\n",
            "     56       45.6789  0.0753\n",
            "     57       45.6749  0.0866\n",
            "     58       45.6710  0.0794\n",
            "     59       45.6670  0.0850\n",
            "     60       45.6630  0.0801\n",
            "     61       45.6589  0.0768\n",
            "     62       45.6547  0.0804\n",
            "     63       45.6504  0.0833\n",
            "     64       45.6460  0.0842\n",
            "     65       45.6416  0.0787\n",
            "     66       45.6370  0.0921\n",
            "     67       45.5985  0.0856\n",
            "     68       45.5351  0.0808\n",
            "     69       45.5253  0.0832\n",
            "     70       46.5513  0.0777\n",
            "     71       46.4519  0.0798\n",
            "     72       45.1172  0.0802\n",
            "     73       \u001b[36m44.4055\u001b[0m  0.0821\n",
            "     74       \u001b[36m44.4031\u001b[0m  0.0820\n",
            "     75       \u001b[36m44.4003\u001b[0m  0.0778\n",
            "     76       \u001b[36m42.2410\u001b[0m  0.0803\n",
            "     77       \u001b[36m41.6016\u001b[0m  0.0787\n",
            "     78       41.6016  0.0930\n",
            "     79       41.6016  0.0855\n",
            "     80       41.6016  0.0775\n",
            "     81       41.6016  0.0795\n",
            "     82       41.6016  0.0837\n",
            "     83       41.6016  0.0834\n",
            "     84       41.6016  0.0764\n",
            "     85       41.6016  0.0762\n",
            "     86       41.6016  0.0871\n",
            "     87       41.6016  0.0767\n",
            "     88       41.6016  0.0800\n",
            "     89       41.6016  0.0867\n",
            "     90       41.6016  0.0898\n",
            "     91       41.6016  0.0785\n",
            "     92       41.6016  0.0766\n",
            "     93       41.6016  0.0832\n",
            "     94       41.6016  0.0786\n",
            "     95       41.6016  0.0815\n",
            "     96       41.6016  0.0825\n",
            "     97       41.6016  0.0790\n",
            "     98       41.6016  0.0790\n",
            "     99       41.6016  0.0829\n",
            "    100       41.6016  0.0847\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m58.1809\u001b[0m  0.0723\n",
            "      2       \u001b[36m57.6476\u001b[0m  0.0851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m57.3560\u001b[0m  0.1029\n",
            "      4       \u001b[36m54.9335\u001b[0m  0.0761\n",
            "      5       \u001b[36m49.9200\u001b[0m  0.0823\n",
            "      6       \u001b[36m47.3257\u001b[0m  0.0799\n",
            "      7       \u001b[36m46.9720\u001b[0m  0.0802\n",
            "      8       \u001b[36m44.4351\u001b[0m  0.0772\n",
            "      9       46.4849  0.0770\n",
            "     10       \u001b[36m43.9457\u001b[0m  0.0778\n",
            "     11       44.5313  0.0794\n",
            "     12       44.6964  0.0788\n",
            "     13       44.6964  0.0818\n",
            "     14       44.6964  0.0928\n",
            "     15       44.6965  0.0774\n",
            "     16       44.6965  0.0774\n",
            "     17       44.6966  0.0786\n",
            "     18       44.6967  0.0791\n",
            "     19       44.3061  0.0765\n",
            "     20       \u001b[36m43.9156\u001b[0m  0.0786\n",
            "     21       43.9226  0.0822\n",
            "     22       \u001b[36m43.5033\u001b[0m  0.0773\n",
            "     23       \u001b[36m38.4888\u001b[0m  0.0796\n",
            "     24       \u001b[36m38.0269\u001b[0m  0.0793\n",
            "     25       38.7603  0.0854\n",
            "     26       38.6161  0.0775\n",
            "     27       38.4766  0.0883\n",
            "     28       38.4766  0.0779\n",
            "     29       38.4766  0.0839\n",
            "     30       38.4766  0.0810\n",
            "     31       38.4766  0.0944\n",
            "     32       38.4766  0.0803\n",
            "     33       38.4766  0.0826\n",
            "     34       38.4766  0.0810\n",
            "     35       38.4766  0.0761\n",
            "     36       38.4766  0.0795\n",
            "     37       38.4766  0.0828\n",
            "     38       38.4766  0.0768\n",
            "     39       38.4766  0.0900\n",
            "     40       38.4766  0.0826\n",
            "     41       38.4766  0.0793\n",
            "     42       38.4766  0.0859\n",
            "     43       38.4766  0.0803\n",
            "     44       38.4181  0.0762\n",
            "     45       38.3841  0.0771\n",
            "     46       38.3559  0.0792\n",
            "     47       38.2812  0.0793\n",
            "     48       38.2812  0.0870\n",
            "     49       38.2812  0.0798\n",
            "     50       38.2812  0.0872\n",
            "     51       38.2812  0.0868\n",
            "     52       38.2812  0.0807\n",
            "     53       38.2812  0.0789\n",
            "     54       38.2812  0.0816\n",
            "     55       38.2812  0.0849\n",
            "     56       38.2812  0.0780\n",
            "     57       38.2812  0.0803\n",
            "     58       38.2812  0.0797\n",
            "     59       38.2812  0.0787\n",
            "     60       38.2812  0.0808\n",
            "     61       38.2812  0.0892\n",
            "     62       38.2812  0.0880\n",
            "     63       38.2812  0.0865\n",
            "     64       38.2812  0.0826\n",
            "     65       38.2812  0.0804\n",
            "     66       38.2812  0.0825\n",
            "     67       38.2812  0.0841\n",
            "     68       38.2812  0.0811\n",
            "     69       38.2812  0.0771\n",
            "     70       38.2812  0.0789\n",
            "     71       38.2812  0.0810\n",
            "     72       38.2812  0.0820\n",
            "     73       38.2812  0.0852\n",
            "     74       38.2812  0.0806\n",
            "     75       38.2812  0.0953\n",
            "     76       38.2812  0.0791\n",
            "     77       38.2812  0.0803\n",
            "     78       38.2812  0.0864\n",
            "     79       38.2812  0.0840\n",
            "     80       38.2812  0.0777\n",
            "     81       38.2812  0.0832\n",
            "     82       38.2812  0.0789\n",
            "     83       38.2812  0.0788\n",
            "     84       38.2812  0.0844\n",
            "     85       38.2812  0.0773\n",
            "     86       38.2812  0.0892\n",
            "     87       38.2812  0.0922\n",
            "     88       38.2812  0.0815\n",
            "     89       38.2812  0.0821\n",
            "     90       38.2812  0.0822\n",
            "     91       38.2812  0.0800\n",
            "     92       38.2812  0.0835\n",
            "     93       38.2812  0.0845\n",
            "     94       38.2812  0.0793\n",
            "     95       38.2812  0.0834\n",
            "     96       38.2812  0.0844\n",
            "     97       38.2812  0.0849\n",
            "     98       38.2812  0.0817\n",
            "     99       38.2812  0.0928\n",
            "    100       38.2812  0.0827\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3047\u001b[0m  0.0798\n",
            "      2       37.3047  0.0869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.3047  0.0962\n",
            "      4       37.3047  0.0780\n",
            "      5       37.3047  0.0782\n",
            "      6       37.3047  0.0807\n",
            "      7       37.3047  0.0778\n",
            "      8       37.3047  0.0778\n",
            "      9       37.3047  0.0819\n",
            "     10       37.3047  0.0885\n",
            "     11       37.3047  0.0861\n",
            "     12       37.3049  0.0817\n",
            "     13       37.3047  0.0800\n",
            "     14       37.3047  0.0810\n",
            "     15       37.3047  0.0805\n",
            "     16       37.3047  0.0791\n",
            "     17       37.3047  0.0771\n",
            "     18       37.3047  0.0785\n",
            "     19       37.3047  0.0810\n",
            "     20       37.3047  0.0773\n",
            "     21       37.3047  0.0842\n",
            "     22       37.3047  0.0841\n",
            "     23       37.3047  0.0855\n",
            "     24       37.3047  0.0804\n",
            "     25       37.3047  0.0819\n",
            "     26       37.3047  0.0771\n",
            "     27       37.3047  0.0805\n",
            "     28       37.3047  0.0858\n",
            "     29       37.3047  0.0848\n",
            "     30       37.3047  0.0936\n",
            "     31       37.3047  0.0804\n",
            "     32       37.3047  0.0847\n",
            "     33       37.3047  0.0804\n",
            "     34       37.3047  0.0873\n",
            "     35       37.3047  0.0866\n",
            "     36       37.3047  0.0854\n",
            "     37       37.3047  0.0789\n",
            "     38       37.3047  0.0777\n",
            "     39       37.3047  0.0801\n",
            "     40       37.3047  0.0770\n",
            "     41       37.3047  0.0823\n",
            "     42       37.3047  0.0848\n",
            "     43       37.3047  0.0836\n",
            "     44       37.3047  0.0802\n",
            "     45       37.3047  0.0786\n",
            "     46       37.3047  0.0785\n",
            "     47       37.3047  0.0860\n",
            "     48       37.3047  0.0891\n",
            "     49       37.3047  0.0821\n",
            "     50       37.3047  0.0779\n",
            "     51       37.3047  0.0786\n",
            "     52       37.3047  0.0787\n",
            "     53       37.3047  0.0847\n",
            "     54       37.3047  0.0848\n",
            "     55       37.3047  0.0801\n",
            "     56       37.3047  0.0948\n",
            "     57       37.3047  0.0909\n",
            "     58       37.3047  0.0801\n",
            "     59       37.3047  0.0910\n",
            "     60       37.3047  0.0876\n",
            "     61       37.3047  0.0804\n",
            "     62       37.3047  0.0840\n",
            "     63       37.3047  0.0796\n",
            "     64       37.3047  0.0807\n",
            "     65       37.3047  0.0873\n",
            "     66       37.3047  0.0841\n",
            "     67       37.3047  0.0891\n",
            "     68       37.3047  0.0797\n",
            "     69       37.3047  0.0820\n",
            "     70       37.3047  0.0804\n",
            "     71       37.3047  0.0963\n",
            "     72       37.3047  0.0862\n",
            "     73       37.3047  0.0822\n",
            "     74       37.3047  0.0851\n",
            "     75       \u001b[36m34.6423\u001b[0m  0.0789\n",
            "     76       37.3047  0.0792\n",
            "     77       37.3047  0.0819\n",
            "     78       37.3047  0.0911\n",
            "     79       37.3047  0.0871\n",
            "     80       37.3047  0.0793\n",
            "     81       37.3047  0.0858\n",
            "     82       37.3047  0.0792\n",
            "     83       37.3047  0.0891\n",
            "     84       37.3047  0.0755\n",
            "     85       37.3047  0.0780\n",
            "     86       37.3047  0.0795\n",
            "     87       37.3047  0.0803\n",
            "     88       37.3047  0.0791\n",
            "     89       37.3047  0.0832\n",
            "     90       37.3047  0.0774\n",
            "     91       37.3047  0.0781\n",
            "     92       37.3047  0.0847\n",
            "     93       37.3047  0.0776\n",
            "     94       37.3047  0.0862\n",
            "     95       37.3047  0.0894\n",
            "     96       37.3047  0.0833\n",
            "     97       37.3047  0.0805\n",
            "     98       37.3047  0.0850\n",
            "     99       37.3047  0.0813\n",
            "    100       37.3047  0.0816\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m53.1250\u001b[0m  0.0793\n",
            "      2       53.3203  0.0805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       53.1250  0.0952\n",
            "      4       \u001b[36m52.3438\u001b[0m  0.0818\n",
            "      5       \u001b[36m51.6078\u001b[0m  0.0767\n",
            "      6       \u001b[36m51.3672\u001b[0m  0.0793\n",
            "      7       51.3672  0.0898\n",
            "      8       51.3672  0.0818\n",
            "      9       51.3672  0.0846\n",
            "     10       51.3672  0.0789\n",
            "     11       51.3672  0.0820\n",
            "     12       \u001b[36m51.1719\u001b[0m  0.0816\n",
            "     13       \u001b[36m51.1719\u001b[0m  0.0860\n",
            "     14       51.1719  0.0809\n",
            "     15       51.1719  0.0783\n",
            "     16       51.1719  0.0771\n",
            "     17       51.1719  0.0850\n",
            "     18       51.1719  0.0761\n",
            "     19       51.1719  0.0839\n",
            "     20       51.1719  0.0768\n",
            "     21       51.1719  0.0739\n",
            "     22       51.1719  0.0744\n",
            "     23       51.1719  0.0786\n",
            "     24       51.1719  0.0767\n",
            "     25       51.1719  0.0794\n",
            "     26       51.1719  0.0820\n",
            "     27       51.1719  0.0762\n",
            "     28       51.1719  0.0819\n",
            "     29       51.1719  0.0782\n",
            "     30       51.1719  0.0767\n",
            "     31       51.1719  0.0790\n",
            "     32       51.1719  0.0815\n",
            "     33       51.1719  0.0831\n",
            "     34       51.1719  0.0754\n",
            "     35       51.1719  0.0766\n",
            "     36       51.1719  0.0789\n",
            "     37       51.1719  0.0789\n",
            "     38       51.1719  0.0791\n",
            "     39       51.1719  0.0824\n",
            "     40       51.1719  0.0770\n",
            "     41       51.1719  0.0798\n",
            "     42       51.1719  0.0803\n",
            "     43       51.1719  0.0824\n",
            "     44       51.1719  0.0891\n",
            "     45       51.1719  0.0808\n",
            "     46       51.1719  0.0775\n",
            "     47       51.1719  0.0787\n",
            "     48       51.1719  0.0823\n",
            "     49       51.1719  0.0858\n",
            "     50       51.1719  0.0870\n",
            "     51       51.1719  0.0806\n",
            "     52       51.1719  0.0828\n",
            "     53       51.1719  0.0798\n",
            "     54       51.1719  0.0874\n",
            "     55       51.1719  0.0800\n",
            "     56       51.1719  0.0887\n",
            "     57       51.1719  0.0846\n",
            "     58       51.1719  0.0781\n",
            "     59       51.1719  0.0800\n",
            "     60       51.1719  0.0790\n",
            "     61       51.1719  0.0830\n",
            "     62       51.1719  0.0795\n",
            "     63       51.1719  0.0819\n",
            "     64       51.1719  0.0877\n",
            "     65       51.1719  0.0804\n",
            "     66       51.1719  0.0799\n",
            "     67       51.1719  0.0833\n",
            "     68       51.1719  0.0874\n",
            "     69       51.1719  0.0804\n",
            "     70       51.1719  0.0778\n",
            "     71       51.1719  0.0849\n",
            "     72       51.1719  0.0820\n",
            "     73       51.1719  0.0804\n",
            "     74       51.1719  0.0817\n",
            "     75       51.1719  0.0867\n",
            "     76       51.1719  0.0798\n",
            "     77       51.1719  0.0830\n",
            "     78       51.1719  0.0821\n",
            "     79       51.1719  0.0867\n",
            "     80       51.1719  0.1051\n",
            "     81       51.1719  0.0804\n",
            "     82       51.1719  0.0851\n",
            "     83       51.1719  0.0790\n",
            "     84       51.1719  0.0794\n",
            "     85       51.1719  0.0909\n",
            "     86       51.1719  0.0836\n",
            "     87       51.1719  0.0794\n",
            "     88       51.1719  0.0778\n",
            "     89       51.1719  0.0815\n",
            "     90       51.1719  0.0844\n",
            "     91       51.1719  0.0831\n",
            "     92       \u001b[36m50.9766\u001b[0m  0.0873\n",
            "     93       50.9766  0.0773\n",
            "     94       50.9766  0.0786\n",
            "     95       50.9766  0.0807\n",
            "     96       50.9766  0.0881\n",
            "     97       50.9766  0.0797\n",
            "     98       50.9766  0.0819\n",
            "     99       50.9766  0.0822\n",
            "    100       50.9766  0.0813\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m47.4780\u001b[0m  0.0714\n",
            "      2       48.0015  0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       \u001b[36m46.1300\u001b[0m  0.0874\n",
            "      4       \u001b[36m39.0280\u001b[0m  0.0851\n",
            "      5       41.3530  0.0753\n",
            "      6       41.3435  0.0840\n",
            "      7       41.3435  0.0819\n",
            "      8       41.3436  0.0822\n",
            "      9       41.3437  0.0781\n",
            "     10       41.3792  0.0828\n",
            "     11       41.4062  0.0803\n",
            "     12       41.4062  0.0783\n",
            "     13       41.3775  0.0868\n",
            "     14       41.4062  0.0786\n",
            "     15       41.4062  0.0756\n",
            "     16       41.4062  0.0833\n",
            "     17       41.4062  0.0767\n",
            "     18       41.4062  0.0776\n",
            "     19       41.4062  0.0757\n",
            "     20       41.4062  0.0783\n",
            "     21       41.4062  0.0765\n",
            "     22       41.4062  0.0883\n",
            "     23       41.4062  0.0792\n",
            "     24       41.4062  0.0768\n",
            "     25       41.4063  0.0795\n",
            "     26       41.3408  0.0838\n",
            "     27       41.3418  0.0752\n",
            "     28       41.3427  0.0801\n",
            "     29       41.3433  0.0870\n",
            "     30       41.3439  0.0770\n",
            "     31       41.3443  0.0779\n",
            "     32       41.3446  0.0748\n",
            "     33       41.3449  0.0857\n",
            "     34       39.9859  0.0769\n",
            "     35       39.1571  0.0758\n",
            "     36       39.2931  0.0791\n",
            "     37       39.2923  0.0778\n",
            "     38       39.2919  0.0866\n",
            "     39       39.2912  0.0773\n",
            "     40       39.2880  0.0817\n",
            "     41       39.2830  0.0845\n",
            "     42       39.2702  0.0768\n",
            "     43       39.0625  0.0818\n",
            "     44       39.0625  0.0775\n",
            "     45       39.0625  0.0780\n",
            "     46       39.0625  0.0826\n",
            "     47       39.0625  0.0952\n",
            "     48       39.0625  0.0799\n",
            "     49       39.0625  0.0791\n",
            "     50       39.0625  0.0794\n",
            "     51       39.0625  0.0800\n",
            "     52       39.0625  0.0775\n",
            "     53       39.0625  0.0842\n",
            "     54       39.0625  0.0806\n",
            "     55       39.0625  0.0782\n",
            "     56       39.0625  0.0798\n",
            "     57       39.0625  0.0813\n",
            "     58       39.0625  0.0813\n",
            "     59       39.0625  0.0790\n",
            "     60       39.2578  0.0791\n",
            "     61       39.2578  0.0781\n",
            "     62       39.2578  0.0883\n",
            "     63       39.2578  0.0796\n",
            "     64       39.2578  0.0824\n",
            "     65       39.2578  0.0792\n",
            "     66       39.2578  0.0873\n",
            "     67       39.2578  0.0822\n",
            "     68       39.2578  0.0796\n",
            "     69       39.2578  0.0932\n",
            "     70       39.2578  0.0857\n",
            "     71       39.2578  0.0824\n",
            "     72       39.2578  0.0890\n",
            "     73       39.2578  0.0825\n",
            "     74       39.2578  0.0853\n",
            "     75       39.2578  0.0792\n",
            "     76       39.2578  0.0870\n",
            "     77       39.2578  0.0816\n",
            "     78       39.2578  0.0881\n",
            "     79       39.2578  0.0797\n",
            "     80       39.2578  0.0840\n",
            "     81       39.2578  0.0804\n",
            "     82       39.2578  0.0803\n",
            "     83       39.2578  0.0883\n",
            "     84       39.2578  0.0903\n",
            "     85       56.3049  0.0804\n",
            "     86       50.9766  0.0827\n",
            "     87       51.1719  0.0827\n",
            "     88       51.1719  0.0782\n",
            "     89       51.1719  0.0800\n",
            "     90       51.1719  0.0897\n",
            "     91       51.1719  0.0788\n",
            "     92       51.1719  0.0824\n",
            "     93       51.1719  0.0793\n",
            "     94       51.1719  0.0897\n",
            "     95       51.1719  0.0771\n",
            "     96       51.1719  0.0791\n",
            "     97       51.1719  0.0850\n",
            "     98       51.1719  0.0839\n",
            "     99       51.1719  0.0778\n",
            "    100       51.1719  0.0800\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m33.6833\u001b[0m  0.0713\n",
            "      2       \u001b[36m33.0351\u001b[0m  0.0855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       35.1133  0.0896\n",
            "      4       36.1328  0.0883\n",
            "      5       36.1328  0.0772\n",
            "      6       36.1328  0.0797\n",
            "      7       36.1328  0.0892\n",
            "      8       36.1328  0.0923\n",
            "      9       36.1328  0.0776\n",
            "     10       36.1500  0.0800\n",
            "     11       37.3047  0.0773\n",
            "     12       37.3047  0.0750\n",
            "     13       37.3047  0.0827\n",
            "     14       37.3047  0.0871\n",
            "     15       37.3047  0.0821\n",
            "     16       37.3047  0.0786\n",
            "     17       37.3047  0.0771\n",
            "     18       37.3047  0.0775\n",
            "     19       37.3047  0.0839\n",
            "     20       37.3047  0.0820\n",
            "     21       37.3047  0.0810\n",
            "     22       37.3047  0.0782\n",
            "     23       37.3047  0.0799\n",
            "     24       37.3047  0.0777\n",
            "     25       37.3047  0.0776\n",
            "     26       37.3047  0.0874\n",
            "     27       37.3047  0.0772\n",
            "     28       37.3047  0.0830\n",
            "     29       37.3047  0.0812\n",
            "     30       37.3047  0.0896\n",
            "     31       37.3047  0.0783\n",
            "     32       37.3047  0.0793\n",
            "     33       37.3047  0.0831\n",
            "     34       37.3047  0.0782\n",
            "     35       37.3047  0.0765\n",
            "     36       37.3047  0.0804\n",
            "     37       37.3047  0.0772\n",
            "     38       37.3047  0.0890\n",
            "     39       37.3047  0.0836\n",
            "     40       37.3047  0.0832\n",
            "     41       37.3047  0.0825\n",
            "     42       37.3047  0.0776\n",
            "     43       37.3047  0.0809\n",
            "     44       37.3047  0.0798\n",
            "     45       37.3047  0.0824\n",
            "     46       37.3047  0.0812\n",
            "     47       37.3047  0.0851\n",
            "     48       37.3047  0.0774\n",
            "     49       37.3047  0.0781\n",
            "     50       37.3047  0.0838\n",
            "     51       37.3047  0.0941\n",
            "     52       37.3047  0.0825\n",
            "     53       37.3047  0.0793\n",
            "     54       37.3047  0.0804\n",
            "     55       37.3047  0.0780\n",
            "     56       37.3047  0.0840\n",
            "     57       37.3047  0.0826\n",
            "     58       37.3047  0.0804\n",
            "     59       37.3047  0.0778\n",
            "     60       37.3047  0.0776\n",
            "     61       37.3047  0.0791\n",
            "     62       37.3047  0.0846\n",
            "     63       37.3047  0.0861\n",
            "     64       37.3047  0.0811\n",
            "     65       37.3047  0.0908\n",
            "     66       37.3047  0.0880\n",
            "     67       37.3047  0.0814\n",
            "     68       37.3047  0.0833\n",
            "     69       37.3047  0.0797\n",
            "     70       37.3047  0.0785\n",
            "     71       37.3047  0.0791\n",
            "     72       37.3047  0.0788\n",
            "     73       37.3047  0.0821\n",
            "     74       37.3047  0.0802\n",
            "     75       37.3047  0.0857\n",
            "     76       37.3047  0.0813\n",
            "     77       37.3047  0.0831\n",
            "     78       37.3047  0.0771\n",
            "     79       37.3047  0.0806\n",
            "     80       37.3047  0.0819\n",
            "     81       37.3047  0.0834\n",
            "     82       37.3047  0.0867\n",
            "     83       37.3047  0.0811\n",
            "     84       37.3047  0.0798\n",
            "     85       37.3047  0.0801\n",
            "     86       37.3047  0.0839\n",
            "     87       37.3047  0.1042\n",
            "     88       37.3047  0.0813\n",
            "     89       37.3047  0.0831\n",
            "     90       37.3047  0.0862\n",
            "     91       37.3047  0.0823\n",
            "     92       37.3047  0.0870\n",
            "     93       37.3047  0.0857\n",
            "     94       37.3047  0.0803\n",
            "     95       37.3047  0.0798\n",
            "     96       37.3047  0.0797\n",
            "     97       37.3047  0.0815\n",
            "     98       37.3047  0.0822\n",
            "     99       37.3047  0.0914\n",
            "    100       37.3047  0.0802\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.4269\u001b[0m  0.0747\n",
            "      2       37.4269  0.0835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       37.4269  0.0903\n",
            "      4       37.4269  0.0829\n",
            "      5       37.4269  0.0760\n",
            "      6       37.4269  0.0800\n",
            "      7       37.4269  0.0805\n",
            "      8       37.4269  0.0767\n",
            "      9       37.4269  0.0779\n",
            "     10       37.5964  0.0780\n",
            "     11       37.6218  0.0835\n",
            "     12       37.6218  0.0852\n",
            "     13       38.0117  0.0787\n",
            "     14       38.4016  0.0754\n",
            "     15       38.4016  0.0816\n",
            "     16       38.4016  0.0817\n",
            "     17       \u001b[36m37.2320\u001b[0m  0.0792\n",
            "     18       37.2320  0.0727\n",
            "     19       37.2320  0.0741\n",
            "     20       37.2320  0.0780\n",
            "     21       37.2320  0.0751\n",
            "     22       37.2320  0.0759\n",
            "     23       37.2320  0.0928\n",
            "     24       37.2320  0.0777\n",
            "     25       37.2320  0.0774\n",
            "     26       37.2320  0.0775\n",
            "     27       37.2320  0.0822\n",
            "     28       37.2320  0.0816\n",
            "     29       37.2320  0.0775\n",
            "     30       37.2320  0.0775\n",
            "     31       37.2320  0.0809\n",
            "     32       37.2320  0.0858\n",
            "     33       37.2320  0.0790\n",
            "     34       37.2320  0.0812\n",
            "     35       37.2320  0.0792\n",
            "     36       37.2320  0.0851\n",
            "     37       37.2320  0.0964\n",
            "     38       37.2320  0.0818\n",
            "     39       37.2320  0.0788\n",
            "     40       37.2326  0.0929\n",
            "     41       37.2320  0.0811\n",
            "     42       37.2320  0.0765\n",
            "     43       37.2320  0.0767\n",
            "     44       37.2320  0.0808\n",
            "     45       37.2320  0.0827\n",
            "     46       37.2320  0.0792\n",
            "     47       37.2320  0.0815\n",
            "     48       37.2320  0.0913\n",
            "     49       37.2320  0.0778\n",
            "     50       37.2320  0.0779\n",
            "     51       37.2320  0.0827\n",
            "     52       37.2320  0.0824\n",
            "     53       37.2320  0.0789\n",
            "     54       37.2320  0.0812\n",
            "     55       37.2320  0.0827\n",
            "     56       37.2320  0.0795\n",
            "     57       37.2320  0.0788\n",
            "     58       37.2320  0.0804\n",
            "     59       37.2320  0.0856\n",
            "     60       37.2320  0.0849\n",
            "     61       37.2320  0.0811\n",
            "     62       37.2320  0.0790\n",
            "     63       37.2320  0.0827\n",
            "     64       37.2320  0.0871\n",
            "     65       37.2320  0.0805\n",
            "     66       37.2320  0.0791\n",
            "     67       37.2320  0.0789\n",
            "     68       37.2320  0.0830\n",
            "     69       37.2320  0.0797\n",
            "     70       37.2320  0.0808\n",
            "     71       37.2320  0.0848\n",
            "     72       37.2320  0.0885\n",
            "     73       37.2320  0.0824\n",
            "     74       37.2320  0.0861\n",
            "     75       37.2320  0.0797\n",
            "     76       37.2320  0.0813\n",
            "     77       37.2320  0.0818\n",
            "     78       37.2320  0.0844\n",
            "     79       37.2320  0.0783\n",
            "     80       37.2320  0.0787\n",
            "     81       37.2320  0.0824\n",
            "     82       37.2320  0.0848\n",
            "     83       37.2320  0.0810\n",
            "     84       37.2320  0.0931\n",
            "     85       37.2320  0.0786\n",
            "     86       37.2320  0.0818\n",
            "     87       37.2320  0.0811\n",
            "     88       37.2320  0.0871\n",
            "     89       37.2320  0.0773\n",
            "     90       37.2320  0.0801\n",
            "     91       37.2320  0.0791\n",
            "     92       37.2320  0.0841\n",
            "     93       37.2320  0.0798\n",
            "     94       37.2320  0.0787\n",
            "     95       37.2320  0.0853\n",
            "     96       37.2320  0.0873\n",
            "     97       37.2320  0.0794\n",
            "     98       37.2320  0.0837\n",
            "     99       37.2320  0.0787\n",
            "    100       37.2320  0.0825\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m52.7331\u001b[0m  0.0540\n",
            "      2       52.7331  0.0621\n",
            "      3       52.7331  0.0599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       52.7331  0.0677\n",
            "      5       52.7331  0.0642\n",
            "      6       52.7331  0.0590\n",
            "      7       52.7331  0.0675\n",
            "      8       52.7332  0.0648\n",
            "      9       52.7332  0.0663\n",
            "     10       52.7332  0.0670\n",
            "     11       52.7332  0.0695\n",
            "     12       52.7332  0.0654\n",
            "     13       52.7332  0.0621\n",
            "     14       52.7332  0.0629\n",
            "     15       52.7332  0.0605\n",
            "     16       52.7332  0.0603\n",
            "     17       52.7333  0.0693\n",
            "     18       52.7333  0.0639\n",
            "     19       52.7333  0.0598\n",
            "     20       52.7333  0.0611\n",
            "     21       52.7333  0.0633\n",
            "     22       52.7333  0.0655\n",
            "     23       52.7333  0.0657\n",
            "     24       52.7333  0.0647\n",
            "     25       52.7333  0.0697\n",
            "     26       52.7334  0.0721\n",
            "     27       52.7334  0.0634\n",
            "     28       52.7334  0.0640\n",
            "     29       52.7334  0.0661\n",
            "     30       52.7334  0.0662\n",
            "     31       52.7334  0.0623\n",
            "     32       52.7334  0.0639\n",
            "     33       52.7334  0.0608\n",
            "     34       52.7334  0.0623\n",
            "     35       52.7335  0.0628\n",
            "     36       52.7335  0.0624\n",
            "     37       52.7335  0.0681\n",
            "     38       52.7335  0.0625\n",
            "     39       52.7335  0.0663\n",
            "     40       52.7335  0.0595\n",
            "     41       52.7335  0.0669\n",
            "     42       52.7335  0.0647\n",
            "     43       52.7335  0.0681\n",
            "     44       52.7336  0.0645\n",
            "     45       52.7336  0.0620\n",
            "     46       52.7336  0.0627\n",
            "     47       52.7336  0.0635\n",
            "     48       52.7336  0.0608\n",
            "     49       52.7336  0.0629\n",
            "     50       52.7336  0.0628\n",
            "     51       52.7336  0.0659\n",
            "     52       52.7336  0.0626\n",
            "     53       52.7337  0.0774\n",
            "     54       52.7337  0.0665\n",
            "     55       52.7337  0.0641\n",
            "     56       52.7337  0.0707\n",
            "     57       52.7337  0.0638\n",
            "     58       52.7337  0.0677\n",
            "     59       52.7337  0.0653\n",
            "     60       52.7337  0.0639\n",
            "     61       52.7337  0.0615\n",
            "     62       52.7338  0.0647\n",
            "     63       52.7338  0.0639\n",
            "     64       52.7338  0.0619\n",
            "     65       52.7338  0.0657\n",
            "     66       52.7338  0.0623\n",
            "     67       52.7338  0.0648\n",
            "     68       52.7338  0.0672\n",
            "     69       52.7338  0.0610\n",
            "     70       52.7338  0.0621\n",
            "     71       52.7339  0.0702\n",
            "     72       52.7339  0.0633\n",
            "     73       52.7339  0.0681\n",
            "     74       52.7339  0.0645\n",
            "     75       52.7339  0.0669\n",
            "     76       52.7339  0.0615\n",
            "     77       52.7339  0.0614\n",
            "     78       52.7339  0.0766\n",
            "     79       52.7339  0.0641\n",
            "     80       52.7340  0.0625\n",
            "     81       52.7340  0.0625\n",
            "     82       52.7340  0.0658\n",
            "     83       52.7340  0.0617\n",
            "     84       52.7340  0.0735\n",
            "     85       52.7340  0.0626\n",
            "     86       52.7340  0.0645\n",
            "     87       52.7340  0.0715\n",
            "     88       52.7340  0.0620\n",
            "     89       52.7341  0.0664\n",
            "     90       52.7341  0.0619\n",
            "     91       52.7341  0.0597\n",
            "     92       52.7341  0.0662\n",
            "     93       52.7341  0.0653\n",
            "     94       52.7341  0.0597\n",
            "     95       52.7341  0.0627\n",
            "     96       52.7341  0.0616\n",
            "     97       52.7341  0.0667\n",
            "     98       52.7342  0.0662\n",
            "     99       52.7342  0.0653\n",
            "    100       52.7342  0.0618\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m58.2031\u001b[0m  0.0606\n",
            "      2       58.2031  0.0722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       58.2031  0.0696\n",
            "      4       58.2031  0.0721\n",
            "      5       58.2031  0.0621\n",
            "      6       58.2031  0.0598\n",
            "      7       58.2031  0.0624\n",
            "      8       58.2031  0.0591\n",
            "      9       58.2031  0.0600\n",
            "     10       58.2031  0.0613\n",
            "     11       58.2031  0.0642\n",
            "     12       58.2031  0.0629\n",
            "     13       58.2031  0.0638\n",
            "     14       58.2031  0.0609\n",
            "     15       58.2031  0.0624\n",
            "     16       58.2031  0.0674\n",
            "     17       58.2031  0.0683\n",
            "     18       58.2031  0.0654\n",
            "     19       58.2031  0.0637\n",
            "     20       58.2031  0.0622\n",
            "     21       58.2031  0.0620\n",
            "     22       58.2031  0.0668\n",
            "     23       58.2031  0.0632\n",
            "     24       58.2031  0.0632\n",
            "     25       58.2031  0.0629\n",
            "     26       58.2031  0.0621\n",
            "     27       58.2031  0.0647\n",
            "     28       58.2031  0.0620\n",
            "     29       58.2031  0.0676\n",
            "     30       58.2031  0.0628\n",
            "     31       58.2031  0.0655\n",
            "     32       58.2031  0.0620\n",
            "     33       58.2031  0.0763\n",
            "     34       58.2031  0.0656\n",
            "     35       58.2031  0.0675\n",
            "     36       58.2031  0.0611\n",
            "     37       58.2031  0.0603\n",
            "     38       58.2031  0.0620\n",
            "     39       58.2031  0.0643\n",
            "     40       58.2031  0.0666\n",
            "     41       58.2031  0.0644\n",
            "     42       58.2031  0.0610\n",
            "     43       58.2031  0.0706\n",
            "     44       58.2031  0.0730\n",
            "     45       58.2031  0.0635\n",
            "     46       58.2031  0.0628\n",
            "     47       58.2031  0.0620\n",
            "     48       58.2031  0.0703\n",
            "     49       58.2031  0.0675\n",
            "     50       58.2031  0.0632\n",
            "     51       58.2031  0.0645\n",
            "     52       58.2031  0.0629\n",
            "     53       58.2031  0.0633\n",
            "     54       58.2031  0.0600\n",
            "     55       58.2031  0.0628\n",
            "     56       58.2031  0.0675\n",
            "     57       58.2031  0.0624\n",
            "     58       58.2031  0.0627\n",
            "     59       58.2031  0.0658\n",
            "     60       58.2031  0.0613\n",
            "     61       58.2031  0.0748\n",
            "     62       58.2031  0.0627\n",
            "     63       58.2031  0.0686\n",
            "     64       58.2031  0.0708\n",
            "     65       58.2031  0.0615\n",
            "     66       58.2031  0.0618\n",
            "     67       58.2031  0.0628\n",
            "     68       58.2031  0.0614\n",
            "     69       58.2031  0.0683\n",
            "     70       58.2031  0.0604\n",
            "     71       58.2031  0.0658\n",
            "     72       58.2031  0.0640\n",
            "     73       58.2031  0.0640\n",
            "     74       58.2031  0.0685\n",
            "     75       58.2031  0.0643\n",
            "     76       58.2031  0.0630\n",
            "     77       58.2031  0.0643\n",
            "     78       58.2031  0.0654\n",
            "     79       58.2031  0.0732\n",
            "     80       58.2031  0.0640\n",
            "     81       58.2031  0.0600\n",
            "     82       58.2031  0.0612\n",
            "     83       58.2031  0.0647\n",
            "     84       58.2031  0.0609\n",
            "     85       58.2031  0.0643\n",
            "     86       58.2031  0.0609\n",
            "     87       58.2031  0.0628\n",
            "     88       58.2031  0.0733\n",
            "     89       58.2031  0.0622\n",
            "     90       58.2031  0.0649\n",
            "     91       58.2031  0.0623\n",
            "     92       58.2031  0.0638\n",
            "     93       58.2031  0.0646\n",
            "     94       58.2031  0.0741\n",
            "     95       58.2031  0.0625\n",
            "     96       58.2031  0.0630\n",
            "     97       58.2031  0.0624\n",
            "     98       58.2031  0.0607\n",
            "     99       58.2031  0.0638\n",
            "    100       58.2031  0.0625\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m44.9473\u001b[0m  0.0552\n",
            "      2       \u001b[36m44.3359\u001b[0m  0.0777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       44.3359  0.0655\n",
            "      4       44.3359  0.0700\n",
            "      5       44.3359  0.0659\n",
            "      6       44.3359  0.0636\n",
            "      7       44.3359  0.0625\n",
            "      8       44.3359  0.0604\n",
            "      9       44.3359  0.0746\n",
            "     10       44.3359  0.0630\n",
            "     11       44.3359  0.0637\n",
            "     12       44.3359  0.0637\n",
            "     13       44.3359  0.0663\n",
            "     14       44.3359  0.0603\n",
            "     15       44.3359  0.0636\n",
            "     16       44.3359  0.0654\n",
            "     17       44.3359  0.0630\n",
            "     18       44.3359  0.0633\n",
            "     19       44.3359  0.0639\n",
            "     20       44.3359  0.0741\n",
            "     21       44.3359  0.0627\n",
            "     22       44.3359  0.0632\n",
            "     23       44.3359  0.0651\n",
            "     24       44.3359  0.0703\n",
            "     25       44.3359  0.0670\n",
            "     26       44.3359  0.0662\n",
            "     27       44.3359  0.0644\n",
            "     28       44.3359  0.0610\n",
            "     29       44.3359  0.0611\n",
            "     30       44.3359  0.0633\n",
            "     31       44.3359  0.0657\n",
            "     32       44.3359  0.0641\n",
            "     33       44.3359  0.0694\n",
            "     34       44.3359  0.0635\n",
            "     35       44.3359  0.0622\n",
            "     36       44.3359  0.0623\n",
            "     37       44.3359  0.0676\n",
            "     38       44.3359  0.0690\n",
            "     39       44.3359  0.0864\n",
            "     40       44.3359  0.0633\n",
            "     41       44.3359  0.0647\n",
            "     42       44.3359  0.0622\n",
            "     43       44.3359  0.0605\n",
            "     44       44.3359  0.0626\n",
            "     45       44.3359  0.0671\n",
            "     46       44.3359  0.0610\n",
            "     47       44.3359  0.0624\n",
            "     48       44.3359  0.0622\n",
            "     49       44.3359  0.0701\n",
            "     50       44.3359  0.0677\n",
            "     51       44.3359  0.0621\n",
            "     52       44.3359  0.0644\n",
            "     53       44.3359  0.0636\n",
            "     54       44.3359  0.0615\n",
            "     55       44.3359  0.0733\n",
            "     56       44.3359  0.0631\n",
            "     57       44.3359  0.0655\n",
            "     58       44.3359  0.0650\n",
            "     59       44.3359  0.0644\n",
            "     60       44.3359  0.0643\n",
            "     61       44.3359  0.0616\n",
            "     62       44.3359  0.0633\n",
            "     63       44.3359  0.0628\n",
            "     64       44.3359  0.0641\n",
            "     65       44.3359  0.0683\n",
            "     66       44.3359  0.0625\n",
            "     67       44.3359  0.0620\n",
            "     68       44.3359  0.0755\n",
            "     69       44.3359  0.0634\n",
            "     70       44.3359  0.0685\n",
            "     71       44.3359  0.0633\n",
            "     72       44.3359  0.0617\n",
            "     73       44.3359  0.0659\n",
            "     74       44.3359  0.0637\n",
            "     75       44.3359  0.0619\n",
            "     76       44.3359  0.0631\n",
            "     77       44.3359  0.0622\n",
            "     78       44.3359  0.0743\n",
            "     79       44.3359  0.0640\n",
            "     80       44.3359  0.0685\n",
            "     81       44.3359  0.0616\n",
            "     82       44.3359  0.0717\n",
            "     83       44.3359  0.0655\n",
            "     84       44.3359  0.0654\n",
            "     85       44.3359  0.0705\n",
            "     86       44.3359  0.0623\n",
            "     87       44.3359  0.0626\n",
            "     88       44.3359  0.0596\n",
            "     89       44.3359  0.0661\n",
            "     90       44.3359  0.0623\n",
            "     91       44.3359  0.0691\n",
            "     92       44.3359  0.0658\n",
            "     93       44.3359  0.0745\n",
            "     94       44.3359  0.0627\n",
            "     95       44.3359  0.0621\n",
            "     96       44.3359  0.0649\n",
            "     97       44.3359  0.0645\n",
            "     98       44.3359  0.0615\n",
            "     99       44.3359  0.0614\n",
            "    100       44.3359  0.0694\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m65.4894\u001b[0m  0.0542\n",
            "      2       \u001b[36m43.9810\u001b[0m  0.0664\n",
            "      3       \u001b[36m37.3047\u001b[0m  0.0637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       37.3047  0.0692\n",
            "      5       37.3047  0.0624\n",
            "      6       37.3047  0.0650\n",
            "      7       37.3047  0.0616\n",
            "      8       37.3047  0.0657\n",
            "      9       37.3047  0.0656\n",
            "     10       37.3047  0.0678\n",
            "     11       37.3047  0.0627\n",
            "     12       37.3047  0.0650\n",
            "     13       37.3047  0.0695\n",
            "     14       37.3047  0.0657\n",
            "     15       37.3047  0.0689\n",
            "     16       37.3047  0.0614\n",
            "     17       37.3047  0.0620\n",
            "     18       37.3047  0.0633\n",
            "     19       37.3047  0.0630\n",
            "     20       37.3047  0.0624\n",
            "     21       37.3047  0.0624\n",
            "     22       37.3047  0.0672\n",
            "     23       37.3047  0.0710\n",
            "     24       37.3047  0.0639\n",
            "     25       37.3047  0.0692\n",
            "     26       37.3047  0.0624\n",
            "     27       37.3047  0.0624\n",
            "     28       37.3047  0.0621\n",
            "     29       37.3047  0.0643\n",
            "     30       37.3047  0.0688\n",
            "     31       37.3047  0.0586\n",
            "     32       37.3047  0.0596\n",
            "     33       37.3047  0.0648\n",
            "     34       37.3047  0.0611\n",
            "     35       37.3047  0.0647\n",
            "     36       37.3047  0.0718\n",
            "     37       37.3047  0.0635\n",
            "     38       37.3047  0.0617\n",
            "     39       37.3047  0.0685\n",
            "     40       37.3047  0.0620\n",
            "     41       37.3047  0.0630\n",
            "     42       37.3047  0.0641\n",
            "     43       37.3047  0.0625\n",
            "     44       37.3047  0.0627\n",
            "     45       37.3047  0.0613\n",
            "     46       37.3047  0.0728\n",
            "     47       37.3047  0.0641\n",
            "     48       37.3047  0.0633\n",
            "     49       37.3047  0.0629\n",
            "     50       37.3047  0.0732\n",
            "     51       37.3047  0.0634\n",
            "     52       37.3047  0.0636\n",
            "     53       37.3047  0.0652\n",
            "     54       37.3047  0.0640\n",
            "     55       37.3047  0.0609\n",
            "     56       37.3047  0.0659\n",
            "     57       37.3047  0.0684\n",
            "     58       37.3047  0.0700\n",
            "     59       37.3047  0.0629\n",
            "     60       37.3047  0.0611\n",
            "     61       37.3047  0.0733\n",
            "     62       37.3047  0.0616\n",
            "     63       37.3047  0.0627\n",
            "     64       37.3047  0.0637\n",
            "     65       37.3047  0.0658\n",
            "     66       37.3047  0.0635\n",
            "     67       37.3047  0.0648\n",
            "     68       37.3047  0.0684\n",
            "     69       37.3047  0.0653\n",
            "     70       37.3047  0.0627\n",
            "     71       37.3047  0.0630\n",
            "     72       37.3047  0.0649\n",
            "     73       37.3047  0.0649\n",
            "     74       37.3047  0.0612\n",
            "     75       37.3047  0.0612\n",
            "     76       37.3047  0.0734\n",
            "     77       37.3047  0.0641\n",
            "     78       37.3047  0.0606\n",
            "     79       37.3047  0.0621\n",
            "     80       37.3047  0.0642\n",
            "     81       37.3047  0.0689\n",
            "     82       37.3047  0.0591\n",
            "     83       37.3047  0.0639\n",
            "     84       37.3047  0.0646\n",
            "     85       37.3047  0.0627\n",
            "     86       37.3047  0.0613\n",
            "     87       37.3047  0.0655\n",
            "     88       37.3047  0.0646\n",
            "     89       37.3047  0.0674\n",
            "     90       37.3047  0.0646\n",
            "     91       37.3047  0.0715\n",
            "     92       37.3047  0.0666\n",
            "     93       37.3047  0.0622\n",
            "     94       37.3047  0.0639\n",
            "     95       37.3047  0.0703\n",
            "     96       37.3047  0.0686\n",
            "     97       37.3047  0.0628\n",
            "     98       37.3047  0.0634\n",
            "     99       37.3047  0.0625\n",
            "    100       37.3047  0.0604\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m62.5000\u001b[0m  0.0624\n",
            "      2       62.5000  0.0657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       62.5000  0.0673\n",
            "      4       62.5000  0.0769\n",
            "      5       62.5000  0.0657\n",
            "      6       62.5000  0.0671\n",
            "      7       62.5000  0.0625\n",
            "      8       62.5000  0.0605\n",
            "      9       62.5000  0.0594\n",
            "     10       62.5000  0.0600\n",
            "     11       62.5000  0.0695\n",
            "     12       62.5000  0.0607\n",
            "     13       62.5000  0.0690\n",
            "     14       62.5000  0.0604\n",
            "     15       62.5000  0.0677\n",
            "     16       62.5000  0.0635\n",
            "     17       62.5000  0.0608\n",
            "     18       62.5000  0.0594\n",
            "     19       62.5000  0.0629\n",
            "     20       62.5000  0.0604\n",
            "     21       62.5000  0.0632\n",
            "     22       62.5000  0.0692\n",
            "     23       62.5000  0.0609\n",
            "     24       62.5000  0.0605\n",
            "     25       62.5000  0.0602\n",
            "     26       62.5000  0.0686\n",
            "     27       62.5000  0.0672\n",
            "     28       62.5000  0.0625\n",
            "     29       62.5000  0.0628\n",
            "     30       62.5000  0.0635\n",
            "     31       62.5000  0.0682\n",
            "     32       62.5000  0.0653\n",
            "     33       62.5000  0.0622\n",
            "     34       62.5000  0.0629\n",
            "     35       62.5000  0.0639\n",
            "     36       62.5000  0.0640\n",
            "     37       62.5000  0.0751\n",
            "     38       62.5000  0.0666\n",
            "     39       62.5000  0.0643\n",
            "     40       62.5000  0.0675\n",
            "     41       62.5000  0.0643\n",
            "     42       62.5000  0.0673\n",
            "     43       62.5000  0.0683\n",
            "     44       62.5000  0.0634\n",
            "     45       62.5000  0.0617\n",
            "     46       62.5000  0.0689\n",
            "     47       62.5000  0.0654\n",
            "     48       62.5000  0.0613\n",
            "     49       62.5000  0.0670\n",
            "     50       62.5000  0.0618\n",
            "     51       62.5000  0.0634\n",
            "     52       62.5000  0.0693\n",
            "     53       62.5000  0.0616\n",
            "     54       62.5000  0.0622\n",
            "     55       62.5000  0.0624\n",
            "     56       62.5000  0.0671\n",
            "     57       62.5000  0.0638\n",
            "     58       62.5000  0.0829\n",
            "     59       62.5000  0.0682\n",
            "     60       62.5000  0.0643\n",
            "     61       62.5000  0.0669\n",
            "     62       62.5000  0.0623\n",
            "     63       62.5000  0.0667\n",
            "     64       62.5000  0.0627\n",
            "     65       62.5000  0.0613\n",
            "     66       62.5000  0.0630\n",
            "     67       62.5000  0.0738\n",
            "     68       62.5000  0.0626\n",
            "     69       62.5000  0.0678\n",
            "     70       62.5000  0.0613\n",
            "     71       62.5000  0.0740\n",
            "     72       62.5000  0.0633\n",
            "     73       62.5000  0.0641\n",
            "     74       62.5000  0.0639\n",
            "     75       62.5000  0.0663\n",
            "     76       62.5000  0.0645\n",
            "     77       62.5000  0.0618\n",
            "     78       62.5000  0.0646\n",
            "     79       62.5000  0.0636\n",
            "     80       62.5000  0.0694\n",
            "     81       62.5000  0.0605\n",
            "     82       62.5000  0.0706\n",
            "     83       62.5000  0.0624\n",
            "     84       62.5000  0.0742\n",
            "     85       62.5000  0.0656\n",
            "     86       62.5000  0.0641\n",
            "     87       62.5000  0.0697\n",
            "     88       62.5000  0.0630\n",
            "     89       62.5000  0.0645\n",
            "     90       62.5000  0.0612\n",
            "     91       62.5000  0.0667\n",
            "     92       62.5000  0.0647\n",
            "     93       62.5000  0.0621\n",
            "     94       62.5000  0.0619\n",
            "     95       62.5000  0.0639\n",
            "     96       62.5000  0.0658\n",
            "     97       62.5000  0.0685\n",
            "     98       62.5000  0.0620\n",
            "     99       62.5000  0.0685\n",
            "    100       62.5000  0.0634\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m59.5703\u001b[0m  0.0590\n",
            "      2       59.5703  0.0662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       59.5703  0.0773\n",
            "      4       59.5703  0.0684\n",
            "      5       59.5703  0.0666\n",
            "      6       59.5703  0.0645\n",
            "      7       59.5703  0.0612\n",
            "      8       59.5703  0.0619\n",
            "      9       59.5703  0.0690\n",
            "     10       59.5703  0.0624\n",
            "     11       59.5703  0.0636\n",
            "     12       59.5703  0.0771\n",
            "     13       59.5703  0.0605\n",
            "     14       59.5703  0.0609\n",
            "     15       59.5703  0.0634\n",
            "     16       59.5703  0.0684\n",
            "     17       59.5703  0.0660\n",
            "     18       59.5703  0.0672\n",
            "     19       59.5703  0.0620\n",
            "     20       59.5703  0.0650\n",
            "     21       59.5703  0.0641\n",
            "     22       59.5703  0.0624\n",
            "     23       59.5703  0.0614\n",
            "     24       59.5703  0.0621\n",
            "     25       59.5703  0.0669\n",
            "     26       59.5703  0.0634\n",
            "     27       59.5703  0.0666\n",
            "     28       59.5703  0.0658\n",
            "     29       59.5703  0.0766\n",
            "     30       59.5703  0.0649\n",
            "     31       59.5703  0.0661\n",
            "     32       59.5703  0.0628\n",
            "     33       59.5703  0.0624\n",
            "     34       59.5703  0.0634\n",
            "     35       59.5703  0.0627\n",
            "     36       59.5703  0.0634\n",
            "     37       59.5703  0.0598\n",
            "     38       59.5703  0.0670\n",
            "     39       59.5703  0.0602\n",
            "     40       59.5703  0.0650\n",
            "     41       59.5703  0.0630\n",
            "     42       59.5703  0.0624\n",
            "     43       59.5703  0.0737\n",
            "     44       59.5703  0.0642\n",
            "     45       59.5703  0.0632\n",
            "     46       59.5703  0.0618\n",
            "     47       59.5703  0.0631\n",
            "     48       59.5703  0.0671\n",
            "     49       59.5703  0.0733\n",
            "     50       59.5703  0.0672\n",
            "     51       59.5703  0.0635\n",
            "     52       59.5703  0.0646\n",
            "     53       59.5703  0.0617\n",
            "     54       59.5703  0.0614\n",
            "     55       59.5703  0.0623\n",
            "     56       59.5703  0.0642\n",
            "     57       59.5703  0.0621\n",
            "     58       59.5703  0.0713\n",
            "     59       59.5703  0.0658\n",
            "     60       59.5703  0.0632\n",
            "     61       59.5703  0.0694\n",
            "     62       59.5703  0.0688\n",
            "     63       59.5703  0.0663\n",
            "     64       59.5703  0.0633\n",
            "     65       59.5703  0.0844\n",
            "     66       59.5703  0.0628\n",
            "     67       59.5703  0.0656\n",
            "     68       59.5703  0.0603\n",
            "     69       59.5703  0.0628\n",
            "     70       59.5703  0.0689\n",
            "     71       59.5703  0.0638\n",
            "     72       59.5703  0.0636\n",
            "     73       59.5703  0.0706\n",
            "     74       59.5703  0.0745\n",
            "     75       59.5703  0.0650\n",
            "     76       59.5703  0.0676\n",
            "     77       59.5703  0.0623\n",
            "     78       59.5703  0.0632\n",
            "     79       59.5703  0.0654\n",
            "     80       59.5703  0.0723\n",
            "     81       59.5703  0.0631\n",
            "     82       59.5703  0.0616\n",
            "     83       59.5703  0.0630\n",
            "     84       59.5703  0.0633\n",
            "     85       59.5703  0.0646\n",
            "     86       59.5703  0.0682\n",
            "     87       59.5703  0.0649\n",
            "     88       59.5703  0.0754\n",
            "     89       59.5703  0.0650\n",
            "     90       59.5703  0.0674\n",
            "     91       59.5703  0.0648\n",
            "     92       59.5703  0.0640\n",
            "     93       59.5703  0.0630\n",
            "     94       59.5703  0.0663\n",
            "     95       59.5703  0.0647\n",
            "     96       59.5703  0.0683\n",
            "     97       59.5703  0.0641\n",
            "     98       59.5703  0.0678\n",
            "     99       59.5703  0.0669\n",
            "    100       59.5703  0.0643\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m39.4531\u001b[0m  0.0565\n",
            "      2       39.4531  0.0656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       39.4531  0.0758\n",
            "      4       39.4531  0.0728\n",
            "      5       39.4531  0.0704\n",
            "      6       39.4531  0.0626\n",
            "      7       39.4531  0.0643\n",
            "      8       39.4531  0.0699\n",
            "      9       39.4531  0.0690\n",
            "     10       39.4531  0.0613\n",
            "     11       39.4531  0.0650\n",
            "     12       39.4531  0.0621\n",
            "     13       39.4531  0.0655\n",
            "     14       39.4531  0.0617\n",
            "     15       39.4531  0.0668\n",
            "     16       39.4531  0.0633\n",
            "     17       39.4531  0.0654\n",
            "     18       39.4531  0.0775\n",
            "     19       39.4531  0.0640\n",
            "     20       39.4531  0.0676\n",
            "     21       39.4531  0.0684\n",
            "     22       39.4531  0.0678\n",
            "     23       39.4531  0.0651\n",
            "     24       39.4531  0.0658\n",
            "     25       39.4531  0.0627\n",
            "     26       39.4531  0.0649\n",
            "     27       39.4531  0.0616\n",
            "     28       39.4531  0.0608\n",
            "     29       39.4531  0.0683\n",
            "     30       39.4531  0.0606\n",
            "     31       39.4531  0.0621\n",
            "     32       39.4531  0.0770\n",
            "     33       39.4531  0.0707\n",
            "     34       39.4531  0.0642\n",
            "     35       39.4531  0.0663\n",
            "     36       39.4531  0.0642\n",
            "     37       39.4531  0.0672\n",
            "     38       39.4531  0.0643\n",
            "     39       39.4531  0.0648\n",
            "     40       39.4531  0.0616\n",
            "     41       39.4531  0.0646\n",
            "     42       39.4531  0.0604\n",
            "     43       39.4531  0.0632\n",
            "     44       39.4531  0.0629\n",
            "     45       39.4531  0.0638\n",
            "     46       39.4531  0.0617\n",
            "     47       39.4531  0.0632\n",
            "     48       39.4531  0.0705\n",
            "     49       39.4531  0.0648\n",
            "     50       39.4531  0.0729\n",
            "     51       39.4531  0.0654\n",
            "     52       39.4531  0.0641\n",
            "     53       39.4531  0.0751\n",
            "     54       39.4531  0.0638\n",
            "     55       39.4531  0.0622\n",
            "     56       39.4531  0.0615\n",
            "     57       39.4531  0.0635\n",
            "     58       39.4531  0.0626\n",
            "     59       39.4531  0.0627\n",
            "     60       39.4531  0.0636\n",
            "     61       39.4531  0.0614\n",
            "     62       39.4531  0.0630\n",
            "     63       39.4531  0.0786\n",
            "     64       39.4531  0.0687\n",
            "     65       39.4531  0.0633\n",
            "     66       39.4531  0.0643\n",
            "     67       39.4531  0.0646\n",
            "     68       39.4531  0.0669\n",
            "     69       39.4531  0.0617\n",
            "     70       39.4531  0.0603\n",
            "     71       39.4531  0.0628\n",
            "     72       39.4531  0.0650\n",
            "     73       39.4531  0.0619\n",
            "     74       39.4531  0.0625\n",
            "     75       39.4531  0.0609\n",
            "     76       39.4531  0.0639\n",
            "     77       39.4531  0.0707\n",
            "     78       39.4531  0.0624\n",
            "     79       39.4531  0.0771\n",
            "     80       39.4531  0.0646\n",
            "     81       39.4531  0.0629\n",
            "     82       39.4531  0.0686\n",
            "     83       39.4531  0.0618\n",
            "     84       39.4531  0.0619\n",
            "     85       39.4531  0.0640\n",
            "     86       39.4531  0.0617\n",
            "     87       39.4531  0.0617\n",
            "     88       39.4531  0.0623\n",
            "     89       39.4531  0.0685\n",
            "     90       39.4531  0.0684\n",
            "     91       39.4531  0.0644\n",
            "     92       39.4531  0.0621\n",
            "     93       39.4531  0.0625\n",
            "     94       39.4531  0.0713\n",
            "     95       39.4531  0.0636\n",
            "     96       39.4531  0.0633\n",
            "     97       39.4531  0.0658\n",
            "     98       39.4531  0.0682\n",
            "     99       39.4531  0.0636\n",
            "    100       39.4531  0.0636\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m60.5469\u001b[0m  0.0561\n",
            "      2       60.5469  0.0664\n",
            "      3       60.5469  0.0645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       60.5469  0.0763\n",
            "      5       60.5469  0.0631\n",
            "      6       60.5469  0.0625\n",
            "      7       60.5469  0.0631\n",
            "      8       60.5469  0.0703\n",
            "      9       60.5469  0.0727\n",
            "     10       60.5469  0.0624\n",
            "     11       60.5469  0.0621\n",
            "     12       60.5469  0.0675\n",
            "     13       60.5469  0.0604\n",
            "     14       60.5469  0.0623\n",
            "     15       60.5469  0.0608\n",
            "     16       60.5469  0.0617\n",
            "     17       60.5469  0.0646\n",
            "     18       60.5469  0.0636\n",
            "     19       60.5469  0.0627\n",
            "     20       60.5469  0.0661\n",
            "     21       60.5469  0.0647\n",
            "     22       60.5469  0.0699\n",
            "     23       60.5469  0.0668\n",
            "     24       60.5469  0.0701\n",
            "     25       60.5469  0.0629\n",
            "     26       60.5469  0.0648\n",
            "     27       60.5469  0.0670\n",
            "     28       60.5469  0.0642\n",
            "     29       60.5469  0.0653\n",
            "     30       60.5469  0.0778\n",
            "     31       60.5469  0.0714\n",
            "     32       60.5469  0.0656\n",
            "     33       60.5469  0.0635\n",
            "     34       60.5469  0.0628\n",
            "     35       60.5469  0.0715\n",
            "     36       60.5469  0.0634\n",
            "     37       60.5469  0.0644\n",
            "     38       60.5469  0.0653\n",
            "     39       60.5469  0.0703\n",
            "     40       60.5469  0.0683\n",
            "     41       60.5469  0.0695\n",
            "     42       60.5469  0.0623\n",
            "     43       60.5469  0.0622\n",
            "     44       60.5469  0.0649\n",
            "     45       60.5469  0.0617\n",
            "     46       60.5469  0.0639\n",
            "     47       60.5469  0.0642\n",
            "     48       60.5469  0.0660\n",
            "     49       60.5469  0.0632\n",
            "     50       60.5469  0.0626\n",
            "     51       60.5469  0.0673\n",
            "     52       60.5469  0.0640\n",
            "     53       60.5469  0.0700\n",
            "     54       60.5469  0.0686\n",
            "     55       60.5469  0.0727\n",
            "     56       60.5469  0.0684\n",
            "     57       60.5469  0.0646\n",
            "     58       60.5469  0.0640\n",
            "     59       60.5469  0.0644\n",
            "     60       60.5469  0.0629\n",
            "     61       60.5469  0.0674\n",
            "     62       60.5469  0.0649\n",
            "     63       60.5469  0.0657\n",
            "     64       60.5469  0.0643\n",
            "     65       60.5469  0.0620\n",
            "     66       60.5469  0.0717\n",
            "     67       60.5469  0.0614\n",
            "     68       60.5469  0.0646\n",
            "     69       60.5469  0.0685\n",
            "     70       60.5469  0.0660\n",
            "     71       60.5469  0.0638\n",
            "     72       60.5469  0.0625\n",
            "     73       60.5469  0.0639\n",
            "     74       60.5469  0.0662\n",
            "     75       60.5469  0.0615\n",
            "     76       60.5469  0.0645\n",
            "     77       60.5469  0.0655\n",
            "     78       60.5469  0.0640\n",
            "     79       60.5469  0.0639\n",
            "     80       60.5469  0.0663\n",
            "     81       60.5469  0.0658\n",
            "     82       60.5469  0.0625\n",
            "     83       60.5469  0.0612\n",
            "     84       60.5469  0.0744\n",
            "     85       60.5469  0.0673\n",
            "     86       60.5469  0.0637\n",
            "     87       60.5469  0.0620\n",
            "     88       60.5469  0.0640\n",
            "     89       60.5469  0.0600\n",
            "     90       60.5469  0.0616\n",
            "     91       60.5469  0.0604\n",
            "     92       60.5469  0.0650\n",
            "     93       60.5469  0.0615\n",
            "     94       60.5469  0.0610\n",
            "     95       60.5469  0.0625\n",
            "     96       60.5469  0.0653\n",
            "     97       60.5469  0.0688\n",
            "     98       60.5469  0.0668\n",
            "     99       60.5469  0.0611\n",
            "    100       60.5469  0.0720\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m52.9297\u001b[0m  0.0591\n",
            "      2       52.9297  0.0631\n",
            "      3       52.9297  0.0650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4       52.9297  0.0703\n",
            "      5       52.9297  0.0604\n",
            "      6       52.9297  0.0633\n",
            "      7       52.9297  0.0663\n",
            "      8       52.9297  0.0686\n",
            "      9       52.9297  0.0618\n",
            "     10       52.9297  0.0622\n",
            "     11       52.9297  0.0754\n",
            "     12       52.9297  0.0638\n",
            "     13       52.9297  0.0677\n",
            "     14       52.9297  0.0618\n",
            "     15       52.9297  0.0735\n",
            "     16       52.9297  0.0643\n",
            "     17       52.9297  0.0615\n",
            "     18       52.9297  0.0634\n",
            "     19       52.9297  0.0632\n",
            "     20       52.9297  0.0620\n",
            "     21       52.9297  0.0630\n",
            "     22       52.9297  0.0606\n",
            "     23       52.9297  0.0622\n",
            "     24       52.9297  0.0620\n",
            "     25       52.9297  0.0710\n",
            "     26       52.9297  0.0646\n",
            "     27       52.9297  0.0621\n",
            "     28       52.9297  0.0639\n",
            "     29       52.9297  0.0668\n",
            "     30       52.9297  0.0749\n",
            "     31       52.9297  0.0629\n",
            "     32       52.9297  0.0677\n",
            "     33       52.9297  0.0625\n",
            "     34       52.9297  0.0626\n",
            "     35       52.9297  0.0627\n",
            "     36       52.9297  0.0620\n",
            "     37       52.9297  0.0629\n",
            "     38       52.9297  0.0707\n",
            "     39       52.9297  0.0630\n",
            "     40       52.9297  0.0661\n",
            "     41       52.9297  0.0693\n",
            "     42       52.9297  0.0633\n",
            "     43       52.9297  0.0670\n",
            "     44       52.9297  0.0634\n",
            "     45       52.9297  0.0734\n",
            "     46       52.9297  0.0620\n",
            "     47       52.9297  0.0621\n",
            "     48       52.9297  0.0621\n",
            "     49       52.9297  0.0648\n",
            "     50       52.9297  0.0620\n",
            "     51       52.9297  0.0607\n",
            "     52       52.9297  0.0690\n",
            "     53       52.9297  0.0619\n",
            "     54       52.9297  0.0627\n",
            "     55       52.9297  0.0642\n",
            "     56       52.9297  0.0674\n",
            "     57       52.9297  0.0635\n",
            "     58       52.9297  0.0664\n",
            "     59       52.9297  0.0651\n",
            "     60       52.9297  0.0690\n",
            "     61       52.9297  0.0703\n",
            "     62       52.9297  0.0636\n",
            "     63       52.9297  0.0644\n",
            "     64       52.9297  0.0614\n",
            "     65       52.9297  0.0621\n",
            "     66       52.9297  0.0666\n",
            "     67       52.9297  0.0627\n",
            "     68       52.9297  0.0604\n",
            "     69       52.9297  0.0644\n",
            "     70       52.9297  0.0750\n",
            "     71       52.9297  0.0652\n",
            "     72       52.9297  0.0679\n",
            "     73       52.9297  0.0627\n",
            "     74       52.9297  0.0663\n",
            "     75       52.9297  0.0650\n",
            "     76       52.9297  0.0717\n",
            "     77       52.9297  0.0658\n",
            "     78       52.9297  0.0619\n",
            "     79       52.9297  0.0625\n",
            "     80       52.9297  0.0695\n",
            "     81       52.9297  0.0642\n",
            "     82       52.9297  0.0635\n",
            "     83       52.9297  0.0747\n",
            "     84       52.9297  0.0658\n",
            "     85       52.9297  0.0637\n",
            "     86       52.9297  0.0636\n",
            "     87       52.9297  0.0649\n",
            "     88       52.9297  0.0805\n",
            "     89       52.9297  0.0666\n",
            "     90       52.9297  0.0656\n",
            "     91       52.9297  0.0740\n",
            "     92       52.9297  0.0638\n",
            "     93       52.9297  0.0649\n",
            "     94       52.9297  0.0611\n",
            "     95       52.9297  0.0612\n",
            "     96       52.9297  0.0639\n",
            "     97       52.9297  0.0653\n",
            "     98       52.9297  0.0609\n",
            "     99       52.9297  0.0655\n",
            "    100       52.9297  0.0610\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m60.2339\u001b[0m  0.0666\n",
            "      2       60.2339  0.0724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       60.2339  0.0711\n",
            "      4       60.2339  0.0711\n",
            "      5       60.2339  0.0616\n",
            "      6       60.2339  0.0738\n",
            "      7       60.2339  0.0636\n",
            "      8       60.2339  0.0623\n",
            "      9       60.2339  0.0621\n",
            "     10       60.2339  0.0658\n",
            "     11       60.2339  0.0726\n",
            "     12       60.2339  0.0635\n",
            "     13       60.2339  0.0694\n",
            "     14       60.2339  0.0720\n",
            "     15       60.2339  0.0641\n",
            "     16       60.2339  0.0630\n",
            "     17       60.2339  0.0643\n",
            "     18       60.2339  0.0615\n",
            "     19       60.2339  0.0677\n",
            "     20       60.2339  0.0625\n",
            "     21       60.2339  0.0703\n",
            "     22       60.2339  0.0668\n",
            "     23       60.2339  0.0625\n",
            "     24       60.2339  0.0687\n",
            "     25       60.2339  0.0634\n",
            "     26       60.2339  0.0624\n",
            "     27       60.2339  0.0690\n",
            "     28       60.2339  0.0657\n",
            "     29       60.2339  0.0618\n",
            "     30       60.2339  0.0627\n",
            "     31       60.2339  0.0648\n",
            "     32       60.2339  0.0648\n",
            "     33       60.2339  0.0646\n",
            "     34       60.2339  0.0655\n",
            "     35       60.2339  0.0641\n",
            "     36       60.2339  0.0710\n",
            "     37       60.2339  0.0686\n",
            "     38       60.2339  0.0642\n",
            "     39       60.2339  0.0629\n",
            "     40       60.2339  0.0629\n",
            "     41       60.2339  0.0668\n",
            "     42       60.2339  0.0615\n",
            "     43       60.2339  0.0635\n",
            "     44       60.2339  0.0688\n",
            "     45       60.2339  0.0696\n",
            "     46       60.2339  0.0655\n",
            "     47       60.2339  0.0646\n",
            "     48       60.2339  0.0704\n",
            "     49       60.2339  0.0653\n",
            "     50       60.2339  0.0640\n",
            "     51       60.2339  0.0716\n",
            "     52       60.2339  0.0632\n",
            "     53       60.2339  0.0650\n",
            "     54       60.2339  0.0667\n",
            "     55       60.2339  0.0635\n",
            "     56       60.2339  0.0634\n",
            "     57       60.2339  0.0634\n",
            "     58       60.2339  0.0814\n",
            "     59       60.2339  0.0617\n",
            "     60       60.2339  0.0649\n",
            "     61       60.2339  0.0653\n",
            "     62       60.2339  0.0631\n",
            "     63       60.2339  0.0648\n",
            "     64       60.2339  0.0726\n",
            "     65       60.2339  0.0615\n",
            "     66       60.2339  0.0680\n",
            "     67       60.2339  0.0635\n",
            "     68       60.2339  0.0686\n",
            "     69       60.2339  0.0612\n",
            "     70       60.2339  0.0631\n",
            "     71       60.2339  0.0608\n",
            "     72       60.2339  0.0695\n",
            "     73       60.2339  0.0604\n",
            "     74       60.2339  0.0659\n",
            "     75       60.2339  0.0625\n",
            "     76       60.2339  0.0679\n",
            "     77       60.2339  0.0634\n",
            "     78       60.2339  0.0689\n",
            "     79       60.2339  0.0609\n",
            "     80       60.2339  0.0703\n",
            "     81       60.2339  0.0708\n",
            "     82       60.2339  0.0617\n",
            "     83       60.2339  0.0640\n",
            "     84       60.2339  0.0633\n",
            "     85       60.2339  0.0636\n",
            "     86       60.2339  0.0646\n",
            "     87       60.2339  0.0688\n",
            "     88       60.2339  0.0622\n",
            "     89       60.2339  0.0703\n",
            "     90       60.2339  0.0696\n",
            "     91       60.2339  0.0683\n",
            "     92       60.2339  0.0644\n",
            "     93       60.2339  0.0652\n",
            "     94       60.2339  0.0610\n",
            "     95       60.2339  0.0630\n",
            "     96       60.2339  0.0704\n",
            "     97       60.2339  0.0704\n",
            "     98       60.2339  0.0622\n",
            "     99       60.2339  0.0638\n",
            "    100       60.2339  0.0619\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.6758\u001b[0m  0.0737\n",
            "      2        \u001b[36m1.5530\u001b[0m  0.0816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.4164\u001b[0m  0.0925\n",
            "      4        \u001b[36m1.2397\u001b[0m  0.0769\n",
            "      5        \u001b[36m0.9554\u001b[0m  0.0842\n",
            "      6        \u001b[36m0.7228\u001b[0m  0.0818\n",
            "      7        \u001b[36m0.6756\u001b[0m  0.0849\n",
            "      8        \u001b[36m0.6708\u001b[0m  0.0784\n",
            "      9        \u001b[36m0.6697\u001b[0m  0.0862\n",
            "     10        \u001b[36m0.6690\u001b[0m  0.0800\n",
            "     11        \u001b[36m0.6686\u001b[0m  0.0794\n",
            "     12        \u001b[36m0.6683\u001b[0m  0.0810\n",
            "     13        \u001b[36m0.6681\u001b[0m  0.0862\n",
            "     14        \u001b[36m0.6679\u001b[0m  0.0861\n",
            "     15        \u001b[36m0.6678\u001b[0m  0.0843\n",
            "     16        \u001b[36m0.6677\u001b[0m  0.0774\n",
            "     17        \u001b[36m0.6676\u001b[0m  0.0783\n",
            "     18        \u001b[36m0.6675\u001b[0m  0.0798\n",
            "     19        \u001b[36m0.6674\u001b[0m  0.0767\n",
            "     20        \u001b[36m0.6674\u001b[0m  0.0765\n",
            "     21        \u001b[36m0.6673\u001b[0m  0.0858\n",
            "     22        0.6677  0.0771\n",
            "     23        \u001b[36m0.6672\u001b[0m  0.0760\n",
            "     24        \u001b[36m0.6672\u001b[0m  0.0843\n",
            "     25        \u001b[36m0.6671\u001b[0m  0.0755\n",
            "     26        0.6672  0.0758\n",
            "     27        0.6673  0.0781\n",
            "     28        \u001b[36m0.6666\u001b[0m  0.0758\n",
            "     29        \u001b[36m0.6519\u001b[0m  0.0853\n",
            "     30        0.6906  0.0800\n",
            "     31        0.6731  0.0806\n",
            "     32        0.6699  0.0773\n",
            "     33        0.6691  0.0779\n",
            "     34        0.6659  0.0821\n",
            "     35        0.6687  0.0767\n",
            "     36        0.6672  0.0809\n",
            "     37        0.6668  0.0914\n",
            "     38        0.6666  0.0790\n",
            "     39        0.6664  0.0919\n",
            "     40        0.6663  0.0844\n",
            "     41        0.6663  0.0787\n",
            "     42        0.6662  0.0810\n",
            "     43        0.6661  0.0802\n",
            "     44        0.6661  0.0776\n",
            "     45        0.6660  0.0785\n",
            "     46        0.6660  0.0848\n",
            "     47        0.6659  0.0833\n",
            "     48        0.6659  0.0791\n",
            "     49        0.6658  0.0780\n",
            "     50        0.6658  0.0895\n",
            "     51        0.6658  0.0802\n",
            "     52        0.6657  0.0781\n",
            "     53        0.6657  0.0829\n",
            "     54        0.6657  0.0861\n",
            "     55        0.6656  0.0802\n",
            "     56        0.6656  0.0789\n",
            "     57        0.6656  0.0793\n",
            "     58        0.6656  0.0851\n",
            "     59        0.6655  0.0783\n",
            "     60        0.6655  0.0891\n",
            "     61        0.6655  0.0797\n",
            "     62        0.6655  0.0795\n",
            "     63        0.6654  0.0806\n",
            "     64        0.6654  0.0808\n",
            "     65        0.6654  0.0852\n",
            "     66        0.6654  0.0883\n",
            "     67        0.6653  0.0828\n",
            "     68        0.6653  0.0805\n",
            "     69        0.6653  0.0804\n",
            "     70        0.6653  0.0883\n",
            "     71        0.6653  0.0813\n",
            "     72        0.6652  0.0845\n",
            "     73        0.6652  0.0816\n",
            "     74        0.6652  0.0943\n",
            "     75        0.6652  0.0831\n",
            "     76        0.6651  0.0805\n",
            "     77        0.6651  0.0814\n",
            "     78        0.6651  0.0810\n",
            "     79        0.6649  0.0774\n",
            "     80        0.6649  0.0757\n",
            "     81        0.6649  0.0814\n",
            "     82        0.6649  0.0863\n",
            "     83        0.6648  0.0829\n",
            "     84        0.6648  0.0792\n",
            "     85        0.6648  0.0844\n",
            "     86        0.6648  0.0806\n",
            "     87        0.6647  0.0780\n",
            "     88        0.6647  0.0821\n",
            "     89        0.6647  0.0892\n",
            "     90        0.6647  0.0788\n",
            "     91        0.6647  0.0806\n",
            "     92        0.6646  0.0780\n",
            "     93        0.6646  0.0784\n",
            "     94        0.6646  0.0850\n",
            "     95        0.6646  0.0808\n",
            "     96        0.6646  0.0842\n",
            "     97        0.6645  0.0830\n",
            "     98        0.6645  0.0833\n",
            "     99        0.6645  0.0841\n",
            "    100        0.6645  0.0796\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.6630\u001b[0m  0.0743\n",
            "      2        \u001b[36m1.5092\u001b[0m  0.0826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.2960\u001b[0m  0.0912\n",
            "      4        \u001b[36m0.9866\u001b[0m  0.0768\n",
            "      5        \u001b[36m0.7385\u001b[0m  0.0819\n",
            "      6        \u001b[36m0.6779\u001b[0m  0.0861\n",
            "      7        \u001b[36m0.6710\u001b[0m  0.0777\n",
            "      8        \u001b[36m0.6698\u001b[0m  0.0750\n",
            "      9        \u001b[36m0.6692\u001b[0m  0.0752\n",
            "     10        \u001b[36m0.6688\u001b[0m  0.0855\n",
            "     11        \u001b[36m0.6686\u001b[0m  0.0833\n",
            "     12        \u001b[36m0.6684\u001b[0m  0.0835\n",
            "     13        \u001b[36m0.6682\u001b[0m  0.0797\n",
            "     14        \u001b[36m0.6681\u001b[0m  0.0765\n",
            "     15        \u001b[36m0.6680\u001b[0m  0.0806\n",
            "     16        \u001b[36m0.6679\u001b[0m  0.0758\n",
            "     17        \u001b[36m0.6678\u001b[0m  0.0775\n",
            "     18        \u001b[36m0.6678\u001b[0m  0.0931\n",
            "     19        \u001b[36m0.6677\u001b[0m  0.0787\n",
            "     20        \u001b[36m0.6676\u001b[0m  0.0810\n",
            "     21        \u001b[36m0.6676\u001b[0m  0.0859\n",
            "     22        \u001b[36m0.6675\u001b[0m  0.0775\n",
            "     23        \u001b[36m0.6674\u001b[0m  0.0760\n",
            "     24        \u001b[36m0.6674\u001b[0m  0.0824\n",
            "     25        \u001b[36m0.6673\u001b[0m  0.0813\n",
            "     26        0.6684  0.0780\n",
            "     27        \u001b[36m0.6662\u001b[0m  0.0791\n",
            "     28        0.6691  0.0760\n",
            "     29        0.6713  0.0763\n",
            "     30        0.6697  0.0811\n",
            "     31        0.6688  0.0898\n",
            "     32        0.6684  0.0839\n",
            "     33        0.6680  0.0797\n",
            "     34        0.6676  0.0798\n",
            "     35        0.6674  0.0805\n",
            "     36        0.6671  0.0787\n",
            "     37        0.6669  0.0830\n",
            "     38        0.6666  0.0817\n",
            "     39        0.6663  0.0816\n",
            "     40        \u001b[36m0.6661\u001b[0m  0.0765\n",
            "     41        \u001b[36m0.6659\u001b[0m  0.0765\n",
            "     42        \u001b[36m0.6657\u001b[0m  0.0792\n",
            "     43        \u001b[36m0.6655\u001b[0m  0.0892\n",
            "     44        \u001b[36m0.6654\u001b[0m  0.0765\n",
            "     45        \u001b[36m0.6652\u001b[0m  0.0783\n",
            "     46        \u001b[36m0.6650\u001b[0m  0.0803\n",
            "     47        \u001b[36m0.6649\u001b[0m  0.0841\n",
            "     48        \u001b[36m0.6647\u001b[0m  0.0810\n",
            "     49        \u001b[36m0.6646\u001b[0m  0.0821\n",
            "     50        \u001b[36m0.6645\u001b[0m  0.0778\n",
            "     51        \u001b[36m0.6643\u001b[0m  0.0825\n",
            "     52        \u001b[36m0.6642\u001b[0m  0.0825\n",
            "     53        \u001b[36m0.6641\u001b[0m  0.0789\n",
            "     54        \u001b[36m0.6639\u001b[0m  0.0807\n",
            "     55        \u001b[36m0.6638\u001b[0m  0.0852\n",
            "     56        \u001b[36m0.6637\u001b[0m  0.0790\n",
            "     57        \u001b[36m0.6636\u001b[0m  0.0871\n",
            "     58        \u001b[36m0.6635\u001b[0m  0.0860\n",
            "     59        \u001b[36m0.6633\u001b[0m  0.0760\n",
            "     60        \u001b[36m0.6632\u001b[0m  0.0806\n",
            "     61        \u001b[36m0.6631\u001b[0m  0.0812\n",
            "     62        \u001b[36m0.6630\u001b[0m  0.0760\n",
            "     63        \u001b[36m0.6629\u001b[0m  0.0819\n",
            "     64        \u001b[36m0.6628\u001b[0m  0.1057\n",
            "     65        \u001b[36m0.6627\u001b[0m  0.0795\n",
            "     66        \u001b[36m0.6626\u001b[0m  0.0826\n",
            "     67        \u001b[36m0.6625\u001b[0m  0.0858\n",
            "     68        \u001b[36m0.6625\u001b[0m  0.0865\n",
            "     69        \u001b[36m0.6624\u001b[0m  0.0790\n",
            "     70        \u001b[36m0.6623\u001b[0m  0.0826\n",
            "     71        \u001b[36m0.6622\u001b[0m  0.0786\n",
            "     72        \u001b[36m0.6621\u001b[0m  0.0779\n",
            "     73        \u001b[36m0.6620\u001b[0m  0.0856\n",
            "     74        \u001b[36m0.6619\u001b[0m  0.0809\n",
            "     75        \u001b[36m0.6610\u001b[0m  0.0787\n",
            "     76        \u001b[36m0.6590\u001b[0m  0.0776\n",
            "     77        \u001b[36m0.6481\u001b[0m  0.0830\n",
            "     78        \u001b[36m0.6431\u001b[0m  0.0806\n",
            "     79        \u001b[36m0.6411\u001b[0m  0.0851\n",
            "     80        \u001b[36m0.6398\u001b[0m  0.0817\n",
            "     81        \u001b[36m0.6387\u001b[0m  0.0778\n",
            "     82        \u001b[36m0.6378\u001b[0m  0.0849\n",
            "     83        \u001b[36m0.6370\u001b[0m  0.0798\n",
            "     84        \u001b[36m0.6363\u001b[0m  0.0790\n",
            "     85        \u001b[36m0.6357\u001b[0m  0.0822\n",
            "     86        \u001b[36m0.6351\u001b[0m  0.0806\n",
            "     87        \u001b[36m0.6345\u001b[0m  0.0786\n",
            "     88        \u001b[36m0.6340\u001b[0m  0.0812\n",
            "     89        \u001b[36m0.6336\u001b[0m  0.0812\n",
            "     90        \u001b[36m0.6331\u001b[0m  0.0788\n",
            "     91        \u001b[36m0.6328\u001b[0m  0.0799\n",
            "     92        \u001b[36m0.6324\u001b[0m  0.0864\n",
            "     93        \u001b[36m0.6320\u001b[0m  0.0867\n",
            "     94        \u001b[36m0.6317\u001b[0m  0.0896\n",
            "     95        \u001b[36m0.6314\u001b[0m  0.0862\n",
            "     96        \u001b[36m0.6311\u001b[0m  0.0866\n",
            "     97        \u001b[36m0.6309\u001b[0m  0.0814\n",
            "     98        \u001b[36m0.6306\u001b[0m  0.0792\n",
            "     99        \u001b[36m0.6304\u001b[0m  0.0791\n",
            "    100        \u001b[36m0.6301\u001b[0m  0.0798\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.2769\u001b[0m  0.0754\n",
            "      2        \u001b[36m1.1692\u001b[0m  0.0781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.0581\u001b[0m  0.1090\n",
            "      4        \u001b[36m0.9361\u001b[0m  0.0853\n",
            "      5        \u001b[36m0.7909\u001b[0m  0.0790\n",
            "      6        \u001b[36m0.6967\u001b[0m  0.0773\n",
            "      7        \u001b[36m0.6738\u001b[0m  0.0786\n",
            "      8        \u001b[36m0.6698\u001b[0m  0.0831\n",
            "      9        \u001b[36m0.6687\u001b[0m  0.0777\n",
            "     10        \u001b[36m0.6682\u001b[0m  0.0780\n",
            "     11        \u001b[36m0.6679\u001b[0m  0.0882\n",
            "     12        \u001b[36m0.6676\u001b[0m  0.0779\n",
            "     13        \u001b[36m0.6675\u001b[0m  0.0809\n",
            "     14        \u001b[36m0.6674\u001b[0m  0.0855\n",
            "     15        \u001b[36m0.6673\u001b[0m  0.0887\n",
            "     16        \u001b[36m0.6672\u001b[0m  0.0789\n",
            "     17        \u001b[36m0.6671\u001b[0m  0.0786\n",
            "     18        \u001b[36m0.6670\u001b[0m  0.0769\n",
            "     19        \u001b[36m0.6670\u001b[0m  0.0868\n",
            "     20        \u001b[36m0.6669\u001b[0m  0.0792\n",
            "     21        \u001b[36m0.6669\u001b[0m  0.0755\n",
            "     22        \u001b[36m0.6669\u001b[0m  0.0748\n",
            "     23        \u001b[36m0.6668\u001b[0m  0.0803\n",
            "     24        \u001b[36m0.6668\u001b[0m  0.0797\n",
            "     25        \u001b[36m0.6668\u001b[0m  0.0782\n",
            "     26        \u001b[36m0.6667\u001b[0m  0.0776\n",
            "     27        \u001b[36m0.6667\u001b[0m  0.0814\n",
            "     28        \u001b[36m0.6667\u001b[0m  0.0895\n",
            "     29        \u001b[36m0.6666\u001b[0m  0.0870\n",
            "     30        0.6735  0.0775\n",
            "     31        \u001b[36m0.6661\u001b[0m  0.0788\n",
            "     32        0.6669  0.0790\n",
            "     33        0.6669  0.0764\n",
            "     34        0.6668  0.0783\n",
            "     35        0.6667  0.0790\n",
            "     36        0.6664  0.0762\n",
            "     37        \u001b[36m0.6635\u001b[0m  0.0819\n",
            "     38        0.6715  0.0766\n",
            "     39        0.6689  0.0787\n",
            "     40        0.6677  0.0901\n",
            "     41        0.6670  0.0789\n",
            "     42        0.6664  0.0802\n",
            "     43        0.6658  0.0820\n",
            "     44        0.6653  0.0814\n",
            "     45        0.6649  0.0825\n",
            "     46        0.6644  0.0809\n",
            "     47        0.6647  0.0795\n",
            "     48        0.6645  0.0778\n",
            "     49        0.6637  0.0763\n",
            "     50        \u001b[36m0.6619\u001b[0m  0.0809\n",
            "     51        0.6636  0.0841\n",
            "     52        0.6625  0.0808\n",
            "     53        0.6620  0.0922\n",
            "     54        \u001b[36m0.6616\u001b[0m  0.0798\n",
            "     55        \u001b[36m0.6613\u001b[0m  0.0777\n",
            "     56        \u001b[36m0.6610\u001b[0m  0.0831\n",
            "     57        \u001b[36m0.6607\u001b[0m  0.0803\n",
            "     58        \u001b[36m0.6605\u001b[0m  0.0821\n",
            "     59        \u001b[36m0.6603\u001b[0m  0.0805\n",
            "     60        \u001b[36m0.6600\u001b[0m  0.0790\n",
            "     61        \u001b[36m0.6598\u001b[0m  0.0771\n",
            "     62        \u001b[36m0.6596\u001b[0m  0.0817\n",
            "     63        \u001b[36m0.6594\u001b[0m  0.0832\n",
            "     64        \u001b[36m0.6592\u001b[0m  0.0797\n",
            "     65        \u001b[36m0.6590\u001b[0m  0.0898\n",
            "     66        \u001b[36m0.6588\u001b[0m  0.0869\n",
            "     67        \u001b[36m0.6586\u001b[0m  0.0784\n",
            "     68        \u001b[36m0.6583\u001b[0m  0.0859\n",
            "     69        \u001b[36m0.6581\u001b[0m  0.0791\n",
            "     70        \u001b[36m0.6579\u001b[0m  0.0786\n",
            "     71        \u001b[36m0.6577\u001b[0m  0.0811\n",
            "     72        \u001b[36m0.6575\u001b[0m  0.0875\n",
            "     73        \u001b[36m0.6573\u001b[0m  0.0823\n",
            "     74        \u001b[36m0.6571\u001b[0m  0.0792\n",
            "     75        \u001b[36m0.6570\u001b[0m  0.0793\n",
            "     76        \u001b[36m0.6568\u001b[0m  0.0878\n",
            "     77        \u001b[36m0.6566\u001b[0m  0.0904\n",
            "     78        \u001b[36m0.6564\u001b[0m  0.0808\n",
            "     79        \u001b[36m0.6562\u001b[0m  0.0826\n",
            "     80        \u001b[36m0.6560\u001b[0m  0.0786\n",
            "     81        \u001b[36m0.6558\u001b[0m  0.0767\n",
            "     82        \u001b[36m0.6556\u001b[0m  0.0869\n",
            "     83        \u001b[36m0.6554\u001b[0m  0.0781\n",
            "     84        \u001b[36m0.6553\u001b[0m  0.0783\n",
            "     85        \u001b[36m0.6551\u001b[0m  0.0792\n",
            "     86        \u001b[36m0.6549\u001b[0m  0.0817\n",
            "     87        \u001b[36m0.6547\u001b[0m  0.0903\n",
            "     88        \u001b[36m0.6546\u001b[0m  0.0787\n",
            "     89        \u001b[36m0.6544\u001b[0m  0.0900\n",
            "     90        \u001b[36m0.6542\u001b[0m  0.0869\n",
            "     91        \u001b[36m0.6541\u001b[0m  0.0807\n",
            "     92        \u001b[36m0.6539\u001b[0m  0.0948\n",
            "     93        \u001b[36m0.6537\u001b[0m  0.0805\n",
            "     94        \u001b[36m0.6536\u001b[0m  0.0802\n",
            "     95        \u001b[36m0.6534\u001b[0m  0.0773\n",
            "     96        \u001b[36m0.6533\u001b[0m  0.0773\n",
            "     97        \u001b[36m0.6531\u001b[0m  0.0820\n",
            "     98        \u001b[36m0.6530\u001b[0m  0.0816\n",
            "     99        \u001b[36m0.6528\u001b[0m  0.0808\n",
            "    100        \u001b[36m0.6527\u001b[0m  0.0772\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4918\u001b[0m  0.0861\n",
            "      2        \u001b[36m1.3740\u001b[0m  0.0812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.2482\u001b[0m  0.0904\n",
            "      4        \u001b[36m1.0985\u001b[0m  0.0778\n",
            "      5        \u001b[36m0.8868\u001b[0m  0.0763\n",
            "      6        \u001b[36m0.7161\u001b[0m  0.0787\n",
            "      7        \u001b[36m0.6751\u001b[0m  0.0767\n",
            "      8        \u001b[36m0.6699\u001b[0m  0.0784\n",
            "      9        \u001b[36m0.6688\u001b[0m  0.0766\n",
            "     10        \u001b[36m0.6683\u001b[0m  0.0865\n",
            "     11        \u001b[36m0.6679\u001b[0m  0.0769\n",
            "     12        \u001b[36m0.6677\u001b[0m  0.0859\n",
            "     13        \u001b[36m0.6675\u001b[0m  0.0872\n",
            "     14        \u001b[36m0.6674\u001b[0m  0.0821\n",
            "     15        \u001b[36m0.6673\u001b[0m  0.0822\n",
            "     16        \u001b[36m0.6672\u001b[0m  0.0768\n",
            "     17        \u001b[36m0.6671\u001b[0m  0.0815\n",
            "     18        \u001b[36m0.6670\u001b[0m  0.0825\n",
            "     19        \u001b[36m0.6670\u001b[0m  0.0760\n",
            "     20        \u001b[36m0.6669\u001b[0m  0.0771\n",
            "     21        \u001b[36m0.6669\u001b[0m  0.0765\n",
            "     22        \u001b[36m0.6668\u001b[0m  0.0816\n",
            "     23        \u001b[36m0.6668\u001b[0m  0.0859\n",
            "     24        \u001b[36m0.6668\u001b[0m  0.0784\n",
            "     25        \u001b[36m0.6667\u001b[0m  0.0900\n",
            "     26        \u001b[36m0.6667\u001b[0m  0.0804\n",
            "     27        \u001b[36m0.6667\u001b[0m  0.0802\n",
            "     28        \u001b[36m0.6666\u001b[0m  0.0796\n",
            "     29        \u001b[36m0.6666\u001b[0m  0.0738\n",
            "     30        \u001b[36m0.6666\u001b[0m  0.0763\n",
            "     31        \u001b[36m0.6666\u001b[0m  0.0753\n",
            "     32        \u001b[36m0.6665\u001b[0m  0.0771\n",
            "     33        \u001b[36m0.6665\u001b[0m  0.0804\n",
            "     34        \u001b[36m0.6665\u001b[0m  0.0813\n",
            "     35        \u001b[36m0.6664\u001b[0m  0.0766\n",
            "     36        0.6740  0.0850\n",
            "     37        0.6833  0.0821\n",
            "     38        0.6707  0.0853\n",
            "     39        0.6674  0.0853\n",
            "     40        0.6665  0.0793\n",
            "     41        \u001b[36m0.6661\u001b[0m  0.0761\n",
            "     42        \u001b[36m0.6660\u001b[0m  0.0772\n",
            "     43        \u001b[36m0.6659\u001b[0m  0.0775\n",
            "     44        \u001b[36m0.6658\u001b[0m  0.0843\n",
            "     45        \u001b[36m0.6657\u001b[0m  0.0768\n",
            "     46        \u001b[36m0.6657\u001b[0m  0.0779\n",
            "     47        \u001b[36m0.6657\u001b[0m  0.0762\n",
            "     48        \u001b[36m0.6656\u001b[0m  0.0844\n",
            "     49        \u001b[36m0.6656\u001b[0m  0.0778\n",
            "     50        \u001b[36m0.6655\u001b[0m  0.0852\n",
            "     51        \u001b[36m0.6655\u001b[0m  0.0822\n",
            "     52        \u001b[36m0.6655\u001b[0m  0.0783\n",
            "     53        \u001b[36m0.6655\u001b[0m  0.0803\n",
            "     54        \u001b[36m0.6654\u001b[0m  0.0764\n",
            "     55        \u001b[36m0.6654\u001b[0m  0.0800\n",
            "     56        \u001b[36m0.6654\u001b[0m  0.0791\n",
            "     57        \u001b[36m0.6654\u001b[0m  0.0756\n",
            "     58        \u001b[36m0.6653\u001b[0m  0.0768\n",
            "     59        \u001b[36m0.6653\u001b[0m  0.0746\n",
            "     60        \u001b[36m0.6653\u001b[0m  0.0801\n",
            "     61        \u001b[36m0.6653\u001b[0m  0.0790\n",
            "     62        \u001b[36m0.6653\u001b[0m  0.0794\n",
            "     63        \u001b[36m0.6652\u001b[0m  0.0913\n",
            "     64        \u001b[36m0.6652\u001b[0m  0.0814\n",
            "     65        \u001b[36m0.6652\u001b[0m  0.0786\n",
            "     66        \u001b[36m0.6652\u001b[0m  0.0788\n",
            "     67        \u001b[36m0.6652\u001b[0m  0.0812\n",
            "     68        \u001b[36m0.6652\u001b[0m  0.0787\n",
            "     69        \u001b[36m0.6652\u001b[0m  0.0794\n",
            "     70        \u001b[36m0.6651\u001b[0m  0.0946\n",
            "     71        \u001b[36m0.6651\u001b[0m  0.0802\n",
            "     72        \u001b[36m0.6651\u001b[0m  0.0804\n",
            "     73        \u001b[36m0.6651\u001b[0m  0.0816\n",
            "     74        \u001b[36m0.6651\u001b[0m  0.0799\n",
            "     75        \u001b[36m0.6651\u001b[0m  0.0905\n",
            "     76        \u001b[36m0.6651\u001b[0m  0.0785\n",
            "     77        \u001b[36m0.6650\u001b[0m  0.0792\n",
            "     78        \u001b[36m0.6650\u001b[0m  0.0811\n",
            "     79        \u001b[36m0.6650\u001b[0m  0.0754\n",
            "     80        \u001b[36m0.6650\u001b[0m  0.0768\n",
            "     81        \u001b[36m0.6650\u001b[0m  0.0786\n",
            "     82        \u001b[36m0.6650\u001b[0m  0.0774\n",
            "     83        \u001b[36m0.6650\u001b[0m  0.0782\n",
            "     84        \u001b[36m0.6649\u001b[0m  0.0786\n",
            "     85        \u001b[36m0.6649\u001b[0m  0.0873\n",
            "     86        \u001b[36m0.6649\u001b[0m  0.0839\n",
            "     87        \u001b[36m0.6649\u001b[0m  0.0979\n",
            "     88        \u001b[36m0.6649\u001b[0m  0.0808\n",
            "     89        \u001b[36m0.6649\u001b[0m  0.0799\n",
            "     90        \u001b[36m0.6649\u001b[0m  0.0809\n",
            "     91        \u001b[36m0.6648\u001b[0m  0.0843\n",
            "     92        \u001b[36m0.6648\u001b[0m  0.0803\n",
            "     93        \u001b[36m0.6648\u001b[0m  0.0781\n",
            "     94        \u001b[36m0.6648\u001b[0m  0.0774\n",
            "     95        \u001b[36m0.6648\u001b[0m  0.0824\n",
            "     96        \u001b[36m0.6648\u001b[0m  0.0874\n",
            "     97        \u001b[36m0.6648\u001b[0m  0.0815\n",
            "     98        \u001b[36m0.6647\u001b[0m  0.0884\n",
            "     99        \u001b[36m0.6647\u001b[0m  0.0919\n",
            "    100        \u001b[36m0.6647\u001b[0m  0.0792\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.8657\u001b[0m  0.0748\n",
            "      2        \u001b[36m1.7253\u001b[0m  0.0809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.5470\u001b[0m  0.0900\n",
            "      4        \u001b[36m1.2308\u001b[0m  0.0802\n",
            "      5        \u001b[36m0.8023\u001b[0m  0.0781\n",
            "      6        \u001b[36m0.6776\u001b[0m  0.0890\n",
            "      7        \u001b[36m0.6717\u001b[0m  0.0817\n",
            "      8        \u001b[36m0.6708\u001b[0m  0.0789\n",
            "      9        \u001b[36m0.6701\u001b[0m  0.0789\n",
            "     10        \u001b[36m0.6697\u001b[0m  0.0783\n",
            "     11        \u001b[36m0.6694\u001b[0m  0.0916\n",
            "     12        \u001b[36m0.6692\u001b[0m  0.0839\n",
            "     13        \u001b[36m0.6690\u001b[0m  0.0861\n",
            "     14        \u001b[36m0.6689\u001b[0m  0.0803\n",
            "     15        \u001b[36m0.6688\u001b[0m  0.0794\n",
            "     16        \u001b[36m0.6687\u001b[0m  0.0823\n",
            "     17        \u001b[36m0.6686\u001b[0m  0.0782\n",
            "     18        \u001b[36m0.6685\u001b[0m  0.0782\n",
            "     19        \u001b[36m0.6685\u001b[0m  0.0797\n",
            "     20        \u001b[36m0.6684\u001b[0m  0.0886\n",
            "     21        \u001b[36m0.6683\u001b[0m  0.0852\n",
            "     22        \u001b[36m0.6683\u001b[0m  0.0779\n",
            "     23        \u001b[36m0.6682\u001b[0m  0.0877\n",
            "     24        \u001b[36m0.6674\u001b[0m  0.0794\n",
            "     25        0.6821  0.0792\n",
            "     26        \u001b[36m0.6420\u001b[0m  0.0942\n",
            "     27        0.6520  0.0828\n",
            "     28        \u001b[36m0.6330\u001b[0m  0.0790\n",
            "     29        \u001b[36m0.6145\u001b[0m  0.0873\n",
            "     30        \u001b[36m0.6029\u001b[0m  0.0779\n",
            "     31        \u001b[36m0.6018\u001b[0m  0.0830\n",
            "     32        \u001b[36m0.5928\u001b[0m  0.0832\n",
            "     33        0.6029  0.0809\n",
            "     34        0.5955  0.0862\n",
            "     35        \u001b[36m0.5902\u001b[0m  0.0868\n",
            "     36        0.5988  0.0780\n",
            "     37        0.6051  0.0762\n",
            "     38        0.5943  0.0794\n",
            "     39        \u001b[36m0.5836\u001b[0m  0.0773\n",
            "     40        \u001b[36m0.5787\u001b[0m  0.0756\n",
            "     41        0.5826  0.0812\n",
            "     42        0.5942  0.0824\n",
            "     43        0.6006  0.0765\n",
            "     44        0.6016  0.0806\n",
            "     45        0.5925  0.0773\n",
            "     46        0.5862  0.0804\n",
            "     47        0.5823  0.0862\n",
            "     48        \u001b[36m0.5783\u001b[0m  0.0782\n",
            "     49        \u001b[36m0.5766\u001b[0m  0.0769\n",
            "     50        0.5826  0.0790\n",
            "     51        \u001b[36m0.5762\u001b[0m  0.0839\n",
            "     52        0.5980  0.0772\n",
            "     53        0.5909  0.0882\n",
            "     54        0.5806  0.0791\n",
            "     55        \u001b[36m0.5762\u001b[0m  0.0773\n",
            "     56        0.5860  0.0852\n",
            "     57        \u001b[36m0.5759\u001b[0m  0.0792\n",
            "     58        0.5774  0.0801\n",
            "     59        0.5761  0.0799\n",
            "     60        0.5809  0.0860\n",
            "     61        \u001b[36m0.5730\u001b[0m  0.0808\n",
            "     62        0.5754  0.0771\n",
            "     63        0.5733  0.0782\n",
            "     64        0.5780  0.0800\n",
            "     65        \u001b[36m0.5718\u001b[0m  0.0818\n",
            "     66        0.5818  0.0840\n",
            "     67        0.5879  0.0781\n",
            "     68        0.5860  0.0792\n",
            "     69        0.6019  0.0807\n",
            "     70        0.5855  0.0802\n",
            "     71        \u001b[36m0.5704\u001b[0m  0.0818\n",
            "     72        0.5753  0.0850\n",
            "     73        0.5753  0.0822\n",
            "     74        0.5789  0.0811\n",
            "     75        0.5998  0.0825\n",
            "     76        0.5795  0.0814\n",
            "     77        0.5785  0.0773\n",
            "     78        \u001b[36m0.5641\u001b[0m  0.0920\n",
            "     79        0.5772  0.0839\n",
            "     80        0.5674  0.0796\n",
            "     81        0.5764  0.0812\n",
            "     82        0.5675  0.0774\n",
            "     83        0.5728  0.0818\n",
            "     84        0.5673  0.0869\n",
            "     85        0.5708  0.0819\n",
            "     86        0.5716  0.0811\n",
            "     87        \u001b[36m0.5628\u001b[0m  0.0814\n",
            "     88        0.5764  0.0791\n",
            "     89        0.5843  0.0907\n",
            "     90        0.5738  0.0828\n",
            "     91        0.5865  0.0788\n",
            "     92        0.5838  0.0795\n",
            "     93        0.5755  0.0815\n",
            "     94        0.5632  0.0835\n",
            "     95        0.5741  0.0758\n",
            "     96        0.5799  0.0891\n",
            "     97        0.5699  0.0800\n",
            "     98        0.5679  0.0780\n",
            "     99        0.5721  0.0817\n",
            "    100        0.5816  0.0825\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.3077\u001b[0m  0.0707\n",
            "      2        \u001b[36m1.1945\u001b[0m  0.0767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.0830\u001b[0m  0.0964\n",
            "      4        \u001b[36m0.9763\u001b[0m  0.0857\n",
            "      5        \u001b[36m0.8616\u001b[0m  0.0838\n",
            "      6        \u001b[36m0.7382\u001b[0m  0.0796\n",
            "      7        \u001b[36m0.6798\u001b[0m  0.0786\n",
            "      8        \u001b[36m0.6684\u001b[0m  0.0853\n",
            "      9        \u001b[36m0.6664\u001b[0m  0.0779\n",
            "     10        \u001b[36m0.6658\u001b[0m  0.0815\n",
            "     11        \u001b[36m0.6655\u001b[0m  0.0798\n",
            "     12        \u001b[36m0.6653\u001b[0m  0.0849\n",
            "     13        \u001b[36m0.6652\u001b[0m  0.0776\n",
            "     14        \u001b[36m0.6651\u001b[0m  0.0840\n",
            "     15        \u001b[36m0.6650\u001b[0m  0.0765\n",
            "     16        \u001b[36m0.6649\u001b[0m  0.0781\n",
            "     17        \u001b[36m0.6649\u001b[0m  0.0787\n",
            "     18        \u001b[36m0.6648\u001b[0m  0.0829\n",
            "     19        \u001b[36m0.6648\u001b[0m  0.0803\n",
            "     20        \u001b[36m0.6648\u001b[0m  0.0840\n",
            "     21        \u001b[36m0.6648\u001b[0m  0.0896\n",
            "     22        \u001b[36m0.6647\u001b[0m  0.0765\n",
            "     23        \u001b[36m0.6647\u001b[0m  0.0846\n",
            "     24        \u001b[36m0.6647\u001b[0m  0.0826\n",
            "     25        \u001b[36m0.6647\u001b[0m  0.0887\n",
            "     26        \u001b[36m0.6647\u001b[0m  0.0772\n",
            "     27        \u001b[36m0.6647\u001b[0m  0.0751\n",
            "     28        \u001b[36m0.6646\u001b[0m  0.0779\n",
            "     29        \u001b[36m0.6646\u001b[0m  0.0789\n",
            "     30        \u001b[36m0.6646\u001b[0m  0.0928\n",
            "     31        \u001b[36m0.6628\u001b[0m  0.0774\n",
            "     32        0.6721  0.0899\n",
            "     33        0.6673  0.0809\n",
            "     34        0.6664  0.0757\n",
            "     35        0.6700  0.0790\n",
            "     36        0.6635  0.0849\n",
            "     37        0.6639  0.0790\n",
            "     38        0.6638  0.0816\n",
            "     39        0.6631  0.0825\n",
            "     40        0.6631  0.0857\n",
            "     41        \u001b[36m0.6627\u001b[0m  0.0786\n",
            "     42        0.6634  0.0801\n",
            "     43        \u001b[36m0.6582\u001b[0m  0.0777\n",
            "     44        \u001b[36m0.6560\u001b[0m  0.0868\n",
            "     45        \u001b[36m0.6547\u001b[0m  0.0771\n",
            "     46        \u001b[36m0.6536\u001b[0m  0.0801\n",
            "     47        \u001b[36m0.6526\u001b[0m  0.0805\n",
            "     48        \u001b[36m0.6516\u001b[0m  0.0780\n",
            "     49        0.6528  0.0791\n",
            "     50        \u001b[36m0.6492\u001b[0m  0.0853\n",
            "     51        \u001b[36m0.6462\u001b[0m  0.0758\n",
            "     52        \u001b[36m0.6452\u001b[0m  0.0774\n",
            "     53        \u001b[36m0.6439\u001b[0m  0.0833\n",
            "     54        \u001b[36m0.6431\u001b[0m  0.0861\n",
            "     55        \u001b[36m0.6424\u001b[0m  0.0794\n",
            "     56        \u001b[36m0.6418\u001b[0m  0.0942\n",
            "     57        \u001b[36m0.6412\u001b[0m  0.0822\n",
            "     58        \u001b[36m0.6407\u001b[0m  0.0787\n",
            "     59        \u001b[36m0.6402\u001b[0m  0.0753\n",
            "     60        \u001b[36m0.6398\u001b[0m  0.0768\n",
            "     61        \u001b[36m0.6393\u001b[0m  0.0844\n",
            "     62        \u001b[36m0.6389\u001b[0m  0.0771\n",
            "     63        \u001b[36m0.6385\u001b[0m  0.0793\n",
            "     64        \u001b[36m0.6382\u001b[0m  0.0822\n",
            "     65        \u001b[36m0.6378\u001b[0m  0.0809\n",
            "     66        \u001b[36m0.6375\u001b[0m  0.0818\n",
            "     67        \u001b[36m0.6372\u001b[0m  0.0787\n",
            "     68        \u001b[36m0.6369\u001b[0m  0.0805\n",
            "     69        \u001b[36m0.6366\u001b[0m  0.0862\n",
            "     70        \u001b[36m0.6363\u001b[0m  0.0798\n",
            "     71        \u001b[36m0.6361\u001b[0m  0.0804\n",
            "     72        \u001b[36m0.6351\u001b[0m  0.0832\n",
            "     73        \u001b[36m0.6349\u001b[0m  0.0788\n",
            "     74        0.6420  0.0816\n",
            "     75        0.6357  0.0778\n",
            "     76        0.6358  0.0798\n",
            "     77        0.6357  0.0806\n",
            "     78        0.6355  0.0804\n",
            "     79        0.6353  0.0818\n",
            "     80        0.6352  0.0769\n",
            "     81        0.6350  0.0879\n",
            "     82        \u001b[36m0.6348\u001b[0m  0.0788\n",
            "     83        \u001b[36m0.6347\u001b[0m  0.0770\n",
            "     84        \u001b[36m0.6345\u001b[0m  0.0806\n",
            "     85        \u001b[36m0.6344\u001b[0m  0.0777\n",
            "     86        \u001b[36m0.6343\u001b[0m  0.0770\n",
            "     87        \u001b[36m0.6341\u001b[0m  0.0931\n",
            "     88        \u001b[36m0.6340\u001b[0m  0.0802\n",
            "     89        \u001b[36m0.6339\u001b[0m  0.0799\n",
            "     90        \u001b[36m0.6338\u001b[0m  0.0828\n",
            "     91        \u001b[36m0.6336\u001b[0m  0.0784\n",
            "     92        \u001b[36m0.6335\u001b[0m  0.0788\n",
            "     93        \u001b[36m0.6334\u001b[0m  0.0822\n",
            "     94        \u001b[36m0.6333\u001b[0m  0.0818\n",
            "     95        \u001b[36m0.6332\u001b[0m  0.0812\n",
            "     96        \u001b[36m0.6331\u001b[0m  0.0772\n",
            "     97        \u001b[36m0.6330\u001b[0m  0.0878\n",
            "     98        \u001b[36m0.6329\u001b[0m  0.0816\n",
            "     99        \u001b[36m0.6328\u001b[0m  0.0822\n",
            "    100        \u001b[36m0.6328\u001b[0m  0.0816\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4553\u001b[0m  0.0716\n",
            "      2        \u001b[36m1.3341\u001b[0m  0.0864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.2088\u001b[0m  0.0912\n",
            "      4        \u001b[36m1.0728\u001b[0m  0.0779\n",
            "      5        \u001b[36m0.8931\u001b[0m  0.0876\n",
            "      6        \u001b[36m0.7252\u001b[0m  0.0784\n",
            "      7        \u001b[36m0.6760\u001b[0m  0.0808\n",
            "      8        \u001b[36m0.6690\u001b[0m  0.0843\n",
            "      9        \u001b[36m0.6677\u001b[0m  0.0786\n",
            "     10        \u001b[36m0.6671\u001b[0m  0.0861\n",
            "     11        \u001b[36m0.6668\u001b[0m  0.0777\n",
            "     12        \u001b[36m0.6665\u001b[0m  0.0788\n",
            "     13        \u001b[36m0.6664\u001b[0m  0.0791\n",
            "     14        \u001b[36m0.6662\u001b[0m  0.0793\n",
            "     15        \u001b[36m0.6661\u001b[0m  0.0759\n",
            "     16        \u001b[36m0.6660\u001b[0m  0.0775\n",
            "     17        \u001b[36m0.6660\u001b[0m  0.0783\n",
            "     18        \u001b[36m0.6659\u001b[0m  0.0826\n",
            "     19        \u001b[36m0.6658\u001b[0m  0.0793\n",
            "     20        \u001b[36m0.6658\u001b[0m  0.0762\n",
            "     21        \u001b[36m0.6657\u001b[0m  0.0757\n",
            "     22        \u001b[36m0.6657\u001b[0m  0.0764\n",
            "     23        \u001b[36m0.6656\u001b[0m  0.0896\n",
            "     24        \u001b[36m0.6656\u001b[0m  0.0779\n",
            "     25        \u001b[36m0.6655\u001b[0m  0.0776\n",
            "     26        \u001b[36m0.6655\u001b[0m  0.0905\n",
            "     27        \u001b[36m0.6655\u001b[0m  0.0781\n",
            "     28        \u001b[36m0.6654\u001b[0m  0.0766\n",
            "     29        \u001b[36m0.6654\u001b[0m  0.0776\n",
            "     30        0.6656  0.0877\n",
            "     31        \u001b[36m0.6652\u001b[0m  0.0818\n",
            "     32        0.6652  0.0798\n",
            "     33        0.6652  0.0883\n",
            "     34        0.6652  0.0800\n",
            "     35        \u001b[36m0.6652\u001b[0m  0.0841\n",
            "     36        \u001b[36m0.6651\u001b[0m  0.0814\n",
            "     37        0.6693  0.0803\n",
            "     38        \u001b[36m0.6651\u001b[0m  0.0850\n",
            "     39        \u001b[36m0.6651\u001b[0m  0.0795\n",
            "     40        \u001b[36m0.6650\u001b[0m  0.0797\n",
            "     41        \u001b[36m0.6650\u001b[0m  0.0788\n",
            "     42        \u001b[36m0.6649\u001b[0m  0.0949\n",
            "     43        \u001b[36m0.6649\u001b[0m  0.0810\n",
            "     44        \u001b[36m0.6649\u001b[0m  0.0896\n",
            "     45        \u001b[36m0.6649\u001b[0m  0.0809\n",
            "     46        \u001b[36m0.6648\u001b[0m  0.0857\n",
            "     47        \u001b[36m0.6648\u001b[0m  0.0803\n",
            "     48        \u001b[36m0.6648\u001b[0m  0.0808\n",
            "     49        \u001b[36m0.6648\u001b[0m  0.0841\n",
            "     50        \u001b[36m0.6647\u001b[0m  0.0804\n",
            "     51        \u001b[36m0.6647\u001b[0m  0.0802\n",
            "     52        \u001b[36m0.6647\u001b[0m  0.0795\n",
            "     53        \u001b[36m0.6647\u001b[0m  0.0898\n",
            "     54        \u001b[36m0.6647\u001b[0m  0.0865\n",
            "     55        \u001b[36m0.6646\u001b[0m  0.0785\n",
            "     56        \u001b[36m0.6646\u001b[0m  0.0782\n",
            "     57        \u001b[36m0.6646\u001b[0m  0.0834\n",
            "     58        \u001b[36m0.6646\u001b[0m  0.0889\n",
            "     59        \u001b[36m0.6646\u001b[0m  0.0833\n",
            "     60        \u001b[36m0.6645\u001b[0m  0.0796\n",
            "     61        \u001b[36m0.6645\u001b[0m  0.0831\n",
            "     62        \u001b[36m0.6645\u001b[0m  0.0840\n",
            "     63        \u001b[36m0.6645\u001b[0m  0.0779\n",
            "     64        \u001b[36m0.6645\u001b[0m  0.0787\n",
            "     65        \u001b[36m0.6645\u001b[0m  0.0785\n",
            "     66        \u001b[36m0.6644\u001b[0m  0.0866\n",
            "     67        \u001b[36m0.6644\u001b[0m  0.0836\n",
            "     68        \u001b[36m0.6644\u001b[0m  0.0789\n",
            "     69        \u001b[36m0.6644\u001b[0m  0.0850\n",
            "     70        \u001b[36m0.6644\u001b[0m  0.0810\n",
            "     71        \u001b[36m0.6643\u001b[0m  0.0803\n",
            "     72        \u001b[36m0.6643\u001b[0m  0.0824\n",
            "     73        \u001b[36m0.6643\u001b[0m  0.0857\n",
            "     74        \u001b[36m0.6643\u001b[0m  0.0830\n",
            "     75        \u001b[36m0.6643\u001b[0m  0.0826\n",
            "     76        \u001b[36m0.6643\u001b[0m  0.0792\n",
            "     77        \u001b[36m0.6643\u001b[0m  0.0777\n",
            "     78        \u001b[36m0.6642\u001b[0m  0.0862\n",
            "     79        \u001b[36m0.6642\u001b[0m  0.0817\n",
            "     80        \u001b[36m0.6642\u001b[0m  0.0827\n",
            "     81        \u001b[36m0.6642\u001b[0m  0.0794\n",
            "     82        \u001b[36m0.6642\u001b[0m  0.0895\n",
            "     83        \u001b[36m0.6642\u001b[0m  0.0814\n",
            "     84        \u001b[36m0.6642\u001b[0m  0.0816\n",
            "     85        \u001b[36m0.6641\u001b[0m  0.0831\n",
            "     86        \u001b[36m0.6641\u001b[0m  0.0771\n",
            "     87        \u001b[36m0.6641\u001b[0m  0.0787\n",
            "     88        \u001b[36m0.6641\u001b[0m  0.0953\n",
            "     89        \u001b[36m0.6641\u001b[0m  0.0820\n",
            "     90        \u001b[36m0.6641\u001b[0m  0.0879\n",
            "     91        \u001b[36m0.6641\u001b[0m  0.0784\n",
            "     92        \u001b[36m0.6640\u001b[0m  0.0811\n",
            "     93        \u001b[36m0.6640\u001b[0m  0.0784\n",
            "     94        \u001b[36m0.6640\u001b[0m  0.0823\n",
            "     95        0.6643  0.0852\n",
            "     96        0.6641  0.0799\n",
            "     97        0.6640  0.0816\n",
            "     98        0.6640  0.0773\n",
            "     99        \u001b[36m0.6640\u001b[0m  0.0845\n",
            "    100        \u001b[36m0.6639\u001b[0m  0.0839\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.1423\u001b[0m  0.0732\n",
            "      2        \u001b[36m1.0425\u001b[0m  0.0859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.9477\u001b[0m  0.0921\n",
            "      4        \u001b[36m0.8611\u001b[0m  0.0813\n",
            "      5        \u001b[36m0.7792\u001b[0m  0.0862\n",
            "      6        \u001b[36m0.7117\u001b[0m  0.0850\n",
            "      7        \u001b[36m0.6803\u001b[0m  0.0825\n",
            "      8        \u001b[36m0.6714\u001b[0m  0.0817\n",
            "      9        \u001b[36m0.6690\u001b[0m  0.0784\n",
            "     10        \u001b[36m0.6681\u001b[0m  0.0778\n",
            "     11        \u001b[36m0.6676\u001b[0m  0.0757\n",
            "     12        \u001b[36m0.6673\u001b[0m  0.0767\n",
            "     13        \u001b[36m0.6672\u001b[0m  0.0755\n",
            "     14        \u001b[36m0.6670\u001b[0m  0.0865\n",
            "     15        \u001b[36m0.6669\u001b[0m  0.0861\n",
            "     16        \u001b[36m0.6668\u001b[0m  0.0774\n",
            "     17        \u001b[36m0.6667\u001b[0m  0.0801\n",
            "     18        \u001b[36m0.6667\u001b[0m  0.0785\n",
            "     19        \u001b[36m0.6666\u001b[0m  0.0770\n",
            "     20        \u001b[36m0.6666\u001b[0m  0.0811\n",
            "     21        \u001b[36m0.6666\u001b[0m  0.0755\n",
            "     22        0.6671  0.0850\n",
            "     23        \u001b[36m0.6665\u001b[0m  0.0771\n",
            "     24        \u001b[36m0.6665\u001b[0m  0.0770\n",
            "     25        \u001b[36m0.6664\u001b[0m  0.0790\n",
            "     26        \u001b[36m0.6664\u001b[0m  0.0921\n",
            "     27        \u001b[36m0.6664\u001b[0m  0.0789\n",
            "     28        \u001b[36m0.6658\u001b[0m  0.0780\n",
            "     29        \u001b[36m0.6596\u001b[0m  0.0882\n",
            "     30        0.6770  0.0794\n",
            "     31        0.6685  0.0787\n",
            "     32        0.6668  0.0797\n",
            "     33        0.6662  0.0851\n",
            "     34        0.6658  0.0786\n",
            "     35        0.6616  0.0784\n",
            "     36        0.6601  0.0805\n",
            "     37        \u001b[36m0.6570\u001b[0m  0.0842\n",
            "     38        \u001b[36m0.6547\u001b[0m  0.0899\n",
            "     39        0.6551  0.0789\n",
            "     40        \u001b[36m0.6501\u001b[0m  0.0780\n",
            "     41        \u001b[36m0.6480\u001b[0m  0.0891\n",
            "     42        \u001b[36m0.6461\u001b[0m  0.0766\n",
            "     43        \u001b[36m0.6445\u001b[0m  0.0791\n",
            "     44        \u001b[36m0.6432\u001b[0m  0.0842\n",
            "     45        \u001b[36m0.6421\u001b[0m  0.0788\n",
            "     46        \u001b[36m0.6412\u001b[0m  0.0773\n",
            "     47        \u001b[36m0.6404\u001b[0m  0.0828\n",
            "     48        0.6426  0.0823\n",
            "     49        0.6492  0.0784\n",
            "     50        0.6406  0.0868\n",
            "     51        \u001b[36m0.6404\u001b[0m  0.0860\n",
            "     52        \u001b[36m0.6400\u001b[0m  0.0801\n",
            "     53        0.6413  0.0798\n",
            "     54        \u001b[36m0.6380\u001b[0m  0.0785\n",
            "     55        \u001b[36m0.6376\u001b[0m  0.0778\n",
            "     56        \u001b[36m0.6372\u001b[0m  0.0834\n",
            "     57        \u001b[36m0.6369\u001b[0m  0.0877\n",
            "     58        \u001b[36m0.6367\u001b[0m  0.0787\n",
            "     59        \u001b[36m0.6364\u001b[0m  0.0790\n",
            "     60        \u001b[36m0.6362\u001b[0m  0.0810\n",
            "     61        \u001b[36m0.6359\u001b[0m  0.0782\n",
            "     62        \u001b[36m0.6357\u001b[0m  0.0777\n",
            "     63        \u001b[36m0.6355\u001b[0m  0.0911\n",
            "     64        \u001b[36m0.6353\u001b[0m  0.0831\n",
            "     65        \u001b[36m0.6351\u001b[0m  0.0786\n",
            "     66        \u001b[36m0.6350\u001b[0m  0.0825\n",
            "     67        \u001b[36m0.6348\u001b[0m  0.0831\n",
            "     68        \u001b[36m0.6346\u001b[0m  0.0790\n",
            "     69        \u001b[36m0.6345\u001b[0m  0.0770\n",
            "     70        \u001b[36m0.6343\u001b[0m  0.0758\n",
            "     71        \u001b[36m0.6342\u001b[0m  0.0780\n",
            "     72        \u001b[36m0.6340\u001b[0m  0.0765\n",
            "     73        \u001b[36m0.6339\u001b[0m  0.0793\n",
            "     74        \u001b[36m0.6338\u001b[0m  0.0800\n",
            "     75        \u001b[36m0.6336\u001b[0m  0.0870\n",
            "     76        \u001b[36m0.6335\u001b[0m  0.0782\n",
            "     77        \u001b[36m0.6334\u001b[0m  0.0859\n",
            "     78        \u001b[36m0.6333\u001b[0m  0.0805\n",
            "     79        \u001b[36m0.6332\u001b[0m  0.0783\n",
            "     80        \u001b[36m0.6330\u001b[0m  0.0866\n",
            "     81        \u001b[36m0.6329\u001b[0m  0.0767\n",
            "     82        \u001b[36m0.6328\u001b[0m  0.0777\n",
            "     83        \u001b[36m0.6327\u001b[0m  0.0786\n",
            "     84        \u001b[36m0.6326\u001b[0m  0.0844\n",
            "     85        \u001b[36m0.6325\u001b[0m  0.0790\n",
            "     86        \u001b[36m0.6324\u001b[0m  0.0807\n",
            "     87        \u001b[36m0.6323\u001b[0m  0.0917\n",
            "     88        \u001b[36m0.6323\u001b[0m  0.0868\n",
            "     89        \u001b[36m0.6322\u001b[0m  0.0813\n",
            "     90        \u001b[36m0.6304\u001b[0m  0.0813\n",
            "     91        0.6313  0.0771\n",
            "     92        0.6317  0.0835\n",
            "     93        \u001b[36m0.6296\u001b[0m  0.0776\n",
            "     94        \u001b[36m0.6281\u001b[0m  0.0779\n",
            "     95        \u001b[36m0.6274\u001b[0m  0.0757\n",
            "     96        \u001b[36m0.6272\u001b[0m  0.0818\n",
            "     97        \u001b[36m0.6271\u001b[0m  0.0819\n",
            "     98        \u001b[36m0.6269\u001b[0m  0.0773\n",
            "     99        \u001b[36m0.6268\u001b[0m  0.0830\n",
            "    100        \u001b[36m0.6264\u001b[0m  0.0850\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.3245\u001b[0m  0.0732\n",
            "      2        \u001b[36m1.2093\u001b[0m  0.0775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.0877\u001b[0m  0.0901\n",
            "      4        \u001b[36m0.9449\u001b[0m  0.0865\n",
            "      5        \u001b[36m0.7810\u001b[0m  0.0776\n",
            "      6        \u001b[36m0.6927\u001b[0m  0.0758\n",
            "      7        \u001b[36m0.6737\u001b[0m  0.0796\n",
            "      8        \u001b[36m0.6705\u001b[0m  0.0797\n",
            "      9        \u001b[36m0.6695\u001b[0m  0.0799\n",
            "     10        \u001b[36m0.6690\u001b[0m  0.0779\n",
            "     11        \u001b[36m0.6687\u001b[0m  0.0774\n",
            "     12        \u001b[36m0.6684\u001b[0m  0.0908\n",
            "     13        \u001b[36m0.6683\u001b[0m  0.0881\n",
            "     14        \u001b[36m0.6681\u001b[0m  0.0805\n",
            "     15        \u001b[36m0.6680\u001b[0m  0.0897\n",
            "     16        \u001b[36m0.6679\u001b[0m  0.0884\n",
            "     17        \u001b[36m0.6679\u001b[0m  0.0828\n",
            "     18        \u001b[36m0.6678\u001b[0m  0.0759\n",
            "     19        \u001b[36m0.6677\u001b[0m  0.0776\n",
            "     20        \u001b[36m0.6677\u001b[0m  0.0896\n",
            "     21        \u001b[36m0.6676\u001b[0m  0.0795\n",
            "     22        \u001b[36m0.6676\u001b[0m  0.0799\n",
            "     23        \u001b[36m0.6673\u001b[0m  0.0797\n",
            "     24        \u001b[36m0.6635\u001b[0m  0.0922\n",
            "     25        0.6639  0.0784\n",
            "     26        \u001b[36m0.6471\u001b[0m  0.0770\n",
            "     27        \u001b[36m0.6458\u001b[0m  0.0804\n",
            "     28        0.6491  0.0823\n",
            "     29        0.6501  0.0815\n",
            "     30        0.6539  0.0757\n",
            "     31        0.6514  0.0783\n",
            "     32        0.6476  0.0785\n",
            "     33        \u001b[36m0.6421\u001b[0m  0.0776\n",
            "     34        \u001b[36m0.6357\u001b[0m  0.0806\n",
            "     35        0.6376  0.0917\n",
            "     36        0.6367  0.0842\n",
            "     37        \u001b[36m0.6350\u001b[0m  0.0789\n",
            "     38        0.6490  0.0781\n",
            "     39        0.6456  0.0829\n",
            "     40        0.6365  0.0816\n",
            "     41        \u001b[36m0.6312\u001b[0m  0.0790\n",
            "     42        \u001b[36m0.6243\u001b[0m  0.0790\n",
            "     43        \u001b[36m0.6135\u001b[0m  0.0816\n",
            "     44        \u001b[36m0.6125\u001b[0m  0.0784\n",
            "     45        0.6208  0.0783\n",
            "     46        \u001b[36m0.6064\u001b[0m  0.0820\n",
            "     47        0.6116  0.0812\n",
            "     48        0.6095  0.0927\n",
            "     49        0.6064  0.0879\n",
            "     50        \u001b[36m0.6028\u001b[0m  0.0772\n",
            "     51        \u001b[36m0.5965\u001b[0m  0.0813\n",
            "     52        \u001b[36m0.5933\u001b[0m  0.0840\n",
            "     53        \u001b[36m0.5850\u001b[0m  0.0783\n",
            "     54        \u001b[36m0.5817\u001b[0m  0.0867\n",
            "     55        0.5887  0.0820\n",
            "     56        0.5958  0.0810\n",
            "     57        0.5830  0.0780\n",
            "     58        0.5849  0.0804\n",
            "     59        \u001b[36m0.5718\u001b[0m  0.0765\n",
            "     60        0.5725  0.0933\n",
            "     61        \u001b[36m0.5713\u001b[0m  0.0804\n",
            "     62        0.5808  0.0808\n",
            "     63        0.5782  0.0806\n",
            "     64        0.5740  0.0866\n",
            "     65        \u001b[36m0.5673\u001b[0m  0.0769\n",
            "     66        \u001b[36m0.5662\u001b[0m  0.0780\n",
            "     67        0.5739  0.0788\n",
            "     68        \u001b[36m0.5619\u001b[0m  0.0794\n",
            "     69        0.5705  0.0809\n",
            "     70        0.5748  0.0850\n",
            "     71        0.5684  0.0911\n",
            "     72        0.5700  0.0857\n",
            "     73        0.5678  0.0836\n",
            "     74        0.5644  0.0808\n",
            "     75        0.5678  0.0883\n",
            "     76        0.5744  0.0834\n",
            "     77        0.5712  0.0806\n",
            "     78        0.5784  0.0799\n",
            "     79        0.5857  0.0828\n",
            "     80        0.5805  0.0841\n",
            "     81        0.5705  0.0852\n",
            "     82        0.5829  0.0840\n",
            "     83        0.6007  0.0952\n",
            "     84        0.5930  0.0938\n",
            "     85        0.5853  0.0834\n",
            "     86        0.5752  0.0806\n",
            "     87        0.5925  0.0794\n",
            "     88        0.5869  0.0766\n",
            "     89        0.5814  0.0790\n",
            "     90        0.6008  0.0786\n",
            "     91        0.6018  0.0772\n",
            "     92        0.5901  0.0797\n",
            "     93        0.5881  0.0804\n",
            "     94        0.5804  0.0793\n",
            "     95        0.5985  0.0785\n",
            "     96        0.6009  0.0948\n",
            "     97        0.6019  0.0781\n",
            "     98        0.6018  0.0785\n",
            "     99        0.5866  0.0870\n",
            "    100        0.5737  0.0800\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4095\u001b[0m  0.0719\n",
            "      2        \u001b[36m1.2852\u001b[0m  0.0825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.1439\u001b[0m  0.1007\n",
            "      4        \u001b[36m0.9685\u001b[0m  0.0799\n",
            "      5        \u001b[36m0.7957\u001b[0m  0.0825\n",
            "      6        \u001b[36m0.7029\u001b[0m  0.0839\n",
            "      7        \u001b[36m0.6744\u001b[0m  0.0779\n",
            "      8        \u001b[36m0.6679\u001b[0m  0.0883\n",
            "      9        \u001b[36m0.6662\u001b[0m  0.0819\n",
            "     10        \u001b[36m0.6655\u001b[0m  0.0812\n",
            "     11        \u001b[36m0.6652\u001b[0m  0.0805\n",
            "     12        \u001b[36m0.6650\u001b[0m  0.0793\n",
            "     13        \u001b[36m0.6649\u001b[0m  0.0806\n",
            "     14        \u001b[36m0.6648\u001b[0m  0.0806\n",
            "     15        \u001b[36m0.6647\u001b[0m  0.0774\n",
            "     16        \u001b[36m0.6571\u001b[0m  0.0842\n",
            "     17        0.6705  0.0831\n",
            "     18        0.6631  0.0856\n",
            "     19        0.6641  0.0778\n",
            "     20        0.6620  0.0934\n",
            "     21        \u001b[36m0.6478\u001b[0m  0.0795\n",
            "     22        \u001b[36m0.6369\u001b[0m  0.0853\n",
            "     23        0.6375  0.0829\n",
            "     24        \u001b[36m0.6302\u001b[0m  0.0784\n",
            "     25        \u001b[36m0.6134\u001b[0m  0.0776\n",
            "     26        0.6265  0.0790\n",
            "     27        0.6263  0.0790\n",
            "     28        0.6251  0.0774\n",
            "     29        0.6232  0.0751\n",
            "     30        \u001b[36m0.6114\u001b[0m  0.0745\n",
            "     31        \u001b[36m0.5912\u001b[0m  0.0799\n",
            "     32        0.6185  0.0966\n",
            "     33        0.6102  0.0840\n",
            "     34        0.5970  0.0806\n",
            "     35        \u001b[36m0.5860\u001b[0m  0.0773\n",
            "     36        0.5927  0.0772\n",
            "     37        0.5994  0.0792\n",
            "     38        0.5860  0.0761\n",
            "     39        0.5879  0.0766\n",
            "     40        0.5946  0.0823\n",
            "     41        \u001b[36m0.5841\u001b[0m  0.0855\n",
            "     42        0.5941  0.0924\n",
            "     43        0.5862  0.0857\n",
            "     44        0.5941  0.0811\n",
            "     45        0.6100  0.0869\n",
            "     46        0.5994  0.0779\n",
            "     47        0.5898  0.0815\n",
            "     48        0.5938  0.0783\n",
            "     49        0.5907  0.0790\n",
            "     50        0.5903  0.0809\n",
            "     51        0.5878  0.0769\n",
            "     52        \u001b[36m0.5795\u001b[0m  0.0780\n",
            "     53        0.5810  0.0888\n",
            "     54        \u001b[36m0.5774\u001b[0m  0.0795\n",
            "     55        0.5843  0.0770\n",
            "     56        0.6084  0.0796\n",
            "     57        0.6030  0.0886\n",
            "     58        0.5955  0.0809\n",
            "     59        0.5858  0.0795\n",
            "     60        0.5842  0.0748\n",
            "     61        0.5989  0.0785\n",
            "     62        0.5999  0.0807\n",
            "     63        0.5792  0.0769\n",
            "     64        0.6050  0.0784\n",
            "     65        0.5962  0.0811\n",
            "     66        0.5858  0.0812\n",
            "     67        0.5808  0.0772\n",
            "     68        0.5789  0.0876\n",
            "     69        0.5783  0.0760\n",
            "     70        0.5781  0.0944\n",
            "     71        \u001b[36m0.5771\u001b[0m  0.0793\n",
            "     72        0.5870  0.0772\n",
            "     73        \u001b[36m0.5727\u001b[0m  0.0781\n",
            "     74        0.5727  0.0786\n",
            "     75        0.6204  0.0815\n",
            "     76        0.5985  0.0782\n",
            "     77        0.6133  0.0773\n",
            "     78        0.6044  0.0773\n",
            "     79        0.5731  0.0867\n",
            "     80        0.5758  0.0819\n",
            "     81        0.5774  0.0766\n",
            "     82        0.5734  0.0944\n",
            "     83        0.5819  0.0834\n",
            "     84        0.5797  0.0778\n",
            "     85        0.5756  0.0844\n",
            "     86        0.5746  0.0807\n",
            "     87        0.5734  0.0799\n",
            "     88        0.5728  0.0790\n",
            "     89        \u001b[36m0.5692\u001b[0m  0.0795\n",
            "     90        0.5699  0.0959\n",
            "     91        0.5854  0.0802\n",
            "     92        0.5729  0.0808\n",
            "     93        \u001b[36m0.5681\u001b[0m  0.0811\n",
            "     94        0.6012  0.0873\n",
            "     95        0.5983  0.0802\n",
            "     96        0.5972  0.0761\n",
            "     97        0.5854  0.0809\n",
            "     98        0.5867  0.0785\n",
            "     99        0.6016  0.0780\n",
            "    100        0.6069  0.0763\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.3672\u001b[0m  0.0583\n",
            "      2        \u001b[36m1.3122\u001b[0m  0.0622\n",
            "      3        \u001b[36m1.2587\u001b[0m  0.0659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.2069\u001b[0m  0.0754\n",
            "      5        \u001b[36m1.1570\u001b[0m  0.0658\n",
            "      6        \u001b[36m1.1093\u001b[0m  0.0637\n",
            "      7        \u001b[36m1.0638\u001b[0m  0.0658\n",
            "      8        \u001b[36m1.0209\u001b[0m  0.0717\n",
            "      9        \u001b[36m0.9805\u001b[0m  0.0600\n",
            "     10        \u001b[36m0.9430\u001b[0m  0.0718\n",
            "     11        \u001b[36m0.9083\u001b[0m  0.0629\n",
            "     12        \u001b[36m0.8765\u001b[0m  0.0622\n",
            "     13        \u001b[36m0.8477\u001b[0m  0.0628\n",
            "     14        \u001b[36m0.8217\u001b[0m  0.0666\n",
            "     15        \u001b[36m0.7986\u001b[0m  0.0623\n",
            "     16        \u001b[36m0.7781\u001b[0m  0.0633\n",
            "     17        \u001b[36m0.7601\u001b[0m  0.0688\n",
            "     18        \u001b[36m0.7444\u001b[0m  0.0716\n",
            "     19        \u001b[36m0.7309\u001b[0m  0.0638\n",
            "     20        \u001b[36m0.7193\u001b[0m  0.0690\n",
            "     21        \u001b[36m0.7094\u001b[0m  0.0673\n",
            "     22        \u001b[36m0.7011\u001b[0m  0.0719\n",
            "     23        \u001b[36m0.6940\u001b[0m  0.0662\n",
            "     24        \u001b[36m0.6881\u001b[0m  0.0674\n",
            "     25        \u001b[36m0.6831\u001b[0m  0.0613\n",
            "     26        \u001b[36m0.6790\u001b[0m  0.0651\n",
            "     27        \u001b[36m0.6756\u001b[0m  0.0625\n",
            "     28        \u001b[36m0.6728\u001b[0m  0.0631\n",
            "     29        \u001b[36m0.6704\u001b[0m  0.0632\n",
            "     30        \u001b[36m0.6685\u001b[0m  0.0708\n",
            "     31        \u001b[36m0.6669\u001b[0m  0.0690\n",
            "     32        \u001b[36m0.6656\u001b[0m  0.0641\n",
            "     33        \u001b[36m0.6646\u001b[0m  0.0644\n",
            "     34        \u001b[36m0.6637\u001b[0m  0.0647\n",
            "     35        \u001b[36m0.6630\u001b[0m  0.0650\n",
            "     36        \u001b[36m0.6624\u001b[0m  0.0682\n",
            "     37        \u001b[36m0.6620\u001b[0m  0.0712\n",
            "     38        \u001b[36m0.6616\u001b[0m  0.0702\n",
            "     39        \u001b[36m0.6613\u001b[0m  0.0648\n",
            "     40        \u001b[36m0.6610\u001b[0m  0.0624\n",
            "     41        \u001b[36m0.6608\u001b[0m  0.0638\n",
            "     42        \u001b[36m0.6606\u001b[0m  0.0628\n",
            "     43        \u001b[36m0.6605\u001b[0m  0.0618\n",
            "     44        \u001b[36m0.6604\u001b[0m  0.0629\n",
            "     45        \u001b[36m0.6603\u001b[0m  0.0736\n",
            "     46        \u001b[36m0.6602\u001b[0m  0.0626\n",
            "     47        \u001b[36m0.6601\u001b[0m  0.0662\n",
            "     48        \u001b[36m0.6601\u001b[0m  0.0627\n",
            "     49        \u001b[36m0.6600\u001b[0m  0.0660\n",
            "     50        \u001b[36m0.6600\u001b[0m  0.0620\n",
            "     51        \u001b[36m0.6600\u001b[0m  0.0621\n",
            "     52        \u001b[36m0.6599\u001b[0m  0.0675\n",
            "     53        \u001b[36m0.6599\u001b[0m  0.0691\n",
            "     54        \u001b[36m0.6599\u001b[0m  0.0646\n",
            "     55        \u001b[36m0.6599\u001b[0m  0.0647\n",
            "     56        \u001b[36m0.6599\u001b[0m  0.0649\n",
            "     57        \u001b[36m0.6599\u001b[0m  0.0638\n",
            "     58        \u001b[36m0.6599\u001b[0m  0.0670\n",
            "     59        \u001b[36m0.6599\u001b[0m  0.0665\n",
            "     60        \u001b[36m0.6598\u001b[0m  0.0626\n",
            "     61        \u001b[36m0.6598\u001b[0m  0.0634\n",
            "     62        \u001b[36m0.6598\u001b[0m  0.0649\n",
            "     63        \u001b[36m0.6598\u001b[0m  0.0713\n",
            "     64        \u001b[36m0.6598\u001b[0m  0.0713\n",
            "     65        \u001b[36m0.6598\u001b[0m  0.0629\n",
            "     66        \u001b[36m0.6598\u001b[0m  0.0738\n",
            "     67        \u001b[36m0.6598\u001b[0m  0.0645\n",
            "     68        \u001b[36m0.6598\u001b[0m  0.0733\n",
            "     69        \u001b[36m0.6598\u001b[0m  0.0623\n",
            "     70        \u001b[36m0.6598\u001b[0m  0.0638\n",
            "     71        \u001b[36m0.6598\u001b[0m  0.0685\n",
            "     72        \u001b[36m0.6598\u001b[0m  0.0675\n",
            "     73        \u001b[36m0.6598\u001b[0m  0.0649\n",
            "     74        \u001b[36m0.6598\u001b[0m  0.0672\n",
            "     75        \u001b[36m0.6598\u001b[0m  0.0648\n",
            "     76        \u001b[36m0.6598\u001b[0m  0.0670\n",
            "     77        \u001b[36m0.6598\u001b[0m  0.0674\n",
            "     78        \u001b[36m0.6598\u001b[0m  0.0685\n",
            "     79        \u001b[36m0.6598\u001b[0m  0.0686\n",
            "     80        \u001b[36m0.6598\u001b[0m  0.0657\n",
            "     81        \u001b[36m0.6598\u001b[0m  0.0637\n",
            "     82        \u001b[36m0.6598\u001b[0m  0.0616\n",
            "     83        \u001b[36m0.6598\u001b[0m  0.0700\n",
            "     84        \u001b[36m0.6598\u001b[0m  0.0644\n",
            "     85        \u001b[36m0.6598\u001b[0m  0.0770\n",
            "     86        \u001b[36m0.6598\u001b[0m  0.0691\n",
            "     87        \u001b[36m0.6598\u001b[0m  0.0653\n",
            "     88        \u001b[36m0.6598\u001b[0m  0.0636\n",
            "     89        \u001b[36m0.6598\u001b[0m  0.0730\n",
            "     90        \u001b[36m0.6598\u001b[0m  0.0633\n",
            "     91        \u001b[36m0.6598\u001b[0m  0.0634\n",
            "     92        \u001b[36m0.6598\u001b[0m  0.0660\n",
            "     93        \u001b[36m0.6598\u001b[0m  0.0649\n",
            "     94        \u001b[36m0.6598\u001b[0m  0.0728\n",
            "     95        \u001b[36m0.6598\u001b[0m  0.0679\n",
            "     96        \u001b[36m0.6598\u001b[0m  0.0630\n",
            "     97        \u001b[36m0.6598\u001b[0m  0.0743\n",
            "     98        \u001b[36m0.6598\u001b[0m  0.0643\n",
            "     99        \u001b[36m0.6598\u001b[0m  0.0632\n",
            "    100        \u001b[36m0.6598\u001b[0m  0.0637\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.5039\u001b[0m  0.0629\n",
            "      2        \u001b[36m1.4459\u001b[0m  0.0664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.3890\u001b[0m  0.0762\n",
            "      4        \u001b[36m1.3333\u001b[0m  0.0692\n",
            "      5        \u001b[36m1.2792\u001b[0m  0.0650\n",
            "      6        \u001b[36m1.2266\u001b[0m  0.0710\n",
            "      7        \u001b[36m1.1759\u001b[0m  0.0654\n",
            "      8        \u001b[36m1.1273\u001b[0m  0.0637\n",
            "      9        \u001b[36m1.0809\u001b[0m  0.0704\n",
            "     10        \u001b[36m1.0369\u001b[0m  0.0641\n",
            "     11        \u001b[36m0.9955\u001b[0m  0.0658\n",
            "     12        \u001b[36m0.9568\u001b[0m  0.0697\n",
            "     13        \u001b[36m0.9210\u001b[0m  0.0622\n",
            "     14        \u001b[36m0.8881\u001b[0m  0.0646\n",
            "     15        \u001b[36m0.8581\u001b[0m  0.0609\n",
            "     16        \u001b[36m0.8310\u001b[0m  0.0631\n",
            "     17        \u001b[36m0.8068\u001b[0m  0.0626\n",
            "     18        \u001b[36m0.7852\u001b[0m  0.0627\n",
            "     19        \u001b[36m0.7663\u001b[0m  0.0751\n",
            "     20        \u001b[36m0.7498\u001b[0m  0.0630\n",
            "     21        \u001b[36m0.7355\u001b[0m  0.0681\n",
            "     22        \u001b[36m0.7232\u001b[0m  0.0627\n",
            "     23        \u001b[36m0.7127\u001b[0m  0.0637\n",
            "     24        \u001b[36m0.7038\u001b[0m  0.0694\n",
            "     25        \u001b[36m0.6963\u001b[0m  0.0644\n",
            "     26        \u001b[36m0.6899\u001b[0m  0.0619\n",
            "     27        \u001b[36m0.6847\u001b[0m  0.0771\n",
            "     28        \u001b[36m0.6803\u001b[0m  0.0667\n",
            "     29        \u001b[36m0.6766\u001b[0m  0.0625\n",
            "     30        \u001b[36m0.6736\u001b[0m  0.0648\n",
            "     31        \u001b[36m0.6711\u001b[0m  0.0675\n",
            "     32        \u001b[36m0.6690\u001b[0m  0.0625\n",
            "     33        \u001b[36m0.6674\u001b[0m  0.0736\n",
            "     34        \u001b[36m0.6660\u001b[0m  0.0669\n",
            "     35        \u001b[36m0.6648\u001b[0m  0.0649\n",
            "     36        \u001b[36m0.6639\u001b[0m  0.0649\n",
            "     37        \u001b[36m0.6632\u001b[0m  0.0672\n",
            "     38        \u001b[36m0.6625\u001b[0m  0.0666\n",
            "     39        \u001b[36m0.6620\u001b[0m  0.0701\n",
            "     40        \u001b[36m0.6616\u001b[0m  0.0700\n",
            "     41        \u001b[36m0.6613\u001b[0m  0.0647\n",
            "     42        \u001b[36m0.6610\u001b[0m  0.0717\n",
            "     43        \u001b[36m0.6608\u001b[0m  0.0627\n",
            "     44        \u001b[36m0.6606\u001b[0m  0.0670\n",
            "     45        \u001b[36m0.6605\u001b[0m  0.0627\n",
            "     46        \u001b[36m0.6603\u001b[0m  0.0675\n",
            "     47        \u001b[36m0.6602\u001b[0m  0.0621\n",
            "     48        \u001b[36m0.6602\u001b[0m  0.0612\n",
            "     49        \u001b[36m0.6601\u001b[0m  0.0708\n",
            "     50        \u001b[36m0.6600\u001b[0m  0.0751\n",
            "     51        \u001b[36m0.6600\u001b[0m  0.0682\n",
            "     52        \u001b[36m0.6599\u001b[0m  0.0707\n",
            "     53        \u001b[36m0.6599\u001b[0m  0.0686\n",
            "     54        \u001b[36m0.6599\u001b[0m  0.0683\n",
            "     55        \u001b[36m0.6599\u001b[0m  0.0660\n",
            "     56        \u001b[36m0.6599\u001b[0m  0.0645\n",
            "     57        \u001b[36m0.6598\u001b[0m  0.0791\n",
            "     58        \u001b[36m0.6598\u001b[0m  0.0649\n",
            "     59        \u001b[36m0.6598\u001b[0m  0.0655\n",
            "     60        \u001b[36m0.6598\u001b[0m  0.0663\n",
            "     61        \u001b[36m0.6598\u001b[0m  0.0630\n",
            "     62        \u001b[36m0.6598\u001b[0m  0.0634\n",
            "     63        \u001b[36m0.6598\u001b[0m  0.0723\n",
            "     64        \u001b[36m0.6598\u001b[0m  0.0632\n",
            "     65        \u001b[36m0.6598\u001b[0m  0.0614\n",
            "     66        \u001b[36m0.6598\u001b[0m  0.0692\n",
            "     67        \u001b[36m0.6598\u001b[0m  0.0692\n",
            "     68        \u001b[36m0.6598\u001b[0m  0.0702\n",
            "     69        \u001b[36m0.6598\u001b[0m  0.0631\n",
            "     70        \u001b[36m0.6598\u001b[0m  0.0653\n",
            "     71        \u001b[36m0.6598\u001b[0m  0.0650\n",
            "     72        \u001b[36m0.6598\u001b[0m  0.0729\n",
            "     73        \u001b[36m0.6598\u001b[0m  0.0619\n",
            "     74        \u001b[36m0.6598\u001b[0m  0.0688\n",
            "     75        \u001b[36m0.6598\u001b[0m  0.0656\n",
            "     76        \u001b[36m0.6598\u001b[0m  0.0692\n",
            "     77        \u001b[36m0.6598\u001b[0m  0.0701\n",
            "     78        \u001b[36m0.6598\u001b[0m  0.0636\n",
            "     79        \u001b[36m0.6598\u001b[0m  0.0636\n",
            "     80        \u001b[36m0.6598\u001b[0m  0.0700\n",
            "     81        \u001b[36m0.6598\u001b[0m  0.0622\n",
            "     82        \u001b[36m0.6598\u001b[0m  0.0695\n",
            "     83        \u001b[36m0.6598\u001b[0m  0.0677\n",
            "     84        \u001b[36m0.6598\u001b[0m  0.0655\n",
            "     85        \u001b[36m0.6598\u001b[0m  0.0615\n",
            "     86        \u001b[36m0.6598\u001b[0m  0.0700\n",
            "     87        \u001b[36m0.6598\u001b[0m  0.0629\n",
            "     88        \u001b[36m0.6598\u001b[0m  0.0661\n",
            "     89        \u001b[36m0.6598\u001b[0m  0.0661\n",
            "     90        \u001b[36m0.6598\u001b[0m  0.0616\n",
            "     91        \u001b[36m0.6598\u001b[0m  0.0660\n",
            "     92        \u001b[36m0.6598\u001b[0m  0.0640\n",
            "     93        \u001b[36m0.6598\u001b[0m  0.0635\n",
            "     94        \u001b[36m0.6598\u001b[0m  0.0621\n",
            "     95        \u001b[36m0.6598\u001b[0m  0.0604\n",
            "     96        \u001b[36m0.6598\u001b[0m  0.0623\n",
            "     97        \u001b[36m0.6598\u001b[0m  0.0676\n",
            "     98        \u001b[36m0.6598\u001b[0m  0.0601\n",
            "     99        \u001b[36m0.6598\u001b[0m  0.0623\n",
            "    100        \u001b[36m0.6598\u001b[0m  0.0654\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.1929\u001b[0m  0.0652\n",
            "      2        \u001b[36m1.1432\u001b[0m  0.0635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.0957\u001b[0m  0.0689\n",
            "      4        \u001b[36m1.0506\u001b[0m  0.0690\n",
            "      5        \u001b[36m1.0081\u001b[0m  0.0624\n",
            "      6        \u001b[36m0.9684\u001b[0m  0.0615\n",
            "      7        \u001b[36m0.9315\u001b[0m  0.0766\n",
            "      8        \u001b[36m0.8976\u001b[0m  0.0660\n",
            "      9        \u001b[36m0.8667\u001b[0m  0.0628\n",
            "     10        \u001b[36m0.8387\u001b[0m  0.0624\n",
            "     11        \u001b[36m0.8136\u001b[0m  0.0669\n",
            "     12        \u001b[36m0.7913\u001b[0m  0.0661\n",
            "     13        \u001b[36m0.7717\u001b[0m  0.0622\n",
            "     14        \u001b[36m0.7546\u001b[0m  0.0617\n",
            "     15        \u001b[36m0.7397\u001b[0m  0.0735\n",
            "     16        \u001b[36m0.7269\u001b[0m  0.0666\n",
            "     17        \u001b[36m0.7160\u001b[0m  0.0713\n",
            "     18        \u001b[36m0.7067\u001b[0m  0.0645\n",
            "     19        \u001b[36m0.6989\u001b[0m  0.0634\n",
            "     20        \u001b[36m0.6923\u001b[0m  0.0683\n",
            "     21        \u001b[36m0.6868\u001b[0m  0.0687\n",
            "     22        \u001b[36m0.6822\u001b[0m  0.0682\n",
            "     23        \u001b[36m0.6784\u001b[0m  0.0639\n",
            "     24        \u001b[36m0.6752\u001b[0m  0.0654\n",
            "     25        \u001b[36m0.6726\u001b[0m  0.0634\n",
            "     26        \u001b[36m0.6705\u001b[0m  0.0666\n",
            "     27        \u001b[36m0.6688\u001b[0m  0.0680\n",
            "     28        \u001b[36m0.6673\u001b[0m  0.0631\n",
            "     29        \u001b[36m0.6661\u001b[0m  0.0673\n",
            "     30        \u001b[36m0.6652\u001b[0m  0.0616\n",
            "     31        \u001b[36m0.6644\u001b[0m  0.0633\n",
            "     32        \u001b[36m0.6638\u001b[0m  0.0807\n",
            "     33        \u001b[36m0.6632\u001b[0m  0.0660\n",
            "     34        \u001b[36m0.6628\u001b[0m  0.0707\n",
            "     35        \u001b[36m0.6625\u001b[0m  0.0630\n",
            "     36        \u001b[36m0.6622\u001b[0m  0.0681\n",
            "     37        \u001b[36m0.6619\u001b[0m  0.0676\n",
            "     38        \u001b[36m0.6618\u001b[0m  0.0713\n",
            "     39        \u001b[36m0.6616\u001b[0m  0.0664\n",
            "     40        \u001b[36m0.6615\u001b[0m  0.0705\n",
            "     41        \u001b[36m0.6614\u001b[0m  0.0635\n",
            "     42        \u001b[36m0.6613\u001b[0m  0.0659\n",
            "     43        \u001b[36m0.6612\u001b[0m  0.0619\n",
            "     44        \u001b[36m0.6612\u001b[0m  0.0629\n",
            "     45        \u001b[36m0.6611\u001b[0m  0.0700\n",
            "     46        \u001b[36m0.6611\u001b[0m  0.0681\n",
            "     47        \u001b[36m0.6610\u001b[0m  0.0696\n",
            "     48        \u001b[36m0.6610\u001b[0m  0.0637\n",
            "     49        \u001b[36m0.6610\u001b[0m  0.0640\n",
            "     50        \u001b[36m0.6610\u001b[0m  0.0653\n",
            "     51        \u001b[36m0.6610\u001b[0m  0.0706\n",
            "     52        \u001b[36m0.6610\u001b[0m  0.0650\n",
            "     53        \u001b[36m0.6609\u001b[0m  0.0632\n",
            "     54        \u001b[36m0.6609\u001b[0m  0.0658\n",
            "     55        \u001b[36m0.6609\u001b[0m  0.0716\n",
            "     56        \u001b[36m0.6609\u001b[0m  0.0643\n",
            "     57        \u001b[36m0.6609\u001b[0m  0.0623\n",
            "     58        \u001b[36m0.6609\u001b[0m  0.0613\n",
            "     59        \u001b[36m0.6609\u001b[0m  0.0652\n",
            "     60        \u001b[36m0.6609\u001b[0m  0.0659\n",
            "     61        \u001b[36m0.6609\u001b[0m  0.0627\n",
            "     62        \u001b[36m0.6609\u001b[0m  0.0711\n",
            "     63        \u001b[36m0.6609\u001b[0m  0.0677\n",
            "     64        \u001b[36m0.6609\u001b[0m  0.0710\n",
            "     65        \u001b[36m0.6609\u001b[0m  0.0708\n",
            "     66        \u001b[36m0.6609\u001b[0m  0.0638\n",
            "     67        \u001b[36m0.6609\u001b[0m  0.0636\n",
            "     68        \u001b[36m0.6609\u001b[0m  0.0631\n",
            "     69        \u001b[36m0.6609\u001b[0m  0.0671\n",
            "     70        \u001b[36m0.6609\u001b[0m  0.0654\n",
            "     71        \u001b[36m0.6609\u001b[0m  0.0639\n",
            "     72        \u001b[36m0.6609\u001b[0m  0.0683\n",
            "     73        \u001b[36m0.6609\u001b[0m  0.0667\n",
            "     74        \u001b[36m0.6609\u001b[0m  0.0631\n",
            "     75        \u001b[36m0.6609\u001b[0m  0.0629\n",
            "     76        \u001b[36m0.6609\u001b[0m  0.0643\n",
            "     77        \u001b[36m0.6609\u001b[0m  0.0719\n",
            "     78        \u001b[36m0.6609\u001b[0m  0.0710\n",
            "     79        \u001b[36m0.6609\u001b[0m  0.0661\n",
            "     80        \u001b[36m0.6609\u001b[0m  0.0704\n",
            "     81        \u001b[36m0.6609\u001b[0m  0.0644\n",
            "     82        \u001b[36m0.6609\u001b[0m  0.0648\n",
            "     83        \u001b[36m0.6609\u001b[0m  0.0637\n",
            "     84        \u001b[36m0.6609\u001b[0m  0.0721\n",
            "     85        \u001b[36m0.6609\u001b[0m  0.0645\n",
            "     86        \u001b[36m0.6609\u001b[0m  0.0649\n",
            "     87        \u001b[36m0.6609\u001b[0m  0.0659\n",
            "     88        \u001b[36m0.6609\u001b[0m  0.0618\n",
            "     89        \u001b[36m0.6609\u001b[0m  0.0650\n",
            "     90        \u001b[36m0.6609\u001b[0m  0.0633\n",
            "     91        \u001b[36m0.6609\u001b[0m  0.0643\n",
            "     92        \u001b[36m0.6609\u001b[0m  0.0717\n",
            "     93        \u001b[36m0.6609\u001b[0m  0.0633\n",
            "     94        \u001b[36m0.6609\u001b[0m  0.0669\n",
            "     95        \u001b[36m0.6609\u001b[0m  0.0772\n",
            "     96        \u001b[36m0.6609\u001b[0m  0.0734\n",
            "     97        \u001b[36m0.6609\u001b[0m  0.0650\n",
            "     98        \u001b[36m0.6609\u001b[0m  0.0713\n",
            "     99        \u001b[36m0.6609\u001b[0m  0.0656\n",
            "    100        \u001b[36m0.6609\u001b[0m  0.0682\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.5090\u001b[0m  0.0576\n",
            "      2        \u001b[36m1.4503\u001b[0m  0.0669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.3928\u001b[0m  0.0632\n",
            "      4        \u001b[36m1.3366\u001b[0m  0.0752\n",
            "      5        \u001b[36m1.2819\u001b[0m  0.0632\n",
            "      6        \u001b[36m1.2288\u001b[0m  0.0722\n",
            "      7        \u001b[36m1.1776\u001b[0m  0.0610\n",
            "      8        \u001b[36m1.1286\u001b[0m  0.0700\n",
            "      9        \u001b[36m1.0818\u001b[0m  0.0673\n",
            "     10        \u001b[36m1.0374\u001b[0m  0.0632\n",
            "     11        \u001b[36m0.9957\u001b[0m  0.0641\n",
            "     12        \u001b[36m0.9568\u001b[0m  0.0647\n",
            "     13        \u001b[36m0.9208\u001b[0m  0.0767\n",
            "     14        \u001b[36m0.8878\u001b[0m  0.0679\n",
            "     15        \u001b[36m0.8577\u001b[0m  0.0614\n",
            "     16        \u001b[36m0.8306\u001b[0m  0.0637\n",
            "     17        \u001b[36m0.8064\u001b[0m  0.0640\n",
            "     18        \u001b[36m0.7849\u001b[0m  0.0640\n",
            "     19        \u001b[36m0.7661\u001b[0m  0.0672\n",
            "     20        \u001b[36m0.7497\u001b[0m  0.0637\n",
            "     21        \u001b[36m0.7355\u001b[0m  0.0758\n",
            "     22        \u001b[36m0.7233\u001b[0m  0.0767\n",
            "     23        \u001b[36m0.7129\u001b[0m  0.0628\n",
            "     24        \u001b[36m0.7040\u001b[0m  0.0703\n",
            "     25        \u001b[36m0.6966\u001b[0m  0.0646\n",
            "     26        \u001b[36m0.6904\u001b[0m  0.0652\n",
            "     27        \u001b[36m0.6852\u001b[0m  0.0734\n",
            "     28        \u001b[36m0.6809\u001b[0m  0.0648\n",
            "     29        \u001b[36m0.6773\u001b[0m  0.0679\n",
            "     30        \u001b[36m0.6743\u001b[0m  0.0646\n",
            "     31        \u001b[36m0.6719\u001b[0m  0.0666\n",
            "     32        \u001b[36m0.6699\u001b[0m  0.0665\n",
            "     33        \u001b[36m0.6682\u001b[0m  0.0638\n",
            "     34        \u001b[36m0.6669\u001b[0m  0.0698\n",
            "     35        \u001b[36m0.6658\u001b[0m  0.0654\n",
            "     36        \u001b[36m0.6649\u001b[0m  0.0722\n",
            "     37        \u001b[36m0.6642\u001b[0m  0.0693\n",
            "     38        \u001b[36m0.6636\u001b[0m  0.0638\n",
            "     39        \u001b[36m0.6631\u001b[0m  0.0647\n",
            "     40        \u001b[36m0.6627\u001b[0m  0.0678\n",
            "     41        \u001b[36m0.6624\u001b[0m  0.0669\n",
            "     42        \u001b[36m0.6621\u001b[0m  0.0668\n",
            "     43        \u001b[36m0.6619\u001b[0m  0.0653\n",
            "     44        \u001b[36m0.6617\u001b[0m  0.0645\n",
            "     45        \u001b[36m0.6616\u001b[0m  0.0674\n",
            "     46        \u001b[36m0.6614\u001b[0m  0.0634\n",
            "     47        \u001b[36m0.6613\u001b[0m  0.0643\n",
            "     48        \u001b[36m0.6613\u001b[0m  0.0727\n",
            "     49        \u001b[36m0.6612\u001b[0m  0.0636\n",
            "     50        \u001b[36m0.6612\u001b[0m  0.0683\n",
            "     51        \u001b[36m0.6611\u001b[0m  0.0678\n",
            "     52        \u001b[36m0.6611\u001b[0m  0.0707\n",
            "     53        \u001b[36m0.6610\u001b[0m  0.0663\n",
            "     54        \u001b[36m0.6610\u001b[0m  0.0652\n",
            "     55        \u001b[36m0.6610\u001b[0m  0.0642\n",
            "     56        \u001b[36m0.6610\u001b[0m  0.0689\n",
            "     57        \u001b[36m0.6610\u001b[0m  0.0712\n",
            "     58        \u001b[36m0.6610\u001b[0m  0.0647\n",
            "     59        \u001b[36m0.6609\u001b[0m  0.0680\n",
            "     60        \u001b[36m0.6609\u001b[0m  0.0632\n",
            "     61        \u001b[36m0.6609\u001b[0m  0.0639\n",
            "     62        \u001b[36m0.6609\u001b[0m  0.0646\n",
            "     63        \u001b[36m0.6609\u001b[0m  0.0648\n",
            "     64        \u001b[36m0.6609\u001b[0m  0.0623\n",
            "     65        \u001b[36m0.6609\u001b[0m  0.0733\n",
            "     66        \u001b[36m0.6609\u001b[0m  0.0659\n",
            "     67        \u001b[36m0.6609\u001b[0m  0.0704\n",
            "     68        \u001b[36m0.6609\u001b[0m  0.0704\n",
            "     69        \u001b[36m0.6609\u001b[0m  0.0649\n",
            "     70        \u001b[36m0.6609\u001b[0m  0.0674\n",
            "     71        \u001b[36m0.6609\u001b[0m  0.0637\n",
            "     72        \u001b[36m0.6609\u001b[0m  0.0692\n",
            "     73        \u001b[36m0.6609\u001b[0m  0.0644\n",
            "     74        \u001b[36m0.6609\u001b[0m  0.0649\n",
            "     75        \u001b[36m0.6609\u001b[0m  0.0724\n",
            "     76        \u001b[36m0.6609\u001b[0m  0.0650\n",
            "     77        \u001b[36m0.6609\u001b[0m  0.0699\n",
            "     78        \u001b[36m0.6609\u001b[0m  0.0702\n",
            "     79        \u001b[36m0.6609\u001b[0m  0.0662\n",
            "     80        \u001b[36m0.6609\u001b[0m  0.0733\n",
            "     81        \u001b[36m0.6609\u001b[0m  0.0675\n",
            "     82        \u001b[36m0.6609\u001b[0m  0.0636\n",
            "     83        \u001b[36m0.6609\u001b[0m  0.0721\n",
            "     84        \u001b[36m0.6609\u001b[0m  0.0616\n",
            "     85        \u001b[36m0.6609\u001b[0m  0.0661\n",
            "     86        \u001b[36m0.6609\u001b[0m  0.0636\n",
            "     87        \u001b[36m0.6609\u001b[0m  0.0625\n",
            "     88        \u001b[36m0.6609\u001b[0m  0.0659\n",
            "     89        \u001b[36m0.6609\u001b[0m  0.0645\n",
            "     90        \u001b[36m0.6609\u001b[0m  0.0816\n",
            "     91        \u001b[36m0.6609\u001b[0m  0.0702\n",
            "     92        \u001b[36m0.6609\u001b[0m  0.0652\n",
            "     93        \u001b[36m0.6609\u001b[0m  0.0725\n",
            "     94        \u001b[36m0.6609\u001b[0m  0.0654\n",
            "     95        \u001b[36m0.6609\u001b[0m  0.0781\n",
            "     96        \u001b[36m0.6609\u001b[0m  0.0682\n",
            "     97        \u001b[36m0.6609\u001b[0m  0.0672\n",
            "     98        \u001b[36m0.6609\u001b[0m  0.0635\n",
            "     99        \u001b[36m0.6609\u001b[0m  0.0685\n",
            "    100        \u001b[36m0.6609\u001b[0m  0.0674\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4297\u001b[0m  0.0595\n",
            "      2        \u001b[36m1.3727\u001b[0m  0.0665\n",
            "      3        \u001b[36m1.3171\u001b[0m  0.0634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m1.2630\u001b[0m  0.0770\n",
            "      5        \u001b[36m1.2106\u001b[0m  0.0640\n",
            "      6        \u001b[36m1.1602\u001b[0m  0.0673\n",
            "      7        \u001b[36m1.1119\u001b[0m  0.0623\n",
            "      8        \u001b[36m1.0660\u001b[0m  0.0721\n",
            "      9        \u001b[36m1.0226\u001b[0m  0.0754\n",
            "     10        \u001b[36m0.9819\u001b[0m  0.0732\n",
            "     11        \u001b[36m0.9441\u001b[0m  0.0631\n",
            "     12        \u001b[36m0.9091\u001b[0m  0.0644\n",
            "     13        \u001b[36m0.8771\u001b[0m  0.0675\n",
            "     14        \u001b[36m0.8481\u001b[0m  0.0689\n",
            "     15        \u001b[36m0.8220\u001b[0m  0.0642\n",
            "     16        \u001b[36m0.7988\u001b[0m  0.0651\n",
            "     17        \u001b[36m0.7782\u001b[0m  0.0684\n",
            "     18        \u001b[36m0.7602\u001b[0m  0.0647\n",
            "     19        \u001b[36m0.7446\u001b[0m  0.0701\n",
            "     20        \u001b[36m0.7311\u001b[0m  0.0624\n",
            "     21        \u001b[36m0.7195\u001b[0m  0.0716\n",
            "     22        \u001b[36m0.7097\u001b[0m  0.0702\n",
            "     23        \u001b[36m0.7014\u001b[0m  0.0643\n",
            "     24        \u001b[36m0.6944\u001b[0m  0.0718\n",
            "     25        \u001b[36m0.6885\u001b[0m  0.0657\n",
            "     26        \u001b[36m0.6836\u001b[0m  0.0661\n",
            "     27        \u001b[36m0.6795\u001b[0m  0.0716\n",
            "     28        \u001b[36m0.6762\u001b[0m  0.0672\n",
            "     29        \u001b[36m0.6734\u001b[0m  0.0672\n",
            "     30        \u001b[36m0.6711\u001b[0m  0.0643\n",
            "     31        \u001b[36m0.6692\u001b[0m  0.0633\n",
            "     32        \u001b[36m0.6677\u001b[0m  0.0630\n",
            "     33        \u001b[36m0.6664\u001b[0m  0.0668\n",
            "     34        \u001b[36m0.6654\u001b[0m  0.0691\n",
            "     35        \u001b[36m0.6645\u001b[0m  0.0663\n",
            "     36        \u001b[36m0.6639\u001b[0m  0.0642\n",
            "     37        \u001b[36m0.6633\u001b[0m  0.0638\n",
            "     38        \u001b[36m0.6628\u001b[0m  0.0643\n",
            "     39        \u001b[36m0.6625\u001b[0m  0.0747\n",
            "     40        \u001b[36m0.6622\u001b[0m  0.0686\n",
            "     41        \u001b[36m0.6619\u001b[0m  0.0640\n",
            "     42        \u001b[36m0.6617\u001b[0m  0.0713\n",
            "     43        \u001b[36m0.6615\u001b[0m  0.0696\n",
            "     44        \u001b[36m0.6614\u001b[0m  0.0646\n",
            "     45        \u001b[36m0.6613\u001b[0m  0.0650\n",
            "     46        \u001b[36m0.6612\u001b[0m  0.0683\n",
            "     47        \u001b[36m0.6611\u001b[0m  0.0641\n",
            "     48        \u001b[36m0.6611\u001b[0m  0.0699\n",
            "     49        \u001b[36m0.6610\u001b[0m  0.0651\n",
            "     50        \u001b[36m0.6610\u001b[0m  0.0678\n",
            "     51        \u001b[36m0.6610\u001b[0m  0.0679\n",
            "     52        \u001b[36m0.6609\u001b[0m  0.0658\n",
            "     53        \u001b[36m0.6609\u001b[0m  0.0687\n",
            "     54        \u001b[36m0.6609\u001b[0m  0.0785\n",
            "     55        \u001b[36m0.6609\u001b[0m  0.0639\n",
            "     56        \u001b[36m0.6609\u001b[0m  0.0692\n",
            "     57        \u001b[36m0.6608\u001b[0m  0.0682\n",
            "     58        \u001b[36m0.6608\u001b[0m  0.0728\n",
            "     59        \u001b[36m0.6608\u001b[0m  0.0648\n",
            "     60        \u001b[36m0.6608\u001b[0m  0.0670\n",
            "     61        \u001b[36m0.6608\u001b[0m  0.0664\n",
            "     62        \u001b[36m0.6608\u001b[0m  0.0654\n",
            "     63        \u001b[36m0.6608\u001b[0m  0.0631\n",
            "     64        \u001b[36m0.6608\u001b[0m  0.0704\n",
            "     65        \u001b[36m0.6608\u001b[0m  0.0662\n",
            "     66        \u001b[36m0.6608\u001b[0m  0.0640\n",
            "     67        \u001b[36m0.6608\u001b[0m  0.0680\n",
            "     68        \u001b[36m0.6608\u001b[0m  0.0734\n",
            "     69        \u001b[36m0.6608\u001b[0m  0.0657\n",
            "     70        \u001b[36m0.6608\u001b[0m  0.0707\n",
            "     71        \u001b[36m0.6608\u001b[0m  0.0655\n",
            "     72        \u001b[36m0.6608\u001b[0m  0.0635\n",
            "     73        \u001b[36m0.6608\u001b[0m  0.0645\n",
            "     74        \u001b[36m0.6608\u001b[0m  0.0640\n",
            "     75        \u001b[36m0.6608\u001b[0m  0.0714\n",
            "     76        \u001b[36m0.6608\u001b[0m  0.0641\n",
            "     77        \u001b[36m0.6608\u001b[0m  0.0640\n",
            "     78        \u001b[36m0.6608\u001b[0m  0.0676\n",
            "     79        \u001b[36m0.6608\u001b[0m  0.0628\n",
            "     80        \u001b[36m0.6608\u001b[0m  0.0675\n",
            "     81        \u001b[36m0.6608\u001b[0m  0.0644\n",
            "     82        \u001b[36m0.6608\u001b[0m  0.0758\n",
            "     83        \u001b[36m0.6608\u001b[0m  0.0751\n",
            "     84        \u001b[36m0.6608\u001b[0m  0.0623\n",
            "     85        \u001b[36m0.6608\u001b[0m  0.0667\n",
            "     86        \u001b[36m0.6608\u001b[0m  0.0651\n",
            "     87        \u001b[36m0.6608\u001b[0m  0.0642\n",
            "     88        \u001b[36m0.6608\u001b[0m  0.0642\n",
            "     89        \u001b[36m0.6608\u001b[0m  0.0623\n",
            "     90        \u001b[36m0.6608\u001b[0m  0.0656\n",
            "     91        \u001b[36m0.6608\u001b[0m  0.0679\n",
            "     92        \u001b[36m0.6608\u001b[0m  0.0630\n",
            "     93        \u001b[36m0.6608\u001b[0m  0.0642\n",
            "     94        \u001b[36m0.6608\u001b[0m  0.0679\n",
            "     95        \u001b[36m0.6608\u001b[0m  0.0706\n",
            "     96        \u001b[36m0.6608\u001b[0m  0.0678\n",
            "     97        \u001b[36m0.6608\u001b[0m  0.0675\n",
            "     98        \u001b[36m0.6608\u001b[0m  0.0702\n",
            "     99        \u001b[36m0.6608\u001b[0m  0.0715\n",
            "    100        \u001b[36m0.6608\u001b[0m  0.0674\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7793\u001b[0m  0.0598\n",
            "      2        \u001b[36m0.7613\u001b[0m  0.0639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.7456\u001b[0m  0.0633\n",
            "      4        \u001b[36m0.7320\u001b[0m  0.0715\n",
            "      5        \u001b[36m0.7204\u001b[0m  0.0650\n",
            "      6        \u001b[36m0.7105\u001b[0m  0.0684\n",
            "      7        \u001b[36m0.7021\u001b[0m  0.0692\n",
            "      8        \u001b[36m0.6950\u001b[0m  0.0701\n",
            "      9        \u001b[36m0.6891\u001b[0m  0.0675\n",
            "     10        \u001b[36m0.6841\u001b[0m  0.0642\n",
            "     11        \u001b[36m0.6800\u001b[0m  0.0657\n",
            "     12        \u001b[36m0.6766\u001b[0m  0.0781\n",
            "     13        \u001b[36m0.6737\u001b[0m  0.0679\n",
            "     14        \u001b[36m0.6714\u001b[0m  0.0676\n",
            "     15        \u001b[36m0.6695\u001b[0m  0.0640\n",
            "     16        \u001b[36m0.6679\u001b[0m  0.0639\n",
            "     17        \u001b[36m0.6666\u001b[0m  0.0651\n",
            "     18        \u001b[36m0.6656\u001b[0m  0.0613\n",
            "     19        \u001b[36m0.6647\u001b[0m  0.0633\n",
            "     20        \u001b[36m0.6640\u001b[0m  0.0623\n",
            "     21        \u001b[36m0.6634\u001b[0m  0.0735\n",
            "     22        \u001b[36m0.6629\u001b[0m  0.0634\n",
            "     23        \u001b[36m0.6626\u001b[0m  0.0632\n",
            "     24        \u001b[36m0.6622\u001b[0m  0.0646\n",
            "     25        \u001b[36m0.6620\u001b[0m  0.0635\n",
            "     26        \u001b[36m0.6618\u001b[0m  0.0758\n",
            "     27        \u001b[36m0.6616\u001b[0m  0.0722\n",
            "     28        \u001b[36m0.6615\u001b[0m  0.0668\n",
            "     29        \u001b[36m0.6613\u001b[0m  0.0673\n",
            "     30        \u001b[36m0.6613\u001b[0m  0.0636\n",
            "     31        \u001b[36m0.6612\u001b[0m  0.0646\n",
            "     32        \u001b[36m0.6611\u001b[0m  0.0664\n",
            "     33        \u001b[36m0.6611\u001b[0m  0.0653\n",
            "     34        \u001b[36m0.6610\u001b[0m  0.0659\n",
            "     35        \u001b[36m0.6610\u001b[0m  0.0618\n",
            "     36        \u001b[36m0.6610\u001b[0m  0.0619\n",
            "     37        \u001b[36m0.6609\u001b[0m  0.0644\n",
            "     38        \u001b[36m0.6609\u001b[0m  0.0637\n",
            "     39        \u001b[36m0.6609\u001b[0m  0.0771\n",
            "     40        \u001b[36m0.6609\u001b[0m  0.0679\n",
            "     41        \u001b[36m0.6609\u001b[0m  0.0691\n",
            "     42        \u001b[36m0.6609\u001b[0m  0.0869\n",
            "     43        \u001b[36m0.6609\u001b[0m  0.0645\n",
            "     44        \u001b[36m0.6609\u001b[0m  0.0695\n",
            "     45        \u001b[36m0.6608\u001b[0m  0.0652\n",
            "     46        \u001b[36m0.6608\u001b[0m  0.0636\n",
            "     47        \u001b[36m0.6608\u001b[0m  0.0685\n",
            "     48        \u001b[36m0.6608\u001b[0m  0.0650\n",
            "     49        \u001b[36m0.6608\u001b[0m  0.0685\n",
            "     50        \u001b[36m0.6608\u001b[0m  0.0652\n",
            "     51        \u001b[36m0.6608\u001b[0m  0.0647\n",
            "     52        \u001b[36m0.6608\u001b[0m  0.0679\n",
            "     53        \u001b[36m0.6608\u001b[0m  0.0670\n",
            "     54        \u001b[36m0.6608\u001b[0m  0.0680\n",
            "     55        \u001b[36m0.6608\u001b[0m  0.0678\n",
            "     56        \u001b[36m0.6608\u001b[0m  0.0686\n",
            "     57        \u001b[36m0.6608\u001b[0m  0.0668\n",
            "     58        \u001b[36m0.6608\u001b[0m  0.0665\n",
            "     59        \u001b[36m0.6608\u001b[0m  0.0622\n",
            "     60        \u001b[36m0.6608\u001b[0m  0.0639\n",
            "     61        \u001b[36m0.6608\u001b[0m  0.0670\n",
            "     62        \u001b[36m0.6608\u001b[0m  0.0738\n",
            "     63        \u001b[36m0.6608\u001b[0m  0.0651\n",
            "     64        \u001b[36m0.6608\u001b[0m  0.0645\n",
            "     65        \u001b[36m0.6608\u001b[0m  0.0727\n",
            "     66        \u001b[36m0.6608\u001b[0m  0.0653\n",
            "     67        \u001b[36m0.6608\u001b[0m  0.0685\n",
            "     68        \u001b[36m0.6608\u001b[0m  0.0653\n",
            "     69        \u001b[36m0.6608\u001b[0m  0.0688\n",
            "     70        \u001b[36m0.6608\u001b[0m  0.0666\n",
            "     71        \u001b[36m0.6608\u001b[0m  0.0794\n",
            "     72        \u001b[36m0.6608\u001b[0m  0.0655\n",
            "     73        \u001b[36m0.6608\u001b[0m  0.0639\n",
            "     74        \u001b[36m0.6608\u001b[0m  0.0669\n",
            "     75        \u001b[36m0.6608\u001b[0m  0.0658\n",
            "     76        \u001b[36m0.6608\u001b[0m  0.0696\n",
            "     77        \u001b[36m0.6608\u001b[0m  0.0647\n",
            "     78        \u001b[36m0.6608\u001b[0m  0.0682\n",
            "     79        \u001b[36m0.6608\u001b[0m  0.0647\n",
            "     80        \u001b[36m0.6608\u001b[0m  0.0645\n",
            "     81        \u001b[36m0.6608\u001b[0m  0.0649\n",
            "     82        \u001b[36m0.6608\u001b[0m  0.0779\n",
            "     83        \u001b[36m0.6608\u001b[0m  0.0657\n",
            "     84        \u001b[36m0.6608\u001b[0m  0.0636\n",
            "     85        \u001b[36m0.6608\u001b[0m  0.0697\n",
            "     86        \u001b[36m0.6608\u001b[0m  0.0735\n",
            "     87        \u001b[36m0.6608\u001b[0m  0.0617\n",
            "     88        \u001b[36m0.6608\u001b[0m  0.0617\n",
            "     89        \u001b[36m0.6608\u001b[0m  0.0719\n",
            "     90        \u001b[36m0.6608\u001b[0m  0.0645\n",
            "     91        \u001b[36m0.6608\u001b[0m  0.0630\n",
            "     92        \u001b[36m0.6608\u001b[0m  0.0639\n",
            "     93        \u001b[36m0.6608\u001b[0m  0.0655\n",
            "     94        0.6608  0.0623\n",
            "     95        \u001b[36m0.6608\u001b[0m  0.0723\n",
            "     96        \u001b[36m0.6608\u001b[0m  0.0700\n",
            "     97        \u001b[36m0.6608\u001b[0m  0.0644\n",
            "     98        0.6608  0.0643\n",
            "     99        \u001b[36m0.6608\u001b[0m  0.0678\n",
            "    100        0.6608  0.0678\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4843\u001b[0m  0.0654\n",
            "      2        \u001b[36m1.4262\u001b[0m  0.0670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.3692\u001b[0m  0.0637\n",
            "      4        \u001b[36m1.3136\u001b[0m  0.0793\n",
            "      5        \u001b[36m1.2596\u001b[0m  0.0641\n",
            "      6        \u001b[36m1.2074\u001b[0m  0.0677\n",
            "      7        \u001b[36m1.1571\u001b[0m  0.0617\n",
            "      8        \u001b[36m1.1089\u001b[0m  0.0675\n",
            "      9        \u001b[36m1.0632\u001b[0m  0.1266\n",
            "     10        \u001b[36m1.0199\u001b[0m  0.0663\n",
            "     11        \u001b[36m0.9794\u001b[0m  0.0684\n",
            "     12        \u001b[36m0.9417\u001b[0m  0.0651\n",
            "     13        \u001b[36m0.9069\u001b[0m  0.0735\n",
            "     14        \u001b[36m0.8751\u001b[0m  0.0652\n",
            "     15        \u001b[36m0.8463\u001b[0m  0.0679\n",
            "     16        \u001b[36m0.8204\u001b[0m  0.0666\n",
            "     17        \u001b[36m0.7973\u001b[0m  0.0625\n",
            "     18        \u001b[36m0.7770\u001b[0m  0.0671\n",
            "     19        \u001b[36m0.7591\u001b[0m  0.0669\n",
            "     20        \u001b[36m0.7436\u001b[0m  0.0655\n",
            "     21        \u001b[36m0.7303\u001b[0m  0.0705\n",
            "     22        \u001b[36m0.7188\u001b[0m  0.0650\n",
            "     23        \u001b[36m0.7091\u001b[0m  0.0656\n",
            "     24        \u001b[36m0.7009\u001b[0m  0.0712\n",
            "     25        \u001b[36m0.6939\u001b[0m  0.0726\n",
            "     26        \u001b[36m0.6881\u001b[0m  0.0641\n",
            "     27        \u001b[36m0.6833\u001b[0m  0.0648\n",
            "     28        \u001b[36m0.6793\u001b[0m  0.0690\n",
            "     29        \u001b[36m0.6760\u001b[0m  0.0727\n",
            "     30        \u001b[36m0.6732\u001b[0m  0.0683\n",
            "     31        \u001b[36m0.6710\u001b[0m  0.0677\n",
            "     32        \u001b[36m0.6691\u001b[0m  0.0686\n",
            "     33        \u001b[36m0.6676\u001b[0m  0.0640\n",
            "     34        \u001b[36m0.6664\u001b[0m  0.0667\n",
            "     35        \u001b[36m0.6653\u001b[0m  0.0632\n",
            "     36        \u001b[36m0.6645\u001b[0m  0.0650\n",
            "     37        \u001b[36m0.6638\u001b[0m  0.0632\n",
            "     38        \u001b[36m0.6633\u001b[0m  0.0698\n",
            "     39        \u001b[36m0.6628\u001b[0m  0.0713\n",
            "     40        \u001b[36m0.6625\u001b[0m  0.0648\n",
            "     41        \u001b[36m0.6622\u001b[0m  0.0656\n",
            "     42        \u001b[36m0.6619\u001b[0m  0.0716\n",
            "     43        \u001b[36m0.6617\u001b[0m  0.0652\n",
            "     44        \u001b[36m0.6616\u001b[0m  0.0755\n",
            "     45        \u001b[36m0.6614\u001b[0m  0.0669\n",
            "     46        \u001b[36m0.6613\u001b[0m  0.0686\n",
            "     47        \u001b[36m0.6612\u001b[0m  0.0670\n",
            "     48        \u001b[36m0.6612\u001b[0m  0.0644\n",
            "     49        \u001b[36m0.6611\u001b[0m  0.0636\n",
            "     50        \u001b[36m0.6610\u001b[0m  0.0721\n",
            "     51        \u001b[36m0.6610\u001b[0m  0.0637\n",
            "     52        \u001b[36m0.6610\u001b[0m  0.0673\n",
            "     53        \u001b[36m0.6609\u001b[0m  0.0673\n",
            "     54        \u001b[36m0.6609\u001b[0m  0.0657\n",
            "     55        \u001b[36m0.6609\u001b[0m  0.0640\n",
            "     56        \u001b[36m0.6609\u001b[0m  0.0664\n",
            "     57        \u001b[36m0.6609\u001b[0m  0.0683\n",
            "     58        \u001b[36m0.6609\u001b[0m  0.0639\n",
            "     59        \u001b[36m0.6609\u001b[0m  0.0777\n",
            "     60        \u001b[36m0.6609\u001b[0m  0.0696\n",
            "     61        \u001b[36m0.6608\u001b[0m  0.0655\n",
            "     62        \u001b[36m0.6608\u001b[0m  0.0672\n",
            "     63        \u001b[36m0.6608\u001b[0m  0.0641\n",
            "     64        \u001b[36m0.6608\u001b[0m  0.0644\n",
            "     65        \u001b[36m0.6608\u001b[0m  0.0636\n",
            "     66        \u001b[36m0.6608\u001b[0m  0.0700\n",
            "     67        \u001b[36m0.6608\u001b[0m  0.0626\n",
            "     68        \u001b[36m0.6608\u001b[0m  0.0677\n",
            "     69        \u001b[36m0.6608\u001b[0m  0.0669\n",
            "     70        \u001b[36m0.6608\u001b[0m  0.0659\n",
            "     71        \u001b[36m0.6608\u001b[0m  0.0668\n",
            "     72        \u001b[36m0.6608\u001b[0m  0.0644\n",
            "     73        \u001b[36m0.6608\u001b[0m  0.0660\n",
            "     74        \u001b[36m0.6608\u001b[0m  0.0762\n",
            "     75        \u001b[36m0.6608\u001b[0m  0.0635\n",
            "     76        \u001b[36m0.6608\u001b[0m  0.0684\n",
            "     77        \u001b[36m0.6608\u001b[0m  0.0670\n",
            "     78        \u001b[36m0.6608\u001b[0m  0.0678\n",
            "     79        \u001b[36m0.6608\u001b[0m  0.0635\n",
            "     80        \u001b[36m0.6608\u001b[0m  0.0626\n",
            "     81        \u001b[36m0.6608\u001b[0m  0.0733\n",
            "     82        \u001b[36m0.6608\u001b[0m  0.0667\n",
            "     83        \u001b[36m0.6608\u001b[0m  0.0661\n",
            "     84        \u001b[36m0.6608\u001b[0m  0.0669\n",
            "     85        \u001b[36m0.6608\u001b[0m  0.0672\n",
            "     86        \u001b[36m0.6608\u001b[0m  0.0644\n",
            "     87        \u001b[36m0.6608\u001b[0m  0.0615\n",
            "     88        \u001b[36m0.6608\u001b[0m  0.0661\n",
            "     89        \u001b[36m0.6608\u001b[0m  0.0702\n",
            "     90        \u001b[36m0.6608\u001b[0m  0.0618\n",
            "     91        \u001b[36m0.6608\u001b[0m  0.0629\n",
            "     92        \u001b[36m0.6608\u001b[0m  0.0664\n",
            "     93        \u001b[36m0.6608\u001b[0m  0.0616\n",
            "     94        \u001b[36m0.6608\u001b[0m  0.0689\n",
            "     95        \u001b[36m0.6608\u001b[0m  0.0806\n",
            "     96        \u001b[36m0.6608\u001b[0m  0.0670\n",
            "     97        \u001b[36m0.6608\u001b[0m  0.0707\n",
            "     98        \u001b[36m0.6608\u001b[0m  0.0641\n",
            "     99        \u001b[36m0.6608\u001b[0m  0.0632\n",
            "    100        \u001b[36m0.6608\u001b[0m  0.0656\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.1320\u001b[0m  0.0610\n",
            "      2        \u001b[36m1.0853\u001b[0m  0.0645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.0410\u001b[0m  0.0681\n",
            "      4        \u001b[36m0.9994\u001b[0m  0.0765\n",
            "      5        \u001b[36m0.9604\u001b[0m  0.0653\n",
            "      6        \u001b[36m0.9244\u001b[0m  0.0645\n",
            "      7        \u001b[36m0.8912\u001b[0m  0.0702\n",
            "      8        \u001b[36m0.8610\u001b[0m  0.0655\n",
            "      9        \u001b[36m0.8338\u001b[0m  0.0644\n",
            "     10        \u001b[36m0.8093\u001b[0m  0.0640\n",
            "     11        \u001b[36m0.7877\u001b[0m  0.0666\n",
            "     12        \u001b[36m0.7686\u001b[0m  0.0754\n",
            "     13        \u001b[36m0.7519\u001b[0m  0.0642\n",
            "     14        \u001b[36m0.7375\u001b[0m  0.0668\n",
            "     15        \u001b[36m0.7251\u001b[0m  0.0645\n",
            "     16        \u001b[36m0.7145\u001b[0m  0.0627\n",
            "     17        \u001b[36m0.7055\u001b[0m  0.0662\n",
            "     18        \u001b[36m0.6979\u001b[0m  0.0707\n",
            "     19        \u001b[36m0.6915\u001b[0m  0.0644\n",
            "     20        \u001b[36m0.6861\u001b[0m  0.0735\n",
            "     21        \u001b[36m0.6817\u001b[0m  0.0641\n",
            "     22        \u001b[36m0.6780\u001b[0m  0.0637\n",
            "     23        \u001b[36m0.6749\u001b[0m  0.0621\n",
            "     24        \u001b[36m0.6724\u001b[0m  0.0653\n",
            "     25        \u001b[36m0.6703\u001b[0m  0.0714\n",
            "     26        \u001b[36m0.6686\u001b[0m  0.0628\n",
            "     27        \u001b[36m0.6672\u001b[0m  0.0658\n",
            "     28        \u001b[36m0.6660\u001b[0m  0.0670\n",
            "     29        \u001b[36m0.6651\u001b[0m  0.0670\n",
            "     30        \u001b[36m0.6643\u001b[0m  0.0646\n",
            "     31        \u001b[36m0.6637\u001b[0m  0.0624\n",
            "     32        \u001b[36m0.6632\u001b[0m  0.0626\n",
            "     33        \u001b[36m0.6628\u001b[0m  0.0759\n",
            "     34        \u001b[36m0.6624\u001b[0m  0.0644\n",
            "     35        \u001b[36m0.6621\u001b[0m  0.0651\n",
            "     36        \u001b[36m0.6619\u001b[0m  0.0622\n",
            "     37        \u001b[36m0.6617\u001b[0m  0.0683\n",
            "     38        \u001b[36m0.6616\u001b[0m  0.0698\n",
            "     39        \u001b[36m0.6614\u001b[0m  0.0676\n",
            "     40        \u001b[36m0.6613\u001b[0m  0.0672\n",
            "     41        \u001b[36m0.6613\u001b[0m  0.0623\n",
            "     42        \u001b[36m0.6612\u001b[0m  0.0635\n",
            "     43        \u001b[36m0.6611\u001b[0m  0.0683\n",
            "     44        \u001b[36m0.6611\u001b[0m  0.0644\n",
            "     45        \u001b[36m0.6610\u001b[0m  0.0661\n",
            "     46        \u001b[36m0.6610\u001b[0m  0.0675\n",
            "     47        \u001b[36m0.6610\u001b[0m  0.0638\n",
            "     48        \u001b[36m0.6610\u001b[0m  0.0709\n",
            "     49        \u001b[36m0.6609\u001b[0m  0.0641\n",
            "     50        \u001b[36m0.6609\u001b[0m  0.0661\n",
            "     51        \u001b[36m0.6609\u001b[0m  0.0699\n",
            "     52        \u001b[36m0.6609\u001b[0m  0.0658\n",
            "     53        \u001b[36m0.6609\u001b[0m  0.0640\n",
            "     54        \u001b[36m0.6609\u001b[0m  0.0668\n",
            "     55        \u001b[36m0.6609\u001b[0m  0.0671\n",
            "     56        \u001b[36m0.6609\u001b[0m  0.0657\n",
            "     57        \u001b[36m0.6609\u001b[0m  0.0639\n",
            "     58        \u001b[36m0.6609\u001b[0m  0.0696\n",
            "     59        \u001b[36m0.6609\u001b[0m  0.0651\n",
            "     60        \u001b[36m0.6609\u001b[0m  0.0693\n",
            "     61        \u001b[36m0.6609\u001b[0m  0.0690\n",
            "     62        \u001b[36m0.6609\u001b[0m  0.0653\n",
            "     63        \u001b[36m0.6609\u001b[0m  0.0737\n",
            "     64        \u001b[36m0.6609\u001b[0m  0.0673\n",
            "     65        \u001b[36m0.6609\u001b[0m  0.0655\n",
            "     66        \u001b[36m0.6608\u001b[0m  0.0673\n",
            "     67        \u001b[36m0.6608\u001b[0m  0.0664\n",
            "     68        \u001b[36m0.6608\u001b[0m  0.0690\n",
            "     69        \u001b[36m0.6608\u001b[0m  0.0738\n",
            "     70        \u001b[36m0.6608\u001b[0m  0.0632\n",
            "     71        \u001b[36m0.6608\u001b[0m  0.0657\n",
            "     72        \u001b[36m0.6608\u001b[0m  0.0702\n",
            "     73        \u001b[36m0.6608\u001b[0m  0.0641\n",
            "     74        \u001b[36m0.6608\u001b[0m  0.0674\n",
            "     75        \u001b[36m0.6608\u001b[0m  0.0653\n",
            "     76        \u001b[36m0.6608\u001b[0m  0.0671\n",
            "     77        \u001b[36m0.6608\u001b[0m  0.0670\n",
            "     78        \u001b[36m0.6608\u001b[0m  0.0654\n",
            "     79        \u001b[36m0.6608\u001b[0m  0.0649\n",
            "     80        \u001b[36m0.6608\u001b[0m  0.0650\n",
            "     81        \u001b[36m0.6608\u001b[0m  0.0671\n",
            "     82        \u001b[36m0.6608\u001b[0m  0.0754\n",
            "     83        \u001b[36m0.6608\u001b[0m  0.0639\n",
            "     84        \u001b[36m0.6608\u001b[0m  0.0670\n",
            "     85        \u001b[36m0.6608\u001b[0m  0.0631\n",
            "     86        \u001b[36m0.6608\u001b[0m  0.0600\n",
            "     87        \u001b[36m0.6608\u001b[0m  0.0683\n",
            "     88        \u001b[36m0.6608\u001b[0m  0.0629\n",
            "     89        \u001b[36m0.6608\u001b[0m  0.0688\n",
            "     90        \u001b[36m0.6608\u001b[0m  0.0603\n",
            "     91        \u001b[36m0.6608\u001b[0m  0.0636\n",
            "     92        \u001b[36m0.6608\u001b[0m  0.0737\n",
            "     93        \u001b[36m0.6608\u001b[0m  0.0657\n",
            "     94        \u001b[36m0.6608\u001b[0m  0.0682\n",
            "     95        \u001b[36m0.6608\u001b[0m  0.0737\n",
            "     96        \u001b[36m0.6608\u001b[0m  0.0710\n",
            "     97        \u001b[36m0.6608\u001b[0m  0.0639\n",
            "     98        \u001b[36m0.6608\u001b[0m  0.0631\n",
            "     99        \u001b[36m0.6608\u001b[0m  0.0633\n",
            "    100        \u001b[36m0.6608\u001b[0m  0.0655\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.1244\u001b[0m  0.0642\n",
            "      2        \u001b[36m1.0778\u001b[0m  0.0649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m1.0337\u001b[0m  0.0667\n",
            "      4        \u001b[36m0.9923\u001b[0m  0.0739\n",
            "      5        \u001b[36m0.9537\u001b[0m  0.0660\n",
            "      6        \u001b[36m0.9180\u001b[0m  0.0672\n",
            "      7        \u001b[36m0.8852\u001b[0m  0.0719\n",
            "      8        \u001b[36m0.8555\u001b[0m  0.0643\n",
            "      9        \u001b[36m0.8286\u001b[0m  0.0673\n",
            "     10        \u001b[36m0.8047\u001b[0m  0.0615\n",
            "     11        \u001b[36m0.7834\u001b[0m  0.0633\n",
            "     12        \u001b[36m0.7648\u001b[0m  0.0704\n",
            "     13        \u001b[36m0.7486\u001b[0m  0.0636\n",
            "     14        \u001b[36m0.7346\u001b[0m  0.0644\n",
            "     15        \u001b[36m0.7225\u001b[0m  0.0699\n",
            "     16        \u001b[36m0.7123\u001b[0m  0.0666\n",
            "     17        \u001b[36m0.7036\u001b[0m  0.0623\n",
            "     18        \u001b[36m0.6963\u001b[0m  0.0626\n",
            "     19        \u001b[36m0.6901\u001b[0m  0.0643\n",
            "     20        \u001b[36m0.6850\u001b[0m  0.0612\n",
            "     21        \u001b[36m0.6807\u001b[0m  0.0629\n",
            "     22        \u001b[36m0.6772\u001b[0m  0.0737\n",
            "     23        \u001b[36m0.6742\u001b[0m  0.0624\n",
            "     24        \u001b[36m0.6718\u001b[0m  0.0685\n",
            "     25        \u001b[36m0.6699\u001b[0m  0.0705\n",
            "     26        \u001b[36m0.6682\u001b[0m  0.0691\n",
            "     27        \u001b[36m0.6669\u001b[0m  0.0679\n",
            "     28        \u001b[36m0.6658\u001b[0m  0.0633\n",
            "     29        \u001b[36m0.6649\u001b[0m  0.0642\n",
            "     30        \u001b[36m0.6642\u001b[0m  0.0704\n",
            "     31        \u001b[36m0.6636\u001b[0m  0.0718\n",
            "     32        \u001b[36m0.6631\u001b[0m  0.0621\n",
            "     33        \u001b[36m0.6627\u001b[0m  0.0689\n",
            "     34        \u001b[36m0.6624\u001b[0m  0.0644\n",
            "     35        \u001b[36m0.6621\u001b[0m  0.0668\n",
            "     36        \u001b[36m0.6619\u001b[0m  0.0649\n",
            "     37        \u001b[36m0.6617\u001b[0m  0.0793\n",
            "     38        \u001b[36m0.6615\u001b[0m  0.0635\n",
            "     39        \u001b[36m0.6614\u001b[0m  0.0672\n",
            "     40        \u001b[36m0.6613\u001b[0m  0.0651\n",
            "     41        \u001b[36m0.6613\u001b[0m  0.0670\n",
            "     42        \u001b[36m0.6612\u001b[0m  0.0637\n",
            "     43        \u001b[36m0.6611\u001b[0m  0.0660\n",
            "     44        \u001b[36m0.6611\u001b[0m  0.0663\n",
            "     45        \u001b[36m0.6610\u001b[0m  0.0724\n",
            "     46        \u001b[36m0.6610\u001b[0m  0.0682\n",
            "     47        \u001b[36m0.6610\u001b[0m  0.0719\n",
            "     48        \u001b[36m0.6610\u001b[0m  0.0624\n",
            "     49        \u001b[36m0.6610\u001b[0m  0.0671\n",
            "     50        \u001b[36m0.6609\u001b[0m  0.0696\n",
            "     51        \u001b[36m0.6609\u001b[0m  0.0722\n",
            "     52        \u001b[36m0.6609\u001b[0m  0.0661\n",
            "     53        \u001b[36m0.6609\u001b[0m  0.0694\n",
            "     54        \u001b[36m0.6609\u001b[0m  0.0633\n",
            "     55        \u001b[36m0.6609\u001b[0m  0.0690\n",
            "     56        \u001b[36m0.6609\u001b[0m  0.0769\n",
            "     57        \u001b[36m0.6609\u001b[0m  0.0717\n",
            "     58        \u001b[36m0.6609\u001b[0m  0.0669\n",
            "     59        \u001b[36m0.6609\u001b[0m  0.0664\n",
            "     60        \u001b[36m0.6609\u001b[0m  0.0677\n",
            "     61        \u001b[36m0.6609\u001b[0m  0.0650\n",
            "     62        \u001b[36m0.6609\u001b[0m  0.0676\n",
            "     63        \u001b[36m0.6609\u001b[0m  0.0677\n",
            "     64        \u001b[36m0.6609\u001b[0m  0.0665\n",
            "     65        \u001b[36m0.6609\u001b[0m  0.0624\n",
            "     66        \u001b[36m0.6609\u001b[0m  0.0738\n",
            "     67        \u001b[36m0.6609\u001b[0m  0.0677\n",
            "     68        \u001b[36m0.6609\u001b[0m  0.0712\n",
            "     69        \u001b[36m0.6609\u001b[0m  0.0705\n",
            "     70        \u001b[36m0.6609\u001b[0m  0.0648\n",
            "     71        \u001b[36m0.6609\u001b[0m  0.0678\n",
            "     72        \u001b[36m0.6609\u001b[0m  0.0643\n",
            "     73        \u001b[36m0.6609\u001b[0m  0.0667\n",
            "     74        \u001b[36m0.6609\u001b[0m  0.0707\n",
            "     75        \u001b[36m0.6609\u001b[0m  0.0626\n",
            "     76        \u001b[36m0.6609\u001b[0m  0.0650\n",
            "     77        \u001b[36m0.6609\u001b[0m  0.0680\n",
            "     78        \u001b[36m0.6609\u001b[0m  0.0649\n",
            "     79        \u001b[36m0.6609\u001b[0m  0.0683\n",
            "     80        \u001b[36m0.6609\u001b[0m  0.0693\n",
            "     81        \u001b[36m0.6609\u001b[0m  0.0729\n",
            "     82        \u001b[36m0.6609\u001b[0m  0.0734\n",
            "     83        \u001b[36m0.6609\u001b[0m  0.0669\n",
            "     84        \u001b[36m0.6609\u001b[0m  0.0641\n",
            "     85        \u001b[36m0.6609\u001b[0m  0.0670\n",
            "     86        \u001b[36m0.6609\u001b[0m  0.0682\n",
            "     87        \u001b[36m0.6609\u001b[0m  0.0685\n",
            "     88        \u001b[36m0.6609\u001b[0m  0.0708\n",
            "     89        \u001b[36m0.6609\u001b[0m  0.0643\n",
            "     90        \u001b[36m0.6609\u001b[0m  0.0682\n",
            "     91        \u001b[36m0.6609\u001b[0m  0.0665\n",
            "     92        \u001b[36m0.6609\u001b[0m  0.0641\n",
            "     93        \u001b[36m0.6609\u001b[0m  0.0657\n",
            "     94        \u001b[36m0.6609\u001b[0m  0.0674\n",
            "     95        \u001b[36m0.6609\u001b[0m  0.0782\n",
            "     96        \u001b[36m0.6609\u001b[0m  0.0646\n",
            "     97        \u001b[36m0.6609\u001b[0m  0.0680\n",
            "     98        \u001b[36m0.6609\u001b[0m  0.0633\n",
            "     99        \u001b[36m0.6609\u001b[0m  0.0682\n",
            "    100        \u001b[36m0.6609\u001b[0m  0.0651\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0175\u001b[0m  0.0657\n",
            "      2        \u001b[36m0.9782\u001b[0m  0.0682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
            "    y_pred = method_caller(estimator, \"predict\", X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
            "    return getattr(estimator, method)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skorch/classifier.py\", line 357, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.9416\u001b[0m  0.0721\n",
            "      4        \u001b[36m0.9078\u001b[0m  0.0708\n",
            "      5        \u001b[36m0.8768\u001b[0m  0.0628\n",
            "      6        \u001b[36m0.8486\u001b[0m  0.0675\n",
            "      7        \u001b[36m0.8233\u001b[0m  0.0643\n",
            "      8        \u001b[36m0.8006\u001b[0m  0.0681\n",
            "      9        \u001b[36m0.7806\u001b[0m  0.0685\n",
            "     10        \u001b[36m0.7629\u001b[0m  0.0706\n",
            "     11        \u001b[36m0.7475\u001b[0m  0.0652\n",
            "     12        \u001b[36m0.7341\u001b[0m  0.0738\n",
            "     13        \u001b[36m0.7226\u001b[0m  0.0653\n",
            "     14        \u001b[36m0.7128\u001b[0m  0.0636\n",
            "     15        \u001b[36m0.7044\u001b[0m  0.0628\n",
            "     16        \u001b[36m0.6973\u001b[0m  0.0728\n",
            "     17        \u001b[36m0.6913\u001b[0m  0.0628\n",
            "     18        \u001b[36m0.6862\u001b[0m  0.0626\n",
            "     19        \u001b[36m0.6820\u001b[0m  0.0651\n",
            "     20        \u001b[36m0.6784\u001b[0m  0.0621\n",
            "     21        \u001b[36m0.6755\u001b[0m  0.0658\n",
            "     22        \u001b[36m0.6730\u001b[0m  0.0640\n",
            "     23        \u001b[36m0.6710\u001b[0m  0.0704\n",
            "     24        \u001b[36m0.6693\u001b[0m  0.0637\n",
            "     25        \u001b[36m0.6679\u001b[0m  0.0800\n",
            "     26        \u001b[36m0.6667\u001b[0m  0.0649\n",
            "     27        \u001b[36m0.6657\u001b[0m  0.0676\n",
            "     28        \u001b[36m0.6649\u001b[0m  0.0628\n",
            "     29        \u001b[36m0.6642\u001b[0m  0.0660\n",
            "     30        \u001b[36m0.6637\u001b[0m  0.0649\n",
            "     31        \u001b[36m0.6632\u001b[0m  0.0604\n",
            "     32        \u001b[36m0.6628\u001b[0m  0.0694\n",
            "     33        \u001b[36m0.6625\u001b[0m  0.0605\n",
            "     34        \u001b[36m0.6622\u001b[0m  0.0643\n",
            "     35        \u001b[36m0.6620\u001b[0m  0.0670\n",
            "     36        \u001b[36m0.6618\u001b[0m  0.0635\n",
            "     37        \u001b[36m0.6616\u001b[0m  0.0648\n",
            "     38        \u001b[36m0.6615\u001b[0m  0.0618\n",
            "     39        \u001b[36m0.6614\u001b[0m  0.0787\n",
            "     40        \u001b[36m0.6613\u001b[0m  0.0715\n",
            "     41        \u001b[36m0.6612\u001b[0m  0.0619\n",
            "     42        \u001b[36m0.6611\u001b[0m  0.0654\n",
            "     43        \u001b[36m0.6610\u001b[0m  0.0657\n",
            "     44        \u001b[36m0.6610\u001b[0m  0.0626\n",
            "     45        \u001b[36m0.6609\u001b[0m  0.0650\n",
            "     46        \u001b[36m0.6609\u001b[0m  0.0636\n",
            "     47        \u001b[36m0.6609\u001b[0m  0.0595\n",
            "     48        \u001b[36m0.6608\u001b[0m  0.0652\n",
            "     49        \u001b[36m0.6608\u001b[0m  0.0625\n",
            "     50        \u001b[36m0.6608\u001b[0m  0.0649\n",
            "     51        \u001b[36m0.6608\u001b[0m  0.0638\n",
            "     52        \u001b[36m0.6607\u001b[0m  0.0626\n",
            "     53        \u001b[36m0.6607\u001b[0m  0.0638\n",
            "     54        \u001b[36m0.6607\u001b[0m  0.0622\n",
            "     55        \u001b[36m0.6607\u001b[0m  0.0680\n",
            "     56        \u001b[36m0.6607\u001b[0m  0.0649\n",
            "     57        \u001b[36m0.6607\u001b[0m  0.0693\n",
            "     58        \u001b[36m0.6607\u001b[0m  0.0630\n",
            "     59        \u001b[36m0.6607\u001b[0m  0.0618\n",
            "     60        \u001b[36m0.6607\u001b[0m  0.0694\n",
            "     61        \u001b[36m0.6607\u001b[0m  0.0649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiyX1qXkVH_6"
      },
      "source": [
        "melhores_parametros = grid_search.best_params_\n",
        "melhor_precisao = grid_search.best_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoCqcsFOVPa_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "a4edd4ff-e124-4d95-f26b-968e1cf2d4e0"
      },
      "source": [
        "melhores_parametros"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 10,\n",
              " 'criterion': torch.nn.modules.loss.BCELoss,\n",
              " 'max_epochs': 100,\n",
              " 'module__activation': <function torch.nn.functional.relu>,\n",
              " 'module__initializer': <function torch.nn.init._make_deprecate.<locals>.deprecated_init>,\n",
              " 'module__neurons': 8,\n",
              " 'optimizer': torch.optim.adam.Adam}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKCjr94mVYrk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ab2975d7-23ac-4fa0-d0b2-bd4964548479"
      },
      "source": [
        "melhor_precisao"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7524153694094391"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6sNlTyEmMbpk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}